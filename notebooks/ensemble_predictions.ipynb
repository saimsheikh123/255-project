{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3f3fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71c7fad",
   "metadata": {},
   "source": [
    "## Load Data and Prepare Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719279cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed data\n",
    "df = pd.read_csv('../data/preprocessed_final.csv')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()[:10]}...\")  # Show first 10 columns\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9a0e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (same as used in individual models)\n",
    "metadata_cols = ['date', 'speaker', 'text', 'text_clean', 'text_clean_nostop']\n",
    "target_cols = [col for col in df.columns if col.startswith('target_') or col.startswith('class_')]\n",
    "feature_cols = [col for col in df.columns if col not in metadata_cols + target_cols]\n",
    "\n",
    "print(f\"Number of features: {len(feature_cols)}\")\n",
    "print(f\"Features: {feature_cols[:15]}...\")  # Show first 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81abcb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary targets\n",
    "y_1d = (df['target_SP500_1d'] > 0).astype(int)\n",
    "y_5d = (df['target_SP500_5d'] > 0).astype(int)\n",
    "\n",
    "print(\"1-Day Binary Target Distribution:\")\n",
    "print(y_1d.value_counts())\n",
    "print(f\"\\n5-Day Binary Target Distribution:\")\n",
    "print(y_5d.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23525129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features\n",
    "X = df[feature_cols].fillna(0)\n",
    "\n",
    "# Time-series split (80/20)\n",
    "split_index = int(len(X) * 0.8)\n",
    "X_train, X_test = X.iloc[:split_index], X.iloc[split_index:]\n",
    "y_1d_train, y_1d_test = y_1d.iloc[:split_index], y_1d.iloc[split_index:]\n",
    "y_5d_train, y_5d_test = y_5d.iloc[:split_index], y_5d.iloc[split_index:]\n",
    "\n",
    "print(f\"Train size: {len(X_train)}\")\n",
    "print(f\"Test size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca51a7e",
   "metadata": {},
   "source": [
    "## Load Pre-trained Models\n",
    "\n",
    "Based on previous results:\n",
    "- **Best 1-day model**: XGBoost (54.90% accuracy, 0.512 F1)\n",
    "- **Best 5-day model**: Logistic Regression (58.26% accuracy, 0.440 F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12dee5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved models\n",
    "try:\n",
    "    with open('../results/xgboost_model.pkl', 'rb') as f:\n",
    "        xgb_model = pickle.load(f)\n",
    "    print(\"✓ Loaded XGBoost model\")\n",
    "except:\n",
    "    print(\"✗ XGBoost model not found - will train new one\")\n",
    "    xgb_model = None\n",
    "\n",
    "try:\n",
    "    with open('../results/logistic_regression_model.pkl', 'rb') as f:\n",
    "        lr_model = pickle.load(f)\n",
    "    print(\"✓ Loaded Logistic Regression model\")\n",
    "except:\n",
    "    print(\"✗ Logistic Regression model not found - will train new one\")\n",
    "    lr_model = None\n",
    "\n",
    "try:\n",
    "    with open('../results/scaler.pkl', 'rb') as f:\n",
    "        scaler = pickle.load(f)\n",
    "    print(\"✓ Loaded scaler\")\n",
    "except:\n",
    "    print(\"✗ Scaler not found - will create new one\")\n",
    "    scaler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdebf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If models don't exist, train them\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "\n",
    "if scaler is None:\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "else:\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "if xgb_model is None:\n",
    "    print(\"Training XGBoost for 1-day predictions...\")\n",
    "    xgb_model = xgb.XGBClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "    xgb_model.fit(X_train, y_1d_train)\n",
    "    print(\"✓ XGBoost trained\")\n",
    "\n",
    "if lr_model is None:\n",
    "    print(\"Training Logistic Regression for 5-day predictions...\")\n",
    "    lr_model = LogisticRegression(\n",
    "        C=1.0,\n",
    "        penalty='l2',\n",
    "        solver='lbfgs',\n",
    "        max_iter=1000,\n",
    "        random_state=42\n",
    "    )\n",
    "    lr_model.fit(X_train_scaled, y_5d_train)\n",
    "    print(\"✓ Logistic Regression trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9ff303",
   "metadata": {},
   "source": [
    "## Generate Predictions from Individual Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8370b61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get probability predictions\n",
    "xgb_proba_1d = xgb_model.predict_proba(X_test)[:, 1]\n",
    "lr_proba_5d = lr_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Get binary predictions with optimal thresholds (from previous results)\n",
    "xgb_pred_1d = (xgb_proba_1d >= 0.35).astype(int)  # Optimal threshold for XGBoost 1-day\n",
    "lr_pred_5d = (lr_proba_5d >= 0.45).astype(int)    # Optimal threshold for LR 5-day\n",
    "\n",
    "print(\"Individual Model Performance:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nXGBoost (1-day):\")\n",
    "print(f\"  Accuracy: {accuracy_score(y_1d_test, xgb_pred_1d):.4f}\")\n",
    "print(f\"  F1 Score: {f1_score(y_1d_test, xgb_pred_1d, average='weighted'):.4f}\")\n",
    "\n",
    "print(f\"\\nLogistic Regression (5-day):\")\n",
    "print(f\"  Accuracy: {accuracy_score(y_5d_test, lr_pred_5d):.4f}\")\n",
    "print(f\"  F1 Score: {f1_score(y_5d_test, lr_pred_5d, average='weighted'):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d2c199",
   "metadata": {},
   "source": [
    "## Ensemble Strategy 1: Averaged Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea240e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average the probabilities for a combined prediction\n",
    "ensemble_proba_avg = (xgb_proba_1d + lr_proba_5d) / 2\n",
    "\n",
    "# Test different thresholds\n",
    "print(\"Ensemble (Average Probabilities) - Testing Thresholds:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "best_acc = 0\n",
    "best_threshold = 0.5\n",
    "results = []\n",
    "\n",
    "for threshold in np.arange(0.30, 0.71, 0.05):\n",
    "    ensemble_pred = (ensemble_proba_avg >= threshold).astype(int)\n",
    "    \n",
    "    # Evaluate against both targets\n",
    "    acc_1d = accuracy_score(y_1d_test, ensemble_pred)\n",
    "    acc_5d = accuracy_score(y_5d_test, ensemble_pred)\n",
    "    f1_1d = f1_score(y_1d_test, ensemble_pred, average='weighted')\n",
    "    f1_5d = f1_score(y_5d_test, ensemble_pred, average='weighted')\n",
    "    \n",
    "    avg_acc = (acc_1d + acc_5d) / 2\n",
    "    \n",
    "    results.append({\n",
    "        'threshold': threshold,\n",
    "        'acc_1d': acc_1d,\n",
    "        'acc_5d': acc_5d,\n",
    "        'f1_1d': f1_1d,\n",
    "        'f1_5d': f1_5d,\n",
    "        'avg_acc': avg_acc\n",
    "    })\n",
    "    \n",
    "    if avg_acc > best_acc:\n",
    "        best_acc = avg_acc\n",
    "        best_threshold = threshold\n",
    "    \n",
    "    print(f\"Threshold {threshold:.2f}: 1d={acc_1d:.4f} (F1={f1_1d:.3f}), 5d={acc_5d:.4f} (F1={f1_5d:.3f}), Avg={avg_acc:.4f}\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(f\"\\nBest Average Accuracy: {best_acc:.4f} at threshold {best_threshold:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890db66e",
   "metadata": {},
   "source": [
    "## Ensemble Strategy 2: Weighted Average (Favor Better Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befa34ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight XGBoost more for 1-day, LR more for 5-day\n",
    "# Try different weight combinations\n",
    "\n",
    "print(\"Ensemble (Weighted Probabilities):\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "weight_configs = [\n",
    "    (0.7, 0.3, \"70% XGB, 30% LR\"),\n",
    "    (0.6, 0.4, \"60% XGB, 40% LR\"),\n",
    "    (0.5, 0.5, \"50% XGB, 50% LR\"),\n",
    "    (0.4, 0.6, \"40% XGB, 60% LR\"),\n",
    "    (0.3, 0.7, \"30% XGB, 70% LR\"),\n",
    "]\n",
    "\n",
    "weighted_results = []\n",
    "\n",
    "for w_xgb, w_lr, label in weight_configs:\n",
    "    ensemble_proba_weighted = w_xgb * xgb_proba_1d + w_lr * lr_proba_5d\n",
    "    \n",
    "    # Find best threshold for this weighting\n",
    "    best_acc_weighted = 0\n",
    "    best_thresh_weighted = 0.5\n",
    "    \n",
    "    for threshold in np.arange(0.30, 0.71, 0.05):\n",
    "        ensemble_pred = (ensemble_proba_weighted >= threshold).astype(int)\n",
    "        acc_1d = accuracy_score(y_1d_test, ensemble_pred)\n",
    "        acc_5d = accuracy_score(y_5d_test, ensemble_pred)\n",
    "        avg_acc = (acc_1d + acc_5d) / 2\n",
    "        \n",
    "        if avg_acc > best_acc_weighted:\n",
    "            best_acc_weighted = avg_acc\n",
    "            best_thresh_weighted = threshold\n",
    "    \n",
    "    # Evaluate at best threshold\n",
    "    ensemble_pred = (ensemble_proba_weighted >= best_thresh_weighted).astype(int)\n",
    "    acc_1d = accuracy_score(y_1d_test, ensemble_pred)\n",
    "    acc_5d = accuracy_score(y_5d_test, ensemble_pred)\n",
    "    f1_1d = f1_score(y_1d_test, ensemble_pred, average='weighted')\n",
    "    f1_5d = f1_score(y_5d_test, ensemble_pred, average='weighted')\n",
    "    \n",
    "    weighted_results.append({\n",
    "        'weights': label,\n",
    "        'w_xgb': w_xgb,\n",
    "        'w_lr': w_lr,\n",
    "        'threshold': best_thresh_weighted,\n",
    "        'acc_1d': acc_1d,\n",
    "        'acc_5d': acc_5d,\n",
    "        'f1_1d': f1_1d,\n",
    "        'f1_5d': f1_5d,\n",
    "        'avg_acc': (acc_1d + acc_5d) / 2\n",
    "    })\n",
    "    \n",
    "    print(f\"{label} (threshold={best_thresh_weighted:.2f}):\")\n",
    "    print(f\"  1-day: {acc_1d:.4f} (F1={f1_1d:.3f})\")\n",
    "    print(f\"  5-day: {acc_5d:.4f} (F1={f1_5d:.3f})\")\n",
    "    print(f\"  Average: {(acc_1d + acc_5d) / 2:.4f}\")\n",
    "    print()\n",
    "\n",
    "weighted_results_df = pd.DataFrame(weighted_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8286f2c",
   "metadata": {},
   "source": [
    "## Ensemble Strategy 3: Majority Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c513422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple majority voting (both models must agree)\n",
    "ensemble_vote = ((xgb_pred_1d + lr_pred_5d) >= 2).astype(int)  # Both predict 1\n",
    "\n",
    "print(\"Ensemble (Majority Voting):\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "acc_1d_vote = accuracy_score(y_1d_test, ensemble_vote)\n",
    "acc_5d_vote = accuracy_score(y_5d_test, ensemble_vote)\n",
    "f1_1d_vote = f1_score(y_1d_test, ensemble_vote, average='weighted')\n",
    "f1_5d_vote = f1_score(y_5d_test, ensemble_vote, average='weighted')\n",
    "\n",
    "print(f\"1-day: Accuracy={acc_1d_vote:.4f}, F1={f1_1d_vote:.3f}\")\n",
    "print(f\"5-day: Accuracy={acc_5d_vote:.4f}, F1={f1_5d_vote:.3f}\")\n",
    "print(f\"Average: {(acc_1d_vote + acc_5d_vote) / 2:.4f}\")\n",
    "\n",
    "print(f\"\\nPrediction distribution:\")\n",
    "print(pd.Series(ensemble_vote).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fa07cc",
   "metadata": {},
   "source": [
    "## Final Comparison: Individual vs Ensemble Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dda4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate baselines\n",
    "baseline_1d = accuracy_score(y_1d_test, np.full(len(y_1d_test), y_1d_train.mode()[0]))\n",
    "baseline_5d = accuracy_score(y_5d_test, np.full(len(y_5d_test), y_5d_train.mode()[0]))\n",
    "\n",
    "# Best ensemble from weighted approach\n",
    "best_weighted = weighted_results_df.loc[weighted_results_df['avg_acc'].idxmax()]\n",
    "best_ensemble_proba = best_weighted['w_xgb'] * xgb_proba_1d + best_weighted['w_lr'] * lr_proba_5d\n",
    "best_ensemble_pred = (best_ensemble_proba >= best_weighted['threshold']).astype(int)\n",
    "\n",
    "print(\"=\"*90)\n",
    "print(\" \"*25 + \"FINAL MODEL COMPARISON\")\n",
    "print(\"=\"*90)\n",
    "\n",
    "comparison = pd.DataFrame([\n",
    "    {\n",
    "        'Model': 'Baseline (1-day)',\n",
    "        '1-Day Acc': baseline_1d,\n",
    "        '1-Day F1': 0.0,\n",
    "        '5-Day Acc': 0.0,\n",
    "        '5-Day F1': 0.0,\n",
    "        'Avg Acc': baseline_1d,\n",
    "        'Strategy': 'Always predict majority class'\n",
    "    },\n",
    "    {\n",
    "        'Model': 'Baseline (5-day)',\n",
    "        '1-Day Acc': 0.0,\n",
    "        '1-Day F1': 0.0,\n",
    "        '5-Day Acc': baseline_5d,\n",
    "        '5-Day F1': 0.0,\n",
    "        'Avg Acc': baseline_5d,\n",
    "        'Strategy': 'Always predict majority class'\n",
    "    },\n",
    "    {\n",
    "        'Model': 'XGBoost (1-day specialist)',\n",
    "        '1-Day Acc': accuracy_score(y_1d_test, xgb_pred_1d),\n",
    "        '1-Day F1': f1_score(y_1d_test, xgb_pred_1d, average='weighted'),\n",
    "        '5-Day Acc': accuracy_score(y_5d_test, xgb_pred_1d),\n",
    "        '5-Day F1': f1_score(y_5d_test, xgb_pred_1d, average='weighted'),\n",
    "        'Avg Acc': (accuracy_score(y_1d_test, xgb_pred_1d) + accuracy_score(y_5d_test, xgb_pred_1d)) / 2,\n",
    "        'Strategy': 'Threshold=0.35'\n",
    "    },\n",
    "    {\n",
    "        'Model': 'LogReg (5-day specialist)',\n",
    "        '1-Day Acc': accuracy_score(y_1d_test, lr_pred_5d),\n",
    "        '1-Day F1': f1_score(y_1d_test, lr_pred_5d, average='weighted'),\n",
    "        '5-Day Acc': accuracy_score(y_5d_test, lr_pred_5d),\n",
    "        '5-Day F1': f1_score(y_5d_test, lr_pred_5d, average='weighted'),\n",
    "        'Avg Acc': (accuracy_score(y_1d_test, lr_pred_5d) + accuracy_score(y_5d_test, lr_pred_5d)) / 2,\n",
    "        'Strategy': 'Threshold=0.45'\n",
    "    },\n",
    "    {\n",
    "        'Model': 'Ensemble (Best Weighted)',\n",
    "        '1-Day Acc': best_weighted['acc_1d'],\n",
    "        '1-Day F1': best_weighted['f1_1d'],\n",
    "        '5-Day Acc': best_weighted['acc_5d'],\n",
    "        '5-Day F1': best_weighted['f1_5d'],\n",
    "        'Avg Acc': best_weighted['avg_acc'],\n",
    "        'Strategy': f\"{best_weighted['weights']}, threshold={best_weighted['threshold']:.2f}\"\n",
    "    }\n",
    "])\n",
    "\n",
    "print(\"\\n\" + comparison.to_string(index=False))\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "\n",
    "# Highlight the best\n",
    "best_1d_idx = comparison['1-Day Acc'].idxmax()\n",
    "best_5d_idx = comparison['5-Day Acc'].idxmax()\n",
    "best_avg_idx = comparison['Avg Acc'].idxmax()\n",
    "\n",
    "print(\"\\nBEST PERFORMERS:\")\n",
    "print(f\"  1-Day Prediction: {comparison.loc[best_1d_idx, 'Model']} ({comparison.loc[best_1d_idx, '1-Day Acc']:.4f})\")\n",
    "print(f\"  5-Day Prediction: {comparison.loc[best_5d_idx, 'Model']} ({comparison.loc[best_5d_idx, '5-Day Acc']:.4f})\")\n",
    "print(f\"  Overall (Average): {comparison.loc[best_avg_idx, 'Model']} ({comparison.loc[best_avg_idx, 'Avg Acc']:.4f})\")\n",
    "print(\"=\"*90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93e16ea",
   "metadata": {},
   "source": [
    "## Visualization: Model Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9de786",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# 1-day accuracy comparison\n",
    "models_for_plot = comparison[comparison['1-Day Acc'] > 0].copy()\n",
    "ax1 = axes[0]\n",
    "bars1 = ax1.barh(models_for_plot['Model'], models_for_plot['1-Day Acc'], color='steelblue', alpha=0.7)\n",
    "ax1.axvline(baseline_1d, color='red', linestyle='--', label=f'Baseline ({baseline_1d:.3f})')\n",
    "ax1.set_xlabel('Accuracy')\n",
    "ax1.set_title('1-Day Return Prediction Performance')\n",
    "ax1.legend()\n",
    "ax1.set_xlim([0.45, 0.60])\n",
    "\n",
    "# 5-day accuracy comparison\n",
    "models_for_plot_5d = comparison[comparison['5-Day Acc'] > 0].copy()\n",
    "ax2 = axes[1]\n",
    "bars2 = ax2.barh(models_for_plot_5d['Model'], models_for_plot_5d['5-Day Acc'], color='darkgreen', alpha=0.7)\n",
    "ax2.axvline(baseline_5d, color='red', linestyle='--', label=f'Baseline ({baseline_5d:.3f})')\n",
    "ax2.set_xlabel('Accuracy')\n",
    "ax2.set_title('5-Day Return Prediction Performance')\n",
    "ax2.legend()\n",
    "ax2.set_xlim([0.45, 0.65])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/ensemble_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Saved visualization to results/ensemble_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec378ba",
   "metadata": {},
   "source": [
    "## Save Best Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76318eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ensemble predictions and configuration\n",
    "ensemble_results = pd.DataFrame({\n",
    "    'xgb_proba_1d': xgb_proba_1d,\n",
    "    'lr_proba_5d': lr_proba_5d,\n",
    "    'ensemble_proba': best_ensemble_proba,\n",
    "    'ensemble_pred': best_ensemble_pred,\n",
    "    'true_1d': y_1d_test.values,\n",
    "    'true_5d': y_5d_test.values\n",
    "})\n",
    "\n",
    "ensemble_results.to_csv('../results/ensemble_predictions.csv', index=False)\n",
    "print(\"✓ Saved ensemble predictions to results/ensemble_predictions.csv\")\n",
    "\n",
    "# Save ensemble configuration\n",
    "ensemble_config = {\n",
    "    'xgb_weight': best_weighted['w_xgb'],\n",
    "    'lr_weight': best_weighted['w_lr'],\n",
    "    'threshold': best_weighted['threshold'],\n",
    "    'xgb_threshold': 0.35,\n",
    "    'lr_threshold': 0.45,\n",
    "    'performance': {\n",
    "        '1d_accuracy': best_weighted['acc_1d'],\n",
    "        '5d_accuracy': best_weighted['acc_5d'],\n",
    "        'avg_accuracy': best_weighted['avg_acc'],\n",
    "        '1d_f1': best_weighted['f1_1d'],\n",
    "        '5d_f1': best_weighted['f1_5d']\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('../results/ensemble_config.pkl', 'wb') as f:\n",
    "    pickle.dump(ensemble_config, f)\n",
    "print(\"✓ Saved ensemble configuration to results/ensemble_config.pkl\")\n",
    "\n",
    "print(\"\\nEnsemble Configuration:\")\n",
    "for key, value in ensemble_config.items():\n",
    "    if key != 'performance':\n",
    "        print(f\"  {key}: {value}\")\n",
    "print(\"  Performance:\")\n",
    "for key, value in ensemble_config['performance'].items():\n",
    "    print(f\"    {key}: {value:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
