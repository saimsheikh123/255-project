{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "b3213eb28cf04eeca9420e2f7c545ba0",
            "ed582dea1de04746a8c9532899145f50",
            "33fdeca261c248b88d1970ddc745d11a",
            "29e3482c14ab4e19b56bd5b9cfb259af",
            "9d2aaef95e2a4cf18b193a507bcf4fea",
            "c7fb4df754f34590b7a6bed9af174a03",
            "4b16847b0e7745f99f9ed0138382ed91",
            "35fbc6909c4347c383891729adc7f2ae",
            "9a93ceaf45f0496e9ce8b3dd95cbf30c",
            "fdea2fd1fde646f1a4e1a6457aaff3ce",
            "3106e0496640435eb913736709e7012b",
            "6f34015c4607433bb9a0a21f894ebf97",
            "ef8618d2826843e59d8f0686908e50fe",
            "38772dbc561d461cb61e08a48a9b2c24",
            "a2f7cbe5e1e94ca6a10b86b640eb48d4",
            "c0f744b629fb4f309d3672bf8aca12ff",
            "e66e5fd3658b4b2abbe0262d35bc4d30",
            "26b436cd08284521a3c31eafb215d158",
            "5d5967ac7a00406494d57ca62ffb67df",
            "9e9020cb14974fd5b63e594f856a2999"
          ]
        },
        "id": "C_YZFyHcyrUL",
        "outputId": "4fdd5b93-39ff-4843-ed1c-7b1ab8d78a65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Environment ready for local execution\n"
          ]
        }
      ],
      "source": [
        "# Local execution - skip Hugging Face login and Colab setup\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "print(\"✅ Environment ready for local execution\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yl5gvSfDvAA-",
        "outputId": "39247b46-3442-4234-c542-8799b3af81b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Working directory: c:\\Users\\Saim\\Downloads\\255 Project-20251205T064946Z-3-001\\255 Project\\data\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Set working directory to data folder\n",
        "os.chdir(r'c:\\Users\\Saim\\Downloads\\255 Project-20251205T064946Z-3-001\\255 Project\\data')\n",
        "print(f\"✅ Working directory: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "818CXqWIv4d2",
        "outputId": "39dcc356-c241-4199-fd5f-6679f52f9fc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Loaded 1456 speeches\n"
          ]
        },
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "link",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "title",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "speaker",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "event",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "year",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "text",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "date",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "text_len",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "location",
                  "rawType": "object",
                  "type": "string"
                }
              ],
              "ref": "78d58117-f86e-4671-bc3d-ba5cc32fd6e8",
              "rows": [
                [
                  "0",
                  "https://www.federalreserve.gov/boarddocs/speeches/1996/19961219.htm",
                  "Supervision of bank risk-taking",
                  "Vice Chair Alice M. Rivlin",
                  "At the The Brookings Institution National Issues Forum, Washington, D.C.",
                  "1996.0",
                  "I discovered when I joined the Board of Governors of the Federal Reserve System about six months ago that most of my friends including my sophisticated public policy oriented friends had only a hazy notion what their central bank did.  Many of them said, enthusiastically, \"Congratulations!\"  Then they asked with a bit of embarrassment, \"Is it a full-time job?\" or \"What will you find to do between meetings?\"  The meetings they were aware of, of course, were those of the Federal Open Market Committee.  They knew that the FOMC meets every six weeks or so to \"set interest rates.\"  That sounds like real power, so the FOMC gets a lot of press attention even when, as happened again this week, we meet and decide to do absolutely nothing at all.  The group gathered here today, however, realizes that monetary policy, while important, is not actually very time-consuming.  If you cared enough to come to this conference, you also have a strong conviction that the health and vigor of the American economy depends not only on good macro-economic policy, although that certainly helps, but also on the safety, soundness and efficiency of the banking system.  We need a banking system that works well and one in which citizens and businesses, foreign and domestic, have high and well placed confidence.  So I want to talk today, as seems appropriate on the fifth anniversary of FDICIA, about the subject that occupies much of our attention at the Federal Reserve: the prudential regulation of banks and how to improve it.  Indeed, I want to focus today, not so much on what Congress needs to do to ensure the safety and soundness of the bank system in this rapidly changing world there are others on the program to take on that task but more narrowly on how bank regulators should go about their jobs of supervising bank risk-taking.  The evolving search for policies that would guarantee a safe, sound and efficient banking system has featured learning from experience.  In the 1930s, Americans learned, expensively, about the hazards of not having a safety net in a crisis that almost wiped out the banking system.  In the 1980s, they learned a lot about the hazards of having a safety net, especially about the moral hazard associated with deposit insurance.  Deposit insurance, which had seemed so benign and so successful in building confidence and preventing runs on banks, suddenly revealed its downside for all to see.  Some insured institutions, mostly thrifts, but also savings banks, and not a few commercial banks, were taking on risks with a \"heads I win, tails you lose\" attitude sometimes collecting on high stakes bets but often leaving deposit insurance funds to pick up the pieces.  At the same time, some regulators, especially the old FSLIC, which was notably strapped for funds, were compounding the problem and greatly increasing the ultimate cost of its resolution by engaging in regulatory \"forbearance\" when faced with technically insolvent institutions. Return to top   The lessons were costly, but Americans do learn from their mistakes.  The advocates of banking reform, many of them participants in this conference, saw the problems posed by moral hazard in the context of ineffectual supervision and set out to design a better system.  Essentially, the reform agenda had two main components: First, expanded powers for depository institutions that would permit them to diversify in ways that might reduce risks and improve operating efficiency; Second, improving the effectiveness of regulation and supervision by instructing regulators, in effect, to act more like the market itself when conducting prudential regulation.  FDICIA was a first step toward meeting the second challenge how to make regulators act more like the market.  It called for a reduction in the potential for regulatory \"forbearance\" by laying down the conditions under which conservatorship and receivership should be initiated.  It called for supervisory sanctions based on measurable performance (in particular, the Prompt Corrective Action provisions that based supervisory action on a bank's risk-based capital ratio).  The Act required the FDIC and RTC to resolve failed institutions on a least-cost basis.  In other words, the Act required the depository receivers to act as if the insurance funds were private insurers, rather than continue the past policy of protecting uninsured depositors and other bank creditors.  Finally, FDICIA placed limitations on the doctrine of \"Too Big To Fail,\" by requiring agency consensus and administration concurrence in order to prop up any large, failing bank.  In a few places, however, FDICIA went too far.  The provisions of the Act that dealt with micro management by regulators were immediately seen to be \"over the top,\" and were later repealed.  The Act provided a framework for regulators to invoke market-like discipline.  It left room for them to move their own regulatory techniques in this direction a subject to which I will return in a minute.  The other objective of reform diversification of bank activities through an expansion of bank powers has not yet resulted in legislation and is still very much an on-going debate.  In part, this failure to take legislative action reflected the long-running ability of the nonbank competition to use its political muscle to forestall increased powers for banks.  But the inaction on expanded powers also reflected a Congressional concern that additional powers might be used to take on additional risk, which, on the heels of the banking collapse of the late 1980s, represented poor timing, to say the least.   There was also some Congressional disposition to punish \"greedy bankers,\" who were seen as the reason for the collapse and the diversion of taxpayer funds to pay for thrift insolvencies.  Whatever the reasons, not only did the 102nd Congress fail to enact expanded bank powers, but so did the next two Congresses.  We are hopeful that the 105th Congress will succeed where its predecessors have failed.  Meanwhile, the regulatory agencies have acted to expand bank powers within the limits of existing law.  The Federal Reserve has proposed both liberalization of Section 20 activities and expedited procedures for processing applications under Regulation Y.  The OCC has acted to liberalize banks' insurance agency powers and, most recently, to liberalize procedures for operating subsidiaries of national banks.  Of course, I would have to turn in my Federal Reserve badge and give up my parking pass if I did not mention that we at the Fed believe that some activities are best carried out in a subsidiary of the holding company rather than a subsidiary of the bank.  We believe that the more distance between the bank and its new, nonbank operations, the more likely that we can separate one from the other and avoid the spreading of the subsidy associated with the safety net. Return to top While the regulators can move in the right direction, it is still imperative that Congress act.  Artificial barriers between and among various forms of financial activity are harmful to the best interests of the consumers of financial services, to the providers of those services, and to the general stability and well-being of our financial system, most broadly defined.  Congress should consider this issue and take the next steps.  Let me turn now to what I consider to be one of the most critical issues facing regulators, especially in a future in which financial markets likely will dictate significant further increases in the scope and complexity of banking activities.  I am referring to the issue of how to conduct optimal supervision of banks.  Fortunately, there appears actually to be an evolving consensus at least on the general principle.  Regulators, including the Federal Reserve, strongly support the basic approach embodied in FDICIA; namely that regulators should place limits on depository institutions in such a way as to replicate, as closely as possible, the discipline that would be imposed by a marketplace consisting of informed participants and devoid of the moral hazard associated with the safety net. Unfortunately, as always, the devil is in the details.  The difficult question is how should a regulator use \"market-based\" or \"performance-based\" measures in determining which, if any, supervisory sanctions or limits to place on a bank.  FDICIA's approach was straightforward.  Supervisory sanctions under Prompt Corrective Action were to be based on the bank's risk performance as measured by its levels of regulatory capital, in particular its leverage ratio and total risk-based capital ratio under the Basle capital standards.  These standards now seem well-intended but rather outdated.  Certainly, the Basle capital standards did the job for which they were designed, namely stopping the secular decline in bank capital levels that, by the late 1980s, threatened general safety and soundness.  But the scope and complexity of banking activities has proceeded apace during the last two decades or so, and standard capital measures, at least for our very largest and most complex organizations, are no longer adequate measures on which to base supervisory action for several reasons: The regulatory capital standards apportion capital only for credit risk and, most recently, for market risk of trading activities.  Interest rate risk is dealt with subjectively, and other forms of risk, including operating risk, are not treated within the standards. Also, the capital standards are, despite the appellation \"risk-based,\" very much a \"one-size-fits-all\" rule.  For example, all non-mortgage loans to corporations and households receive the same arbitrary 8 percent capital requirement.  A secured loan to a triple-A rated company receives the same treatment as an unsecured loan to a junk-rated company.  In other words, the capital standards don't measure credit risk although they represent a crude proxy for such risk within broad categories of banking assets. Finally, the capital standards give insufficient consideration to hedging or mitigating risk through the use of credit derivatives or effective portfolio diversification. Return to top These shortcomings of the regulatory capital standards were beginning to be understood even as they were being implemented, but no consistent, consensus technology existed at that time for invoking a more sophisticated standard than the Basle norms.  To be sure, more sophisticated standards were being used by bank supervisors, during the examination process, to determine the adequacy of capital at any individual institution.  These supervisory determinations of capital adequacy on a bank-by-bank basis,  reflected in the CAMEL ratings given to banks and the BOPEC ratings given to bank holding companies, are much more inclusive than the Basle standards.  Research shows that CAMEL ratings are much better predictors of bank insolvency than \"risk-based\" capital ratios.  But, a bank-by-bank supervision, of course, is not the same thing as the writing of regulations that apply to all banks.  It is now evident that the simple regulatory capital standards that apply to all banks can be quite misleading.  Nominally high regulatory capital ratios even risk-based capital ratios that are 50 or 100 percent higher than the minimums are no longer indicators of bank soundness.  Meanwhile, however, some of our largest and most sophisticated banks have been getting ahead of the regulators and doing the two things one must do in order to properly manage risk and determine capital adequacy.  First, they are statistically quantifying risk by estimating the shape of loss probability distributions associated with their risk positions.  These quantitative measures of risk are calculated by asset type, by product line, and, in some cases, even down to the individual customer level.  Second, the more sophisticated banks are calculating economic capital, or \"risk capital,\" to be allocated to each asset, each line of business, and even to each customer, in order to determine risk-adjusted profitability of each type of bank activity.  In making these risk capital allocations, banks are defining and meeting internal corporate standards for safety and soundness.  For example, a banker might desire to achieve at least a single-A rating on his own corporate debt.  He sees that, over history, single-A debt has a default probability of less than one-tenth of one percent over a one year time horizon.  So the banker sets an internal corporate goal to allocate enough capital so that the probability of losses exceeding capital is less than 0.1 percent.  In the language of statistics, this means that allocated capital must \"cover\" 99.9 percent of the estimated loss probability distribution.  Once the banker estimates risk and allocates capital to that risk, the internal capital allocations can be used in a variety of ways   for example, in so-called RAROC or risk-adjusted return on capital models that measure the relative profitability of bank activities.  If a particular bank product generates a return to allocated capital that is too low, the bank can seek to cut expenses, reprice the product, or focus its efforts on other, more profitable ventures.  These profitability analyses, moreover, are conducted on an \"apples-to-apples\" basis, since the profitability of each business line is adjusted to reflect the riskiness of the business line.  What these bankers have actually done themselves, in calculating these internal capital requirements, is something regulators have never done defined a bank soundness target.  What regulator, for example, has said that he wants capital to be high enough to reduce to 0.1 percent the probability of insolvency?  Regulators have said only that capital ratios should be no lower than some number (8 percent in the case of the Basle standards).  But as we should all be aware, a high capital ratio, if it is accompanied by a highly risky portfolio composition, can result in a bank with a high probability of insolvency.  The question should not be how high is the bank's capital ratio, but how low is its failure probability. Return to top  In sharp contrast to our 8 percent one-size-fits-all capital standard, the internal risk-capital calculations of banks result in a very wide range of capital allocations, even within a particular category of credit instrument.  For example, for an unsecured commercial credit line, typical internal capital allocations might range from less than 1 percent for a triple-A or double-A rated obligor, to well over 20 percent for an obligor in one of the lowest rating categories.  The range of internal capital allocations widens even more when we look at capital calculations for complex risk positions such as various forms of credit derivatives.  This great diversity in economic capital allocations as compared to regulatory capital allocations, creates at least two types of problem. When the regulatory capital requirement is higher than the economic capital allocation, the bank must either engage in costly regulatory arbitrage to evade the regulatory requirement or change its portfolio, possibly leading to suboptimal resource allocation. When the regulatory requirement is lower than the economic capital requirement, the bank may choose to hold capital above the regulatory requirement but below the economic requirement; in this case, the bank's nominally high capital ratio may mask the true nature of its risk position.  Measuring bank soundness and overall bank performance is becoming more critical as the risk activities of banks become more complex.   This condition is especially evident in the various nontraditional activities of banks.  In fact, \"nontraditional\" is no longer a very good adjective to describe much of what goes on at our larger institutions.  Take asset securitization, for example.  No longer do our largest banks simply take in deposit funds and lend out the money to borrowers.  Currently, well over $200 billion in assets that, in times past, have resided on the books of banks, now are owned by remote securitization conduits sponsored by banks.  Sponsorship of securitization, which is now almost solely a large bank phenomenon, holds the potential for completely transforming the traditional paradigm of \"banking.\"  Now, loans are made directly by the conduits, or are made by the banks and then immediately sold to the conduits.  To finance the origination or purchase of the loans, a conduit issues several classes of asset-backed securities collateralized by the loans.  Most of the conduit's debt is issued to investors who require that the senior securities be highly rated, generally double-A and triple-A.  In order to achieve these ratings, the conduit obtains credit enhancements insulating the senior security holders from defaults on the underlying loans.  Generally, it is the bank sponsor that provides these credit enhancements, which can be in the form of standby letters of credit to the conduit, or via the purchase of the most junior/subordinated securities issued by the conduit.  In return for providing the credit protection, as well as the loan origination and servicing functions, the bank lays claim to all residual spreads between the yields on the loans and the interest and non-interest cost of the conduit's securities, net of any loan losses.  In other words, securitization results in banks taking on almost identically the same risks as if the loans were kept on the books of the bank the old-fashioned way. Return to top  But while the credit risk of a securitized loan pool may be the same as the credit risk of holding that loan pool on the books, our capital standards do not always recognize this fact.  For example, by supplying a standby letter of credit covering so-called \"first-dollar\" losses for the conduit, a bank might be able to reduce its regulatory capital requirement, for some of its activities, by 90 percent or more compared with what would be required if the bank held the loans directly on its own books.  The question, of course, is whether the bank's internal capital allocation systems recognize the similarity in risk between, on the one hand, owning the whole loans and, on the other hand, providing a credit enhancement to a securitization conduit.  If the risk measurement and management systems of the bank are faulty, then holding a nominally high capital ratio say, 10 percent is little consolation.  In fact, nominally high capital ratios can be deceiving to market participants.  If, for example, the bank's balance sheet is less than transparent, potential investors or creditors, seeing the nominally high 10 percent capital, but not recognizing that the economic risk capital allocation should, in percentage terms, be much higher, could direct an inappropriately high level of scarce resources toward the bank.  Credit derivatives are another example of the evolution.  The bottom line is that, as we move into the 21st century, traditional notions of \"capital adequacy\" will become less useful in determining the safety and soundness of our largest, most sophisticated, banking organizations. This growing discrepancy is important because \"performance-based\" solutions likely will continue to be touted as the basis for expanded bank powers or reductions in burdensome regulation.  For example, the Federal Reserve's recent proposed liberalization of procedures for Regulation Y activities applies to banking companies that are \"well-capitalized\" and \"well-managed.\"  Similarly, the OCC's recent proposed liberalization of rules for bank operating subsidiaries applies to \"well-capitalized\" institutions.  Also, industry participants continue to call for expanded powers and/or reduced regulatory burden based on \"market tests\" of good management and adequate capital. It will not be easy reaching consensus on how to measure bank soundness and overall bank performance.  It cannot simply be done by observing market indicators.  For example, we cannot easily use the public ratings of holding company debt.  The ratings, after all, are achieved given the existence of the safety net.  The ratings are biased, therefore, from the perspective of achieving our stated goal to impose prudential limits on banks as if there were no net.  In addition, I am sure that there would be disagreement between market participants and regulators over what should be acceptable debt ratings.  The solution may be for the regulators to use the analytical tools developed by the market participants themselves for risk and performance assessment.  Regulators already have begun to move in this direction.  For example, beginning in January 1998, qualifying large multinational banks will be able to use their internal Value-at-Risk models to help set capital requirements for the market risk inherent in their trading activities.  The Federal Reserve is also conducting a pilot test of the pre-commitment approach to capital for market risk.  In this approach, banks can choose their own capital allocations, but would be sanctioned heavily if cumulative trading losses during a quarter were to exceed their chosen capital allocations.  These new and innovative methods for treating the age-old problem of capital adequacy are likely to be followed by an unending, evolutionary flow of improvements in the prudential supervisory process.  As the industry makes technological advances in risk measurement, these advances will become imbedded in the supervisory process.  For example, the banking agencies have announced programs to place an increased emphasis on banks' internal risk measurement and management processes within the assessment of overall management quality that is, how well a bank employs modern technology to manage risk will be reflected in the \"M\" portion of the bank's CAMEL rating.  In a similar vein, now that VaR models are being used to assess regulatory capital for market risk, it is easy to envision that, down the road, banks' internal credit risk models and associated internal capital allocations will also be used to help set regulatory capital requirements.  Regulation and supervision, like industry practices themselves, are continually evolving processes.  As supervisors, our goal must be to stay abreast of best practices, incorporate these practices into our own procedures where appropriate, and do so in a way that allows banks to remain sufficiently flexible and competitive.  In conducting prudential regulation we should always remember that the optimal number of bank failures is not zero.  Indeed, \"market-based\" performance means that some institutions, either through poor management choices, or just because of plain old bad luck, will fail.  As regulators, we must carefully balance these market-like results with concerns over systemic risk.  And, as regulators of banks, we must always remember that we do not operate in a vacuum the activities of nonbank financial institutions are also important to the general well-being of our financial system and the macro economy.  Regulators, of course, can only work with the framework laid down by Congress.  Let me conclude with the hope that this Congress will build on the experience of the last few years, including the experience with FDICIA, and take the next steps toward creating a structural and regulatory framework appropriate to the 21st century.",
                  "19961219.0",
                  "3671",
                  "D.C."
                ],
                [
                  "1",
                  "https://www.federalreserve.gov/boarddocs/speeches/1996/19961206.htm",
                  "Social security",
                  "Chairman Alan Greenspan",
                  "At the Abraham Lincoln Award Ceremony of the Union League of Philadelphia, Philadelphia, Pennsylvania",
                  "1996.0",
                  " I am privileged to accept the Union League of Philadelphia's Abraham Lincoln award.  This is the first time I have been at the Union League in nearly four decades, but I am gratified to learn that your organization remains as vital and active as it was in the 1950s when I visited friends here with some frequency.  Today I would like to address an issue that almost certainly will be at the forefront of American concerns over the next decade:  our largest federal entitlement program, social security.  It is becoming conventional wisdom that the social security system, as currently constructed, will not be fully viable after the so-called baby boom generation starts to retire in about fifteen years.  The most recent report by the social security trustees projected that the trust funds of the system will grow over approximately the next fifteen years.  However, beginning in the year 2012, the annual expected costs of social security are projected to exceed annual earmarked tax receipts, and the consequent deficits are projected to deplete the trust funds by the year 2029.   While such evaluations are based on an uncertain future, the benefit per current retiree under existing law, adjusted for inflation, can be forecast with some precision over the next thirty years.  Somewhat less precision is possible for future retirees. The price escalation of benefits, of course, is even more difficult to pin down.  But since price inflation has an equal effect on wages subject to social security taxation, for all practical purposes, the degree of inflation does not have a large direct effect on the net funding of the system over the long run.  However, the rate of inflation, because it affects the overall economy, presumably does affect the real wage base from which social security taxes and future benefits are derived.  The projection of inflation-adjusted taxes, which are subject to a wider degree of uncertainty than total benefits, is largely driven by real wage growth that is, wage growth adjusted for inflation which, in turn, is primarily determined by the growth of productivity.  Projecting productivity in line with the pattern of the last quarter century suggests a trend of revenue falling far short of the levels required to finance the benefits of the large baby-boomer bulge in retirees anticipated to start at about 2010. I should state, parenthetically, that if recent productivity trends are underestimated, as I suspect they are, for much the same reasons are the projected trends of both real benefits and payroll taxes.  The real future funding shortfall, therefore, would not be materially affected.  Our social security problem is, thus, not merely statistical; it is the consequence of a projected shortfall in real resources dedicated to social security.  In money terms, the current social security trust fund of a half trillion dollars falls far short of the levels required to fund the current obligations to pay promised benefits to those already retired and those who will retire in the years ahead.  Social security, unlike fully funded private retirement programs, is largely an intergenerational transfer.  Today's workers are essentially paying for today's retirees. Under the current system, the social security benefits paid to today's workers when they retire in the future will be primarily dependent upon the payroll taxes acquired from future workers.  Accordingly, if the social security system is to survive in its current form, either real benefits must be curtailed, or real taxes increased.  The latter can come from either higher tax rates or higher real wage growth in effect, higher productivity growth.  However, as I will be explaining shortly, higher productivity is unlikely alone to do the trick.  Moreover, increased social security tax rates, of course, are controversial in that many perceive them, myself included, to adversely affect employment.  A primary cause of social security's funding imbalance stems from the fact that, until very recently, the payments into the social security trust accounts by the average employee, plus employer contributions and interest earned, were inadequate, at retirement, to fund the total of retirement benefits.  This has started to change.  Under the most recent revisions to the law, and presumably conservative economic and demographic assumptions, today's younger workers will be paying social security taxes over their working years that appear sufficient to fund their benefits during retirement.  However, the huge unfunded liability for current retirees, as well as for much of the work force closer to retirement, leaves the system, as a whole, badly underfunded.  As longevity improved far beyond that contemplated by the creators of the system, and productivity growth slowed after 1973, the original premise of the system of intergenerational balance began to fail.  Today the official unfunded liability for the Old Age, Survivors, and Disability funds, which takes into account expected future tax payments and benefits out to the year 2070, has reached a staggering $3 trillion. Return to top  The social security trustees currently project taxes and benefits, under existing, and of necessity, quite tentative economic assumptions, that imply that fully funding social security for the next seventy-five years would require an immediate and permanent increase in social security taxes of about 2.2 percentage points of taxable payrolls on top of the current 12.4 percent tax rate, assuming that such an increase would not impede economic growth.  Of course, benefit reductions of a similar magnitude, or a mix of tax hikes and benefit cuts, could also bring the system back into long-term actuarial balance, at least statistically.  These types of program adjustments, which on the surface seem quite modest, might nonetheless be perceived as transforming what has until recently been a largely popular, subsidized, intergenerational transfer system into something quite contentious.  Moreover, the longer action is deferred, the greater will be the necessary tax increases or, more likely, benefit adjustments required to achieve the goal of long-term actuarial balance.  Clearly, something has to give.  The question is what?  We cannot hope to grow our way out of the problem.  An immediate and sustained increase in annual productivity growth of about 2 percentage points apparently would be needed to close the long-run funding gap without an increase in taxes or a cut in benefits.  The improvement in productivity growth must be this large because higher productivity raises future benefits as well as current and future tax receipts. However, given that we struggle to devise economic policies that might raise productivity growth by a few tenths of a percentage point per annum, a gain of 2 full points seems beyond the reach of credibility.  Nonetheless, this issue does underscore the critical elements in the forthcoming debate, since it focuses on the core of any retirement system, private or public. Simply put, unless social security taxes increase, or as I just indicated, more likely, benefits are adjusted, domestic savings must increase. Potential beneficiaries must further abstain from consuming all of their incomes.  Enough must be set aside over a lifetime of work to fund the excess of consumption over any non-social security income a retiree may still enjoy.  At the simplest level, one could envision households saving by actually storing goods purchased during their working years for consumption during retirement.  Even better, the resources that would have otherwise gone into the stored goods could be diverted to the production of new capital assets, which would, cumulatively, over a working lifetime, produce an even greater quantity of retirement goods and services.  In short, we would be getting more output per worker, our traditional measure of productivity, and a factor that is central in all calculations of long-term social security trust fund financing.  Hence, the bottom line in all retirement programs is physical resource availability.  The finance of any system is merely to facilitate the underlying system of allocating real resources that fund retirement consumption of goods and services.  The basic premise of our current largely pay-as-you-go social security system is that future productivity growth will be adequate to supply promised retirement benefits for current workers.  At existing rates of saving and investment this is becoming increasingly dubious.  Accordingly, there are a number of initiatives, at a minimum, that will surely have to be addressed.  As I argued at length in the Social Security Commission deliberations of 1983, with only marginal effect, some delaying of the age of eligibility for retirement benefits will become increasingly pressing.  For example, adjusting the full-benefits retirement age to keep pace with increases in life expectancy would keep the ratio of retirement years to expected lifespan approximately constant and would help to significantly narrow the funding gap. Hopefully, other modifications to social security benefits also will be judged as necessary.  Moreover, it is becoming increasingly recognized that the Consumer Price Index overstates increases in the cost of living, and thus indexing social security benefits to the CPI goes far beyond the intent of the Congress to insulate retirees from inflation.  In that regard, the recently released report from the Boskin commission makes a valuable contribution to the emerging consensus on this issue.  But, unless future taxes and/or benefits are sufficiently adjusted, there is no substitute for increased domestic savings and investment currently.  To be sure, for relatively short periods of time we can finance part of domestic investment in plant and equipment with foreign savings as we are doing today.  History, however, tells us that there is a limit to how far that can go.  We are also apparently increasing the productivity of our capital.  It is possible that the maturing of emerging technologies, and further substantial deregulation of industry and finance, will, in themselves, improve the growth rate of productivity without large capital investment and savings. But, it would take implausible improvements in capital productivity from current rates to close very much of the social security funding gap from this source.  The necessary boost in domestic savings need not be derived from an improved social security system, but certainly a reduction in the social security funding gap would itself move in that direction.  In a sense, it could create a virtuous cycle with higher savings engendering higher productivity growth which, in turn, would narrow the funding gap still further.  Of course, additional saving can be achieved through a reduction in the overall federal government budget deficit, and intensified efforts to encourage private household and business savings. Return to top  Some have argued for a provision in law to require the social security trust funds to invest in higher-yielding private securities, especially equities, rather than in U.S. Treasuries only.  A higher rate of return, it is alleged, would help solve the social security funding problem.  That may in fact be the case, but if so, what would happen to private retirement programs?  If social security trust funds are shifted in part, or in whole, from U.S. Treasury securities to private debt and equity instruments, holders of those securities in the private sector must be induced to exchange them, net, for U.S. Treasuries.  If, for example, social security funds were invested wholly in equities, presumably they would have to be purchased from the major holders of such equities.  Private pension and insurance funds, among other holders of equities, presumably would have to swap equities for Treasuries.  But, if the social security trust funds achieved a higher rate of return investing in equities than in lower yielding U.S. Treasuries, private sector incomes generated by their asset portfolios, including retirement funds, would fall by the same amount, potentially jeopardizing their financial condition.  This zero-sum result occurs because of the assumption that no new productive saving and investment has been induced by this portfolio reallocation process.  Proceeding further, one must presume that in such a circumstance, in order to induce the private sector to exchange their equities for Treasuries, equity prices must rise and bond prices fall.  But, this would create great market tension.  Bonds and equities are merely the paper claims to income earning assets, and the value of the income stream is not determined by short-run changes in the supply and demand for securities. Rather, equity prices must, in the long run, reflect the underlying earnings of the corporations on which the equities are a claim, as well as society's need to be compensated for postponing consumption into the future and its perception and attitudes toward risk as a consequence of uncertainty about the future.  Indeed, the total market value of debt plus equities, is, to a first approximation, likely to be unaffected by a shift in the balance of paper claims.  One might expect that this tension between the altered relative supply of equity and debt claims, on the one hand, and unaltered overall economic value of the nation's companies, on the other hand, would be resolved by an increase in the issuance of equity securities relative to bonds. This could reverse much, if not all, of the price shift in favor of equities.  However, to complicate the issue still further, it is not clear as to whether, and to what extent, bond prices would rise as corporations cut back on debt issuance.  Certainly with the social security trust funds no longer investing all of their surplus in U.S. Treasuries, the federal debt held by the public would rise, presumably placing downward pressure on bond prices.  At best, the results of this restricted form of privatization are ambiguous.  Thus, the dilemma for the social security trust funds is that a shift to equity investments without an increase in domestic savings may not appreciably increase the rate of return of social security trust fund assets, and to whatever extent that it does, would likely be mirrored by a comparable decline in the incomes of private pension and retirement funds.  I should stress that this does not mean that at least a partial privatization of our social security system does not provide a potentially viable solution to current funding problems.  There are a number of thoughtful initiatives that, through the process of privatization, could increase domestic saving rates.  These are clearly worthy of intensive evaluation.  Perhaps the strongest argument for privatization is that replacing the current unfunded system, which apparently discourages saving, with a fully funded system, is that such a change could boost domestic saving.  But, in any event, we must remember it is because privatization plans might increase savings that makes them potentially viable, not their particular form of financing.  The types of changes that will be required to restore fiscal balance to our social security accounts, in the broader scheme of things, are significant but manageable. More important, most entail changes that are less unsettling if they are put into effect in the near term rather than waiting five or ten years or longer.  Minimizing the potential disruptions associated with the inevitable changes to social security is made all the more essential because of the pressing financial problems in the Medicare system, social security's companion program for retirees. Medicare currently is in an even more precarious position than social security.  The financing of Medicare faces some of the same problems associated with demographics and productivity as social security but faces different, and currently greater, pressures owing to the behavior of medical costs and utilization rates. Reform of the Medicare system will require more immediate and potentially more dramatic changes than those necessary to reform social security.   We owe it to those who will retire after the turn of the century to be given sufficient advance notice to make what alterations in retirement planning may be required.  The longer we wait to make what are surely inevitable adjustments, the more difficult they will become.  If we procrastinate too long, the adjustments could be truly wrenching.  Our citizens deserve better.",
                  "19961206.0",
                  "2596",
                  "Pennsylvania"
                ],
                [
                  "2",
                  "https://www.federalreserve.gov/boarddocs/speeches/1996/19961205.htm",
                  "The challenge of central banking in a democratic society",
                  "Chairman Alan Greenspan",
                  "At the Annual Dinner and Francis Boyer Lecture of The American Enterprise Institute for Public Policy Research, Washington, D.C.",
                  "1996.0",
                  "The Challenge of Central Banking in a Democratic Society  Good evening ladies and gentlemen.  I am especially pleased to accept AEI's Francis Boyer Award for 1996 and be listed with so many of my friends and former associates.  In my lecture this evening I want to give some personal perspectives on central banking and, consequently, I shall be speaking only for myself.  William Jennings Bryan reportedly mesmerized the Democratic Convention of 1896 with his memorable \". . . you shall not crucify mankind upon a cross of gold.\"  His utterances underscored the profoundly divisive role of money in his time a divisiveness that remains apparent today.  Bryan was arguing for monetizing silver at an above-market price in order to expand the money supply.  The presumed consequences would have been an increase in product prices and an accompanying shift in the value of net claims on future wealth from the \"monied interests\" of the East to the indebted farmers of the West who would arguably be able to pay off their obligations with cheaper money.  The debates, before and since, over the issue of our money standard have mirrored the deliberations on the manner in which we have chosen to govern ourselves, and, perhaps more fundamentally, debates on the basic values that should govern our society.  For, at root, money serving as a store of value and medium of exchange is the lubricant that enables a society to organize itself to achieve economic progress.  The ability to store the fruits of one's labor for future consumption is necessary for the accumulation of capital, the spread of technological advances and, as a consequence, rising standards of living.  Clearly in this context, the general price level, that is, the average exchange rate for money against all goods and services, and how it changes over time, plays a profoundly important role in any society, because it influences the nature and scope of our economic and social relationships over time.  It is, thus, no wonder that we at the Federal Reserve, the nation's central bank, and ultimate guardian of the purchasing power of our money, are subject to unending scrutiny.  Indeed, it would be folly were it otherwise.   A central bank in a democratic society is a magnet for many of the tensions that such a society confronts.  Any institution that can affect the purchasing power of the currency is perceived as potentially affecting the level and distribution of wealth among the participants of that society, hardly an inconsequential issue.  Not surprisingly, the evolution of central banking in this nation has been driven by such concerns.  The experiences with paper money during the Revolutionary War were decidedly inauspicious.  \"Not worth a Continental\" was scarcely the epithet one would wish on a medium of exchange.  This moved Alexander Hamilton, with some controversy, to press for legislation that established the soundness of the credit of the United States by assuming, and ultimately repaying, the war debts not only of the fledgling federal government, but of the states as well.  Equally controversial was the chartering of the First Bank of the United States, which, although it had few functions of a modern central bank, was nonetheless believed to be a significant threat to states rights and the Constitution itself.  Although majority controlled by private interests, the Bank engaged in actions perceived to shift power to the federal government.  Such a shift was thought of by many as a fundamental threat to the new democracy, and an essential element of what was feared to be a Hamilton plan to re-establish a powerful aristocracy.  The First Bank and especially its successor Second Bank of the United States endeavored to restrict state bank credit expansion when it appeared inordinate, by gathering bank notes and tendering them for specie.  This reduced the reserve base and the ability of the fledgling American banking system to expand credit.  The issue of states' rights and concern about the power of the central government reflected the free wheeling individualism of that time.  The Second Bank was a major issue of the election of 1832.  Earlier in that year, President Andrew Jackson had vetoed the bill to extend its charter, and the election became a referendum on his veto.  The outcome was a resounding victory for Jackson and the death knell for the Bank.  It has not been easy, however, to separate often seemingly conflicting threads in the debate between advocates of state powers over money and those seeking a national role.  When Andrew Jackson vetoed the charter renewal of the Second Bank of the United States, for example, he argued for the severing of the grip on the economy of easterners and especially foreigners, who owned a significant stock interest in the bank.  Ironically, by helping to create what was perceived to be an unstable currency, he set the stage for the later development of a full-fledged gold standard, the institution that Bryan railed against in 1896 from much the same populist philosophical base as Jackson.  After the Civil War, redemption of the paper greenbacks issued during the war brought an era of a gold-standard-induced deflation, which, while it may not have thwarted the impressive advance of industrialization, was seen by many as suppressing credit availability for the rural interests of the nation, which were still a majority.  The general price level declined for more than two decades, which meant borrowers were paying off their loans in more expensive dollars than those they borrowed.  Not surprisingly, mounting pressures developed for reform, with Bryan bearing the standard for subsidized silver coinage, that is, free silver.  Though Bryan lost to McKinley in 1896 (and again in 1900), the rural-based pressures for a more elastic currency did not diminish and ultimately were reflected, in part, in the creation of the Federal Reserve.  Nonetheless, many of the proponents of banking reform in the 1890s, and in the aftermath of the Panic of 1907, were suspicious of creating a central bank.  In very large measure, those concerns underlay the various threads of reform that were joined together in the design and creation of the Federal Reserve System in 1913.  Its founding followed a prolonged debate on the balance of power between the interests of the New York money center banks and the rest of the nation, still largely rural.  The compromise that resulted from that debate created twelve regional Reserve Banks with a Washington presence vested with a Federal Reserve Board.  Its purpose was to \"furnish an elastic currency, . . . to establish a more effective supervision of banking in the United States, and for other purposes.\"  Monetary policy as we know it today, was not among the \"other purposes.\"  That evolved largely by accident in the 1920s. Return to top   Even with a central bank, the gold standard was still the dominant constraint on the issuance of paper currency and the expansion of bank deposits.  Accordingly, the Federal Reserve was to play a minor role in affecting the purchasing power of the currency for many years to come.  The world changed markedly with the advent of the Great Depression of the 1930s, and the evisceration of the gold standard.  The upheaval, and still festering fear of New York \"monied interests,\" engendered the Banking Acts of 1933 and more importantly of 1935, which vested more of the Federal Reserve's authority with the Board of Governors in Washington.  During World War II, and through 1951, however, monetary policy was effectively subservient to the interests of the Treasury, which sought access to low-cost credit.  With the so-called Federal Reserve-Treasury Accord of 1951, the Federal Reserve began to develop its current degree of independence.  Although in the 1950s and early 1960s there were short-lived bouts of inflation that caused momentary concern about sustained increases in the price level, these events did little to shake the conviction of most that America's economic and financial structure would indefinitely and effectively contain any inflationary forces.  This prescription certainly seems to have been reflected in the low inflation premium then embedded in long-term bonds.  That this view was profoundly wrong soon became apparent.  The 1970s saw inflation and unemployment simultaneously at relatively elevated levels for some time.  The notion that this could occur was nowhere to be found in the conventional wisdom of the economic policy philosophy that developed out of the Keynesian revolution of the 1930s and its subsequent empirical applications.  Moreover, these models embodied the view that aggregate demand expansion, from almost any level, would permanently create new jobs.  When that expansion carried the economy beyond \"full employment\" there would be a cost in terms of higher inflation but only a one-time increase in inflation, so that there existed a permanent trade off between sustainable levels of inflation and employment.  The stagflation of the 1970s required a thorough conceptual overhaul of economic thinking and policymaking.  Monetarism, and new insights into the effects of anticipatory expectations on economic activity and price setting, competed strongly against the traditional Keynesianism.  Gradually the power of state intervention to achieve particular economic outcomes came to be seen as much more limited.  A consensus gradually emerged in the late 1970s that inflation destroyed jobs, or at least could not create them.  This view has become particularly evident in the communiques that have emanated from the high-level international gatherings of the past quarter century.  That inflation could reduce employment was a highly controversial subject in the mid-1970s when introduced into communique language drafts.  At the meetings I attended as Chairman of the Council of Economic Advisers, the notion invariably induced extended debates.  Today in similar communiques such language is accepted boiler plate and rarely the focus of discussion.  This shift in attitudes and understanding provided political support in 1980 and thereafter for the type of monetary policy required to rebalance the economy.  Despite waxing and waning over the decades, a deep-seated tension still exists over government's role as an economic policymaker.  This tension is evident in Congressional debates, campaign rhetoric, and our ubiquitous talk shows. Return to top   It should not be a surprise that the very same ambiguities and conflicts that characterize the rest of our political life have their reflection in the nation's current view of its central bank, the Federal Reserve.  With regard to monetary policy, the view or at least the suspicion still persists in some quarters that an activist, expansionary policy could yield dividends in terms of permanently higher output and employment.  Nonetheless, there is a grudging acceptance of the degree of independence afforded our institution, and an awareness that unless we are free of the appropriations process that our independence could be compromised.  It is generally recognized and appreciated that if the Federal Reserve's monetary policy decisions were subject to Congressional or Presidential override, short-term political forces would soon dominate.  The clear political preference for lower interest rates would unleash inflationary forces, inflicting severe damage on our economy.  Notwithstanding, the central bank has not been immune from the suspicion and lack of respect that has come to afflict virtually all institutions in our society since the traumas of Vietnam, Watergate, and the destabilizing inflation in the 1970s.  The Federal Reserve's most important mission, of course, is monetary policy.  I wish I could say that there is a bound volume of immutable instructions on my desk on how effectively to implement policy to achieve our goals of maximum employment, sustainable economic growth, and price stability.  Instead, we have to deal with a dynamic, continuously evolving economy whose structure appears to change from business cycle to business cycle, an issue I shall return to shortly.  Because monetary policy works with a lag, we need to be forward looking, taking actions to forestall imbalances that may not be visible for many months.  There is no alternative to basing actions on forecasts, at least implicitly.  It means that often we need to tighten or ease before the need for action is evident to the public at large, and that policy may have to reverse course from time to time as the underlying forces acting on the economy shift.  This process is not easy to get right at all times, and it is often difficult to convey to the American people, whose support is essential to our mission.  Because the Fed is perceived as being capable of significantly affecting the lives of all Americans, that we should be subject to constant scrutiny should not come as any surprise.  Indeed, speaking as a citizen, and not Fed Chairman, I would be concerned were it otherwise.  Our monetary policy independence is conditional on pursuing policies that are broadly acceptable to the American people and their representatives in the Congress.  Augmenting concerns about the Federal Reserve is the perception that we are a secretive organization, operating behind closed doors, not always in the interests of the nation as a whole.  This is regrettable, and we continuously strive to alter this misperception.  If we are to maintain the confidence of the American people, it is vitally important that, excepting the certain areas where the premature release of information could frustrate our legislated mission, the Fed must be as transparent as any agency of government.  It cannot be acceptable in a democratic society that a group of unelected individuals are vested with important responsibilities, without being open to full public scrutiny and accountability.  To be sure, if we are to carry out effectively the monetary policy mission the Congress has delegated to us, there are certain Federal Reserve deliberations that have to remain confidential for a period of time.  To open up our debates on monetary policy fully to immediate disclosure would unsettle financial markets and constrain our discussions in a manner that would undercut our ability to function.  Nonetheless, we continue to look for ways to expand the flow of information to the public without compromising our deliberations and purposes.  We have recently commenced to announce all policy actions immediately (federal funds rate changes as well as discount rate changes) and have expanded the minutes of the Federal Open Market Committee.  For many years, the Federal Reserve has maintained what we trust is a highly sophisticated day-by-day, near real-time, evaluation of the American economy and, where relevant, of foreign economies as well.  We are able, partly through our twelve Reserve Banks, to monitor continuously developments in the real world.  The information supplied about local conditions by the directors of the Reserve Banks has been frequently useful in identifying emerging national trends and in evaluating their underlying regional implications. Return to top   The issues with which we are confronted differ in urgency over time.  Inflation concerns were not a dominant factor in economic forecasting in the 1950s and early 1960s, for example.  Since the late 1970s, however, such concerns have become an important element in policymaking.  More recently inflation has been low, but its future course remains uncertain.  The development of comfortable product, but tight labor, markets has been a crucial factor in short-term economic forecasts of recent months a phenomenon for which there is scant historic precedent.  There is, regrettably, no simple model of the American economy that can effectively explain the levels of output, employment, and inflation.  In principle, there may be some unbelievably complex set of equations that does that.  But we have not been able to find them, and do not believe anyone else has either.  Consequently, we are led, of necessity, to employ ad hoc partial models and intensive informative analysis to aid in evaluating economic developments and implementing policy.  There is no alternative to this, though we continuously seek to enhance our knowledge to match the ever growing complexity of the world economy.  At different times in our history a varying set of simple indicators seemed successfully to summarize the state of monetary policy and its relationship to the economy.  Thus, during the decades of the 1970s and 1980s, trends in money supply, first M1, then M2, were useful guides.  We could convey the thrust of our policy with money supply targets, though we felt free to deviate from those targets for good reason.  This presumably helped the Congress, after the fact, to monitor our contribution to the performance of the economy.  I should add that during this period we maintained a fully detailed analysis of the economy, in part, to make sure that money supply was still emitting reliable signals about the state of the economy.  Unfortunately, money supply trends veered off path several years ago as a useful summary of the overall economy.  Thus, to keep the Congress informed on what we are doing, we have been required to explain the full complexity of the substance of our deliberations, and how we see economic relationships and evolving trends.  There are some indications that the money demand relationships to interest rates and income may be coming back on track.  It is too soon to tell, and in any event we can not in the future expect to rely a great deal on money supply in making monetary policy.  Still, if money growth is better behaved, it would be helpful in the conduct of policy and in our communications with the Congress and the public.  In the absence of simple, summary indicators, we will continue our detailed evaluation of economic developments.  As we seek price stability and maximum sustainable growth, the changing economic structures constantly present more analytic challenges.  I doubt the tasks will become any easier for the Federal Reserve as we move into the twenty-first century.  The Congress willing, we will remain as the guardian of the purchasing power of the dollar.  But one factor that will continue to complicate that task is the increasing difficulty of pinning down the notion of what constitutes a stable general price level.  When industrial product was the centerpiece of the economy during the first two-thirds of this century, our overall price indexes served us well.  Pricing a pound of electrolytic copper presented few definitional problems.  The price of a ton of cold rolled steel sheet, or a linear yard of cotton broad woven fabrics, could be reasonably compared over a period of years.  But as the century draws to a close, the simple notion of price has turned decidedly ambiguous.  What is the price of a unit of software or a legal opinion?  How does one evaluate the price change of a cataract operation over a ten-year period when the nature of the procedure and its impact on the patient changes so radically.  Indeed, how will we measure inflation, and the associated financial and real implications, in the twenty-first century when our data using current techniques could become increasingly less adequate to trace price trends over time?  So long as individuals make contractual arrangements for future payments valued in dollars, there must be a presumption on the part of those involved in the transaction about the future purchasing power of money.  No matter how complex individual products become, there will always be some general sense of the purchasing power of money both across time and across goods and services.  Hence, we must assume that embodied in all products is some unit of output and hence of price that is recognizable to producers and consumers and upon which they will base their decisions.  Doubtless, we will develop new techniques of price measurement to unearth them as the years go on.  It is crucial that we do, for inflation can destabilize an economy even if faulty price indexes fail to reveal it.  But where do we draw the line on what prices matter?  Certainly prices of goods and services now being produced our basic measure of inflation matter.  But what about futures prices or more importantly prices of claims on future goods and services, like equities, real estate, or other earning assets?  Are stability of these prices essential to the stability of the economy? Return to top   Clearly, sustained low inflation implies less uncertainty about the future, and lower risk premiums imply higher prices of stocks and other earning assets. We can see that in the inverse relationship exhibited by price/earnings ratios and the rate of inflation in the past.  But how do we know when irrational exuberance has unduly escalated asset values, which then become subject to unexpected and prolonged contractions as they have in Japan over the past decade?  And how do we factor that assessment into monetary policy?  We as central bankers need not be concerned if a collapsing financial asset bubble does not threaten to impair the real economy, its production, jobs, and price stability.  Indeed, the sharp stock market break of 1987 had few negative consequences for the economy.  But we should not underestimate or become complacent about the complexity of the interactions of asset markets and the economy.  Thus, evaluating shifts in balance sheets generally, and in asset prices particularly, must be an integral part of the development of monetary policy.  The public examination of Federal Reserve actions extends well beyond our stewardship of monetary policy.  Our overall management of the Federal Reserve System should, and does, come under considerable scrutiny by the Congress.  Since we expend unappropriated taxpayer funds, we have an especial obligation to be prudent and efficient with the use of those funds.  I am not particularly concerned about the one-third of our annual $2 billion budget that is expended to provide financial services to the private sector in competition with other providers.  Such services include the clearing of checks, the operation of the Fedwire system, and the processing of automated clearing house payments.  We are reimbursed for those services, and at competitive prices still make a reasonable profit for the Treasury.  If we became inefficient and uncompetitive, we would be priced out of the market, and eventually out of that line of business.  An additional one-sixth of our expenses are for providing services to the Treasury and other agencies of government for which we are subject to reimbursement with appropriated funds.  For the remainder, which mainly covers monetary policy, supervision and regulation of banks, and currency operations, we have to be especially diligent, for there is no external arbiter.  The rapidly changing technologies of recent years are pressing us to review thoroughly our structure and operations.  We have already engaged in major consolidations of operations when such consolidations have been made cost effective by the newer technologies.  Although in my experience the Federal Reserve System has been responsible, efficient, and has performed well, the rapidly changing external environment frequently requires us to rethink our role and mission.  Even where we can be competitive, it is not the role of a government agency, especially one vested with an unsurpassable credit rating, to seek out all available market opportunities.  Accordingly, where specific priced services have become effectively and competitively provided by private sector suppliers, the Federal Reserve needs to reassess whether the extent of our participation in those services fulfills a reasonable public purpose.  There are, of course, certain services that the Congress has, and will in the future, deem appropriate for us to subsidize.  But these areas presumably will remain circumscribed.  As a step in our periodic reassessment, a special committee of Federal Reserve Board governors and Reserve Bank presidents has been set up to review our priced services operations and other Systemwide activities.  Another step has been to engage outside accounting firms to audit the Federal Reserve Board and the twelve Reserve Banks.  We had been quite satisfied with the Board as general auditor of the Reserve Banks since 1914.  But the range of activities and the reach of the Federal Reserve in recent years requires us to address the perception that we are auditing ourselves without the full arm's length relationship deemed appropriate in today's environment.  Finally, the substantial changes under way in bank risk management are pressing us to continuously alter our modes of supervision and regulation to keep them as effective and efficient as possible.  Most importantly, all of our recent initiatives, especially the strengthening of the payments system and supervision, are critical to a central mission of the Federal Reserve, to maintain financial stability and reduce and contain systemic risks.  This mission is an extension of our monetary policy.  Our country can not enjoy the long-run \"maximum employment and stable prices\" objectives we are given for monetary policy if the financial system is unstable.  In this regard, the successes that most please us are not so much the visible problems that we solve, but rather all the potential crises that could have happened, but didn't.  Doubtless, the most important defense against such crises is prevention.  Recent mini-crises have identified the rapidly mushrooming payments system as the most vulnerable area of potential danger.  We have no tolerance for error in our electronic payment systems.  Like a breakdown in an electric power grid, small mishaps create large problems.  Consequently, we have endeavored in recent years, as the demands on our system have escalated (we clear $1-1/2 trillion a day on Fedwire), to build in significant safety redundancies.  This has been costly in terms of equipment and buildings.  Along with our other central bank colleagues, we are always looking for ways to reduce the risks that the failure of a single institution will ricochet around the world, shutting down much of the world payments system, and significantly undermining the world's economies.  Accordingly, we are endeavoring to get as close to a real time transaction, clearing, and settlement system as possible.  This would sharply reduce financial float and the risk of breakdown.  Meaningful progress has already been made in this direction.  This evening I have tried to put current central banking issues in historical context.  Monetary arrangements, including central banks, naturally are under constant scrutiny and criticism.  This is no less true of the Federal Reserve in 1996 than of the gold standard in 1896.  Central banks need to respond patiently and responsibly to the commentary, and we need to adapt to changing circumstances in markets and the economy.  A democratic society requires a stable and effectively functioning economy.  I trust that we and our successors at the Federal Reserve will be important contributors to that end.",
                  "19961205.0",
                  "4344",
                  "D.C."
                ],
                [
                  "3",
                  "https://www.federalreserve.gov/boarddocs/speeches/1996/19961203.htm",
                  "Clearinghouses and risk management",
                  "Governor Edward W. Kelley, Jr.",
                  "At the 1996 Payments System Risk Conference, Washington, D.C.",
                  "1996.0",
                  " It is a pleasure to be with you this morning to discuss private-sector payments risk management in our changing financial environment.  Private-sector clearing arrangements, including numerous clearinghouses, are an integral part of the payment system in the United States, and now is an appropriate time to encourage further debate and action on important risk management issues.  I would like to bring some perspective to this topic by first, outlining some of the broad forces affecting clearinghouses and other parts of the payment system; second, discussing the major risks and the different risk management techniques that clearinghouses employ; third, raising some key questions about risk controls for different types of clearing arrangements; and finally, highlighting recent policy developments in this area.  First, the broad forces shaping clearing arrangements both now and in the future.  To date, the growth of electronic payments has been an important force shaping our clearing systems.  In the large-value sector, the volume and value of electronic payments has continued to grow rapidly, heavily influenced, of course, by the growth of trading in the international markets, and electronics now dominates this activity.  In the small-value sector, ACH payments have also grown rapidly, although from a very low base.  An important issue is how fast electronic payments will grow in the near-to-medium term and whether they will begin to replace the check as one of the major payment instruments in the retail sector.  If this were to happen, there would presumably be corresponding adjustments in our clearing institutions.  One important phenomenon affecting the risks in check clearinghouses has been the trend toward converting different types of larger-value payments to electronic form, and processing these payments in environments with stronger risk controls.  The latest example of this trend came earlier this year when the money settlements for most stock trades were converted from checks and drafts to Fedwire fund transfers.  Another broad force that will affect clearinghouses is the advent of interstate branch banking.  Most directly, widespread interstate branch banking over the next few years could increase the number of checks and other items cleared as so-called \"on-us\" items, reducing the number of payments flowing through clearinghouses, and indeed, through correspondent banks and the Federal Reserve.  To some extent, such developments would tend to reduce interbank risk in the payment system.  As interstate banks participate in more and more clearinghouses, they may also begin to look for higher and more uniform risk management standards in the clearinghouses around the country.  In addition, interstate banking may well contribute to pressures to reduce the number of clearinghouses, with those remaining covering broader, even nationwide, geographic areas.  We have already seen evidence of this trend in check clearinghouses in a number of regions.  Of course, the prospects for clearinghouse consolidation would be heavily influenced by the degree to which economies of scale exist in current operations and whether new technologies and organizational techniques can be brought to bear on traditional practices. Return to top  To the extent new clearing arrangements and technologies are adopted, there may also be significant new opportunities to improve risk management.  For example, technological improvements and declining computing costs might help increase the use of automated risk management systems in clearing arrangements for retail payments, which have not traditionally employed strong risk controls.  Let me turn to the types of risks that exist in clearing arrangements.  One key type of risk is interbank credit risk.  In the clearinghouse context, this is the financial risk that a bank or other participant will default on its payment or settlement obligations to the clearing group when they are due, causing losses to other participants.  There is also liquidity risk.  If settlement payments are delayed or otherwise not completed on time, one or more banks in a clearinghouse, for example, might be short of cash, which would prevent the completion of other transactions.  The significance of this risk will usually depend on the size and intraday timing of clearinghouse settlements.  Further, there are legal risks.  There has been much discussion over the past few years, for example, of the need for strong legal foundations for bilateral and multilateral netting arrangements, including clearinghouse arrangements.  I would note that significant progress has been made on this front in the United States with changes in netting law.  There are also operational and security risks.  Concerns about these risks are often greatest in the wholesale payments area, where the dollar flows are largest.  However, operational and security breakdowns could pose very significant problems for retail payment systems, especially if large numbers of payment items were involved.  You are no doubt aware of publicity surrounding these risks in connection with the development of emerging payment technologies, such as stored-value cards, Internet-based payment systems, and new retail banking technologies generally.  Discussions have centered, for example, on the use of the Internet or other \"open networks\" for delivering banking services and making payments.  One can also imagine that clearinghouses or other multilateral arrangements might be developed for some of these new payment technologies.  Risks related to operational and security failures could be a very important component of the risks faced by such new clearing arrangements.  I would urge that all banking organizations take these operational risks seriously and act with great prudence in evaluating and managing them.  A fundamental concern of central banks, of course, is systemic risk.  This can involve risks that one bank's problem will spill over onto others, risks that whole clearing systems may cease to operate effectively, and even more broadly, risks that unexpected events will destabilize the banking system as a whole.  It is this type of concern that has motivated a sustained effort by the international central banking community in a number of areas.  In the payment field, concerns about systemic risk have led central banks to call for reductions in settlement risk, in general, and stronger clearing and settlement arrangements, in particular.  The usual focus of concern is on payment systems that are explicitly designed to handle large-value payments.  But the same types of risk   credit, liquidity, legal, operational, and systemic   are often present in clearing systems for smaller-value payments; only the scale of risk is different.  It is also important to recognize that although the average dollar value of daily clearings and settlements may be relatively low, the number of checks or other items in the daily clearings may be very high.  These payments may include paychecks, corporate payments to suppliers and securities holders, and other routine but very important payments whose completion we take for granted as part of the normal functioning of the economy.  Thus, a settlement failure in a check clearinghouse, for example, could be extremely disruptive to the banking system, and even to segments of the economy more broadly, if many thousands of payments were returned or not completed on time.  Let me turn now to a variety of techniques for risk control commonly used by clearinghouses in the wholesale financial markets to control interbank credit, liquidity, and systemic risks.  These are clearinghouses for payments and securities as well as futures, options, and foreign exchange contracts.   Their risk control techniques often encompass membership standards relating to operational expertise and creditworthiness. Most clearinghouses also designate a risk manager along with a risk management committee.  Further, the clearing rules and operational systems typically implement some type of credit and liquidity risk limits, such as caps on net debit positions.  For many clearinghouses, limits are enforced in real time.  In some, certain limits are enforced after the fact, provided members remain in good standing.  To ensure that settlement can occur even if a member defaults, clearinghouses typically employ backstop liquidity resources, such as margin or collateral deposits, participants' funds, and lines of credit.  Loss sharing rules are intended to allocate credit losses unambiguously to surviving members, in the event that a participant's default would not be covered by its collateral or other funds at the clearinghouse.  For what we traditionally think of as \"small-value\" payments, however, the clearinghouse has often been treated simply as a convenient way to exchange bundles of checks and other items and to administer settlements.  Although a handful of check and ACH clearinghouses use some more advanced risk controls, the vast majority seem to take the approach that if anything goes wrong, clearinghouse participants will take two aspirin and return payments in the morning.  While this point of view is not necessarily wrong, and may be quite cost-effective when amounts at risk are low, it also should not be defended simply because we have always done things this way.  Instead, we need to ask ourselves some basic questions about the reasons why risks and risk controls have been viewed differently for different clearinghouses. First, does the type of instrument determine the types of risk and appropriate controls?  For example, is one method of risk control appropriate for credit transfers and another for debit transfers?  Second, does the technology matter?  Is one type of risk control appropriate for paper-based instruments such as checks, and another for similar transfers made electronically, such as ACH debit transfers?  Is one type of risk control appropriate for batch-processing systems and another type for real-time processing systems?  Third, does scale matter?  Are stronger risk controls appropriate if large systemic risks are generated by huge daily values of payments and settlements, but not if daily payment flows are relatively small?  If you believe that only the amount of dollars at risk matters, what about the potential disruption in the banking system that could occur if one of the larger check clearinghouses were to fail?  Fourth, do the participants matter?  Is one standard of risk control appropriate for highly creditworthy institutions and another for less creditworthy institutions?  Should risk controls vary by institutional type of participant?  In addition, since many institutions participate in more than one clearinghouse, do we get too limited a picture of risk and risk management if we analyze clearinghouses individually? Return to top  Finally, are there minimum risk standards that all clearing houses should meet or do risk profiles vary across different organizations, making such standards awkward and unnecessary?  And if there are minimum standards, can they be met by different risk control methods?  Without endeavoring to give specific answers to these questions this morning, let me turn to the development of central bank policy toward private clearinghouses over the past few years.  Clearinghouse risks and many of the risk management techniques I have mentioned have been analyzed in a series of reports prepared by the G-10 central banks and published by the Bank for International Settlements.  The key report on clearing arrangements that employ multilateral netting was the 1990 \"Report of the Committee on Interbank Netting Schemes,\" known as the Lamfalussy Report.  This report depended heavily on earlier work on netting arrangements by the Federal Reserve and the U.S. banking industry.  In late 1994, the Board formally adopted the Lamfalussy Minimum Standards for controlling risk in netting systems by incorporating it into our policy statement on large-dollar payments risk.  At that time, however, the Board announced that, for the time being, it would not apply the large-dollar policy statement to clearinghouses that use batch processing operations.  Since the Board's large-dollar policy statement was adopted, we were pleased to see that the NOCH/NACHA Task Force on Settlement Risk Management has used the type of risk analysis employed in the policy statement to evaluate the risks in check and ACH clearinghouses.  This is an important step in establishing a firm consensus on the risk analysis framework that is appropriate for such private-sector clearinghouses.  The report does not identify significant systemic risks or call for more highly developed risk controls in these clearinghouses.  However, the report does urge the private sector to take more definitive steps to evaluate the risks in clearinghouses and stronger actions to strengthen risk management where needed.  The emphasis in the report on voluntary efforts by the banking industry and clearinghouse associations is welcome.  In the United States, it has often been the clearinghouse participants themselves that have designed and pressed for the most innovative and effective tools for risk management.  We would welcome further steps along these lines.  The Task Force Report also raises the question of whether the Federal Reserve could offer improved net settlement services to the banking industry that would also serve to reduce interbank risk.  This is a question that I believe has become increasingly important, particularly with the advent of interstate branch banking and the growth of clearinghouses offering nationwide services.  Currently, the Federal Reserve offers a same-day net settlement service to national clearinghouses in which banks use the Fedwire to execute the fund transfers necessary to complete their multilateral net settlements each day.  This model has three very significant virtues from the point of view of risk control:  It is fast; it has the strongest real-time risk controls employed by the Federal Reserve; and settlement is normally final soon after the settlement process starts.  These characteristics greatly speed up the final transfer of funds and the successful completion of settlement.  The result is that the duration of interbank risk exposures, typically overnight exposures in check clearinghouses, is shortened significantly.  Over the past few years, these risk reduction benefits have helped increase interest in the Federal Reserve's national same-day settlement service.  Some have asked whether the beneficial risk reduction characteristics of the national Fedwire-based net settlement service can be retained but offered in a somewhat more convenient format.  The Federal Reserve staff is actively reviewing this possibility along with the Board's general risk policies relating to smaller-dollar clearing arrangements.  I expect that there will be good progress to report on these issues relatively early next year.  Let me conclude with three observations.  First, it is encouraging that the banking industry is becoming more sensitized to issues of risk in check, ACH, and similar clearing arrangements.  Too often, our attitude has been that if there are strong risk controls on the large-dollar systems, we can simply ignore risk in the rest of the clearing infrastructure.  Second, those with a direct stake in individual clearing systems need to act on their growing sensitivity to risk and address the need to strengthen risk management.  The types of concerns that I outlined above need to be analyzed in the context of specific clearinghouses and specific control systems.  We believe that this is an important job of the owners and participants.  Finally, we need to ask ourselves why, in an era when electronic technology has made instantaneous communication and final fund transfers possible, we still incur the risks of conducting multilateral interbank settlements that are not final until the next banking day.  Clearly we should not allow long-standing operational conventions to dictate the design of interbank settlements, and thereby increase payment-system risk, if these conventions are now obsolete and improvements are possible.  As I noted, the Federal Reserve is actively analyzing clearinghouse developments and reviewing its small-dollar netting policies.  To date, the work of the private sector has been encouraging.  However, it is clear that the job of improving risk management is not finished.  All of us have more work to do.  Indeed, improving payment risk management in a changing environment is an ongoing responsibility.",
                  "19961203.0",
                  "2527",
                  "D.C."
                ],
                [
                  "4",
                  "https://www.federalreserve.gov/boarddocs/speeches/1996/19961125.htm",
                  "Supervisory and regulatory responses to financial innovation and industry dynamics",
                  "Governor Susan M. Phillips",
                  "At the BAI Seminar on Regulatory Policy Changes, Washington, D.C.",
                  "1996.0",
                  "Supervisory and Regulatory Responses to Financial Innovation and Industry Dynamics  It is a pleasure to be here and participate in your discussions of current changes in bank regulatory policies.  In your program this morning, you have already heard a lot about the Federal Reserve Board's Regulation Y proposal, and I will not repeat the details.  Still, I think it would be useful to highlight two of the key principles the Board identified in seeking comment on Regulation Y   two principles that I believe illustrate a more general restructuring of the Board's overall approach to regulation and supervision.  These principles also animate the Board's recent proposals in the section 20 area and elsewhere.   First, in proposing to expand the laundry list of activities in which a bank holding company may engage, the Board stated that, to the extent possible, the restrictions a bank holding company faces in conducting a specific activity should be no more onerous than those applying to an insured depository institution conducting the same activity.   Second, in proposing to streamline the application process for bank holding company acquisitions, the Board stated that review of those applications should focus on how the proposal would affect the organization   as opposed to serving as a vehicle for comprehensively evaluating and addressing supervisory issues at the applicant organization.  Put another way, well-managed, well-capitalized institutions who have demonstrated that they are serving the needs of their community should have greater freedom to expand and innovate.   I believe these two principles reflect the Board's recognition that technological and financial innovation is remaking the banking industry.  Regulatory and supervisory approaches should also adapt to the changing environment. Return to top Regulation Y and Section 20 Initiatives As you know, the dramatic changes which have swept over the banking industry the past several years have also affected the entire financial services industry.  Advances in telecommunications and computer technology have provided banks and their competitors with new and more efficient opportunities to expand regionally, nationally and globally.  At the same time financial innovation has enabled institutions to fine tune and expand product lines and activities.   The structure of the industry is also changing as the recent wave of mergers among larger organizations and the advent of true interstate banking speed the pace of industry consolidation.  Despite this consolidation, however, competition in the industry is increasing.  Smaller banks are becoming more efficient, and the competition with nonbank financial institutions is growing steadily.   As a result of all these changes, the banking industry is now competing with an increasing number of financial service providers on a dynamic playing field.  Unfortunately, the nation's banking laws have not been updated to reflect this changing environment.  As the risks of holding company activities become increasingly transparent, it becomes increasingly anomalous that the banking laws severely restrict two banking related activities   underwriting and dealing in securities and insurance.  Except for some types of insurance underwriting, these activities are generally no more risky, and often significantly less risky, than many activities in which banks routinely engage   namely, lending.   Although I remain hopeful that Congress will address some of these issues, we at the Board are trying to provide banks as much latitude, commensurate with risk, that existing laws allow.  We have recognized in the Regulation Y proposal that if banks may engage in a given activity, there is no logic in prohibiting or imposing any additional restrictions on that activity when it is conducted in a holding company.   Similarly, in the section 20 arena, the Board recently eliminated a restriction on cross-marketing and employee interlocks between a bank and a securities affiliate, and substantially reduced restrictions on director and officer interlocks.  Here again, part of the calculus was whether there was anything unique to a section 20 subsidiary that warranted firewalls that are not imposed on any other type of bank affiliate engaged in activities posing similar risks.  The answer was generally, \"No.\"   I expect that the Board will be asking the same question when we undertake a more comprehensive review of the other firewalls in the coming months.  While there may be legal or reputational risks unique to affiliation with a securities firm that justify some of the existing restrictions, many firewalls may not address such risks and thus can no longer be justified.   Finally, I believe that these issues will be hotly debated in the coming months as Congress considers repealing not only section 20 of the Glass-Steagall Act, but all of the Glass-Steagall Act.  I expect Congress will also consider the repercussions of the Comptroller's decision of last week to allow a bank's operating subsidiaries to engage in activities forbidden the bank.  Here the debate becomes more subtle   not about whether an activity is appropriate for a bank holding company, but rather where in the bank holding company it should be conducted.  In particular, should riskier activities be conducted in separately capitalized affiliates of banks, or as subsidiaries of banks, under the federal safety net and with the benefit of the federal subsidy inherent in that safety net.  There also appear to me some unanswered legal and accounting questions relating to the separateness of a bank and its operating subsidiary. Return to top Changes in Bank Supervision As the industry changes, the nature of supervision is also undergoing significant change.  The traditional goals of supervisors remain the same   that is, to ensure the safety and soundness of financial institutions so that they do not become a source of systemic risk, pose a threat to the payment system, or burden taxpayers with unnecessary losses.   However, supervisors are looking to accomplish these goals in ways that are more risk-focused and burden-sensitive.  An example of such change that was put forward in the Regulation Y proposal is the reassessment of the role of an application in the supervisory process.  This step parallels recent Congressional action to eliminate the prior approval process entirely for strong bank holding companies wishing to engage in previously approved nonbanking activities   legislation proposed and supported by the Board.   In the past, the Board may have tended to use the application process to address and resolve supervisory issues at the applicant organization   sometimes involving matters that had little to do with the proposed acquisition or activity.  The Board's proposal to limit the application process to ensuring that it assesses only the pertinent issues relating to an application, including the statutory and regulatory factors the Board must consider, clearly signals that the Board intends to reduce the role of the application process as a supervisory tool.  Supervisory matters that are not significant to an organization's overall well-being or which are not related to a specific application under consideration are best addressed through other, more targeted supervisory actions.  These tools include the advancement of guidance on sound banking practices, enhanced off-site surveillance, the move to risk-focused examinations, and an increasing emphasis on improving market transparency through better public disclosure of the risk profiles of financial institutions.  I believe these initiatives are more efficient and effective in meeting supervisory goals and would like to briefly discuss some initiatives in each of these areas.   First, we are expanding efforts to promote sound banking practices.  Through our evaluations of many institutions, we as regulators are in a unique position to identify and promote sound risk management practices within the industry.  In earlier years, supervisors used guidance for relatively narrow purposes typically to advise examiners or bankers on interpretations of existing regulations or procedures for compliance.  Today, guidance is moving away from narrow, compliance-oriented prescriptions toward the identification and dissemination of sound practices for managing the risks involved in the various activities banks conduct.   Please note my emphasis on \"sound,\" not \"best,\" practices.  Sound practices reflect those minimum principles to be employed to ensure that the activity is conducted prudently.  Best practice, in my view, can and does occur in institutions of every size, shape and level of sophistication, but supervisors should focus on sound practices and leave the determination of what is \"best\" to the judgment of individual institutions.   For example, since 1993, the U.S. banking agencies have issued a series of instructions, policy statements, and examination manuals stressing the importance of managing various risks posed by the institution's activities.  The most notable example is the guidance issued in 1993 and 1994 on derivatives and trading activities.  This initiative has continued to encompass investment activities, and, this summer, interagency guidance on sound practices for managing interest rate risk exposures was issued.  I believe the dissemination of this type of guidance is a good example of supervisors adding value, and we expect to continue to emphasize this approach in the future.  We are also attempting to make greater use of the banking industry's sound, internally developed models and practices in risk management in order to reduce regulatory burden and to improve the effectiveness of our supervision.  For example, the agencies' newly revised capital standards for market risk related to a bank's trading activities will permit large trading banks to use their internal \"value-at-risk\" models to calculate their capital requirements for market risk, subject to examiner oversight and a few regulatory constraints.  Another area where regulators are innovating is in the examination process.   The cornerstone of the bank supervisory process is the verification of prudent practices and financial condition through on-site examinations, coupled with off-site surveillance.  Traditionally, on-site examinations have focused on compliance issues and verifying the condition of the institution at a point in time by reconciling accounts, testing individual transactions and performing ratio analysis.  This process is changing.  For example, examiners are now placing more emphasis on evaluating the soundness of a bank's process for managing and controlling risks.  Testing the soundness of the institution's risk management and internal control processes provides greater assurance of an institution's soundness on an ongoing basis.  To fully implement this approach, this year the Federal Reserve began assigning a formal rating to risk management in our examination reports.  This change reflects the increasing importance we place on sound management and adequate internal controls.  To improve the examination process, the Federal Reserve and other banking agencies are also emphasizing more pre-visitation planning in order to better identify those areas of a bank's activities that pose the greatest risk.  In other words, the examination scope is now more customized and focused.  We are also making greater use of computer technology in the examination process, using automated systems that permit examiners to download data from a bank's computer, analyze portfolios on their personal computers, and identify concentrations and other characteristics within the bank's loan portfolio.  As a result, examiners should be able to reduce materially the amount of time they spend on manual operations and should be able to devote more time to identifying and evaluating risks.  I would emphasize, however, that although we are revising the on-site examination process, the Board remains convinced of its fundamental importance.  Although performance-based regulation has much to commend it, and is already used as a tool by all the agencies, we find that our examiners generally detect problems before they manifest themselves in lower capital ratios, downgrades from rating services, or criticism from outside auditors.  Simply put, there really is no substitute for a hands-on review by persons unbeholden in any way to the institution.  Another area of innovative change relates to surveillance activities between on-site examinations.  Traditionally, surveillance efforts have relied on standardized ratios and screens compiled through regulatory reporting forms.  However, those screens are sometimes not flexible or comprehensive enough to provide a true profile of the bank's risk.  One enhancement we are making to our surveillance activities is to tailor the information we collect to the bank's activities, including making greater use of the bank's own internal management reports and the results of internal risk models.  In recent years, for example, the Federal Reserve has begun to collect internal loan classification reports prepared by most of our larger banks, as well as other information generated by their internal risk management systems.  Such changes merely reflect the evolving nature of bank activities and the improved procedures banks have for measuring risks and managing their activities.  As with examinations, disclosure practices of the past also focused narrowly on the financial condition of the institution at a point in time, using conventional accounting and regulatory measures.  Today, however, disclosures are expanding to include a description not only of the level of risk taken by the company but also of management's philosophy for managing and controlling risk.  This improved transparency enhances market discipline and rewards prudent management.  We have already done much to improve disclosures for derivatives and market risks, and we will continue to urge better and more broadly based disclosure on all of an institution's major activities and exposures. Return to top Conclusion I hope this review of supervisory initiatives illustrates that supervisors are making concerted efforts to keep pace with market practices and financial innovations.  Just as innovation poses new challenges to the industry, it also poses challenges to supervisors.  I believe the Board is responding and is making significant progress in adapting its existing supervisory regimes.  But as we make changes to our own processes to make regulations less burdensome and to allow increased activities by banking organizations, we are finding that the supervisory process is becoming more important, not less important, in meeting our responsibilities for a safe and sound banking system.   Thank you.",
                  "19961125.0",
                  "2222",
                  "D.C."
                ]
              ],
              "shape": {
                "columns": 9,
                "rows": 5
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>link</th>\n",
              "      <th>title</th>\n",
              "      <th>speaker</th>\n",
              "      <th>event</th>\n",
              "      <th>year</th>\n",
              "      <th>text</th>\n",
              "      <th>date</th>\n",
              "      <th>text_len</th>\n",
              "      <th>location</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://www.federalreserve.gov/boarddocs/speec...</td>\n",
              "      <td>Supervision of bank risk-taking</td>\n",
              "      <td>Vice Chair Alice M. Rivlin</td>\n",
              "      <td>At the The Brookings Institution National Issu...</td>\n",
              "      <td>1996.0</td>\n",
              "      <td>I discovered when I joined the Board of Govern...</td>\n",
              "      <td>19961219.0</td>\n",
              "      <td>3671</td>\n",
              "      <td>D.C.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://www.federalreserve.gov/boarddocs/speec...</td>\n",
              "      <td>Social security</td>\n",
              "      <td>Chairman Alan Greenspan</td>\n",
              "      <td>At the Abraham Lincoln Award Ceremony of the U...</td>\n",
              "      <td>1996.0</td>\n",
              "      <td>I am privileged to accept the Union League of...</td>\n",
              "      <td>19961206.0</td>\n",
              "      <td>2596</td>\n",
              "      <td>Pennsylvania</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://www.federalreserve.gov/boarddocs/speec...</td>\n",
              "      <td>The challenge of central banking in a democrat...</td>\n",
              "      <td>Chairman Alan Greenspan</td>\n",
              "      <td>At the Annual Dinner and Francis Boyer Lecture...</td>\n",
              "      <td>1996.0</td>\n",
              "      <td>The Challenge of Central Banking in a Democrat...</td>\n",
              "      <td>19961205.0</td>\n",
              "      <td>4344</td>\n",
              "      <td>D.C.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://www.federalreserve.gov/boarddocs/speec...</td>\n",
              "      <td>Clearinghouses and risk management</td>\n",
              "      <td>Governor Edward W. Kelley, Jr.</td>\n",
              "      <td>At the 1996 Payments System Risk Conference, W...</td>\n",
              "      <td>1996.0</td>\n",
              "      <td>It is a pleasure to be with you this morning ...</td>\n",
              "      <td>19961203.0</td>\n",
              "      <td>2527</td>\n",
              "      <td>D.C.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://www.federalreserve.gov/boarddocs/speec...</td>\n",
              "      <td>Supervisory and regulatory responses to financ...</td>\n",
              "      <td>Governor Susan M. Phillips</td>\n",
              "      <td>At the BAI Seminar on Regulatory Policy Change...</td>\n",
              "      <td>1996.0</td>\n",
              "      <td>Supervisory and Regulatory Responses to Financ...</td>\n",
              "      <td>19961125.0</td>\n",
              "      <td>2222</td>\n",
              "      <td>D.C.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                link  \\\n",
              "0  https://www.federalreserve.gov/boarddocs/speec...   \n",
              "1  https://www.federalreserve.gov/boarddocs/speec...   \n",
              "2  https://www.federalreserve.gov/boarddocs/speec...   \n",
              "3  https://www.federalreserve.gov/boarddocs/speec...   \n",
              "4  https://www.federalreserve.gov/boarddocs/speec...   \n",
              "\n",
              "                                               title  \\\n",
              "0                    Supervision of bank risk-taking   \n",
              "1                                    Social security   \n",
              "2  The challenge of central banking in a democrat...   \n",
              "3                 Clearinghouses and risk management   \n",
              "4  Supervisory and regulatory responses to financ...   \n",
              "\n",
              "                          speaker  \\\n",
              "0      Vice Chair Alice M. Rivlin   \n",
              "1         Chairman Alan Greenspan   \n",
              "2         Chairman Alan Greenspan   \n",
              "3  Governor Edward W. Kelley, Jr.   \n",
              "4      Governor Susan M. Phillips   \n",
              "\n",
              "                                               event    year  \\\n",
              "0  At the The Brookings Institution National Issu...  1996.0   \n",
              "1  At the Abraham Lincoln Award Ceremony of the U...  1996.0   \n",
              "2  At the Annual Dinner and Francis Boyer Lecture...  1996.0   \n",
              "3  At the 1996 Payments System Risk Conference, W...  1996.0   \n",
              "4  At the BAI Seminar on Regulatory Policy Change...  1996.0   \n",
              "\n",
              "                                                text        date  text_len  \\\n",
              "0  I discovered when I joined the Board of Govern...  19961219.0      3671   \n",
              "1   I am privileged to accept the Union League of...  19961206.0      2596   \n",
              "2  The Challenge of Central Banking in a Democrat...  19961205.0      4344   \n",
              "3   It is a pleasure to be with you this morning ...  19961203.0      2527   \n",
              "4  Supervisory and Regulatory Responses to Financ...  19961125.0      2222   \n",
              "\n",
              "       location  \n",
              "0          D.C.  \n",
              "1  Pennsylvania  \n",
              "2          D.C.  \n",
              "3          D.C.  \n",
              "4          D.C.  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('fed_speeches_1996_2020.csv')\n",
        "print(f\"✅ Loaded {len(df)} speeches\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "dmvZfE5E_Nhf",
        "outputId": "cc4517a1-bdb8-4c43-9e3b-ff7c43336841"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "speaker",
                  "rawType": "object",
                  "type": "unknown"
                },
                {
                  "name": "text",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "date",
                  "rawType": "datetime64[ns]",
                  "type": "datetime"
                }
              ],
              "ref": "089328d2-e8b2-43ef-87c3-086ffd29dc05",
              "rows": [
                [
                  "0",
                  "Vice Chair Alice M. Rivlin",
                  "I discovered when I joined the Board of Governors of the Federal Reserve System about six months ago that most of my friends including my sophisticated public policy oriented friends had only a hazy notion what their central bank did.  Many of them said, enthusiastically, \"Congratulations!\"  Then they asked with a bit of embarrassment, \"Is it a full-time job?\" or \"What will you find to do between meetings?\"  The meetings they were aware of, of course, were those of the Federal Open Market Committee.  They knew that the FOMC meets every six weeks or so to \"set interest rates.\"  That sounds like real power, so the FOMC gets a lot of press attention even when, as happened again this week, we meet and decide to do absolutely nothing at all.  The group gathered here today, however, realizes that monetary policy, while important, is not actually very time-consuming.  If you cared enough to come to this conference, you also have a strong conviction that the health and vigor of the American economy depends not only on good macro-economic policy, although that certainly helps, but also on the safety, soundness and efficiency of the banking system.  We need a banking system that works well and one in which citizens and businesses, foreign and domestic, have high and well placed confidence.  So I want to talk today, as seems appropriate on the fifth anniversary of FDICIA, about the subject that occupies much of our attention at the Federal Reserve: the prudential regulation of banks and how to improve it.  Indeed, I want to focus today, not so much on what Congress needs to do to ensure the safety and soundness of the bank system in this rapidly changing world there are others on the program to take on that task but more narrowly on how bank regulators should go about their jobs of supervising bank risk-taking.  The evolving search for policies that would guarantee a safe, sound and efficient banking system has featured learning from experience.  In the 1930s, Americans learned, expensively, about the hazards of not having a safety net in a crisis that almost wiped out the banking system.  In the 1980s, they learned a lot about the hazards of having a safety net, especially about the moral hazard associated with deposit insurance.  Deposit insurance, which had seemed so benign and so successful in building confidence and preventing runs on banks, suddenly revealed its downside for all to see.  Some insured institutions, mostly thrifts, but also savings banks, and not a few commercial banks, were taking on risks with a \"heads I win, tails you lose\" attitude sometimes collecting on high stakes bets but often leaving deposit insurance funds to pick up the pieces.  At the same time, some regulators, especially the old FSLIC, which was notably strapped for funds, were compounding the problem and greatly increasing the ultimate cost of its resolution by engaging in regulatory \"forbearance\" when faced with technically insolvent institutions. Return to top   The lessons were costly, but Americans do learn from their mistakes.  The advocates of banking reform, many of them participants in this conference, saw the problems posed by moral hazard in the context of ineffectual supervision and set out to design a better system.  Essentially, the reform agenda had two main components: First, expanded powers for depository institutions that would permit them to diversify in ways that might reduce risks and improve operating efficiency; Second, improving the effectiveness of regulation and supervision by instructing regulators, in effect, to act more like the market itself when conducting prudential regulation.  FDICIA was a first step toward meeting the second challenge how to make regulators act more like the market.  It called for a reduction in the potential for regulatory \"forbearance\" by laying down the conditions under which conservatorship and receivership should be initiated.  It called for supervisory sanctions based on measurable performance (in particular, the Prompt Corrective Action provisions that based supervisory action on a bank's risk-based capital ratio).  The Act required the FDIC and RTC to resolve failed institutions on a least-cost basis.  In other words, the Act required the depository receivers to act as if the insurance funds were private insurers, rather than continue the past policy of protecting uninsured depositors and other bank creditors.  Finally, FDICIA placed limitations on the doctrine of \"Too Big To Fail,\" by requiring agency consensus and administration concurrence in order to prop up any large, failing bank.  In a few places, however, FDICIA went too far.  The provisions of the Act that dealt with micro management by regulators were immediately seen to be \"over the top,\" and were later repealed.  The Act provided a framework for regulators to invoke market-like discipline.  It left room for them to move their own regulatory techniques in this direction a subject to which I will return in a minute.  The other objective of reform diversification of bank activities through an expansion of bank powers has not yet resulted in legislation and is still very much an on-going debate.  In part, this failure to take legislative action reflected the long-running ability of the nonbank competition to use its political muscle to forestall increased powers for banks.  But the inaction on expanded powers also reflected a Congressional concern that additional powers might be used to take on additional risk, which, on the heels of the banking collapse of the late 1980s, represented poor timing, to say the least.   There was also some Congressional disposition to punish \"greedy bankers,\" who were seen as the reason for the collapse and the diversion of taxpayer funds to pay for thrift insolvencies.  Whatever the reasons, not only did the 102nd Congress fail to enact expanded bank powers, but so did the next two Congresses.  We are hopeful that the 105th Congress will succeed where its predecessors have failed.  Meanwhile, the regulatory agencies have acted to expand bank powers within the limits of existing law.  The Federal Reserve has proposed both liberalization of Section 20 activities and expedited procedures for processing applications under Regulation Y.  The OCC has acted to liberalize banks' insurance agency powers and, most recently, to liberalize procedures for operating subsidiaries of national banks.  Of course, I would have to turn in my Federal Reserve badge and give up my parking pass if I did not mention that we at the Fed believe that some activities are best carried out in a subsidiary of the holding company rather than a subsidiary of the bank.  We believe that the more distance between the bank and its new, nonbank operations, the more likely that we can separate one from the other and avoid the spreading of the subsidy associated with the safety net. Return to top While the regulators can move in the right direction, it is still imperative that Congress act.  Artificial barriers between and among various forms of financial activity are harmful to the best interests of the consumers of financial services, to the providers of those services, and to the general stability and well-being of our financial system, most broadly defined.  Congress should consider this issue and take the next steps.  Let me turn now to what I consider to be one of the most critical issues facing regulators, especially in a future in which financial markets likely will dictate significant further increases in the scope and complexity of banking activities.  I am referring to the issue of how to conduct optimal supervision of banks.  Fortunately, there appears actually to be an evolving consensus at least on the general principle.  Regulators, including the Federal Reserve, strongly support the basic approach embodied in FDICIA; namely that regulators should place limits on depository institutions in such a way as to replicate, as closely as possible, the discipline that would be imposed by a marketplace consisting of informed participants and devoid of the moral hazard associated with the safety net. Unfortunately, as always, the devil is in the details.  The difficult question is how should a regulator use \"market-based\" or \"performance-based\" measures in determining which, if any, supervisory sanctions or limits to place on a bank.  FDICIA's approach was straightforward.  Supervisory sanctions under Prompt Corrective Action were to be based on the bank's risk performance as measured by its levels of regulatory capital, in particular its leverage ratio and total risk-based capital ratio under the Basle capital standards.  These standards now seem well-intended but rather outdated.  Certainly, the Basle capital standards did the job for which they were designed, namely stopping the secular decline in bank capital levels that, by the late 1980s, threatened general safety and soundness.  But the scope and complexity of banking activities has proceeded apace during the last two decades or so, and standard capital measures, at least for our very largest and most complex organizations, are no longer adequate measures on which to base supervisory action for several reasons: The regulatory capital standards apportion capital only for credit risk and, most recently, for market risk of trading activities.  Interest rate risk is dealt with subjectively, and other forms of risk, including operating risk, are not treated within the standards. Also, the capital standards are, despite the appellation \"risk-based,\" very much a \"one-size-fits-all\" rule.  For example, all non-mortgage loans to corporations and households receive the same arbitrary 8 percent capital requirement.  A secured loan to a triple-A rated company receives the same treatment as an unsecured loan to a junk-rated company.  In other words, the capital standards don't measure credit risk although they represent a crude proxy for such risk within broad categories of banking assets. Finally, the capital standards give insufficient consideration to hedging or mitigating risk through the use of credit derivatives or effective portfolio diversification. Return to top These shortcomings of the regulatory capital standards were beginning to be understood even as they were being implemented, but no consistent, consensus technology existed at that time for invoking a more sophisticated standard than the Basle norms.  To be sure, more sophisticated standards were being used by bank supervisors, during the examination process, to determine the adequacy of capital at any individual institution.  These supervisory determinations of capital adequacy on a bank-by-bank basis,  reflected in the CAMEL ratings given to banks and the BOPEC ratings given to bank holding companies, are much more inclusive than the Basle standards.  Research shows that CAMEL ratings are much better predictors of bank insolvency than \"risk-based\" capital ratios.  But, a bank-by-bank supervision, of course, is not the same thing as the writing of regulations that apply to all banks.  It is now evident that the simple regulatory capital standards that apply to all banks can be quite misleading.  Nominally high regulatory capital ratios even risk-based capital ratios that are 50 or 100 percent higher than the minimums are no longer indicators of bank soundness.  Meanwhile, however, some of our largest and most sophisticated banks have been getting ahead of the regulators and doing the two things one must do in order to properly manage risk and determine capital adequacy.  First, they are statistically quantifying risk by estimating the shape of loss probability distributions associated with their risk positions.  These quantitative measures of risk are calculated by asset type, by product line, and, in some cases, even down to the individual customer level.  Second, the more sophisticated banks are calculating economic capital, or \"risk capital,\" to be allocated to each asset, each line of business, and even to each customer, in order to determine risk-adjusted profitability of each type of bank activity.  In making these risk capital allocations, banks are defining and meeting internal corporate standards for safety and soundness.  For example, a banker might desire to achieve at least a single-A rating on his own corporate debt.  He sees that, over history, single-A debt has a default probability of less than one-tenth of one percent over a one year time horizon.  So the banker sets an internal corporate goal to allocate enough capital so that the probability of losses exceeding capital is less than 0.1 percent.  In the language of statistics, this means that allocated capital must \"cover\" 99.9 percent of the estimated loss probability distribution.  Once the banker estimates risk and allocates capital to that risk, the internal capital allocations can be used in a variety of ways   for example, in so-called RAROC or risk-adjusted return on capital models that measure the relative profitability of bank activities.  If a particular bank product generates a return to allocated capital that is too low, the bank can seek to cut expenses, reprice the product, or focus its efforts on other, more profitable ventures.  These profitability analyses, moreover, are conducted on an \"apples-to-apples\" basis, since the profitability of each business line is adjusted to reflect the riskiness of the business line.  What these bankers have actually done themselves, in calculating these internal capital requirements, is something regulators have never done defined a bank soundness target.  What regulator, for example, has said that he wants capital to be high enough to reduce to 0.1 percent the probability of insolvency?  Regulators have said only that capital ratios should be no lower than some number (8 percent in the case of the Basle standards).  But as we should all be aware, a high capital ratio, if it is accompanied by a highly risky portfolio composition, can result in a bank with a high probability of insolvency.  The question should not be how high is the bank's capital ratio, but how low is its failure probability. Return to top  In sharp contrast to our 8 percent one-size-fits-all capital standard, the internal risk-capital calculations of banks result in a very wide range of capital allocations, even within a particular category of credit instrument.  For example, for an unsecured commercial credit line, typical internal capital allocations might range from less than 1 percent for a triple-A or double-A rated obligor, to well over 20 percent for an obligor in one of the lowest rating categories.  The range of internal capital allocations widens even more when we look at capital calculations for complex risk positions such as various forms of credit derivatives.  This great diversity in economic capital allocations as compared to regulatory capital allocations, creates at least two types of problem. When the regulatory capital requirement is higher than the economic capital allocation, the bank must either engage in costly regulatory arbitrage to evade the regulatory requirement or change its portfolio, possibly leading to suboptimal resource allocation. When the regulatory requirement is lower than the economic capital requirement, the bank may choose to hold capital above the regulatory requirement but below the economic requirement; in this case, the bank's nominally high capital ratio may mask the true nature of its risk position.  Measuring bank soundness and overall bank performance is becoming more critical as the risk activities of banks become more complex.   This condition is especially evident in the various nontraditional activities of banks.  In fact, \"nontraditional\" is no longer a very good adjective to describe much of what goes on at our larger institutions.  Take asset securitization, for example.  No longer do our largest banks simply take in deposit funds and lend out the money to borrowers.  Currently, well over $200 billion in assets that, in times past, have resided on the books of banks, now are owned by remote securitization conduits sponsored by banks.  Sponsorship of securitization, which is now almost solely a large bank phenomenon, holds the potential for completely transforming the traditional paradigm of \"banking.\"  Now, loans are made directly by the conduits, or are made by the banks and then immediately sold to the conduits.  To finance the origination or purchase of the loans, a conduit issues several classes of asset-backed securities collateralized by the loans.  Most of the conduit's debt is issued to investors who require that the senior securities be highly rated, generally double-A and triple-A.  In order to achieve these ratings, the conduit obtains credit enhancements insulating the senior security holders from defaults on the underlying loans.  Generally, it is the bank sponsor that provides these credit enhancements, which can be in the form of standby letters of credit to the conduit, or via the purchase of the most junior/subordinated securities issued by the conduit.  In return for providing the credit protection, as well as the loan origination and servicing functions, the bank lays claim to all residual spreads between the yields on the loans and the interest and non-interest cost of the conduit's securities, net of any loan losses.  In other words, securitization results in banks taking on almost identically the same risks as if the loans were kept on the books of the bank the old-fashioned way. Return to top  But while the credit risk of a securitized loan pool may be the same as the credit risk of holding that loan pool on the books, our capital standards do not always recognize this fact.  For example, by supplying a standby letter of credit covering so-called \"first-dollar\" losses for the conduit, a bank might be able to reduce its regulatory capital requirement, for some of its activities, by 90 percent or more compared with what would be required if the bank held the loans directly on its own books.  The question, of course, is whether the bank's internal capital allocation systems recognize the similarity in risk between, on the one hand, owning the whole loans and, on the other hand, providing a credit enhancement to a securitization conduit.  If the risk measurement and management systems of the bank are faulty, then holding a nominally high capital ratio say, 10 percent is little consolation.  In fact, nominally high capital ratios can be deceiving to market participants.  If, for example, the bank's balance sheet is less than transparent, potential investors or creditors, seeing the nominally high 10 percent capital, but not recognizing that the economic risk capital allocation should, in percentage terms, be much higher, could direct an inappropriately high level of scarce resources toward the bank.  Credit derivatives are another example of the evolution.  The bottom line is that, as we move into the 21st century, traditional notions of \"capital adequacy\" will become less useful in determining the safety and soundness of our largest, most sophisticated, banking organizations. This growing discrepancy is important because \"performance-based\" solutions likely will continue to be touted as the basis for expanded bank powers or reductions in burdensome regulation.  For example, the Federal Reserve's recent proposed liberalization of procedures for Regulation Y activities applies to banking companies that are \"well-capitalized\" and \"well-managed.\"  Similarly, the OCC's recent proposed liberalization of rules for bank operating subsidiaries applies to \"well-capitalized\" institutions.  Also, industry participants continue to call for expanded powers and/or reduced regulatory burden based on \"market tests\" of good management and adequate capital. It will not be easy reaching consensus on how to measure bank soundness and overall bank performance.  It cannot simply be done by observing market indicators.  For example, we cannot easily use the public ratings of holding company debt.  The ratings, after all, are achieved given the existence of the safety net.  The ratings are biased, therefore, from the perspective of achieving our stated goal to impose prudential limits on banks as if there were no net.  In addition, I am sure that there would be disagreement between market participants and regulators over what should be acceptable debt ratings.  The solution may be for the regulators to use the analytical tools developed by the market participants themselves for risk and performance assessment.  Regulators already have begun to move in this direction.  For example, beginning in January 1998, qualifying large multinational banks will be able to use their internal Value-at-Risk models to help set capital requirements for the market risk inherent in their trading activities.  The Federal Reserve is also conducting a pilot test of the pre-commitment approach to capital for market risk.  In this approach, banks can choose their own capital allocations, but would be sanctioned heavily if cumulative trading losses during a quarter were to exceed their chosen capital allocations.  These new and innovative methods for treating the age-old problem of capital adequacy are likely to be followed by an unending, evolutionary flow of improvements in the prudential supervisory process.  As the industry makes technological advances in risk measurement, these advances will become imbedded in the supervisory process.  For example, the banking agencies have announced programs to place an increased emphasis on banks' internal risk measurement and management processes within the assessment of overall management quality that is, how well a bank employs modern technology to manage risk will be reflected in the \"M\" portion of the bank's CAMEL rating.  In a similar vein, now that VaR models are being used to assess regulatory capital for market risk, it is easy to envision that, down the road, banks' internal credit risk models and associated internal capital allocations will also be used to help set regulatory capital requirements.  Regulation and supervision, like industry practices themselves, are continually evolving processes.  As supervisors, our goal must be to stay abreast of best practices, incorporate these practices into our own procedures where appropriate, and do so in a way that allows banks to remain sufficiently flexible and competitive.  In conducting prudential regulation we should always remember that the optimal number of bank failures is not zero.  Indeed, \"market-based\" performance means that some institutions, either through poor management choices, or just because of plain old bad luck, will fail.  As regulators, we must carefully balance these market-like results with concerns over systemic risk.  And, as regulators of banks, we must always remember that we do not operate in a vacuum the activities of nonbank financial institutions are also important to the general well-being of our financial system and the macro economy.  Regulators, of course, can only work with the framework laid down by Congress.  Let me conclude with the hope that this Congress will build on the experience of the last few years, including the experience with FDICIA, and take the next steps toward creating a structural and regulatory framework appropriate to the 21st century.",
                  "1996-12-19 00:00:00"
                ],
                [
                  "1",
                  "Chairman Alan Greenspan",
                  " I am privileged to accept the Union League of Philadelphia's Abraham Lincoln award.  This is the first time I have been at the Union League in nearly four decades, but I am gratified to learn that your organization remains as vital and active as it was in the 1950s when I visited friends here with some frequency.  Today I would like to address an issue that almost certainly will be at the forefront of American concerns over the next decade:  our largest federal entitlement program, social security.  It is becoming conventional wisdom that the social security system, as currently constructed, will not be fully viable after the so-called baby boom generation starts to retire in about fifteen years.  The most recent report by the social security trustees projected that the trust funds of the system will grow over approximately the next fifteen years.  However, beginning in the year 2012, the annual expected costs of social security are projected to exceed annual earmarked tax receipts, and the consequent deficits are projected to deplete the trust funds by the year 2029.   While such evaluations are based on an uncertain future, the benefit per current retiree under existing law, adjusted for inflation, can be forecast with some precision over the next thirty years.  Somewhat less precision is possible for future retirees. The price escalation of benefits, of course, is even more difficult to pin down.  But since price inflation has an equal effect on wages subject to social security taxation, for all practical purposes, the degree of inflation does not have a large direct effect on the net funding of the system over the long run.  However, the rate of inflation, because it affects the overall economy, presumably does affect the real wage base from which social security taxes and future benefits are derived.  The projection of inflation-adjusted taxes, which are subject to a wider degree of uncertainty than total benefits, is largely driven by real wage growth that is, wage growth adjusted for inflation which, in turn, is primarily determined by the growth of productivity.  Projecting productivity in line with the pattern of the last quarter century suggests a trend of revenue falling far short of the levels required to finance the benefits of the large baby-boomer bulge in retirees anticipated to start at about 2010. I should state, parenthetically, that if recent productivity trends are underestimated, as I suspect they are, for much the same reasons are the projected trends of both real benefits and payroll taxes.  The real future funding shortfall, therefore, would not be materially affected.  Our social security problem is, thus, not merely statistical; it is the consequence of a projected shortfall in real resources dedicated to social security.  In money terms, the current social security trust fund of a half trillion dollars falls far short of the levels required to fund the current obligations to pay promised benefits to those already retired and those who will retire in the years ahead.  Social security, unlike fully funded private retirement programs, is largely an intergenerational transfer.  Today's workers are essentially paying for today's retirees. Under the current system, the social security benefits paid to today's workers when they retire in the future will be primarily dependent upon the payroll taxes acquired from future workers.  Accordingly, if the social security system is to survive in its current form, either real benefits must be curtailed, or real taxes increased.  The latter can come from either higher tax rates or higher real wage growth in effect, higher productivity growth.  However, as I will be explaining shortly, higher productivity is unlikely alone to do the trick.  Moreover, increased social security tax rates, of course, are controversial in that many perceive them, myself included, to adversely affect employment.  A primary cause of social security's funding imbalance stems from the fact that, until very recently, the payments into the social security trust accounts by the average employee, plus employer contributions and interest earned, were inadequate, at retirement, to fund the total of retirement benefits.  This has started to change.  Under the most recent revisions to the law, and presumably conservative economic and demographic assumptions, today's younger workers will be paying social security taxes over their working years that appear sufficient to fund their benefits during retirement.  However, the huge unfunded liability for current retirees, as well as for much of the work force closer to retirement, leaves the system, as a whole, badly underfunded.  As longevity improved far beyond that contemplated by the creators of the system, and productivity growth slowed after 1973, the original premise of the system of intergenerational balance began to fail.  Today the official unfunded liability for the Old Age, Survivors, and Disability funds, which takes into account expected future tax payments and benefits out to the year 2070, has reached a staggering $3 trillion. Return to top  The social security trustees currently project taxes and benefits, under existing, and of necessity, quite tentative economic assumptions, that imply that fully funding social security for the next seventy-five years would require an immediate and permanent increase in social security taxes of about 2.2 percentage points of taxable payrolls on top of the current 12.4 percent tax rate, assuming that such an increase would not impede economic growth.  Of course, benefit reductions of a similar magnitude, or a mix of tax hikes and benefit cuts, could also bring the system back into long-term actuarial balance, at least statistically.  These types of program adjustments, which on the surface seem quite modest, might nonetheless be perceived as transforming what has until recently been a largely popular, subsidized, intergenerational transfer system into something quite contentious.  Moreover, the longer action is deferred, the greater will be the necessary tax increases or, more likely, benefit adjustments required to achieve the goal of long-term actuarial balance.  Clearly, something has to give.  The question is what?  We cannot hope to grow our way out of the problem.  An immediate and sustained increase in annual productivity growth of about 2 percentage points apparently would be needed to close the long-run funding gap without an increase in taxes or a cut in benefits.  The improvement in productivity growth must be this large because higher productivity raises future benefits as well as current and future tax receipts. However, given that we struggle to devise economic policies that might raise productivity growth by a few tenths of a percentage point per annum, a gain of 2 full points seems beyond the reach of credibility.  Nonetheless, this issue does underscore the critical elements in the forthcoming debate, since it focuses on the core of any retirement system, private or public. Simply put, unless social security taxes increase, or as I just indicated, more likely, benefits are adjusted, domestic savings must increase. Potential beneficiaries must further abstain from consuming all of their incomes.  Enough must be set aside over a lifetime of work to fund the excess of consumption over any non-social security income a retiree may still enjoy.  At the simplest level, one could envision households saving by actually storing goods purchased during their working years for consumption during retirement.  Even better, the resources that would have otherwise gone into the stored goods could be diverted to the production of new capital assets, which would, cumulatively, over a working lifetime, produce an even greater quantity of retirement goods and services.  In short, we would be getting more output per worker, our traditional measure of productivity, and a factor that is central in all calculations of long-term social security trust fund financing.  Hence, the bottom line in all retirement programs is physical resource availability.  The finance of any system is merely to facilitate the underlying system of allocating real resources that fund retirement consumption of goods and services.  The basic premise of our current largely pay-as-you-go social security system is that future productivity growth will be adequate to supply promised retirement benefits for current workers.  At existing rates of saving and investment this is becoming increasingly dubious.  Accordingly, there are a number of initiatives, at a minimum, that will surely have to be addressed.  As I argued at length in the Social Security Commission deliberations of 1983, with only marginal effect, some delaying of the age of eligibility for retirement benefits will become increasingly pressing.  For example, adjusting the full-benefits retirement age to keep pace with increases in life expectancy would keep the ratio of retirement years to expected lifespan approximately constant and would help to significantly narrow the funding gap. Hopefully, other modifications to social security benefits also will be judged as necessary.  Moreover, it is becoming increasingly recognized that the Consumer Price Index overstates increases in the cost of living, and thus indexing social security benefits to the CPI goes far beyond the intent of the Congress to insulate retirees from inflation.  In that regard, the recently released report from the Boskin commission makes a valuable contribution to the emerging consensus on this issue.  But, unless future taxes and/or benefits are sufficiently adjusted, there is no substitute for increased domestic savings and investment currently.  To be sure, for relatively short periods of time we can finance part of domestic investment in plant and equipment with foreign savings as we are doing today.  History, however, tells us that there is a limit to how far that can go.  We are also apparently increasing the productivity of our capital.  It is possible that the maturing of emerging technologies, and further substantial deregulation of industry and finance, will, in themselves, improve the growth rate of productivity without large capital investment and savings. But, it would take implausible improvements in capital productivity from current rates to close very much of the social security funding gap from this source.  The necessary boost in domestic savings need not be derived from an improved social security system, but certainly a reduction in the social security funding gap would itself move in that direction.  In a sense, it could create a virtuous cycle with higher savings engendering higher productivity growth which, in turn, would narrow the funding gap still further.  Of course, additional saving can be achieved through a reduction in the overall federal government budget deficit, and intensified efforts to encourage private household and business savings. Return to top  Some have argued for a provision in law to require the social security trust funds to invest in higher-yielding private securities, especially equities, rather than in U.S. Treasuries only.  A higher rate of return, it is alleged, would help solve the social security funding problem.  That may in fact be the case, but if so, what would happen to private retirement programs?  If social security trust funds are shifted in part, or in whole, from U.S. Treasury securities to private debt and equity instruments, holders of those securities in the private sector must be induced to exchange them, net, for U.S. Treasuries.  If, for example, social security funds were invested wholly in equities, presumably they would have to be purchased from the major holders of such equities.  Private pension and insurance funds, among other holders of equities, presumably would have to swap equities for Treasuries.  But, if the social security trust funds achieved a higher rate of return investing in equities than in lower yielding U.S. Treasuries, private sector incomes generated by their asset portfolios, including retirement funds, would fall by the same amount, potentially jeopardizing their financial condition.  This zero-sum result occurs because of the assumption that no new productive saving and investment has been induced by this portfolio reallocation process.  Proceeding further, one must presume that in such a circumstance, in order to induce the private sector to exchange their equities for Treasuries, equity prices must rise and bond prices fall.  But, this would create great market tension.  Bonds and equities are merely the paper claims to income earning assets, and the value of the income stream is not determined by short-run changes in the supply and demand for securities. Rather, equity prices must, in the long run, reflect the underlying earnings of the corporations on which the equities are a claim, as well as society's need to be compensated for postponing consumption into the future and its perception and attitudes toward risk as a consequence of uncertainty about the future.  Indeed, the total market value of debt plus equities, is, to a first approximation, likely to be unaffected by a shift in the balance of paper claims.  One might expect that this tension between the altered relative supply of equity and debt claims, on the one hand, and unaltered overall economic value of the nation's companies, on the other hand, would be resolved by an increase in the issuance of equity securities relative to bonds. This could reverse much, if not all, of the price shift in favor of equities.  However, to complicate the issue still further, it is not clear as to whether, and to what extent, bond prices would rise as corporations cut back on debt issuance.  Certainly with the social security trust funds no longer investing all of their surplus in U.S. Treasuries, the federal debt held by the public would rise, presumably placing downward pressure on bond prices.  At best, the results of this restricted form of privatization are ambiguous.  Thus, the dilemma for the social security trust funds is that a shift to equity investments without an increase in domestic savings may not appreciably increase the rate of return of social security trust fund assets, and to whatever extent that it does, would likely be mirrored by a comparable decline in the incomes of private pension and retirement funds.  I should stress that this does not mean that at least a partial privatization of our social security system does not provide a potentially viable solution to current funding problems.  There are a number of thoughtful initiatives that, through the process of privatization, could increase domestic saving rates.  These are clearly worthy of intensive evaluation.  Perhaps the strongest argument for privatization is that replacing the current unfunded system, which apparently discourages saving, with a fully funded system, is that such a change could boost domestic saving.  But, in any event, we must remember it is because privatization plans might increase savings that makes them potentially viable, not their particular form of financing.  The types of changes that will be required to restore fiscal balance to our social security accounts, in the broader scheme of things, are significant but manageable. More important, most entail changes that are less unsettling if they are put into effect in the near term rather than waiting five or ten years or longer.  Minimizing the potential disruptions associated with the inevitable changes to social security is made all the more essential because of the pressing financial problems in the Medicare system, social security's companion program for retirees. Medicare currently is in an even more precarious position than social security.  The financing of Medicare faces some of the same problems associated with demographics and productivity as social security but faces different, and currently greater, pressures owing to the behavior of medical costs and utilization rates. Reform of the Medicare system will require more immediate and potentially more dramatic changes than those necessary to reform social security.   We owe it to those who will retire after the turn of the century to be given sufficient advance notice to make what alterations in retirement planning may be required.  The longer we wait to make what are surely inevitable adjustments, the more difficult they will become.  If we procrastinate too long, the adjustments could be truly wrenching.  Our citizens deserve better.",
                  "1996-12-06 00:00:00"
                ],
                [
                  "2",
                  "Chairman Alan Greenspan",
                  "The Challenge of Central Banking in a Democratic Society  Good evening ladies and gentlemen.  I am especially pleased to accept AEI's Francis Boyer Award for 1996 and be listed with so many of my friends and former associates.  In my lecture this evening I want to give some personal perspectives on central banking and, consequently, I shall be speaking only for myself.  William Jennings Bryan reportedly mesmerized the Democratic Convention of 1896 with his memorable \". . . you shall not crucify mankind upon a cross of gold.\"  His utterances underscored the profoundly divisive role of money in his time a divisiveness that remains apparent today.  Bryan was arguing for monetizing silver at an above-market price in order to expand the money supply.  The presumed consequences would have been an increase in product prices and an accompanying shift in the value of net claims on future wealth from the \"monied interests\" of the East to the indebted farmers of the West who would arguably be able to pay off their obligations with cheaper money.  The debates, before and since, over the issue of our money standard have mirrored the deliberations on the manner in which we have chosen to govern ourselves, and, perhaps more fundamentally, debates on the basic values that should govern our society.  For, at root, money serving as a store of value and medium of exchange is the lubricant that enables a society to organize itself to achieve economic progress.  The ability to store the fruits of one's labor for future consumption is necessary for the accumulation of capital, the spread of technological advances and, as a consequence, rising standards of living.  Clearly in this context, the general price level, that is, the average exchange rate for money against all goods and services, and how it changes over time, plays a profoundly important role in any society, because it influences the nature and scope of our economic and social relationships over time.  It is, thus, no wonder that we at the Federal Reserve, the nation's central bank, and ultimate guardian of the purchasing power of our money, are subject to unending scrutiny.  Indeed, it would be folly were it otherwise.   A central bank in a democratic society is a magnet for many of the tensions that such a society confronts.  Any institution that can affect the purchasing power of the currency is perceived as potentially affecting the level and distribution of wealth among the participants of that society, hardly an inconsequential issue.  Not surprisingly, the evolution of central banking in this nation has been driven by such concerns.  The experiences with paper money during the Revolutionary War were decidedly inauspicious.  \"Not worth a Continental\" was scarcely the epithet one would wish on a medium of exchange.  This moved Alexander Hamilton, with some controversy, to press for legislation that established the soundness of the credit of the United States by assuming, and ultimately repaying, the war debts not only of the fledgling federal government, but of the states as well.  Equally controversial was the chartering of the First Bank of the United States, which, although it had few functions of a modern central bank, was nonetheless believed to be a significant threat to states rights and the Constitution itself.  Although majority controlled by private interests, the Bank engaged in actions perceived to shift power to the federal government.  Such a shift was thought of by many as a fundamental threat to the new democracy, and an essential element of what was feared to be a Hamilton plan to re-establish a powerful aristocracy.  The First Bank and especially its successor Second Bank of the United States endeavored to restrict state bank credit expansion when it appeared inordinate, by gathering bank notes and tendering them for specie.  This reduced the reserve base and the ability of the fledgling American banking system to expand credit.  The issue of states' rights and concern about the power of the central government reflected the free wheeling individualism of that time.  The Second Bank was a major issue of the election of 1832.  Earlier in that year, President Andrew Jackson had vetoed the bill to extend its charter, and the election became a referendum on his veto.  The outcome was a resounding victory for Jackson and the death knell for the Bank.  It has not been easy, however, to separate often seemingly conflicting threads in the debate between advocates of state powers over money and those seeking a national role.  When Andrew Jackson vetoed the charter renewal of the Second Bank of the United States, for example, he argued for the severing of the grip on the economy of easterners and especially foreigners, who owned a significant stock interest in the bank.  Ironically, by helping to create what was perceived to be an unstable currency, he set the stage for the later development of a full-fledged gold standard, the institution that Bryan railed against in 1896 from much the same populist philosophical base as Jackson.  After the Civil War, redemption of the paper greenbacks issued during the war brought an era of a gold-standard-induced deflation, which, while it may not have thwarted the impressive advance of industrialization, was seen by many as suppressing credit availability for the rural interests of the nation, which were still a majority.  The general price level declined for more than two decades, which meant borrowers were paying off their loans in more expensive dollars than those they borrowed.  Not surprisingly, mounting pressures developed for reform, with Bryan bearing the standard for subsidized silver coinage, that is, free silver.  Though Bryan lost to McKinley in 1896 (and again in 1900), the rural-based pressures for a more elastic currency did not diminish and ultimately were reflected, in part, in the creation of the Federal Reserve.  Nonetheless, many of the proponents of banking reform in the 1890s, and in the aftermath of the Panic of 1907, were suspicious of creating a central bank.  In very large measure, those concerns underlay the various threads of reform that were joined together in the design and creation of the Federal Reserve System in 1913.  Its founding followed a prolonged debate on the balance of power between the interests of the New York money center banks and the rest of the nation, still largely rural.  The compromise that resulted from that debate created twelve regional Reserve Banks with a Washington presence vested with a Federal Reserve Board.  Its purpose was to \"furnish an elastic currency, . . . to establish a more effective supervision of banking in the United States, and for other purposes.\"  Monetary policy as we know it today, was not among the \"other purposes.\"  That evolved largely by accident in the 1920s. Return to top   Even with a central bank, the gold standard was still the dominant constraint on the issuance of paper currency and the expansion of bank deposits.  Accordingly, the Federal Reserve was to play a minor role in affecting the purchasing power of the currency for many years to come.  The world changed markedly with the advent of the Great Depression of the 1930s, and the evisceration of the gold standard.  The upheaval, and still festering fear of New York \"monied interests,\" engendered the Banking Acts of 1933 and more importantly of 1935, which vested more of the Federal Reserve's authority with the Board of Governors in Washington.  During World War II, and through 1951, however, monetary policy was effectively subservient to the interests of the Treasury, which sought access to low-cost credit.  With the so-called Federal Reserve-Treasury Accord of 1951, the Federal Reserve began to develop its current degree of independence.  Although in the 1950s and early 1960s there were short-lived bouts of inflation that caused momentary concern about sustained increases in the price level, these events did little to shake the conviction of most that America's economic and financial structure would indefinitely and effectively contain any inflationary forces.  This prescription certainly seems to have been reflected in the low inflation premium then embedded in long-term bonds.  That this view was profoundly wrong soon became apparent.  The 1970s saw inflation and unemployment simultaneously at relatively elevated levels for some time.  The notion that this could occur was nowhere to be found in the conventional wisdom of the economic policy philosophy that developed out of the Keynesian revolution of the 1930s and its subsequent empirical applications.  Moreover, these models embodied the view that aggregate demand expansion, from almost any level, would permanently create new jobs.  When that expansion carried the economy beyond \"full employment\" there would be a cost in terms of higher inflation but only a one-time increase in inflation, so that there existed a permanent trade off between sustainable levels of inflation and employment.  The stagflation of the 1970s required a thorough conceptual overhaul of economic thinking and policymaking.  Monetarism, and new insights into the effects of anticipatory expectations on economic activity and price setting, competed strongly against the traditional Keynesianism.  Gradually the power of state intervention to achieve particular economic outcomes came to be seen as much more limited.  A consensus gradually emerged in the late 1970s that inflation destroyed jobs, or at least could not create them.  This view has become particularly evident in the communiques that have emanated from the high-level international gatherings of the past quarter century.  That inflation could reduce employment was a highly controversial subject in the mid-1970s when introduced into communique language drafts.  At the meetings I attended as Chairman of the Council of Economic Advisers, the notion invariably induced extended debates.  Today in similar communiques such language is accepted boiler plate and rarely the focus of discussion.  This shift in attitudes and understanding provided political support in 1980 and thereafter for the type of monetary policy required to rebalance the economy.  Despite waxing and waning over the decades, a deep-seated tension still exists over government's role as an economic policymaker.  This tension is evident in Congressional debates, campaign rhetoric, and our ubiquitous talk shows. Return to top   It should not be a surprise that the very same ambiguities and conflicts that characterize the rest of our political life have their reflection in the nation's current view of its central bank, the Federal Reserve.  With regard to monetary policy, the view or at least the suspicion still persists in some quarters that an activist, expansionary policy could yield dividends in terms of permanently higher output and employment.  Nonetheless, there is a grudging acceptance of the degree of independence afforded our institution, and an awareness that unless we are free of the appropriations process that our independence could be compromised.  It is generally recognized and appreciated that if the Federal Reserve's monetary policy decisions were subject to Congressional or Presidential override, short-term political forces would soon dominate.  The clear political preference for lower interest rates would unleash inflationary forces, inflicting severe damage on our economy.  Notwithstanding, the central bank has not been immune from the suspicion and lack of respect that has come to afflict virtually all institutions in our society since the traumas of Vietnam, Watergate, and the destabilizing inflation in the 1970s.  The Federal Reserve's most important mission, of course, is monetary policy.  I wish I could say that there is a bound volume of immutable instructions on my desk on how effectively to implement policy to achieve our goals of maximum employment, sustainable economic growth, and price stability.  Instead, we have to deal with a dynamic, continuously evolving economy whose structure appears to change from business cycle to business cycle, an issue I shall return to shortly.  Because monetary policy works with a lag, we need to be forward looking, taking actions to forestall imbalances that may not be visible for many months.  There is no alternative to basing actions on forecasts, at least implicitly.  It means that often we need to tighten or ease before the need for action is evident to the public at large, and that policy may have to reverse course from time to time as the underlying forces acting on the economy shift.  This process is not easy to get right at all times, and it is often difficult to convey to the American people, whose support is essential to our mission.  Because the Fed is perceived as being capable of significantly affecting the lives of all Americans, that we should be subject to constant scrutiny should not come as any surprise.  Indeed, speaking as a citizen, and not Fed Chairman, I would be concerned were it otherwise.  Our monetary policy independence is conditional on pursuing policies that are broadly acceptable to the American people and their representatives in the Congress.  Augmenting concerns about the Federal Reserve is the perception that we are a secretive organization, operating behind closed doors, not always in the interests of the nation as a whole.  This is regrettable, and we continuously strive to alter this misperception.  If we are to maintain the confidence of the American people, it is vitally important that, excepting the certain areas where the premature release of information could frustrate our legislated mission, the Fed must be as transparent as any agency of government.  It cannot be acceptable in a democratic society that a group of unelected individuals are vested with important responsibilities, without being open to full public scrutiny and accountability.  To be sure, if we are to carry out effectively the monetary policy mission the Congress has delegated to us, there are certain Federal Reserve deliberations that have to remain confidential for a period of time.  To open up our debates on monetary policy fully to immediate disclosure would unsettle financial markets and constrain our discussions in a manner that would undercut our ability to function.  Nonetheless, we continue to look for ways to expand the flow of information to the public without compromising our deliberations and purposes.  We have recently commenced to announce all policy actions immediately (federal funds rate changes as well as discount rate changes) and have expanded the minutes of the Federal Open Market Committee.  For many years, the Federal Reserve has maintained what we trust is a highly sophisticated day-by-day, near real-time, evaluation of the American economy and, where relevant, of foreign economies as well.  We are able, partly through our twelve Reserve Banks, to monitor continuously developments in the real world.  The information supplied about local conditions by the directors of the Reserve Banks has been frequently useful in identifying emerging national trends and in evaluating their underlying regional implications. Return to top   The issues with which we are confronted differ in urgency over time.  Inflation concerns were not a dominant factor in economic forecasting in the 1950s and early 1960s, for example.  Since the late 1970s, however, such concerns have become an important element in policymaking.  More recently inflation has been low, but its future course remains uncertain.  The development of comfortable product, but tight labor, markets has been a crucial factor in short-term economic forecasts of recent months a phenomenon for which there is scant historic precedent.  There is, regrettably, no simple model of the American economy that can effectively explain the levels of output, employment, and inflation.  In principle, there may be some unbelievably complex set of equations that does that.  But we have not been able to find them, and do not believe anyone else has either.  Consequently, we are led, of necessity, to employ ad hoc partial models and intensive informative analysis to aid in evaluating economic developments and implementing policy.  There is no alternative to this, though we continuously seek to enhance our knowledge to match the ever growing complexity of the world economy.  At different times in our history a varying set of simple indicators seemed successfully to summarize the state of monetary policy and its relationship to the economy.  Thus, during the decades of the 1970s and 1980s, trends in money supply, first M1, then M2, were useful guides.  We could convey the thrust of our policy with money supply targets, though we felt free to deviate from those targets for good reason.  This presumably helped the Congress, after the fact, to monitor our contribution to the performance of the economy.  I should add that during this period we maintained a fully detailed analysis of the economy, in part, to make sure that money supply was still emitting reliable signals about the state of the economy.  Unfortunately, money supply trends veered off path several years ago as a useful summary of the overall economy.  Thus, to keep the Congress informed on what we are doing, we have been required to explain the full complexity of the substance of our deliberations, and how we see economic relationships and evolving trends.  There are some indications that the money demand relationships to interest rates and income may be coming back on track.  It is too soon to tell, and in any event we can not in the future expect to rely a great deal on money supply in making monetary policy.  Still, if money growth is better behaved, it would be helpful in the conduct of policy and in our communications with the Congress and the public.  In the absence of simple, summary indicators, we will continue our detailed evaluation of economic developments.  As we seek price stability and maximum sustainable growth, the changing economic structures constantly present more analytic challenges.  I doubt the tasks will become any easier for the Federal Reserve as we move into the twenty-first century.  The Congress willing, we will remain as the guardian of the purchasing power of the dollar.  But one factor that will continue to complicate that task is the increasing difficulty of pinning down the notion of what constitutes a stable general price level.  When industrial product was the centerpiece of the economy during the first two-thirds of this century, our overall price indexes served us well.  Pricing a pound of electrolytic copper presented few definitional problems.  The price of a ton of cold rolled steel sheet, or a linear yard of cotton broad woven fabrics, could be reasonably compared over a period of years.  But as the century draws to a close, the simple notion of price has turned decidedly ambiguous.  What is the price of a unit of software or a legal opinion?  How does one evaluate the price change of a cataract operation over a ten-year period when the nature of the procedure and its impact on the patient changes so radically.  Indeed, how will we measure inflation, and the associated financial and real implications, in the twenty-first century when our data using current techniques could become increasingly less adequate to trace price trends over time?  So long as individuals make contractual arrangements for future payments valued in dollars, there must be a presumption on the part of those involved in the transaction about the future purchasing power of money.  No matter how complex individual products become, there will always be some general sense of the purchasing power of money both across time and across goods and services.  Hence, we must assume that embodied in all products is some unit of output and hence of price that is recognizable to producers and consumers and upon which they will base their decisions.  Doubtless, we will develop new techniques of price measurement to unearth them as the years go on.  It is crucial that we do, for inflation can destabilize an economy even if faulty price indexes fail to reveal it.  But where do we draw the line on what prices matter?  Certainly prices of goods and services now being produced our basic measure of inflation matter.  But what about futures prices or more importantly prices of claims on future goods and services, like equities, real estate, or other earning assets?  Are stability of these prices essential to the stability of the economy? Return to top   Clearly, sustained low inflation implies less uncertainty about the future, and lower risk premiums imply higher prices of stocks and other earning assets. We can see that in the inverse relationship exhibited by price/earnings ratios and the rate of inflation in the past.  But how do we know when irrational exuberance has unduly escalated asset values, which then become subject to unexpected and prolonged contractions as they have in Japan over the past decade?  And how do we factor that assessment into monetary policy?  We as central bankers need not be concerned if a collapsing financial asset bubble does not threaten to impair the real economy, its production, jobs, and price stability.  Indeed, the sharp stock market break of 1987 had few negative consequences for the economy.  But we should not underestimate or become complacent about the complexity of the interactions of asset markets and the economy.  Thus, evaluating shifts in balance sheets generally, and in asset prices particularly, must be an integral part of the development of monetary policy.  The public examination of Federal Reserve actions extends well beyond our stewardship of monetary policy.  Our overall management of the Federal Reserve System should, and does, come under considerable scrutiny by the Congress.  Since we expend unappropriated taxpayer funds, we have an especial obligation to be prudent and efficient with the use of those funds.  I am not particularly concerned about the one-third of our annual $2 billion budget that is expended to provide financial services to the private sector in competition with other providers.  Such services include the clearing of checks, the operation of the Fedwire system, and the processing of automated clearing house payments.  We are reimbursed for those services, and at competitive prices still make a reasonable profit for the Treasury.  If we became inefficient and uncompetitive, we would be priced out of the market, and eventually out of that line of business.  An additional one-sixth of our expenses are for providing services to the Treasury and other agencies of government for which we are subject to reimbursement with appropriated funds.  For the remainder, which mainly covers monetary policy, supervision and regulation of banks, and currency operations, we have to be especially diligent, for there is no external arbiter.  The rapidly changing technologies of recent years are pressing us to review thoroughly our structure and operations.  We have already engaged in major consolidations of operations when such consolidations have been made cost effective by the newer technologies.  Although in my experience the Federal Reserve System has been responsible, efficient, and has performed well, the rapidly changing external environment frequently requires us to rethink our role and mission.  Even where we can be competitive, it is not the role of a government agency, especially one vested with an unsurpassable credit rating, to seek out all available market opportunities.  Accordingly, where specific priced services have become effectively and competitively provided by private sector suppliers, the Federal Reserve needs to reassess whether the extent of our participation in those services fulfills a reasonable public purpose.  There are, of course, certain services that the Congress has, and will in the future, deem appropriate for us to subsidize.  But these areas presumably will remain circumscribed.  As a step in our periodic reassessment, a special committee of Federal Reserve Board governors and Reserve Bank presidents has been set up to review our priced services operations and other Systemwide activities.  Another step has been to engage outside accounting firms to audit the Federal Reserve Board and the twelve Reserve Banks.  We had been quite satisfied with the Board as general auditor of the Reserve Banks since 1914.  But the range of activities and the reach of the Federal Reserve in recent years requires us to address the perception that we are auditing ourselves without the full arm's length relationship deemed appropriate in today's environment.  Finally, the substantial changes under way in bank risk management are pressing us to continuously alter our modes of supervision and regulation to keep them as effective and efficient as possible.  Most importantly, all of our recent initiatives, especially the strengthening of the payments system and supervision, are critical to a central mission of the Federal Reserve, to maintain financial stability and reduce and contain systemic risks.  This mission is an extension of our monetary policy.  Our country can not enjoy the long-run \"maximum employment and stable prices\" objectives we are given for monetary policy if the financial system is unstable.  In this regard, the successes that most please us are not so much the visible problems that we solve, but rather all the potential crises that could have happened, but didn't.  Doubtless, the most important defense against such crises is prevention.  Recent mini-crises have identified the rapidly mushrooming payments system as the most vulnerable area of potential danger.  We have no tolerance for error in our electronic payment systems.  Like a breakdown in an electric power grid, small mishaps create large problems.  Consequently, we have endeavored in recent years, as the demands on our system have escalated (we clear $1-1/2 trillion a day on Fedwire), to build in significant safety redundancies.  This has been costly in terms of equipment and buildings.  Along with our other central bank colleagues, we are always looking for ways to reduce the risks that the failure of a single institution will ricochet around the world, shutting down much of the world payments system, and significantly undermining the world's economies.  Accordingly, we are endeavoring to get as close to a real time transaction, clearing, and settlement system as possible.  This would sharply reduce financial float and the risk of breakdown.  Meaningful progress has already been made in this direction.  This evening I have tried to put current central banking issues in historical context.  Monetary arrangements, including central banks, naturally are under constant scrutiny and criticism.  This is no less true of the Federal Reserve in 1996 than of the gold standard in 1896.  Central banks need to respond patiently and responsibly to the commentary, and we need to adapt to changing circumstances in markets and the economy.  A democratic society requires a stable and effectively functioning economy.  I trust that we and our successors at the Federal Reserve will be important contributors to that end.",
                  "1996-12-05 00:00:00"
                ],
                [
                  "3",
                  "Governor Edward W. Kelley, Jr.",
                  " It is a pleasure to be with you this morning to discuss private-sector payments risk management in our changing financial environment.  Private-sector clearing arrangements, including numerous clearinghouses, are an integral part of the payment system in the United States, and now is an appropriate time to encourage further debate and action on important risk management issues.  I would like to bring some perspective to this topic by first, outlining some of the broad forces affecting clearinghouses and other parts of the payment system; second, discussing the major risks and the different risk management techniques that clearinghouses employ; third, raising some key questions about risk controls for different types of clearing arrangements; and finally, highlighting recent policy developments in this area.  First, the broad forces shaping clearing arrangements both now and in the future.  To date, the growth of electronic payments has been an important force shaping our clearing systems.  In the large-value sector, the volume and value of electronic payments has continued to grow rapidly, heavily influenced, of course, by the growth of trading in the international markets, and electronics now dominates this activity.  In the small-value sector, ACH payments have also grown rapidly, although from a very low base.  An important issue is how fast electronic payments will grow in the near-to-medium term and whether they will begin to replace the check as one of the major payment instruments in the retail sector.  If this were to happen, there would presumably be corresponding adjustments in our clearing institutions.  One important phenomenon affecting the risks in check clearinghouses has been the trend toward converting different types of larger-value payments to electronic form, and processing these payments in environments with stronger risk controls.  The latest example of this trend came earlier this year when the money settlements for most stock trades were converted from checks and drafts to Fedwire fund transfers.  Another broad force that will affect clearinghouses is the advent of interstate branch banking.  Most directly, widespread interstate branch banking over the next few years could increase the number of checks and other items cleared as so-called \"on-us\" items, reducing the number of payments flowing through clearinghouses, and indeed, through correspondent banks and the Federal Reserve.  To some extent, such developments would tend to reduce interbank risk in the payment system.  As interstate banks participate in more and more clearinghouses, they may also begin to look for higher and more uniform risk management standards in the clearinghouses around the country.  In addition, interstate banking may well contribute to pressures to reduce the number of clearinghouses, with those remaining covering broader, even nationwide, geographic areas.  We have already seen evidence of this trend in check clearinghouses in a number of regions.  Of course, the prospects for clearinghouse consolidation would be heavily influenced by the degree to which economies of scale exist in current operations and whether new technologies and organizational techniques can be brought to bear on traditional practices. Return to top  To the extent new clearing arrangements and technologies are adopted, there may also be significant new opportunities to improve risk management.  For example, technological improvements and declining computing costs might help increase the use of automated risk management systems in clearing arrangements for retail payments, which have not traditionally employed strong risk controls.  Let me turn to the types of risks that exist in clearing arrangements.  One key type of risk is interbank credit risk.  In the clearinghouse context, this is the financial risk that a bank or other participant will default on its payment or settlement obligations to the clearing group when they are due, causing losses to other participants.  There is also liquidity risk.  If settlement payments are delayed or otherwise not completed on time, one or more banks in a clearinghouse, for example, might be short of cash, which would prevent the completion of other transactions.  The significance of this risk will usually depend on the size and intraday timing of clearinghouse settlements.  Further, there are legal risks.  There has been much discussion over the past few years, for example, of the need for strong legal foundations for bilateral and multilateral netting arrangements, including clearinghouse arrangements.  I would note that significant progress has been made on this front in the United States with changes in netting law.  There are also operational and security risks.  Concerns about these risks are often greatest in the wholesale payments area, where the dollar flows are largest.  However, operational and security breakdowns could pose very significant problems for retail payment systems, especially if large numbers of payment items were involved.  You are no doubt aware of publicity surrounding these risks in connection with the development of emerging payment technologies, such as stored-value cards, Internet-based payment systems, and new retail banking technologies generally.  Discussions have centered, for example, on the use of the Internet or other \"open networks\" for delivering banking services and making payments.  One can also imagine that clearinghouses or other multilateral arrangements might be developed for some of these new payment technologies.  Risks related to operational and security failures could be a very important component of the risks faced by such new clearing arrangements.  I would urge that all banking organizations take these operational risks seriously and act with great prudence in evaluating and managing them.  A fundamental concern of central banks, of course, is systemic risk.  This can involve risks that one bank's problem will spill over onto others, risks that whole clearing systems may cease to operate effectively, and even more broadly, risks that unexpected events will destabilize the banking system as a whole.  It is this type of concern that has motivated a sustained effort by the international central banking community in a number of areas.  In the payment field, concerns about systemic risk have led central banks to call for reductions in settlement risk, in general, and stronger clearing and settlement arrangements, in particular.  The usual focus of concern is on payment systems that are explicitly designed to handle large-value payments.  But the same types of risk   credit, liquidity, legal, operational, and systemic   are often present in clearing systems for smaller-value payments; only the scale of risk is different.  It is also important to recognize that although the average dollar value of daily clearings and settlements may be relatively low, the number of checks or other items in the daily clearings may be very high.  These payments may include paychecks, corporate payments to suppliers and securities holders, and other routine but very important payments whose completion we take for granted as part of the normal functioning of the economy.  Thus, a settlement failure in a check clearinghouse, for example, could be extremely disruptive to the banking system, and even to segments of the economy more broadly, if many thousands of payments were returned or not completed on time.  Let me turn now to a variety of techniques for risk control commonly used by clearinghouses in the wholesale financial markets to control interbank credit, liquidity, and systemic risks.  These are clearinghouses for payments and securities as well as futures, options, and foreign exchange contracts.   Their risk control techniques often encompass membership standards relating to operational expertise and creditworthiness. Most clearinghouses also designate a risk manager along with a risk management committee.  Further, the clearing rules and operational systems typically implement some type of credit and liquidity risk limits, such as caps on net debit positions.  For many clearinghouses, limits are enforced in real time.  In some, certain limits are enforced after the fact, provided members remain in good standing.  To ensure that settlement can occur even if a member defaults, clearinghouses typically employ backstop liquidity resources, such as margin or collateral deposits, participants' funds, and lines of credit.  Loss sharing rules are intended to allocate credit losses unambiguously to surviving members, in the event that a participant's default would not be covered by its collateral or other funds at the clearinghouse.  For what we traditionally think of as \"small-value\" payments, however, the clearinghouse has often been treated simply as a convenient way to exchange bundles of checks and other items and to administer settlements.  Although a handful of check and ACH clearinghouses use some more advanced risk controls, the vast majority seem to take the approach that if anything goes wrong, clearinghouse participants will take two aspirin and return payments in the morning.  While this point of view is not necessarily wrong, and may be quite cost-effective when amounts at risk are low, it also should not be defended simply because we have always done things this way.  Instead, we need to ask ourselves some basic questions about the reasons why risks and risk controls have been viewed differently for different clearinghouses. First, does the type of instrument determine the types of risk and appropriate controls?  For example, is one method of risk control appropriate for credit transfers and another for debit transfers?  Second, does the technology matter?  Is one type of risk control appropriate for paper-based instruments such as checks, and another for similar transfers made electronically, such as ACH debit transfers?  Is one type of risk control appropriate for batch-processing systems and another type for real-time processing systems?  Third, does scale matter?  Are stronger risk controls appropriate if large systemic risks are generated by huge daily values of payments and settlements, but not if daily payment flows are relatively small?  If you believe that only the amount of dollars at risk matters, what about the potential disruption in the banking system that could occur if one of the larger check clearinghouses were to fail?  Fourth, do the participants matter?  Is one standard of risk control appropriate for highly creditworthy institutions and another for less creditworthy institutions?  Should risk controls vary by institutional type of participant?  In addition, since many institutions participate in more than one clearinghouse, do we get too limited a picture of risk and risk management if we analyze clearinghouses individually? Return to top  Finally, are there minimum risk standards that all clearing houses should meet or do risk profiles vary across different organizations, making such standards awkward and unnecessary?  And if there are minimum standards, can they be met by different risk control methods?  Without endeavoring to give specific answers to these questions this morning, let me turn to the development of central bank policy toward private clearinghouses over the past few years.  Clearinghouse risks and many of the risk management techniques I have mentioned have been analyzed in a series of reports prepared by the G-10 central banks and published by the Bank for International Settlements.  The key report on clearing arrangements that employ multilateral netting was the 1990 \"Report of the Committee on Interbank Netting Schemes,\" known as the Lamfalussy Report.  This report depended heavily on earlier work on netting arrangements by the Federal Reserve and the U.S. banking industry.  In late 1994, the Board formally adopted the Lamfalussy Minimum Standards for controlling risk in netting systems by incorporating it into our policy statement on large-dollar payments risk.  At that time, however, the Board announced that, for the time being, it would not apply the large-dollar policy statement to clearinghouses that use batch processing operations.  Since the Board's large-dollar policy statement was adopted, we were pleased to see that the NOCH/NACHA Task Force on Settlement Risk Management has used the type of risk analysis employed in the policy statement to evaluate the risks in check and ACH clearinghouses.  This is an important step in establishing a firm consensus on the risk analysis framework that is appropriate for such private-sector clearinghouses.  The report does not identify significant systemic risks or call for more highly developed risk controls in these clearinghouses.  However, the report does urge the private sector to take more definitive steps to evaluate the risks in clearinghouses and stronger actions to strengthen risk management where needed.  The emphasis in the report on voluntary efforts by the banking industry and clearinghouse associations is welcome.  In the United States, it has often been the clearinghouse participants themselves that have designed and pressed for the most innovative and effective tools for risk management.  We would welcome further steps along these lines.  The Task Force Report also raises the question of whether the Federal Reserve could offer improved net settlement services to the banking industry that would also serve to reduce interbank risk.  This is a question that I believe has become increasingly important, particularly with the advent of interstate branch banking and the growth of clearinghouses offering nationwide services.  Currently, the Federal Reserve offers a same-day net settlement service to national clearinghouses in which banks use the Fedwire to execute the fund transfers necessary to complete their multilateral net settlements each day.  This model has three very significant virtues from the point of view of risk control:  It is fast; it has the strongest real-time risk controls employed by the Federal Reserve; and settlement is normally final soon after the settlement process starts.  These characteristics greatly speed up the final transfer of funds and the successful completion of settlement.  The result is that the duration of interbank risk exposures, typically overnight exposures in check clearinghouses, is shortened significantly.  Over the past few years, these risk reduction benefits have helped increase interest in the Federal Reserve's national same-day settlement service.  Some have asked whether the beneficial risk reduction characteristics of the national Fedwire-based net settlement service can be retained but offered in a somewhat more convenient format.  The Federal Reserve staff is actively reviewing this possibility along with the Board's general risk policies relating to smaller-dollar clearing arrangements.  I expect that there will be good progress to report on these issues relatively early next year.  Let me conclude with three observations.  First, it is encouraging that the banking industry is becoming more sensitized to issues of risk in check, ACH, and similar clearing arrangements.  Too often, our attitude has been that if there are strong risk controls on the large-dollar systems, we can simply ignore risk in the rest of the clearing infrastructure.  Second, those with a direct stake in individual clearing systems need to act on their growing sensitivity to risk and address the need to strengthen risk management.  The types of concerns that I outlined above need to be analyzed in the context of specific clearinghouses and specific control systems.  We believe that this is an important job of the owners and participants.  Finally, we need to ask ourselves why, in an era when electronic technology has made instantaneous communication and final fund transfers possible, we still incur the risks of conducting multilateral interbank settlements that are not final until the next banking day.  Clearly we should not allow long-standing operational conventions to dictate the design of interbank settlements, and thereby increase payment-system risk, if these conventions are now obsolete and improvements are possible.  As I noted, the Federal Reserve is actively analyzing clearinghouse developments and reviewing its small-dollar netting policies.  To date, the work of the private sector has been encouraging.  However, it is clear that the job of improving risk management is not finished.  All of us have more work to do.  Indeed, improving payment risk management in a changing environment is an ongoing responsibility.",
                  "1996-12-03 00:00:00"
                ],
                [
                  "4",
                  "Governor Susan M. Phillips",
                  "Supervisory and Regulatory Responses to Financial Innovation and Industry Dynamics  It is a pleasure to be here and participate in your discussions of current changes in bank regulatory policies.  In your program this morning, you have already heard a lot about the Federal Reserve Board's Regulation Y proposal, and I will not repeat the details.  Still, I think it would be useful to highlight two of the key principles the Board identified in seeking comment on Regulation Y   two principles that I believe illustrate a more general restructuring of the Board's overall approach to regulation and supervision.  These principles also animate the Board's recent proposals in the section 20 area and elsewhere.   First, in proposing to expand the laundry list of activities in which a bank holding company may engage, the Board stated that, to the extent possible, the restrictions a bank holding company faces in conducting a specific activity should be no more onerous than those applying to an insured depository institution conducting the same activity.   Second, in proposing to streamline the application process for bank holding company acquisitions, the Board stated that review of those applications should focus on how the proposal would affect the organization   as opposed to serving as a vehicle for comprehensively evaluating and addressing supervisory issues at the applicant organization.  Put another way, well-managed, well-capitalized institutions who have demonstrated that they are serving the needs of their community should have greater freedom to expand and innovate.   I believe these two principles reflect the Board's recognition that technological and financial innovation is remaking the banking industry.  Regulatory and supervisory approaches should also adapt to the changing environment. Return to top Regulation Y and Section 20 Initiatives As you know, the dramatic changes which have swept over the banking industry the past several years have also affected the entire financial services industry.  Advances in telecommunications and computer technology have provided banks and their competitors with new and more efficient opportunities to expand regionally, nationally and globally.  At the same time financial innovation has enabled institutions to fine tune and expand product lines and activities.   The structure of the industry is also changing as the recent wave of mergers among larger organizations and the advent of true interstate banking speed the pace of industry consolidation.  Despite this consolidation, however, competition in the industry is increasing.  Smaller banks are becoming more efficient, and the competition with nonbank financial institutions is growing steadily.   As a result of all these changes, the banking industry is now competing with an increasing number of financial service providers on a dynamic playing field.  Unfortunately, the nation's banking laws have not been updated to reflect this changing environment.  As the risks of holding company activities become increasingly transparent, it becomes increasingly anomalous that the banking laws severely restrict two banking related activities   underwriting and dealing in securities and insurance.  Except for some types of insurance underwriting, these activities are generally no more risky, and often significantly less risky, than many activities in which banks routinely engage   namely, lending.   Although I remain hopeful that Congress will address some of these issues, we at the Board are trying to provide banks as much latitude, commensurate with risk, that existing laws allow.  We have recognized in the Regulation Y proposal that if banks may engage in a given activity, there is no logic in prohibiting or imposing any additional restrictions on that activity when it is conducted in a holding company.   Similarly, in the section 20 arena, the Board recently eliminated a restriction on cross-marketing and employee interlocks between a bank and a securities affiliate, and substantially reduced restrictions on director and officer interlocks.  Here again, part of the calculus was whether there was anything unique to a section 20 subsidiary that warranted firewalls that are not imposed on any other type of bank affiliate engaged in activities posing similar risks.  The answer was generally, \"No.\"   I expect that the Board will be asking the same question when we undertake a more comprehensive review of the other firewalls in the coming months.  While there may be legal or reputational risks unique to affiliation with a securities firm that justify some of the existing restrictions, many firewalls may not address such risks and thus can no longer be justified.   Finally, I believe that these issues will be hotly debated in the coming months as Congress considers repealing not only section 20 of the Glass-Steagall Act, but all of the Glass-Steagall Act.  I expect Congress will also consider the repercussions of the Comptroller's decision of last week to allow a bank's operating subsidiaries to engage in activities forbidden the bank.  Here the debate becomes more subtle   not about whether an activity is appropriate for a bank holding company, but rather where in the bank holding company it should be conducted.  In particular, should riskier activities be conducted in separately capitalized affiliates of banks, or as subsidiaries of banks, under the federal safety net and with the benefit of the federal subsidy inherent in that safety net.  There also appear to me some unanswered legal and accounting questions relating to the separateness of a bank and its operating subsidiary. Return to top Changes in Bank Supervision As the industry changes, the nature of supervision is also undergoing significant change.  The traditional goals of supervisors remain the same   that is, to ensure the safety and soundness of financial institutions so that they do not become a source of systemic risk, pose a threat to the payment system, or burden taxpayers with unnecessary losses.   However, supervisors are looking to accomplish these goals in ways that are more risk-focused and burden-sensitive.  An example of such change that was put forward in the Regulation Y proposal is the reassessment of the role of an application in the supervisory process.  This step parallels recent Congressional action to eliminate the prior approval process entirely for strong bank holding companies wishing to engage in previously approved nonbanking activities   legislation proposed and supported by the Board.   In the past, the Board may have tended to use the application process to address and resolve supervisory issues at the applicant organization   sometimes involving matters that had little to do with the proposed acquisition or activity.  The Board's proposal to limit the application process to ensuring that it assesses only the pertinent issues relating to an application, including the statutory and regulatory factors the Board must consider, clearly signals that the Board intends to reduce the role of the application process as a supervisory tool.  Supervisory matters that are not significant to an organization's overall well-being or which are not related to a specific application under consideration are best addressed through other, more targeted supervisory actions.  These tools include the advancement of guidance on sound banking practices, enhanced off-site surveillance, the move to risk-focused examinations, and an increasing emphasis on improving market transparency through better public disclosure of the risk profiles of financial institutions.  I believe these initiatives are more efficient and effective in meeting supervisory goals and would like to briefly discuss some initiatives in each of these areas.   First, we are expanding efforts to promote sound banking practices.  Through our evaluations of many institutions, we as regulators are in a unique position to identify and promote sound risk management practices within the industry.  In earlier years, supervisors used guidance for relatively narrow purposes typically to advise examiners or bankers on interpretations of existing regulations or procedures for compliance.  Today, guidance is moving away from narrow, compliance-oriented prescriptions toward the identification and dissemination of sound practices for managing the risks involved in the various activities banks conduct.   Please note my emphasis on \"sound,\" not \"best,\" practices.  Sound practices reflect those minimum principles to be employed to ensure that the activity is conducted prudently.  Best practice, in my view, can and does occur in institutions of every size, shape and level of sophistication, but supervisors should focus on sound practices and leave the determination of what is \"best\" to the judgment of individual institutions.   For example, since 1993, the U.S. banking agencies have issued a series of instructions, policy statements, and examination manuals stressing the importance of managing various risks posed by the institution's activities.  The most notable example is the guidance issued in 1993 and 1994 on derivatives and trading activities.  This initiative has continued to encompass investment activities, and, this summer, interagency guidance on sound practices for managing interest rate risk exposures was issued.  I believe the dissemination of this type of guidance is a good example of supervisors adding value, and we expect to continue to emphasize this approach in the future.  We are also attempting to make greater use of the banking industry's sound, internally developed models and practices in risk management in order to reduce regulatory burden and to improve the effectiveness of our supervision.  For example, the agencies' newly revised capital standards for market risk related to a bank's trading activities will permit large trading banks to use their internal \"value-at-risk\" models to calculate their capital requirements for market risk, subject to examiner oversight and a few regulatory constraints.  Another area where regulators are innovating is in the examination process.   The cornerstone of the bank supervisory process is the verification of prudent practices and financial condition through on-site examinations, coupled with off-site surveillance.  Traditionally, on-site examinations have focused on compliance issues and verifying the condition of the institution at a point in time by reconciling accounts, testing individual transactions and performing ratio analysis.  This process is changing.  For example, examiners are now placing more emphasis on evaluating the soundness of a bank's process for managing and controlling risks.  Testing the soundness of the institution's risk management and internal control processes provides greater assurance of an institution's soundness on an ongoing basis.  To fully implement this approach, this year the Federal Reserve began assigning a formal rating to risk management in our examination reports.  This change reflects the increasing importance we place on sound management and adequate internal controls.  To improve the examination process, the Federal Reserve and other banking agencies are also emphasizing more pre-visitation planning in order to better identify those areas of a bank's activities that pose the greatest risk.  In other words, the examination scope is now more customized and focused.  We are also making greater use of computer technology in the examination process, using automated systems that permit examiners to download data from a bank's computer, analyze portfolios on their personal computers, and identify concentrations and other characteristics within the bank's loan portfolio.  As a result, examiners should be able to reduce materially the amount of time they spend on manual operations and should be able to devote more time to identifying and evaluating risks.  I would emphasize, however, that although we are revising the on-site examination process, the Board remains convinced of its fundamental importance.  Although performance-based regulation has much to commend it, and is already used as a tool by all the agencies, we find that our examiners generally detect problems before they manifest themselves in lower capital ratios, downgrades from rating services, or criticism from outside auditors.  Simply put, there really is no substitute for a hands-on review by persons unbeholden in any way to the institution.  Another area of innovative change relates to surveillance activities between on-site examinations.  Traditionally, surveillance efforts have relied on standardized ratios and screens compiled through regulatory reporting forms.  However, those screens are sometimes not flexible or comprehensive enough to provide a true profile of the bank's risk.  One enhancement we are making to our surveillance activities is to tailor the information we collect to the bank's activities, including making greater use of the bank's own internal management reports and the results of internal risk models.  In recent years, for example, the Federal Reserve has begun to collect internal loan classification reports prepared by most of our larger banks, as well as other information generated by their internal risk management systems.  Such changes merely reflect the evolving nature of bank activities and the improved procedures banks have for measuring risks and managing their activities.  As with examinations, disclosure practices of the past also focused narrowly on the financial condition of the institution at a point in time, using conventional accounting and regulatory measures.  Today, however, disclosures are expanding to include a description not only of the level of risk taken by the company but also of management's philosophy for managing and controlling risk.  This improved transparency enhances market discipline and rewards prudent management.  We have already done much to improve disclosures for derivatives and market risks, and we will continue to urge better and more broadly based disclosure on all of an institution's major activities and exposures. Return to top Conclusion I hope this review of supervisory initiatives illustrates that supervisors are making concerted efforts to keep pace with market practices and financial innovations.  Just as innovation poses new challenges to the industry, it also poses challenges to supervisors.  I believe the Board is responding and is making significant progress in adapting its existing supervisory regimes.  But as we make changes to our own processes to make regulations less burdensome and to allow increased activities by banking organizations, we are finding that the supervisory process is becoming more important, not less important, in meeting our responsibilities for a safe and sound banking system.   Thank you.",
                  "1996-11-25 00:00:00"
                ],
                [
                  "5",
                  "Governor Laurence H. Meyer",
                  "The Transformation of the U.S. Banking Industry and Resulting Challenges to Regulators Good morning.  It is a pleasure to be here on Ohio Bankers Day. The over-riding theme of my remarks is the profound transformation the banking industry has undergone over the last 15 years or so and the challenges that these changes pose to bank regulators.  At the end, I hope to have time to take some questions and learn where you think the banking industry is going, and how consistent with our responsibilities regulators can promote a more efficient, resilient, and profitable financial services industry.  I plan to learn as much or more from you as you learn from me. The Role of Banks Let me begin with a few observations about the importance of the banking industry in the economy and why banking receives such special attention in terms of regulation. Banks, like other financial intermediaries, pool and absorb risks for depositors and provide stable sources of investment and working capital funds for nonfinancial industries. Banks also provide a unique mix of services among all financial intermediaries, including a \"safe haven\" for small, unsophisticated investors through insured deposits, an important source of funds for small borrowers who often have limited access to other sources of external finance, a smoothly functioning payments system that allows financial and real resources to flow relatively freely to their highest-return uses, a conduit for monetary policy, and a backup source of liquidity for any sector in temporary difficulty through its access to the discount window. Throughout all the changes of the past, and through all the changes to the banking industry in the foreseeable future, banks will continue to perform these important functions, and a goal of bank regulators is to make sure that there is a healthy banking industry to do so. Return to top The Rationale for Bank Regulation But there are two particularly important characteristics of the banking system that demand our attention as regulators indeed, are critical to understanding why there are bank regulators.  First, banks have access to a government safety net through deposit insurance, the discount window, and payment system guarantees.  This gives the government a direct stake in keeping bank risks under control, just like a private insurance company has a stake in controlling the risks of policyholders.  Because deposit insurance can never be fully and accurately priced, it is necessary for us to monitor and sometimes to act to control bank risks in order to protect the potential call on taxpayers.  It is also important to understand that an unintended consequence of the safety net is that it creates or augments incentives for some banks to take additional risks.  That is, the safety net creates moral hazard incentives to gamble because the safety net and potentially taxpayers may absorb most of the losses if the gamble fails.  Deposit insurance gets in the way of the depositors signaling a bank when it takes excessive risks. The second characteristic of banks that requires the special attention of regulators is that banks are capable of being the conduits of systemic risk and crisis in financial markets.  A breakdown of the payments system or other contagion effect that hampers the ability of banks to intermediate credit flows could have serious adverse consequences for the economy, again requiring the special attention of regulators to bank risks. The challenge is to strike a balance in regulation so that, on the one hand, taxpayers are protected, extensions of the safety net are avoided, and moral hazard incentives are mitigated without, on the other hand, undermining the competitiveness of the banking industry and its ability to take risk, and therefore damaging the entity the regulators are trying to protect. Return to top The Evolution of Bank Regulation Although this rationale for bank regulation has not changed, in the last decade and a half there has been a significant evolution in approach of regulators toward maintaining the safety and soundness of the banking industry.  From the 1930s through most of the 1970s, regulators focused on keeping the banking industry safe and sound by protecting banks from competition and by limiting the activities in which they could participate.  This meant, for example, prohibiting interstate banking, restricting the rates that banks could pay on deposits, and preventing commercial banks from competing in other product markets, such as investment banking.  During this period, the financial services industry was segmented into separate entities providing commercial banking, investment banking, insurance services, etc.  This separation was largely due to legislative and regulatory decisions.  A consequence of the separation was that firms in each segment of the financial services industry were protected from competition from firms providing the other services. Starting in the late 1970s, the changed economic environment along with advances in technology, financial innovations, and globalization resulted in increased competition to U.S. banks by thrifts, nondepository financial institutions, foreign banks, and the capital markets.  Higher and more variable interest rates, and the accompanying increased yield sensitivity of depositors and borrowers, contributed to the development of money market mutual funds as alternatives to bank deposits and the growth of finance companies and commercial paper as substitutes for bank loans. The increase in external competition brought a swift response from both banks and their regulators. Banks responded to the challenge by expanding in ways that they could, also taking advantage of improvements in technology and applied finance.  They expanded their roles as intermediaries through off-balance-sheet activities such as securitization, back-up lines of credit and derivatives, and, in the process, substituted fee income for some of the interest income lost through competition with other financial intermediaries. In addition, banks sought expanded powers to help them compete, including being able to cross state borders, set their own deposit rates and account types, and by the late-1980s expand into securities underwriting activities. Regulators responded to the new environment by reducing the regulatory burden on banks and allowing them to compete on a more level playing field with nonbanking firms.  That is, the new market realities required a reorientation in emphasis from protecting banks from competition to giving banks the opportunity to compete not only with other banks but with nonbank competitors as well.  By allowing banks to enter other states, set their own prices, and engage in other than traditional banking activities, the orientation of regulators evolved toward protecting the safety net while allowing banks to deliver financial services to the public efficiently, profitably, and with sufficient capital to be protected against unforeseen events. Return to top Structural Change in the Banking Industry As a result of this process of structural change, the banking industry of the mid-1990s in many ways hardly resembles that of the late 1970s and early 1980s.  Some of the major changes that I want to focus on are the increased consolidation of the industry, the decline in traditional banking services as a result of increased outside competition, the expansion in bank powers, including the move into nontraditional activities to offset the competition for their traditional products, the increased emphasis on risk management in response to the increased complexity of financial instruments and practices, and the evolution of capital standards and capital positions to keep abreast of the changing risk profiles of banking organization. Consolidation in the banking industry One of the most obvious and dramatic changes is the consolidation of the banking industry. The number of independent banking organizations by which I mean top-tier holding companies plus unaffiliated banks has shrunk by more than one-third since the late 1970s, from more than 12,000 to fewer than 8,000.  The percentage of banking assets controlled by organizations with more than $100 billion has about doubled, and is now close to a fifth of all U.S. banking assets, while the percentage of banking assets in banking organizations with less than $100 million in assets has dropped by half, from about 14 percent to 7 percent of industry assets. Much of the consolidation is a direct outgrowth of the removal of geographic restrictions on bank branching and holding company acquisitions by the individual states, a process that is now being extended by the Reagle-Neal Interstate Banking and Branch Efficiency Act of 1994.  This deregulation encourages the banking industry to become more efficient at serving the public’s needs by allowing the efficient competitors to succeed and manage more of the industry’s resources.  The banking industry has also become stronger through the geographic diversification of risks made possible by interstate banking. Importantly, the interstate expansion of large banks does not mean the end of small banks.  Past experience has consistently shown that when large banking organizations enter a new local market by acquisition, the existing small banks that are efficient can compete successfully and maintain their market shares and profitability.  We fully expect thousands of small banks to remain in business even after nationwide branching is fully implemented. The emergence of, and response to, increased outside competition: a decline in traditional banking and the growth of nontraditional activities Over the last 15 years, there has also been a substantial increase in competition to the U.S. banking industry from capital markets, less-regulated domestic financial institutions, and foreign institutions.  As a result, U.S. banks have lost substantial market shares of many of the asset and liability categories that were the mainstay of traditional banking.  However, these declines in market share for banks in traditional product lines do not suggest that the banking industry itself is in decline.  After factoring into the analysis the rapid expansion of nontraditional off-balance-sheet activities, research suggests that the banking industry continues to grow, although not as fast as financial markets as a whole.  The banking industry, for example, has grown at about the same rate as GDP and the new products of the banking industry such as derivative contracts and other off-balance-sheet activities have skyrocketed. The most important indicators of whether the banking industry is in decline measures of financial performance are even more positive.  The banking industry is profitable, able to raise capital in financial markets, and has a relatively high market-to-book ratio.  These performance indicators also suggest that resources will continue to flow into the industry, rather than out of the industry.  The evidence taken as a whole suggests that the banking industry is weathering the increase in outside competition and is competing well against it. Return to top The expansion of bank powers The powers of banking organizations also grew dramatically over this time period in two different ways.  First, in the early 1980s, the Monetary Control Act gave banks the right to set their own deposit interest rates and offer new types of accounts, such as household transactions accounts that paid market-based interest rates. Another major way in which banking organization powers expanded over this period was the increase in the number of banking activities permitted to nonbank affiliates of bank holding companies.  Regulators allowed bank holding companies to enter more and more product markets over this time period.  Bank holding companies can now have separately capitalized subsidiaries that offer investment advice, provide discount brokerage services, and underwrite both debt and equity securities, albeit under restricted circumstances.  The market also played a large part in blurring the old distinctions between banks and nonbanks, as other financial services companies began to offer more products with characteristics close to those of bank deposits and loans. Again, the regulatory shift in orientation was in large part a reaction to the market banks were given more power to compete with nonbanks in part because nonbanks were figuring out better ways to compete against banks. It is also notable that over time banks have taken much greater advantage of the powers they already had.  As I mentioned earlier, banks greatly increased their use of off-balance-sheet guarantees to follow some of their loan customers who chose to borrow their funds elsewhere, and banks were also active players in the new derivative products of the 1980s and 1990s. Increased emphasis on risk management and the growing importance of market risk Despite these many changes, the core business of banking has remained the measurement, acceptance, and management of risk, although a number of important developments over the last 15 to 20 years have improved the abilities of banks to perform these functions.  The most notable developments are in the area of market risks.  Derivative contracts such as futures and swaps are essentially new lines of business for banks in the last decade and a half, which allow banks to measure, accept, and manage market risks to a much greater extent than in the past. In the 1970s, banks primarily measured, accepted, and managed the credit risks of illiquid loans and dealt little with market risks other than minimal asset-liability duration matching.  The rapid developments in market risk tools have facilitated an expansion of the core business of banking to put an increased emphasis on market risks, but banks are nonetheless still primarily in the same core business of measuring, accepting, and managing risks. However, it is important to recognize that having access to improved risk management technologies does not necessarily make banks safer.  Despite the improvements in the abilities of banks to understand and control risks, the risks of the institutions themselves ultimately also depend importantly on the incentives of bank managers and owners to control risks, and on the economic environment in which they operate.  There is little benefit, and perhaps net costs, in having a bank manager know how to measure, accept, and manage risks accurately if this ability is used to take excessive risks that are largely borne by the federal safety net and potentially by taxpayers.  Similarly, when the economic environment turns against bank investments, many banks will become risky and some will fail, even if they have managed their risks fairly well. Return to top The source of the large number of bank failures in the 1980s and the dramatic improvement in the health of the banking system in the 1990s These caveats are well illustrated by comparing the circumstances of U.S. banks in the 1980s versus the 1990s.  During the 1980s, bank failures were increasing, and by the end of the decade banks were failing at the rate of about 200 per year.  Even greater problems were experienced by the savings and loan industry.  These problems have been largely attributed to two factors. First, when banks or savings and loans get into very low or negative capital positions, the moral hazard problem I discussed earlier may become more severe.  There is a possibility of purposely taking on additional risks to gamble their way out of trouble.  When there is little capital at risk, the owners get much of the benefits if the gamble pays off, and the safety net and taxpayers bear most of the losses if the gamble fails. Second, the 1980s saw a number of turbulent economic changes.  These included fluctuations in interest rates and inflation rates, swings in the prices of commercial real estate and junk bonds that could not be easily forecast, and regional recessions that caused significant numbers of problem loans.  These changes caused damage at many financial institutions, particularly those in geographically undiversified positions without sufficient capital to protect themselves. Given the poor condition of many banks as late as 1991, it is amazing how healthy the banking industry is now, having written off most of its bad assets, raised large amounts of capital, and returned to profitability, likely having its fifth straight year of record profits in 1996.  Bank failures have now retreated to at or near single digits per year.  Clearly, this turnaround is too rapid to be completely accounted for by technical and financial innovations in the measurement, acceptance, and management of risk, or by improvements in the diversification and capitalization of banks.  Changes in attitudes toward risk taking brought about by the higher capital standards and other factors, and changes in the economic environment have also played important roles in the improved health and wealth of the banking industry. The evolution of capital standards and capital positions The final development I will discuss is the evolution of the financial capital positions of U.S. banks, since capital is the cornerstone of defense against bank risks.  Capital serves two functions in this regard.  First, it helps improve the incentives of banks to keep their own risks under control, reducing moral hazard incentives to take those risks that are largely imposed on others. Second, capital is a buffer stock available to absorb risks and economic shocks without creating bankruptcy costs and systemic problems associated with the failure of financial institutions. A goal of capital requirements along with bank supervision and quality risk management by the banks themselves is to make the safety net a moot issue for most banks.  That is, by having enough capital available to absorb potential losses and having both the bank and supervisor carefully monitoring and acting to control portfolio risks, the moral hazard incentives of the safety net and the vulnerability of the deposit insurance funds can be kept to a minimum.  It is similarly true that the more we can do to keep risk to the safety net under control using capital and other tools, the more powers we can safely grant to banks without placing undue stress on the safety net or meaningfully expanding safety net protection to other activities. At the end of the 1970s, capital regulation was relatively ad hoc and depended largely on the judgment and discretion of the individual bank’s supervisors.  Starting in 1981, regulations required banks to hold capital equal to a flat percentage of their balance sheet assets.  The next refinement was based on Basle Accord risk-based capital standards adopted in 1988 and implemented starting in 1990 requiring banks to hold different amounts of capital depending on the perceived credit risk of different on- and off-balance-sheet assets.  In addition, to reduce discretion in the enforcement of the standards and the closure of capital-impaired banks, Congress included \"prompt corrective action\" provisions in the FDIC Improvement Act of 1991 (FDICIA). Under prompt corrective action, or PCA, banks with capital ratios below certain threshold values are subject to increasingly severe mandatory and discretionary sanctions.  Finally, risk-based capital standards which originally only covered credit risks are now being extended to cover market risks. The process by which the new market risk standards were arrived at is indicative of the new orientation toward incentive-based regulation, allowing well capitalized, efficient banks to compete and imposing costs more selectively on undercapitalized, poorly managed banks.  The standards also permit banks that are more efficient at monitoring and controlling their risks to hold less capital than inefficient banks.  These regulatory standards are much like what the market would do in the absence of the safety net.  The new standards, which apply to banks with substantial trading, allow banks to use their own internal models of risk that are employed in their everyday operations to determine the capital requirements on their trading books.  This approach also reflects a new effort to develop refinements in regulatory standards in cooperation with the industry, in part by better understanding the \"best practices\" that are evolving in the industry and using these as a basis for regulatory standards across the industry. A cumulative effect of the many changes in capital regulation in the 1980s and early 1990s, as well as other factors, is that banks have much higher capital ratios today than they did 15 years ago, and even 5 years ago.  This is especially true at the largest banking organizations.  For the banking industry as a whole, the equity-to-assets ratio rose from less than 6 percent at the end of the 1970s to over 8 percent in the mid-1990s.  For the largest banking organizations, the capital ratio rose from less than 4 percent to over 7 percent. Return to top The Implications of the Transformation of Banking for Bank Regulation We should not be too sanguine about bank capital, however.  While the current capital standards are significant improvements over what they replaced, they are still based on broad one-size-fits-all rules.  Moreover, the market has begun to focus more on the capital-risk trade-off: no large bank or parent banking organization, for example, has AAA long-term debt, and only a handful are rated AA, despite the capital ratios I just quoted.  Banks at the cutting edge are risk rating their loan portfolios and internally allocating capital to them for management and profitability analysis.  Such allocations are superior ways of developing capital allocation for individual banks. Perhaps we will be able in the future to harness banks’ internal capital allocations for regulatory purposes.  Indeed, the reason for choosing the topics I have discussed thus far is that these structural changes represent an on-going process and are going to continue to challenge us in the future.  In the final portion of my remarks, I will try to identify some of the most important challenges that regulators will face as a result of these changes. Maintaining local competition in the face of continued bank consolidation First, with regard to future banking industry consolidation, the Riegle-Neal Interstate Banking and Branching Efficiency Act of 1994 essentially expands the existing regional compacts to the nation as a whole, and overturns the McFadden Act prohibition on interstate branching.  Interstate branching to almost all the states is permitted as of June 1, 1997.  The removal of these artificial barriers to trade is beneficial and will likely improve efficiency and diversification of risks in the banking industry. The exact future structure of the banking industry is unknown, but presumably will be driven not just by the removal of legal barriers to competition, but by shifts in technology, efficiency, and risk diversification.  The firms with the greatest managerial efficiencies are expected to take over those with the lowest efficiencies and improve them.  Research in banking suggests that these differences in managerial efficiency are much larger than any scale and scope economies. Various models predict that several thousand banking organizations are likely to disappear under nationwide banking, but that the remaining banks will still number in the thousands, as small community banks that serve their constituents well are likely to remain in business. There appear to be two key challenges to regulators regarding consolidation.  The first is to be sure that there is adequate competition from banks and nonbanks in local banking markets. Research has suggested that high local market concentration leads to prices that are unfavorable to bank customers low deposit rates for retail depositors and high loan rates for small business loans.  High concentration may also lead to reduced managerial efficiency, as the price cushion provided by market power allows a \"quiet life\" for managers in which relatively little effort is required to be profitable.  Insuring an adequate amount of local-market competition is essential to avoid these potential problems. The second challenge brought on by consolidation is to make sure that mergers and acquisitions do not create excessive risks.  In this regard, it is important that capital be sufficient to cover any problems during the transition period when the banks and systems are learning to work together, on top of the normal risks of ongoing operations. The interaction of bank powers and bank structure The future expansion of banking organization powers also raises some challenges to regulators. Indeed, financial reform will likely be a high priority of the next Congress, perhaps including repeal of Glass-Steagall.  One of the results of financial reform, along the lines of the bill Congressman Leach introduced last session, would be the emergence of financial services holding companies that could include both commercial and investment banks.  There is also a prospect that banks might be able to expand into insurance activities as well.  This would take to a perhaps logical conclusion the recent blurring of the lines between financial services firms. Whether or not the Glass-Steagall Act is repealed, we face the challenges of insuring that the proposed recent expansion of bank powers through section 20 subsidiaries does not inadvertently expand the safety net protection afforded to banks to protect other, previously nonbank, activities. This would give an unfair subsidy to banking organizations. While there is no perfect system for allowing financial intermediaries to gain the most from the synergies of joint production while avoiding expansion of the safety net, there are several steps that seem likely to keep this problem under control.  First, we need to be sure to require plenty of capital in the bank to keep the value of access to the safety net low.  Second, we need to provide reasonable insulation of the bank from the risks of the nonbanking enterprises.  The Board believes that the best way to do this is by placing new activities in holding company subsidiaries, rather than in the bank itself or its subsidiaries.  The further the separation from the bank, the better is the insulation.  A third safeguard to protect the bank and prevent the expansion of the safety net subsidy is the adoption of prudential limitations through firewalls and rules that prohibit or limit certain bank and affiliate transactions.  While firewalls may temporarily bend under stress, they nonetheless serve a useful purpose.  On the other hand, we must strike a balance and not make the firewalls so rigid that they would eliminate the economic synergies between the banks and their affiliates.  In this spirit, the Board last month made an effort to modify firewalls to allow banks to achieve efficiency gains with respect to security underwriting in Section 20 affiliates without creating excessive risks. The issue of what bank structure is appropriate and prudent in light of expanded banking powers is a particularly controversial one.  While the Board’s view that the expanded powers should be carried out only in subsidiaries of the bank holding company was incorporated into the Congressman Leach’s unsuccessful financial modernization bill in the last Congress, this preference is not shared by all parties to this debate.  Some stress the costs associated with the holding company structure and  question its benefits from a safety and soundness perspective and, as a result, favor either allowing the new activities to be carried out in a subsidiary of the bank itself or at least allowing banks an option with respect to structural form. Return to top Staying up-to-date in the supervision of bank risk management as financial products and practices evolve  There will undoubtedly be further developments in the ways that banks perform their core functions of risk measurement, acceptance, and management as markets continue to evolve improved \"best practices\" in dealing with market and credit risks.  This evolution will continue to challenge regulators to keep capital standards and other risk monitoring and control mechanisms from falling too far behind.  One particular challenge is that the continued development of derivative products and other means of managing risks can also allow bank employees to take excessive risks and hide them from supervisors and perhaps from the owners of the bank.  It is difficult for regulators to quantify these risks, and even more difficult to design risk-based deposit insurance and risk-based capital systems that accurately incorporate these risks. In response, regulators will need to stick with capital as the cornerstone of defense against bank risks, both to reduce moral hazard incentives and to provide a buffer stock to absorb losses.  A challenge will be to continue to update the capital standards in line with current or not-too-out-of-date risk measurement techniques.  Expansion of the recently implemented \"internal models\" type of approach may be helpful in this regard, using, as I noted earlier, banks’ own risk measurements to help set their capital requirements.  In addition, many of the techniques used to quantify and control market risks may be transferable for use in quantifying and controlling credit risks in the future. The task of measuring capital and risks can also be made easier if bank portfolios are made somewhat more transparent.  Increased transparency would also facilitate market discipline a highly desirable goal in our rapidly changing financial environment.  A problem here is that it is not always clear how to best encourage transparency.  For example, partial market value accounting may involve more costs than benefits.  However, it seems clear that this is an issue that will remain on our plates for the foreseeable future. In addition, the capital standards can and should be augmented by bank supervisors in individual cases.  The risk-based capital standards and prompt corrective action rules are, and will remain, only minimum capital guidelines for normal circumstances.  Supervisors need to require additional capital when banks are explicitly taking additional risks that are not captured by the guidelines, or when bank risks are excessively opaque and it is too difficult to determine if excessive risks might be undertaken.  To accomplish this, it is important to continue to examine banks on a regular basis.  There is simply no market substitute for the type of information that can be gathered under the auspices of a bank examination with access to the complete records of a bank. However, as financial transactions become more complex, supervisors cannot be expected to monitor every detail.  Increasingly, supervisors will focus on banks’ risk management procedures. Banks will have to convince supervisors that they have prudent risk management procedures and policies and that the bank follows them.  Increasingly, supervisors will emphasize your process of risk management and control, and proof that you are using those techniques, in order to determine whether your capital is adequate for your risk profile and procedures. Reducing the burden of regulation and increasing the uniformity in regulation across banking agencies While recent banking legislation significantly reduced the regulatory burdens on the banking industry, we all realize that keeping the costs of supervision and regulation low is an important on-going task for all parties.  It is particularly important for the federal banking agencies to continue efforts at improved cooperation with each other, including standardization of certain policies and procedures and data collection.  In short, we must try to reap the potential benefits of multiple regulators in terms of encouraging innovation and providing checks and balances on regulatory excess, without incurring the potential costs of \"competition in laxity\" and excessive overlap and duplication of efforts.  I am optimistic that this can be done, perhaps by augmenting the role of the FFEIC. Conclusion I want to leave some time for questions, so let me just sum up with a few comments.  The banking industry has been transformed over the last decade and a half, and regulators have tried to adopt policies to allow the industry to become stronger, more efficient, and better able to meet the competition without placing undue stress on the safety net.  This represents a change from an earlier regulatory philosophy of protecting banks from competition, and I think the change is in the right direction.  We still face a lot of challenges from the continuing evolution and consolidation of the industry, but we will do our best at trying to let the strong, efficient banks compete, so long as they are not imposing significant risks on the safety net and taxpayers.",
                  "1996-11-21 00:00:00"
                ],
                [
                  "6",
                  "Chairman Alan Greenspan",
                  "Banking in the Global Marketplace  It is again a pleasure to be here in Tokyo at the invitation of the Bank of Japan. Tokyo's role as one of the world's key financial centers depends importantly on the confidence of the international community in the Bank of Japan and the great respect in which it is held.  As Tokyo continues to evolve as a financial center, the role of the Bank of Japan will correspondingly increase, as well.  Frankly, when I think about the potential for serious disruption in international financial markets, I take considerable comfort from the high degree of cooperation between the Bank of Japan and the Federal Reserve, with contacts at all levels and covering a full range of issues very strong and getting stronger.  The last time I addressed this distinguished group was four years ago.  Since then, of course, much has happened in international financial markets.  The processes of growth, globalization, and innovation have continued.  Extraordinary advances in risk measurement and risk management and in sensitivity to risks in general have been perhaps the most salutary aspects of that ongoing evolution.  Other developments, including the financial problems of banks and other financial institutions in Japan, but also, for example, the Mexican peso crisis and Barings, were less favorable and have posed serious challenges.  Nonetheless, I believe that from a long-term perspective the responses to those challenges will prove to have had important positive consequences as well.  One notable response to the developments in international financial markets came from the leaders of the G-7 countries.  At the G-7 Summit meeting in Halifax in 1995 and again in Lyon in 1996, they set in motion a series of initiatives aimed at promoting stability in international markets.  I will say a few words about some of those initiatives in a few moments, because I think they deserve our attention.  However, before doing so, I will focus my remarks this afternoon on the nature of supervision, the sharing of risks between the private and the public sector, and the implications for the behavior of banks and bank supervisors. Return to top The nature of supervision and the sharing of risks  It is useful, I believe, to begin by reminding ourselves just why there is bank supervision and regulation.  At bottom, of course, is the historical experience of the effects on the real economy of financial market disruptions and bank failures, especially when the disruptions and failures spread beyond the initial impetus.  But it is critical also to understand some key implications of the safety net provided to banks in most countries, involving in the case of the United States, for example, a system of deposit insurance, payment guarantees, and discount window credit.  Since the safety net makes bank creditors feel safer, the banking system is larger, more stable, and more able to take risk and extend more credit than otherwise would be the case.  In the process, banks contribute significantly to economic growth.  The safety net, however, also engenders a disconnect between risk-taking by banks and banks' cost of capital and funding and hence has made necessary a degree of supervision and regulation that would not be necessary without the safety net.  That is, regulators are compelled to act as a surrogate for market discipline since the market signals that usually accompany excessive risk-taking are substantially muted, in part because the costs of deposit insurance or of access to the safety net more generally do not, and probably cannot, vary sufficiently with risk.  The problems that arise from the short-circuiting of the pressures of market discipline have led us increasingly to understand that the ideal strategy for supervision and regulation is to simulate the market responses that would occur if there were no safety net, but without giving up the basic requirement that financial market disruptions be minimized.  These implications of the safety net highlight the dilemma of the regulator.  How do we preserve an innovative and flexible banking system without either exposing the taxpayer to excessive potential costs or the financial system to excessive systemic risk? Return to top  In addressing these issues, it is important to remember that many of the benefits banks provide modern societies derive from their willingness to take risks and from their use of a relatively high degree of financial leverage.  Through leverage, in the form principally of taking deposits, banks perform a critical role in the financial intermediation process, providing savers with additional investment choices and borrowers with a greater range of sources of credit, thereby facilitating a more efficient allocation of resources and contributing importantly to greater economic growth.  Indeed, it has been the evident value of intermediation and leverage that has shaped the development of our financial systems from the earliest times certainly since Renaissance goldsmiths discovered that lending out deposited gold was feasible and profitable.  Of course, this same leverage and risk-taking also greatly increase the possibility of bank failure.  Without leverage, losses from risk-taking would be absorbed by a bank's owners, virtually eliminating the chance that the bank would be unable to meet its obligations in the case of a \"failure.\"  Some failures can be of a bank's own making, resulting, for example, from poor credit judgments.  For the most part, these failures are a normal and important part of the market process and provide discipline and information to other participants regarding the level of business risks.  Other failures can result from, and contribute to, the rare episodes of severe economic or market turmoil that affect broad segments of an economy and are not the consequence of the imprudence of individual banks. Because of important roles that banks and other financial intermediaries play in our financial systems, such failures could have large ripple effects that spread throughout business and financial markets at great costs.  Over time, societies have concluded that leverage and intermediation are essential to economic performance, but also that some bank failures could have unacceptable economic costs.  In response, central banks were created and were accorded new responsibilities, and what we now call prudential regulation evolved.  In the United States, these initiatives took the shape of the creation of the Federal Reserve in 1913 after several financial panics in the late 19th and early 20th centuries, and of federal deposit insurance and a broadened role for bank supervisors in the 1930s.  While the responses in other countries were often less overt, they were generally still significant in their effects.  This expanded role of governments, central banks, and bank supervisors implies a complex approach to managing and even sharing the risks of failure between governments and privately owned banks.  Some of what central banks do might be termed \"shaping\" or reducing some kinds of risks, primarily by providing liquidity in certain situations to reduce the odds of extreme market outcomes, in which uncertainty feeds market panics. Traditionally this was accomplished by making discount or Lombard facilities available, so that depositories could turn illiquid assets into liquid resources and not exacerbate unsettled market conditions by forced selling of such assets or calling loans.  Similarly, open market operations, in situations like that which followed the 1987 stock market crash, satisfy increased needs for liquidity that otherwise could feed cumulative, self-reinforcing, contractions across many financial markets. Return to top  Guarding against systemic problems also has involved, on very rare occasions, an element of more overt risk-sharing, in which the government or more accurately the taxpayer is potentially asked to bear some of the cost of failure.  Activating such risk-sharing quite appropriately occurs at most maybe two or three times a century.  The willingness to do so arises from society's judgment that some bank failures may have serious adverse effects on the entire economy and that requiring banks to carry enough capital to avoid any risk of failure under all circumstances itself would have unacceptable costs in terms of reduced intermediation.  If banks had to absorb all financial risk, then the degree to which they could leverage, of necessity, would be limited, and their contribution to economic growth, modest.  Risk-sharing encourages leverage and intermediation.  Eliminating risk-sharing and asking banks to remove the possibility of failure would lead to a much smaller banking system.  To attract or at least retain equity capital, a private financial institution must earn, at a minimum, the overall economy's rate of return, adjusted for risk.  In their management of market or credit risk, well-run banks carefully consider potential losses from most possible market outcomes and hold sufficient capital to protect themselves from all but the most extreme situations.  But banks and other private businesses recognize that to be safe against all possible risks implies a level of capital on which it would be difficult, if not impossible, to earn a competitive rate of return.  On the other hand, if central banks or governments effectively insulate private institutions from the largest potential losses, however incurred, increased laxity could be costly to society as well.  Leverage would escalate to the outer edge of prudence, if not beyond.  Lenders to banks (as well as their owners or managers) would learn to anticipate central bank or government intervention and would become less responsible, perhaps reckless, in their practices.  Such laxity would hold the potential of a major call on taxpayers.  And central banks would risk inflationary instabilities from excess money creation if they acted too readily and too often to head off possible market turmoil.  In practice, the policy choice of how much, if any, of the extreme market risk that government authorities should absorb is fraught with many complexities.  Yet we central bankers make this decision every day, either explicitly or by default.  Moreover, we can never know for sure whether the decisions we made were appropriate.  The question is not whether our actions are seen to have been necessary in retrospect; the absence of a fire does not mean that we should not have paid for fire insurance.  Rather, the question is whether, ex ante, the probability of a systemic collapse was sufficient to warrant intervention.  Often, we cannot wait to see whether, in hindsight, the problem will be judged to have been an isolated event and largely benign. Return to top  Thus, governments have been given certain responsibilities related to their banking and financial systems that must be balanced.  We have the responsibility to prevent major financial market disruptions through development and enforcement of prudent regulatory standards and, if necessary in rare circumstances, through direct intervention in market events. But we also have the responsibility to assure that private sector institutions have the capacity to take prudent and appropriate risks, even though such risks will sometimes result in unanticipated bank losses or even bank failures.   Our goal as supervisors, therefore, should not be to prevent all bank failures, but to maintain sufficient prudential standards so that banking problems which do occur do not become widespread.  We try to achieve the proper balance through official regulations, as well as through formal and informal supervisory policies and procedures.  To some extent, we do this over time by signalling to the market, through our actions, the kinds of circumstances in which we might be willing to intervene to quell financial turmoil, and conversely, what levels of difficulties we expect private institutions to resolve by themselves.  The market, then, responds by adjusting the cost of capital to banks.  Throughout most of this century, we have made our decisions largely in a domestic context.  However, in recent decades that situation has changed markedly for many countries and is rapidly changing for all.  While failures will inevitably occur in a dynamic market, the safety net   not to mention concerns over systemic risk   requires that regulators not be indifferent to how banks manage their risks.  To avoid having to resort to numbing micromanagement, regulators have increasingly insisted that banks put in place systems that allow management to have both the information and procedures to be aware of their own true risk exposures on a global basis and to be able to modify such exposures.  The better these risk information and control systems, the more risk a bank can prudently assume. Return to top Role of banks  The use of new technology and instruments in rapidly changing financial markets means that some bank balance sheets are already obsolescent before the ink dries.  They are not even necessarily indicative of risk exposures that might prevail the next day.  In such a context, the supervisor must rely on his evaluation of risk management procedures as a supplement to and in extreme cases, a substitute for balance sheet facts.  As the 21st century unfolds, the supervisors' evaluation of safety and soundness, of necessity, increasingly will be focussed on process, and less on historical records.  Well-functioning risk management systems are necessary, but not sufficient, for taking on greater risk.  Banks must also have the capital resources to absorb the inevitable losses that result from risk-taking and still remain solvent.  Thus, banks are required to maintain both reserves consistent with expected losses and capital sufficient to absorb the vast majority of unexpected losses that experience and data suggest could occur, but whose timing and size are not predictable.  Determination of appropriate capital levels is not just a regulatory concern. Increasingly, bankers are treating the determination of proper capital levels as integral to the meeting of shareholder goals.  Shareholder value is maximized, almost surely, when long run risk adjusted return on equity is maximized.  One method of quantifying the risk adjusted return is to measure returns net of expected losses against the capital that should be allocated to a transaction to reflect that transaction's risk.  Some bankers are doing exactly that: quantifying risks, allocating sufficient capital to cover those measured risks, and then trying to focus on those lines of business for which risk adjusted returns to allocated capital are the highest.  It does not matter whether the bank concentrates on low risk, low capital business, or on high risk, high capital business, only that it concentrates on businesses for which it has a comparative advantage, that is, businesses that earn an above average rate on its internally allocated capital, after provisions for expected losses. Regulators should take notice of this emerging business philosophy for a bank that properly measures its risks and allocates capital to those risks is well on its way to being a safe and sound bank, as well as one that meets its shareholders' objectives.  Most bankers in recent years have been confronted with an increasing complexity of financial instruments and transactions.  However, these complexities would not have arisen in actual market circumstances without the technological advances that also allowed these risks to be measured and managed.  Banks can now quantify the dimensions of risks for instruments and transactions that we could only conceptualize a few years ago.  Consider just two examples of what risk quantification permits today: securitization and the day-to-day control of market risk in a portfolio of complex derivative contracts.  In both of these cases, risk quantification is a prerequisite to informed risk-based pricing.  Moreover, the comparison of the risk-based price to current market conditions is critical to management decisions regarding withdrawing, cutting back, or expanding a bank's scale of activity in specific credit markets. Return to top  The largest U.S. banking organizations are moving into new areas of risk evaluation for internal management purposes, including the quantification of credit risk.  They have or are developing procedures for allocating capital against various types of loans, based on estimates of credit risk for various categories.  For example, in middle market lending at these institutions, a first step is to classify loans into various rating categories usually 1 to 10, with 1-rated loans being equivalent to triple-A securities and 10-rated loans about to be written off as loss.  Periodically, each loan is re-evaluated and re-categorized if necessary. Such categorizations have been done for some time, but the more sophisticated banks are going an important step beyond this point:  They are using historical data to estimate the mean and variance of defaults and actual losses on each grade of loan.  The result can be interpreted as attempting to infer the loss probability distribution for each category or subportfolio of loans, and for the entire loan portfolio.  Consider how such information can be used.  Estimates of expected losses and the probability distribution of unexpected losses are critical for pricing credits correctly and deciding whether competitive market rates thus imply withdrawing, cutting back, or expanding various types of credit.  A prerequisite, however, is a judgment by management as to the proper amount of capital to allocate to each of the subportfolios or risk categories so that risk-adjusted rates of return can be calculated.  These capital allocations, as I noted, are for internal management, not regulatory, purposes.  But I am impressed with what they teach us, the regulators, and what they imply for regulatory capital.  The internal capital allocations used by banks in the United States range from less than 2 percent for highly rated loans to 20 percent or more for the most risky credits.  In addition, credit enhancements, such as most junior positions in securitized loan pools, can have theoretical capital allocations that widen still further the range of appropriate internal capital allocations.  Compare this wide range of internal capital allocations with the 8 percent, one-size-fits-all Basle standard.  In fact the average risk-based capital ratio for large U.S. banks approaches 12 percent, far above the 8 percent minimum.  Nonetheless, consider the anomaly of a bank with a 12 percent risk-weighted capital ratio being viewed by the public as having a strong capital position when the bank's own capital allocation models suggest that it should have 15 percent capital, or more.  The supervisor, I believe, is not being misled in most such cases, and should be capable of making the appropriate judgmental adjustments.  Moreover, the markets clearly make such adjustments:  I note that banks with very high risk-based capital ratios still may not achieve triple-A ratings on their debt, and some do not even have single-A ratings.  We at the Federal Reserve are beginning a review of the internal credit risk-capital allocation models of major U.S. banks in order to understand better the strengths and weaknesses of these models. We already know, however, that there has been an irreversible application of risk measurement technology without which banks would not be able to design, price, and manage many of the newer financial products, like credit derivatives.  These same or similar technologies can and are beginning to be used to price and manage traditional banking products. Return to top  The widespread adoption of these techniques lies in the future, but, as I suggested earlier, some forms of risk quantification are now being used by banks to enhance shareholder values.  Unfortunately, some bankers believe that new technologies and the growth of some activities will reduce their franchise values by driving down spreads.  On the other hand, the byproducts of these new technologies include lower underwriting expenses and the more accurate estimation of probable losses.  These byproducts act to offset the effects of increasing competition created by the new technologies, both by raising profits on existing operations and by opening up opportunities with customers previously not served.  More generally, and of much greater importance, rapidly changing technology is broadening and deepening financial markets while inevitably enhancing competitive pressures. In one sense this trend has been with us since the industrial revolution, but it has clearly accelerated in recent years in banking markets.  Because the hot hand of competition is always putting pressure on us, we in our darker moments wish it would just go away.  I very often succumbed to such melancholy when I was in the private sector.  But we are wrong. Competition is the force which keeps us on our toes, makes us better and more productive, and creates higher market values for our banking institutions, just as it does for other firms. Competition is what has raised our standards of living for generations.  Technological change and the accompanying competition are irreversible, and those banks unwilling or unable to adapt to them will lose market share and suffer lower risk adjusted rates of return.  But the banks that embrace the cost-cutting and risk-reducing effects of the technology will, in my judgment, tend to find it a rewarding experience. Return to top Role of supervisors  As financial markets change, regulators too must adapt to the new technology, and, in this regard, some important lessons are being learned.  Technological change is not the sole province of the private sector.  For example, the private sector, for a considerable time, has been accustomed to product planning cycles in which the planning of the replacement product is begun, if not well along, by the time a new product is being introduced.  Similarly, regulators are beginning to understand that the supervision of a financial institution is, of necessity, a continually evolving process reflecting the continually changing financial landscape.  This is not a fault, but rather a description of an appropriate regulatory process. Indeed, given our own long lead times, we must begin designing the next generation of supervisory procedures even while introducing the latest modification, much as you are forced to do for your own products.  Increasingly, the new supervisory techniques and requirements try to harness both the new technologies and market incentives to improve oversight while reducing regulatory burden, burdens that are becoming progressively obsolescent and counterproductive.  This is becoming especially true in evaluating the capital adequacy of banks.  One example is the recent consensus reached by international banking regulators to use internal model approaches for measuring market risks at banks and allocating regulatory capital to those risks.  Looking further down the road, the Federal Reserve Board has been studying an alternative capital allocation process for market risk, the so-called pre-commitment approach.  This methodology would provide market and other financial incentives for banks to choose their own capital allocations for trading risk that they believe are consistent with their own risk management capabilities, as well as with regulatory objectives.  With the Board's encouragement, the New York Clearing House Association is organizing a pilot study of the pre-commitment approach. The next natural step is to begin to review ways to harness, for supervisory purposes, the banks' own models for the measurement of credit risk.  The decision to craft a bank's capital requirements for trading activities around accepted and verifiable internal risk measures was an important step in the supervision and regulation of large, internationally active banks.  It is all the more noteworthy because it recognizes the importance of both quantitative and qualitative criteria in the measurement and management of trading risks.  As risk management techniques evolve for other bank activities, supervisors will need to understand the new procedures and how they affect overall banking risks.  Time and again, though, events are demonstrating that despite the complexity of transactions and the alleged sophistication of management systems, it is the lack of simple basic policies and controls that so often lead to problems at banks.  Fortunately, in many cases, the technology that has enabled institutions to design complex new products also provides the techniques with which the resulting risks can be identified, measured, and controlled.  Management also must have the knowledge and motivation to employ these techniques to ensure that risks are adequately contained.  We must never forget that no matter how technologically complex our supervisory systems become, the basic unit of supervision on which all else rests remains the human judgment of the degree of risk on a specific loan, based on the creditworthiness and character of a borrower.  If those credit judgments are persistently flawed, no degree of complexity of supposed risk dispersion or elegance of credit models will help. Return to top  Today's technology allows us to measure risk in ways that were unthinkable a decade ago.  The next decade will likely produce further dramatic changes.  But already today, we can seriously begin to contemplate a regulatory quantification of what we mean by the soundness of a financial institution.   Recall that while the objective of bank regulation and supervision is to assure a minimum level of prudential soundness, the precise meaning of soundness has always been tenuous and ill-defined.  This is why judgment has been, and will continue to be, a critical component of prudential supervision.  However, the technology and techniques banks have developed, and are developing, allow us greatly to improve that judgment by constructing measures of soundness in probability terms.  If we can obtain reasonable estimates of portfolio loss distributions, soundness can be defined, for example, as the probability of losses exceeding capital.  In other words, soundness can be defined in terms of a quantifiable insolvency probability.  Moreover, one can conceive of definitions of soundness that go beyond simply the probability of insolvency to encompass also the level and variability of losses to a deposit insurance fund in the event of insolvency.  All of these approaches, however, require the regulators to establish targets regarding acceptable failure rates or an insurance fund's exposure to potential losses. Note that a bank could meet any particular quantitative soundness standard by increasing its capital or by reducing the riskiness of its portfolio.  I do not mean to suggest that we have reached the point at which we can now establish quantitatively precise soundness standards.  We have not.  These procedures are in their infancy and are hampered by the lack of micro data bases which have to be laboriously constructed at, or by, individual banks.  Moreover, ascertaining relevant probabilities, the basis of an evaluation of soundness, presupposes an estimation of the shape of these distributions, arguably the most difficult aspect of this process.  The technical methodology is also changing with experience and with conceptual progress in the academic and professional communities.  Within the United States, the Federal Reserve and other bank supervisors are placing growing importance on a bank's risk management process and are strengthening our supervisory procedures, where necessary, to assist examiners in identifying management weaknesses and strengths.  We are also working to develop supervisory tools and techniques that utilize available technology and that help supervisors perform their duties with less disruption to banks.  These improvements range from software designed to download data about a bank's loan portfolio to an examiner's personal computer, to simply more thoughtful reviews of internal management reports.  Such automation enhancements will permit examiners, themselves, to analyze more efficiently the various concentrations within loan or investment portfolios and, therefore, help them to identify the underlying risks and discuss those risks with bank management.  Countries in which supervisors conduct on-site examinations or otherwise review specific loans or loan portfolios may find such technology particularly useful.  Within the United States, the growing volume and complexity of transactions, particularly at the largest institutions, require such productivity enhancements and other modifications to our supervisory procedures in order for us to do our job effectively.  For example, rather than evaluate a high percentage of a bank's loans and investment products by reviewing individual transactions after the fact, we will increasingly seek to ensure that the management process itself is sound, and that adequate policies and controls exist.  While still important, the amount of transaction testing, especially at large banks, will decline.  However, supervisors everywhere should expect bank boards of directors and senior managements to perform their leadership and oversight roles.  By themselves supervisors cannot expect to detect or prevent every unsound practice, nor to ensure that all weak management processes are improved.  We can expect our banking systems to be sound only by ensuring that directors and managers provide guidance regarding their appetite for risk; that they bring personnel to the bank with the integrity and skills to do the job; and that they monitor compliance with their own directives.  Encouraging and promoting sound qualitative risk management and internal controls has been and should remain a high priority of bank supervisors.  Indeed, it is as important, in my view, as the development of quantitative prudential standards. Return to top Supervisory cooperation  Let me turn briefly to the G-7 initiatives to which I referred earlier.  The communique from the Lyon Summit meeting in June stated four objectives designed to promote stability in international financial markets.  First, cooperation among the authorities responsible for the supervision of internationally active financial institutions should be enhanced.  The largest banks in every country and even many of the smaller banks are now actively engaged in international markets.  Their organization charts cut across national boundaries.  Therefore, it has become important that supervision also be seen in an international context.  Increasingly also their organization charts cut across the sometimes subtle boundaries between banks and other financial and non-financial institutions.  In order to maintain financially sound institutions and financial markets, cooperation across countries and between bank and nonbank supervisors is desirable and, at times, essential.  To be sure, bank supervisors from G-10 countries have been actively working together in the Basle Committee on Banking Supervision and its predecessor committees since the mid 1970s.  Supervisors of securities firms have also been working together in IOSCO.  But it is only fairly recently, and in part a result of the encouragement by G-7 leaders in Halifax, that banking and securities supervisors have been trying to coordinate their efforts.  This is not an easy task, since the philosophy of, and motivation for, supervision of banking activities are different from the supervision of securities operations.  What kind of supervisory information needs to be shared among supervisors, which supervisors need to be involved, and in what circumstances, are difficult questions but properly are being addressed.  The Joint Forum, which includes insurance regulators as well, is struggling with these questions and with the complex question of how financial conglomerates ought to be supervised.  I am confident that these various efforts will help to promote a safer global marketplace, but they are not the last word.  As our supervisory systems mature, so too must our international cooperation develop further. Return to top  Second, risk management should be strengthened and transparency should be improved.  I do not intend to say more than I already have about risk management, but I would like to emphasize the importance of transparency, by which I mean in this context enhanced reporting and public disclosure of financial activities.  Market and supervisory pressures have led to substantially more, as well as more meaningful, public disclosure of risk positions and risk management procedures.  I might note also that, earlier this year, a central bank working group under the able chairmanship of Shinichi Yoshikuni of the Bank of Japan recommended a reporting system that, when fully implemented, will add considerably to our knowledge of derivatives market activities.  This and other initiatives will enable financial market participants as well as supervisors to gain more information and a better perspective with which to evaluate the activities of individual firms.  It is only through adequate disclosure that market discipline can effectively be brought to bear as an important complement to supervisory oversight.  In an increasingly complex and integrated global marketplace, the scope and sophistication of disclosures by individual institutions must increase commensurately.  If they do not, institutions will find themselves being shut out of markets not by regulators but by their counterparties.  Third, prudential supervision in all market economies must be enhanced, and by their history this applies in particular to emerging market economies.  This is an area of work that has attracted considerable attention from a wide range of national and international bodies. With emerging market economies growing rapidly, with the close interrelationship between macroeconomic and financial system performance and stability, and with international financial transactions involving these countries becoming increasingly important, it is difficult to exaggerate the importance of sound financial systems in these economies, for their own sake and for the sake of global financial stability.  Ultimately, of course, it is the responsibility of those countries themselves to ensure adequate prudential standards.   But we all have key roles to play in sharing our experiences and our expertise, and in offering leadership and guidance.  Finally, the G-7 leaders felt that the implications of the recent technological advances associated with electronic money should be studied.  Central banks have studied many aspects of electronic money.  My own sense is that the issues raised are not yet matters that threaten global financial stability.  But it is an engrossing area.  We should make sure we understand how that technology is developing and what it might mean, while at the same time we allow scope for continued innovation and technical change. Return to top Conclusion  To conclude, let me reiterate the basic principle I put forward earlier:  Our soundness standards should be no more or no less stringent than those the market place would impose. If banks were unregulated, they would take on any amount of risk they wished, and the market would price their capital and debt accordingly.  Ideally, banks should also face regulatory responses to their portfolio risks that simulate market signals.  And these signals should be just as tough, but no tougher than market signals in an unregulated world. Perfection would occur if bankers had a genuinely difficult choice deciding if they really wanted their institutions to remain insured or become unregulated.  In the final analysis, such an approach is the only way to control the moral hazard of the safety net, to balance stability requirements with risk-taking.  An important and increasingly feasible prerequisite in achieving that balance is for the regulators to quantify what their goals are, especially what is meant by soundness.   Measuring actual risks relative to these goals would be facilitated if regulators harness for supervisory purposes the market-oriented tools already used internally by banks for management purposes.  When seeking to implement this principle and utilize new technologies, we must take care to remember that we are unlikely ever to be able to measure risk in absolutely precise ways.  Quantification procedures are still extrapolations of the past, and behavior is always changing.  Models will still doubtless be haunted by specification and estimation errors.  The global financial marketplace will still remain highly complex, and I have no doubt that participants will continue to invent instruments and procedures that models will not be able to capture until sufficient experience is gained.  Thus, I am not proposing nor do I anticipate that bank supervisors will be relying on a black box based on statistical and econometric rules.  I am suggesting, however, that new paradigms are in the process of evolving which will provide us with tools that will permit greater quantification of both risk standards and risk management.  Such quantification will not solve all of our problems, nor will it ever substitute for human judgment, which ultimately is the technology we must rely on to parse the most difficult problems.  Nonetheless, quantification will facilitate great improvements in both risk management and what regulators will be able to do. The financial world is dynamic and I have little doubt that there will be a continuous need to modify what we develop.  In the end, judgment must be augmented with technology, and technology must be tempered with judgment.  Financial institutions and regulators around the world have a common interest in using evolving new technologies to meet their own separate objectives: maximizing shareholder value and maintaining safe and sound financial systems.  One cannot be done without the other.  And, as financial institutions increasingly apply these new technologies, supervisors will be replacing their procedures with those that depend increasingly on risk management, risk quantification, market simulations, and within the confines of law reduced barriers. The \"best practice\" for supervisors is to assure that regulatory restrictions are not a barrier to the \"best practices\" of the institutions they supervise.  If institutions succeed in employing improved risk management and all its tools in order to increase the risk adjusted rate of return, shareholders, the financial system in general, and our economies as a whole, all will be better off.",
                  "1996-11-18 00:00:00"
                ],
                [
                  "7",
                  "Governor Edward W. Kelley, Jr.",
                  "The Future of Electronic Payments     I am delighted to be with you this morning to discuss the future of electronic payments.  This topic is being intensively addressed in the retail banking area, as stored value cards and Internet-based payment systems are introduced to the public, both in the United States and around the world.  This morning, however, I want to focus my remarks on the wholesale and correspondent banking markets, where electronic payments already are the norm, but where significant challenges still exist in trying to manage and reduce risks in the payment system. Predicting the future would be folly.  However, the enormous amount of creative effort now being invested in addressing settlement risk issues is a very promising sign.  I believe it is a time for all of us to push forward aggressively in the wholesale banking area with the arduous work of making changes in the institutional arrangements for clearing and settlement. Let me get right into that theme with a very specific announcement about Fedwire operations.  I am pleased to announce that yesterday the Federal Reserve Board approved the date on which the Fedwire funds transfer system will regularly open for business at 12:30 a.m.  Eastern Time.  That date is Monday, December 8, 1997.  Let me repeat.  The date is Monday, December 8, 1997.  I would like to remind you of several key parts of the early Fedwire program.  Most importantly, participation will be voluntary.  There is no Federal Reserve requirement that depository institutions must be open to process Fedwires at 12:30 a.m.  Participation in the early morning will be determined by the needs of the marketplace.  In addition, Federal Reserve daylight overdraft credit will be available during the early morning period, 12:30 a.m. to 8:30 a.m., on the same terms as during the normal operating day.  The Board's full daylight overdraft program, including overdraft caps and fees, will be applied in the usual manner.  I should note that although daylight overdraft fees will not change, they will be quoted on a basis that reflects the longer Fedwire operating day, beginning in December 1997.  Again, this will not represent a change in the actual charge for credit on an hourly basis.  The Board will, however, closely monitor the patterns of daylight overdrafts in the early morning period and will review these patterns, along with general developments in the daylight overdraft area, after more experience is gained with the current daylight overdraft fee structure.  Dara Hunt, the Product Manager for the Federal Reserve's Wholesale Payments Product Office, will be discussing many of the detailed aspects of early Fedwire funds transfer operations later this morning. Return to top Finally, I should note that the Board has also proposed that the Fedwire securities transfer system be opened earlier in the morning on a voluntary basis.  A number of comments have been received on that proposal and we are in the process of analyzing them.  As I am sure you know, the Board made the decision to open the Fedwire funds transfer system at 12:30 a.m. back in February 1994 but deferred the implementation date for that decision until late 1997.  A major reason for this approach was to allow the banking industry time to prepare for early Fedwire and to implement other technical changes that we have been making to the Fedwire system, such as improved message formats.  In retrospect, much has happened in the past few years and I would like to review these developments as an introduction to my main theme that it is \"a time for action.\"  The volume of funds being moved has grown rapidly in recent years, risks have grown apace, and much work has been done to move toward meeting the challenges and opportunities these conditions present.   Now, the broader context.  Statistical reports from the Bank for International Settlements, the International Monetary Fund, and other organizations have continued to document the growth of activity in the international financial markets.  Trading volumes have increased dramatically.  New instruments and players have arrived on the scene.  Settlement flows have continued to grow, even as techniques such as netting have been introduced to reduce both ordinary credit risks and settlement risks.  The traditional business of foreign exchange trading, for example, has grown exponentially and generated very large settlement exposures and money flows throughout the international banking system.  The estimated turnover in the foreign exchange markets now averages well over one trillion dollars per day, while the flow of funds through Fedwire and CHIPS now averages well over two trillion dollars per day.  Risks have escalated in international settlements and these are motivating both commercial and central banks to take action.  It is now clear that the settlement process involves more direct credit risk than earlier thought.  For example, in the typical foreign exchange settlement, a payment to settle one side of a contract effectively becomes irrevocable one or more days before the payment to settle the other side of the deal is received. Over weekends with holidays there can be four or five calendar days between the beginning and end of the settlement process, which generates very long periods of exposure.  Given the enormous flows of funds involved, aggregate exposures for major dealing banks can be very large in proportion to capital.  Return to top There is also liquidity risk.  If settlement payments are not completed, as scheduled, the cash position of one and possibly a whole group of banks in the major currencies may be adversely affected.  To a certain extent, managing so-called \"fails\" to deliver currencies or securities are part of the international banking business.  However, large-scale fails would place significant pressures on the international banking system.  Further, there are legal risks.  There has been much discussion over the past few years, for example, of the need for strong legal foundations for netting arrangements.  Significant progress has been made in a number of countries, including the United States.  However, additional progress is essential and we should not assume that the job is complete.  There are also operational and security risks.  This audience, in particular, is aware of these risks, since operational and security concerns are typically the greatest in the wholesale payments area, where the dollar flow of payments is the largest.  However, I would like to note that there has been a lot of public discussion lately of risks in the retail banking area.  These discussions have centered, for example, on the use of the Internet or other so-called \"open systems\" for delivering banking services and making payments.  There are important operational and security issues involved in such activities, and I would urge that all banking organizations take these seriously.  I might add that these new developments in the retail area may provide significant opportunities to re-examine bank-wide computer information security policies and the strategies for implementing them.  A fundamental concern of central banks, of course, is systemic risk.  This can involve risks that one bank's problem will spill over onto others, risks that whole clearing systems may cease to operate effectively, and even more broadly, risks that unexpected events will destabilize the banking system as a whole.  It is this type of concern that has motivated a sustained effort by the central banking community in a number of areas.  In the payment field, concerns about systemic risk have led central banks to call for reductions in settlement risk, in general, and stronger clearing and settlement arrangements, in particular.  Over the past ten years a series of reports dealing with the issue of international settlements has been published by the G-10 central banks through the good offices of the BIS.  The latest report was issued in March, and was written by the Committee on Payment and Settlement Systems, which is chaired by the President of the Federal Reserve Bank of New York, Bill McDonough.  That report clearly called for action to reduce settlement risk in the near term.  We should be clear-sighted, however, about the differing roles of central banks and private-sector institutions in pressing forward with efforts to reduce settlement risk.  To date, the central banks have provided a solid framework for analyzing risk.  Settlement risk has been analyzed in a number of BIS reports, including the Lamfalussy Report on Netting Schemes and the McDonough Report on Settlement Risk in Foreign Exchange Transactions.  In addition, risks in securities settlement systems have been extensively analyzed in reports on delivery versus payment and cross-border securities settlement arrangements.  Return to top Central banks as a group have strongly suggested that the banking industry move forward with risk reduction and will be monitoring progress toward this goal.  Moreover, central banks have recognized the need for flexibility, where possible, in taking steps that will permit the private sector to build more efficient clearing and settlement arrangements that will help reduce settlement risk.  One step is the Federal Reserve's decision to open Fedwire at 12:30 a.m., which was conceived in large measure as a means to allow banks and their customers to move money earlier in the day, if they wish, and to synchronize more closely the settlements among different financial markets around the world.  Finally, the framework for central bank cooperation in overseeing cross-border and multicurrency clearing arrangements set out in the Lamfalussy Report, along with the general cooperative process involving the Committee on Payment and Settlement Systems, has provided clear points of contact between the G-10 central banks as a group and the developers of various international clearing projects.  The Fed is encouraged that the banking industry has become engaged in efforts to analyze and reduce risk.  Reports over the past few years on settlement risk, including a major report by the New York Foreign Exchange Committee, as well as new project  initiatives for clearing arrangements, have set the stage for real progress.  All these efforts have made it clear that the banking industry must maintain, and even increase, its momentum in finding solutions to reduce settlement risk.  At the end of the day, it is the international banking industry that is in the best position to understand the details of its own operations and to seek innovative ways to reduce risk.  We have already seen some very creative proposals emerge in the past few years, and I have no doubt that there will be more innovative ideas that emerge from the current creative ferment in the international markets.  I would like to turn now to some longer term questions posed by the early opening of Fedwire and the broader market developments.  First, there is a question of whether established clearing organizations will now take advantage of the earlier Fedwire hours and consider speeding up their money settlement processes.  For example, several years ago some in the futures industry urged the Federal Reserve to open the Fedwire earlier in order that interbank funds transfers associated with morning margin settlements may be completed before morning trading begins.  Now that a specific date for the early opening of Fedwire has been set, it may be time to consider the timing of these and other money flows once again.  Second, there is a question of whether we will see the emergence of early morning money market trading as a result of earlier Fedwire hours and related developments.  In particular, will federal funds trading occur in the early morning?  Further, if the Fedwire securities transfer system were opened earlier, would trading and money settlements relating to repo and other collateralized transactions occur earlier?  It is possible, for example, that if money settlements for both existing and new clearing arrangements were to take place earlier in the morning, money market trading might begin to emerge to accommodate the earlier funding needs of banks and other financial institutions.  A closely related issue is the extent to which market participants will look to daylight overdraft credit from the Federal Reserve as an ultimate source for funding early settlements, particularly if formal money market trading does not develop.  As I mentioned earlier, these relationships will bear careful watching.  Return to top Third, there is a question about whether the conventional settlement times for foreign exchange trades can be shortened, if new institutional arrangements are put in place.  Today many currency trades settle on day T + 2, that is, trade date plus two business days.  In part, the two days needed for settlement result from activities taking place across different time zones. However, the two days also allow extra time for back office and correspondent banking functions to be completed.  New trading arrangements, such as electronic brokerage, along with new clearing arrangements, may well cut short some of these requirements and allow changes in long-standing clearing conventions.  Fourth, there is a question about the size of flows through international correspondent banking networks.  These flows have grown rapidly with the increase in international banking activity.  The role of the dollar in international finance, along with highly efficient U.S. dollar money markets and correspondent banking services, have placed the internationally active correspondent banks that operate in the United States at the center of this growth.  Settlement risk reduction, for example through netting, may well reduce the growth or even the level of settlement flows through correspondent banks.  Although such possibilities may be difficult for some to accept, they are not necessarily a bad thing.  For example, reduced settlement flows might work to bring risks more in line with rewards in some areas.  At the same time, of course, reduced settlement flows might also contribute to even greater competitive pressures on the correspondent banking industry than exist today.  I would, however, expect the correspondent banking business to adjust to changing conditions by providing new products and services and by continuing to increase efficiency.  In this way, the industry will continue to be able to offer key international settlement services in the United States.  In conclusion, we must all recognize that the banking environment is characterized by changing players, financial techniques, and technologies.  In addition, the sheer volume of cross-border activity has increased, to the point where many markets and their clearing systems have become inherently international in scope.  Our response should be that innovation, along with international trade in financial services, is a good thing and that there is every reason to encourage change.   At the same time, prudent management is essential, in order for innovation and global markets to benefit the wider economy.  In the payments field, there is much work yet to do to ensure that strong foundations are laid under the expanding international financial markets.  The blueprints and initial projects show promise.  But I also believe that there will be very hard and detailed work yet to come.  I urge all of you to stay with this job and see it through to the end.",
                  "1996-10-31 00:00:00"
                ],
                [
                  "8",
                  "Governor Susan M. Phillips",
                  " It is a pleasure to join you today for the 23rd Annual Accounting Lecture Series at the University of Tennessee.  I understand that one of the objectives of this lecture series is to foster discussion of accounting and auditing issues facing the accounting profession and to promote communication and coordination among professional accounting organizations.  I applaud your efforts.  U.S. accounting and auditing standards are central to the integrity of our financial system.  They are also important to the Federal Reserve's efforts to supervise and regulate banking organizations, as well as efforts to enhance and harmonize such standards internationally.  For these reasons, I welcome the opportunity to talk with you this evening about U.S. bank accounting issues and international harmonization from a bank supervisory perspective. The Heightened Importance of Accounting and Auditing Standards By way of background, four developments have heightened the importance of accounting and auditing standards in the bank supervisory framework.   First, there has been a marked increase in the issuance of accounting and auditing standards that have had a major impact on the banking industry.  This trend seemed to start with the accounting standard for foreign currency translation in 1981.  Since then, and particularly in this decade, new Financial Accounting Standards Board (FASB) standards and proposals affecting banks have been issued at a blistering pace in such areas as loan-loss accounting, asset securitization, mortgage servicing, securities activities, and derivatives.  Bankers and examiners have felt the impact of these accounting developments and have seen business strategies and transaction types change as a result.  Indeed, many feel that the increased complexity of certain types of financial transactions has been driven, in part, by changes in accounting and disclosure requirements.  Second, new statutes have prompted more attention to accounting and auditing practices.  For example, section 112 of the Federal Deposit Insurance Corporation Improvement Act of 1991 (FDICIA) sets forth new rules for audit committees and certain auditor and management reports by the larger banks.  Section 121 of FDICIA requires that bank regulatory reporting requirements be consistent with generally accepted accounting principles (GAAP) or more stringent than GAAP.  Third, changes in accounting treatments can often dramatically affect reported results.  For example, when implemented in 1994, FASB Interpretation No. 39 on netting of assets and liabilities   called \"FIN 39\"   increased the total assets of some of the largest banks by billions of dollars each and by around $100 billion for the banking industry as a whole.  Later in 1994, another FASB interpretation on netting of repurchase transactions   FIN 41   caused billion dollar decreases in assets at some of the money center banks.  Thus, sometimes even obscure accounting standards can have a significant effect on the \"bottom line\" of financial institutions.  The fourth development that has increased the importance of accounting and auditing standards perhaps the most to bank supervisors is their crucial role in risk-focused supervision of financial institutions.  During recent years, the Federal Reserve has endeavored to streamline the examination process to make it more focused on risks and to make greater use of technological innovations.  This approach recognizes that while financial and technological innovations do not change the substance of the fundamental risks of banking, these risks may be repackaged in more complex forms that are difficult to measure and manage.  Increasingly, since 1991, our examination guidance has stressed the need for banking organizations to implement sound risk management practices that provide for  Active oversight by management and the board of directors Clearly defined policies, procedures, and authority Comprehensive risk measurement and reporting systems Adequate audits and systems of internal controls. In this regard, the Federal Reserve recognizes that accounting, auditing, and disclosure play a crucial role in the financial marketplace.  Accounting standards provide the foundation for credible financial statements and other disclosures that are key means for communicating a firm's operating results and its overall health, as well as for making more transparent various operating activities.  Disclosure of reliable information facilitates market discipline, strengthens confidence, and reduces the chance that rumors and misleading information could cause market instability.   Such results have obvious implications for supervisors' abilities to oversee the safety and soundness of depository institutions and for the Federal Reserve in its responsibilities for financial market stability.  These standards are also important to the federal banking agencies because of their critical role in regulatory financial reports   such as the bank Call Report and bank holding company Y-Reports.  The supervisory agencies monitor these reports to follow financial developments at depository institutions.  When reported financial information indicates a deterioration in financial condition, these monitoring systems signal the need for on-site examinations, targeted reviews, and other appropriate actions.  Because these reports are largely based on GAAP, accounting standards have an important impact on the information that is available for examination and other supervisory purposes.  The better the quality of financial information   and of the accounting standards that shape this information   the greater our ability to monitor and supervise banks effectively.  Moreover, because our quarterly regulatory financial reports are generally available to the public, they serve an important public disclosure purpose as well.  By facilitating market discipline, public disclosure helps reinforce supervisory efforts to encourage banks to maintain sound risk management practices and internal controls. In this regard, auditor attestations help ensure that market discipline is based on quality information.  Adequate audits and internal controls are critical to risk management. The risks inherent in bank operations are difficult to quantify and can pose a threat to the bank's safety and soundness.  Controls assuring the quality and integrity of business processes are important, and breakdowns can be devastating.  Indeed, a breakdown in internal controls or risk management systems was a root cause of several recent financial problems of large institutions.  At Barings Bank, it was not market risk, credit risk, or inadequate risk measurement   but poor internal controls surrounding a single trader that closed the bank.  Similar internal control weaknesses were apparent at Daiwa, Sumitomo, and Kidder Peabody.  Internal controls are appropriately receiving more attention from not only supervisors but from boards of directors and senior management.   This is a healthy market reaction to these problems.  For these reasons, the Federal Reserve has increasingly recognized that, together with on-site examinations and capital standards, improved standards for accounting, supervisory reporting, disclosure, and controls are important parts of its supervisory approach to addressing complex new transactions, such as those involving derivatives.  Return to top Recent Initiatives Domestic Efforts In view of the importance of accurate accounting information, the Federal Reserve has renewed its focus on the quality of information in supervisory reports that are available to the public.  Specifically:  The Federal Reserve has been working with the other federal banking agencies to develop regulatory reporting requirements that are more consistent with disclosures in published annual reports. The Federal Reserve has long required that bank holding companies follow GAAP for purposes of its FR Y-9C regulatory financial reports, and, last year, the Federal Reserve strongly pushed for adoption of GAAP for the bank Call Report.  We were very pleased that the banking agencies, under the auspices of the Federal Financial Institutions Examination Council (FFIEC), announced in November 1995 their plan to adopt GAAP as the basis of bank Call Reports in March 1997. Eliminating regulatory accounting principles or \"RAP\"   for example, in the areas of asset sales with recourse, futures and options contracts netting, and excess servicing fees   means that banks must no longer maintain a separate set of books for regulators.  We hope that this Call Report initiative should thus reduce the reporting burden on banking organizations.  In recent years, we have also significantly improved the information on derivatives in the bank Call Report and bank holding company FR Y reports and have made this information more consistent with derivatives disclosures required by FASB Statement No. 119.  In many cases, market developments or new products outpace the development of formal accounting guidance.  This creates particular challenges for bank supervisors.  Should new regulations or even examination guidelines be delayed until accounting standards are issued?  In some instances, we have not felt that we could wait. For example, the Federal Reserve and the other banking agencies, under the auspices of the FFIEC, have gone beyond GAAP and SEC disclosures this year by requiring new regulatory report disclosures on derivatives' credit losses.  Next  year, new items will be added for net deferred losses or gains on derivatives used as hedges and for credit derivatives.  Furthermore, the banking agencies plan to require new information for the assessment of overall interest rate risk.  We hope that accounting guidance will be finalized soon in these areas, at which time we may have to revise our regulatory report requirements.  We are also encouraging banks to disclose in their annual reports more data on their risk exposures and provide more in-depth discussions of their risk management processes and operating results.  For example, in September 1996 and 1995 we published, as the lead articles in our official monthly publication, the Federal Reserve Bulletin, analyses of derivatives disclosure in the 1993-95 annual reports of the top ten U.S. dealer banks.  In reviewing qualitative and quantitative disclosures, the analyses address information about (a) market, credit, and liquidity risks of trading activities, (b) end-user derivatives activities, and (c) the earnings contribution of these activities.  Furthermore, the tables presented in these articles summarize the major types of derivatives disclosures made by the top ten U.S. dealer institutions.  Improved public disclosure enhances market discipline, which in turn has the potential to allow regulation and supervision to be less intrusive.  External audits attest to the fairness of public financial statement disclosures.  In this regard, in July of this year, the Federal Reserve launched two Systemwide working groups to  Explore ways of enhancing market discipline through further improvements in public disclosures about on- and off-balance-sheet activities Develop supervisory guidance on sound practices for banks' internal and external audit processes and improve the use of audit information in the risk-focused supervision process.   These working groups are chaired by Jerry Edwards, our chief accountant, and they are expected to issue supervisory guidance on audits and recommendations for improved public disclosure in 1997.  International Efforts Turning to international initiatives, the Federal Reserve has been active behind the scenes in promoting improvements in supervisory reporting and public financial statement disclosures, as well as enhancements to reporting on global market statistics.  As banking and financial markets generally have become increasingly global in scope, efforts to press for increased market transparency must proceed in an international arena.   The Federal Reserve played a major role in developing the joint report by the Basle Committee and the International Organisation of Securities Commissions (IOSCO), which sets forth a framework for international supervisory reporting of derivatives.  The report was issued last year and is being implemented by supervisors of banks and securities firms in many major industrialized countries.  We expect that, over time, this initiative will lead to greater convergence among these countries in the supervisory reporting of derivatives activities.  Turning to public disclosures, Peter Fisher, Executive Vice President, Federal Reserve Bank of New York, chaired an international working group of the Euro-currency Standing Committee that issued a report in September 1994 recommending improved qualitative and quantitative disclosures by financial intermediaries about the credit and market risks of their trading activities.     Our 1995 analysis of the derivatives disclosure by the top ten U.S. dealer banks, which I mentioned earlier, was the model for a joint report issued in November 1995 by the Basle Committee and IOSCO that covered a sample of seventy-nine of the largest banks and securities firms in the G-10 countries.  The joint study revealed major differences in the level of disclosure about trading and derivatives activities among the participating countries and highlighted the higher quality and quantity of information U.S. dealer banks provide. This study is being repeated this year and should be published by the end of this month.   Turning to market statistics, another report by the Euro-currency Standing Committee was prepared on \"Proposals for Improving Global Derivatives Market Statistics,\" and was made public in July 1996.  The report described a framework of regular reporting from the major dealers in the G-10 member countries, which would provide internationally consistent information on the size and structure of derivatives markets in order to increase market transparency and thereby help central banks, other authorities, and market participants to monitor patterns of activity in the global financial system.  Consultations with market participants and supervisors are under way, and central banks are considering implementation of the new reporting system as of the end of 1997. Internationally, accounting and auditing standards are receiving increasing recognition from banking supervisors.  For example, the Basle Committee has recently decided to restructure its activities in 1997, creating a new risk management subgroup that will be chaired by the Federal Reserve.  This subgroup will develop supervisory guidance on bank risk management practices and on improved internal controls and audit standards.  The Basle Committee also plans to form a new information subgroup that will encourage adoption of better standards for public disclosure, both for trading and derivatives activities and for traditional balance sheet risks. In addition, the Basle Committee will form a new accounting task force to address ways of improving international accounting standards.  Based on these initiatives, I expect that the Basle Committee will likely become more involved in providing comments to the International Accounting Standards Committee (IASC) as it moves forward with its project to develop a core set of international accounting standards by March 1998.  These include the development or revision of international accounting standards for income taxes; presentation of financial statements; intangible assets, leasing, loan and securities impairment; provisions and contingencies; and financial instruments and investments.  IOSCO has indicated that successful completion of this project will allow it to consider endorsing the IASC's standards for cross-border securities registrations in all global markets. Return to top Future Directions I recognize that, while there is widespread interest in improved disclosure, there is not yet an international consensus on the precise form and content these added disclosures should take.  What is most important is that disclosure reflect the risk management systems of the reporting entities.  Individual firms should pursue better ways to disclose the nature and magnitude of the risks they assume and their earnings impact.  We may well have to go through a period of experimentation to achieve a consensus on what comprises effective public disclosure.  Clearly, the international efforts of the type I have outlined should help move over time toward a consensus regarding recommendations for improved disclosures by internationally active companies.  In turning from disclosure to accounting standards, I will state the obvious that if developing new and useful disclosures is a difficult task, then establishing better methods of accounting for derivatives and hedging must be even more challenging.  Nevertheless, I strongly encourage the FASB to continue its efforts to devise a reasonable, consistent framework for hedge accounting.  When major losses on derivatives contracts occur, a harsh light is cast on the deficiencies in current accounting and disclosure practices for derivatives.  Such losses highlight how critical it is that auditors thoroughly understand the risks inherent in their client's business and their need to maintain prudent skepticism when encountering leveraged or other high-powered contracts that are being represented as hedges. Summary and Conclusion In summary, I think the Federal Reserve and other regulatory agencies have made significant progress in strengthening their supervisory approaches and risk management guidance.  I believe that regulators, by focusing on risk management systems and processes, will not interfere with the prudent development of new products that meet customer needs.  Clearly, in the context of risk-focused supervision, accounting and auditing standards will continue to have heightened importance for years to come.  One of the financial market's greatest challenges is to the accounting profession:  How can financial statements best convey information about risk management activities to shareholders, creditors, and other interested parties?  I understate the challenge when I say it is difficult to devise meaningful and understandable disclosure that is also comparable to previous reports and to those of other firms.  The disclosure, moreover, should not compromise proprietary information; it must be flexible to accommodate future advances in risk management.  Furthermore, the benefits derived should exceed the cost of providing the disclosure.  To further complicate the challenge, the information needs to be independently verifiable.  These issues must be considered not only in the context of U.S. standards but also from an international perspective.  Efforts now under way to develop international accounting, disclosure, and auditing standards are encouraging.  Bank supervisors will be working in tandem to facilitate the efforts of the international professional accounting groups.  These are daunting challenges.  Nevertheless, I am certain that as the profession moves forward to meet these challenges, new ways of viewing risks and reporting them in financial statements will be devised.  Financial reporting and supervisory reporting will become even more critical to efficient financial markets and effective bank supervision activities.  Thank you.",
                  "1996-10-24 00:00:00"
                ],
                [
                  "9",
                  "Chairman Alan Greenspan",
                  "Remarks by Chairman Alan Greenspan Technological advances and productivity At the 80th Anniversary Awards Dinner of The Conference Board, New York, New York October 16, 1996  It is a pleasure to be with you this evening, and accept your honorary award.  The Conference Board has been an important institution in my life.  It was where I started as an economist.  It was where I came into contact with a business world I had never known before.  The year was 1948, and I brought my newly minted degree to what was then called the National Industrial Conference Board, to work with my old professor, then chief economist at the Conference Board, Martin Gainsbrugh.  Although I had other offers of employment at higher pay, it was an easy call to come work at a research operation with, perhaps, one of the best business-oriented libraries in the country.  Much of my professional development, I trace back to those early days rummaging through a remarkable array of documents, books, statistics all available at a young economist's fingertips.  What I learned during my five years at the Board proved invaluable in later life.  Accordingly, I am most grateful and privileged to be here to celebrate with you on your eightieth anniversary.  The world of 1948 was vastly different from the world of 1996.  The American economy, more then than now, was viewed as the ultimate in technology and productivity in virtually all fields of economic endeavor.  The quintessential model of industrial might in those days was the array of vast, smoke-encased integrated steel mills in the Pittsburgh district and on the shores of Lake Michigan.  Output was things, big physical things.  Virtually unimaginable a half century ago was the extent to which concepts and ideas would substitute for physical resources and human brawn in the production of goods and services.  In 1948 radios were still being powered by vacuum tubes.  Today, transistors deliver far higher quality with a mere fraction of the bulk.  Fiber-optics has replaced huge tonnages of copper wire, and advances in architectural and engineering design have made possible the construction of buildings with much greater floor space but significantly less physical material than the buildings erected just after World War II.  Accordingly, while the weight of current economic output is probably only modestly higher than it was a half century ago, value added, adjusted for price change, has risen well over threefold.  The displacement of human physical effort by ideas is, of course, also evident in changed production processes.  Word processors have markedly reduced the effort required to produce a manuscript.  Turn-of-the-century steel mills, and even those operating in 1948, valued the physical brawn that could move coiled sheets from one segment of a plant to another.  Today, we perform these tasks with devices whose mechanical leverage is designed and guided by the insights coded into a computer program.  Radical transformations in what we produce in the way of goods and services and how we produce them occur perhaps once or twice in a century, at most.  After the Civil War, the rapid spread of railroads and the transcontinental development of the telegraph opened up national markets where virtually none existed earlier.  Large national companies emerged to do business from coast to coast and increasingly abroad.  Productivity accelerated.  At the turn of the century, electric power began its major expansion, revolutionizing the means of production in a manner that eventually created significant productivity advances.  Yet, with all the extraordinary technological advances of the past couple of decades, why have our recent productivity data failed to register any improvement?  That there has been an acceleration of overall technological change is scarcely in doubt.  Indeed, to a significant segment of our work force it has contributed to a heightened fear of job skill obsolescence, and a resultant sense of job insecurity.  Is it possible that that much of the frenetic activity is mere wheel spinning and, as a consequence, very little real value added is being produced or maybe ever will be?  I suspect this view is mistaken, for two reasons.  First, insofar as recent productivity growth is concerned, I have a serious question about the quality of the data that we employ to measure output in today's economy.  I shall come back to that issue shortly.  Second, like the major technological advances of earlier periods, it will take time for our newest innovations to work their way into the nation's infrastructure in a productive manner.  Motor vehicle transportation, for example, did not become a major productive force in the industrial world until highways and service stations permitted their capabilities to be activated.  Similarly, as Professor Paul David of Stanford and others have observed in an interesting line of research, it took a generation for electric motors to replace the steam engine to a point where aggregate productivity was measurably accelerated in the manufacturing area.  To capitalize on gravity and function most effectively, steam engines, and their vertically rotating belts, were installed in factories that tended to be tall and narrow.  When electric motors were substituted for steam engines in these buildings, their superior capabilities were significantly constrained by an older infrastructure.  It was only when plants were built horizontally that the electric motor came into its own and became a major factor in the advance of manufacturing productivity.  Professor David suspects, with many good reasons, that the ability of computer-based technologies to become fully reflected in our overall national productivity is being delayed as the infrastructure gradually, but progressively, adjusts to new modes of production.  With the ongoing turnover of the capital stock, computer-related synergies will, presumably, substantially raise real value added per hour in the years ahead.  One of the crucial ways in which computerization is already elevating living standards is by facilitating increasing customization to meet particular consumer needs.  The ability to pick and choose among a widening variety of products clearly enhances the well-being and satisfaction of consumers.  In the 1920s, as legend has it, Henry Ford learned that a market limited to only black sedans was soon threatened by early customization.  Color choices of other automakers helped undercut Ford's market.  While there can be little doubt that major gains are being made in today's market in the quality, choice, and availability of goods and services for American consumers, it is also clear that we measure these trends rather poorly.  To measure productivity and standards of living we need measures of output but, to measure output, we need to be able to define products clearly and in terms of units that do not change from one period to the next.  These conditions hold, more or less, for electrolytic copper, for cold rolled carbon steel, and for certain types of coal.  In these cases we can define reasonably well the unit of output and, accordingly, can know the price per unit.  But what is the unit of software?  What is its price per unit and how does that price move from one period to the next?  Also, we know that we are expending an increasing proportion of our gross domestic product denominated in current dollars on medical services.  But what is the physical equivalent unit of output of medical care?  What is the true price trend for the removal of cataracts, when the technology and the nature of the whole procedure is so dramatically different from what it was, say, forty or even twenty years ago?  How does one price procedures when there has been a shift toward less invasive arthroscopic surgery?  How does one evaluate the changed aftermath of such procedures on the day-by-day lives of patients?  We do our best to construct overall price indexes.  They may have served our purposes well in 1948, when industrial product was the centerpiece of the economy and certainly at the time of the founding of the Conference Board in 1916.  But what do they tell us today?  Indeed, how will we measure inflation, and the associated financial market implications, in the twenty-first century when our data using current techniques could become increasingly less adequate to trace price trends over time?  But so long as individuals make future contractual arrangements valued in dollars, there must be a presumption on the part of those involved in the transaction about the future purchasing power of money.  No matter how complex individual products become, there will always be some general sense of the purchasing power of money both across time and across goods and services.  Hence, we must assume that embodied in all products is some unit of output and hence of price that is recognizable to producers and consumers and upon which they will base their decisions.  Doubtless, we will develop new techniques of price measurement to unearth them as the years go on.  I recognize that we are dealing with issues that have difficult metaphysical dimensions deciding what actually constitutes the definable \"physical\" or \"real\" unit of a given good.  Recognizing that philosophers have been addressing related questions for over two thousand years, perhaps we should not be too optimistic about reaching quick, definitive answers in all cases.  But I trust that you will agree that we should encourage a good deal more research on the issue than it has received in recent years.  Other challenges at least as great as complications of price measurement will surely confront us as we advance into, and through, the twenty-first century.  But forecasting the future and its challenges is forecasting technology and, as another Stanford professor, Nathan Rosenberg, has documented so well, technology projections are a precarious activity.  History is strewn with the most erudite scientists of earlier ages proffering forecasts of technological developments, which, in retrospect, seem incomprehensible in their degree of inaccuracy.  But as Rosenberg points out, the evolution of even mature technologies is uncertain because most advances reflect the synergy of two or more innovations that are often chance outcomes, rendering the direction of change exceptionally difficult to predict.  While the future, as always, is fog-bound, with the inexorable turn of the calendar, the twenty-first century will nonetheless arrive.  And one thing we can be sure of:  it will be full of technological surprises.",
                  "1996-10-16 00:00:00"
                ],
                [
                  "10",
                  "Governor Lawrence B. Lindsey",
                  "Remarks by Governor Lawrence B. Lindsey At the Atlantic Economic Society, Washington, D.C. October 11, 1996 How To Grow Faster      It is my pleasure to be here today to discuss some of the most important issues facing our country today.  Without any doubt, the question that I have been asked the most often in the last year or so is, how do we get the economy to grow faster?        I can well understand the interest in this issue.  Even though employment is high and inflation is low, the growth of real incomes for American workers has been virtually non-existent.   The level of real compensation per hour in the second quarter of this year was essentially unchanged from its level in 1992, the first full year of the current economic expansion.  Even during the much maligned 1980s, growth in real compensation per hour in the business sector averaged 1/2 of 1 percent per year a far cry from no change in four years.        When it comes to economic growth, small changes mean a lot.  For example, that extra 1/2 of 1 percent growth per year in real incomes is the equivalent of roughly $300,000 worth of added consumption over the lifetime of an average American born this year, or $4,000 per year.  So, if we want to pay to send every American to college, cover rising health care costs, pay off the national debt, raise the homeownership rate to a new high, send a man to Mars, and have enough left over for a fairly nice vacation every other year, let's  find a way of raising the growth rate by half a percent per year.        Of course, all I have done by saying this is to fulfill the punchline of the old joke about an economist stranded on a desert island trying to figure out how to open a can of tuna fish. The punchline: assume a can opener.  The truth of the matter is that there is no magic formula in the growth business.  How fast an economy can grow is determined by three simple facts: how fast the available quantity and quality of labor is growing, how fast the capital stock is growing, and how much improvement, if any, is occurring in how well that labor and capital is being used.  These are not always attractive or viable options, however.        For example, Americans put in 10 percent more hours on the job since 1992 to take home 11 percent more pay.  This increase in work occurred because more people joined the labor force and the number of unemployed declined.   Of course, it is better to have these people working than not working.  But, in both the technical and the vernacular discussion of economic growth, simply employing more people at a flat level of compensation is not considered a successful growth strategy for an economy.        Adding capital may seem a more attractive option, but it is not a free lunch.  Capital formation requires foregoing current consumption in order to invest in productive plant and equipment.  Similarly, making more productive use of existing resources is not as painless in practice as it might seem.  We have made enormous strides in increasing productivity in our manufacturing sector and have the data to prove it.  But this has been accompanied by such headline-grabbing phenomena as corporate downsizing and layoffs.  Manufacturing output is up 24 percent since the business-cycle trough in 1991, but manufacturing employment is actually lower today than it was that year.  We can all appreciate that this manufacturing productivity success story was accompanied by a good deal of individual pain and sacrifice.       Complicating this entire discussion is the fact that the public policy debate on faster growth is taking place in the midst of the political process.  There is little political appeal in telling people that if they work harder, for more hours, consume less, and are willing to have their lives disrupted every few years to retrain and relocate, that ten years from now gross domestic product will be significantly higher than it otherwise would be.  It is interesting that some societies have succeeded in doing just this, particularly in East Asia.  But, without exception, each of these successes took place in a society which started from a lower base, had more to gain, and thus could do so more rapidly than America can today.       There is, however, one option that from time immemorial always seems to find its way into the political discourse: print money.   This year we have frequently heard from various quarters that it is a shortage of money, or its analog interest rates are too high which is preventing the American economy from growing faster.  The supposed remedy usually involves some degree of making monetary policy decisionmaking more responsive to the political process.  It is a familiar refrain, dating back long before William Jennings Bryan and his \"cross of gold\" speech.  Gibbon found evidence of politically motivated inflation in late Republican Rome, for example.  Time and repetition have not improved the merits of the case.       If there were any empirical evidence, let alone any logic, to the case that simply printing money leads to sustained higher economic growth for any period, I would be the first to advocate that we buy every printing press on the planet and start chopping down trees. Or, we could save the trees and simply decree that everyone should add a zero to every unit of currency, bank account, and bond that they own.  Frankly, as a recipe for sustained growth, money creation simply does not pass the test.       But what of policy at the moment?  Now, I do not want to get the bond markets all excited, so let me stress that I am not talking about a few basis points one way or the other. Rather, is monetary policy in any fundamental sense currently restraining real growth?  The most likely channel through which this alleged monetary restraint is supposed to work is by restricting access to credit.  Yet all of the survey and market evidence we have indicates that access to credit by businesses of all sizes is ample, at spreads which are quite low by historic standards.  Furthermore, on the consumer side, no one,  including those who have advocated easier access to credit by households in the past, now maintains that home loans, auto loans, or even unsecured credit in the form of credit cards, is difficult to get.  Indeed, a more reasonable view is that we are awash in credit.       But, I do not mean to imply that monetary policy is irrelevant to economic growth.  Let me go back to the first principles I stated earlier.  While monetary policy cannot  influence the amount of labor or capital available to an economy in any sustainable way, it probably can help augment growth by improving the way in which resources are used.  I believe that the best pro-growth prescription is to run monetary policy in a stable, predictable fashion which involves little or no inflation.  Let me explain why this is the case.       First, I believe that a stable and predictable economic environment is most likely to foster sound business decisions and a longer term outlook by decisionmakers.  A longer-term focus is needed to justify many of the research, development, and investment expenditures which benefit the economy in a sustained manner.   Second, a stable non-inflationary environment is most likely to lead investors to minimize the time and effort they spend on socially nonproductive hedging strategies designed to protect wealth in the event of a dramatic change in policy.  A reallocation of resources away from wealth protection and into wealth creation not only qualitatively improves the use of scarce capital, it also creates incentives for some of our most talented people to similarly redirect their efforts.  Third, a low-inflation environment is likely to minimize the level of, and attendant distortions from, taxation, certainly redirecting capital to better uses, and probably increasing the willingness to save, as well.       While these effects are probably difficult to quantify, they are more certain to bear fruit than either a simple policy of rapid money creation or even a more politically sensitive monetary policy.  One need not go back too far in the macroeconomic literature in this country to find frequent references to the political business cycle.  Such cycles involve needless shocks to the economy.  In the last twenty-five years, we have learned, somewhat painfully, that economies are subject to shocks over which they have little control and that such shocks are disruptive to long-term planning and growth.   It would seem foolish indeed to needlessly subject an economy to additional shocks that would be entirely a function of domestic political circumstances.       Having denied the efficacy of an often cited recipe for faster economic growth, I do have some positive suggestions for those who want to adopt policies to make America grow faster.   Consider returning to first principles.  Public policy must address how to most effectively increase the efficiency with which we use the labor and capital resources at our disposal.  To this end, the focus of public policy should turn from directing the private sector on how to increase its productivity toward asking the public sector to make better use of the resources under its control.  I suggest this for a very practical set of reasons.       First, the private sector already has a mechanism in place which disciplines its use of resources.  It's called competition.  The fact is that the private manufacturing sector is producing 24 percent more output with less labor than five years ago.  CEOs of companies who did not successfully increase the output they got from the same or fewer inputs quickly found themselves out of a job.  By contrast, employment in the public sector is up 6.2 percent over the same period.  Would anyone contend that even with this increase in labor input that the quality of services the government delivers has increased a commensurate 24 percent?   It seems quite clear that some lessons on efficiency can flow from the private sector to the public sector.       The second very practical reason why public policy must focus on resources now consumed by the public sector is that the lines of control are, at least in theory, more direct. Public policy directed at the private sector must resort to such indirect methods as incentives, guidelines, and directives.  Not only is efficiency lost in the communication of public objectives, but such regulation itself consumes valuable resources.  By contrast, politicians should be able to redirect public-sector resources more directly and efficiently, resulting in potential increases to the national growth rate.       Third, because the public sector has been spared the disciplining hand of competition for so long, the inefficient use of resources in that sector is far larger than any resource misallocations which exist in the private sector.  As I mentioned at the outset, growth is not a free lunch.  Even productivity improvements and efficiency moves have their costs.  The key is not to find a free lunch but the lowest-cost lunch available.  I suggest three low-cost growth lunches for consideration, which I will call the three Es: education, entitlements, and efficiency criteria. Education   I can think of no single industry in America in which resources are more poorly utilized than elementary and secondary education.  The failure of American education in recent years is now constraining economic growth because of a lack of basic skills.  I am not talking about such high-tech skills as computer literacy and using a keyboard.  Last month, in a meeting at the Federal Reserve Board with the Bankers Roundtable, bankers cited an inability to find workers who could convert fractions into decimals and vice versa.  Education has become their number-one concern.       Was it a lack of resources which created this problem or an alleged cutback in money spent on education?  The statistics suggest otherwise.  During the 1980s, for example, after adjusting for inflation, per pupil expenditures on public schools rose 39 percent, from $4,762 to $6,610 per year.  The most recent data, for the 1994-1995 year, indicates that this figure has grown to $6,857.  For an interesting contrast, consider that real per capita defense expenditures during the same decade rose only 30.3 percent.  In short, in a decade known for its rapid defense buildup and alleged neglect of social expenditure, education spending grew much more rapidly than defense.       The view that our public school system needs some radical restructuring and some competition is widely held in the public at large.   A recent poll on support for education vouchers for low-income students indicated that 73 percent of the public supported such a plan.  This included 82 percent of parents with students in school (who know the best how bad things are) and 90 percent of African Americans, many of whom probably suffer the most from the existing public-sector education monopoly.        The public understands intuitively that the low productivity of our public education system is caused by the way educational resources are utilized.  A good measure of just what we are wasting is given by the very limited competition which does exist.   About 5 percent of the nation's children are educated in the Catholic school system.  The cost per pupil is about 60 percent lower in that system than in the public schools.       The disastrous effect that the public education monopoly is having on economic growth is two-fold.  The most important effect is long term.  In a world where a mind is a terrible thing to waste, we are slowing the long-term rate of economic growth by causing a permanent underutilization of our nation's potential labor force.  Worse still, the costs of this wastage on the fabric of society far exceeds the mere gross domestic product we forego.       But the education structure is also causing a secondary, but still important, cost on society.  We are quite literally wasting resources wasting money if you will.  One can tell this because the price mechanism, which directs the private market to produce only those goods which consumers value more than the cost of production, is not allowed to work.  The cost of public schools is covered by taxes and the price of public school education is set at zero for consumers.  To not opt for public school education, you either have to believe that the schooling is worth less than zero or that the tuition you will pay at another school provides an education worth at least that much more than the taxes you pay toward a public school.  Yet, people are willing to pay.  The direction in which economic resources should flow in this industry follows logically.       Nowhere is this more clear than in Washington, D.C.  Although the metropolitan area is seeing an explosion in the number of children attending its schools, many families that can afford to leave the city, regardless of race,  are doing so.  This is in spite of the fact that per pupil spending in D.C. is 37 percent higher than in its neighboring counties.  The result is that while such suburban counties as Prince George's, in Maryland, and Fairfax, in Virginia, have seen school enrollments jump 12.8 percent and 11.0 percent respectively in the last five years, the D.C. schools have actually seen a modest decline.    In the D.C. area, an expensive and inefficient version of school choice exists.  Those that can afford the house prices in suburban jurisdictions and are willing to pay still more in an extended commute back to the city to work, do so.  Those that cannot are trapped.   The Congress came close to passing a school voucher plan for low- and moderate-income students trapped in the D.C. schools. Unfortunately, the plan was derailed by special-interest lobbying.       Politics may get in the way in New York as well.  There, the city's Catholic school system has offered to take 1,000 of the public schools' children who scored in the bottom 5 percent of performance.  Opposition from those with a vested interest in the public school system has expressed a great deal of skepticism about the plan.       As these two examples amply illustrate, we may not be maximizing our labor to its fullest potential.  Competition is a wonderful thing.  It is time to bring competition and choice to this vital American industry and enjoy the resulting gains in economic efficiency and growth. Entitlements   Just as our public-sector education system is a major drag on labor's contribution to economic growth, our public-sector retirement and health care schemes are a major impediment to capital formation.  As of October 1995, the net unfunded liabilities of the social security retirement system were roughly $2.8 trillion.  That is the difference, in present-value terms, between what we have told people we are going to give them in benefits based on what they have earned, and what we expect to collect from them in taxes.  While official estimates of the similar liability on the health care side are harder to pin down, they are roughly of the same order of magnitude.  In short, the government has promised Americans about $5 trillion more in benefits than it will collect from them in taxes.       Now it is certainly easy to understand how the political marketplace could produce this result.  The contrast to the private marketplace is striking.  In the private sector, the law puts severe restrictions on the capacity of firms to underfund their pension and health care plans. But this does not explain why the great majority of these plans not only meet the legal minimums, but are actually overfunded.   In addition, private-sector trends suggest a move away from the corporate management of such plans toward individuals being responsible for their own pension and health care decisionmaking, with the company playing the role of facilitator.   In addition, the private marketplace must have assets to stand behind the commitments.  The unfunded liabilities of the social security and Medicare systems have absolutely nothing standing behind them, not even government paper.       Thus, private provision for future pension liabilities requires the act of saving to purchase the financial assets to cover those liabilities.  The public scheme promises the future benefit with no act of saving being involved.  Some have pointed to the so-called social security surplus to say that there is no current problem.  The surplus, which is the difference between current cash income and outgo has been accumulating at the rate of $50 billion per year for the past eight years.  But that is not saving.  Each dollar of cash income to the system, by law, purchases the promise of future benefits.  The amount of the future benefits purchased with each dollar varies among individuals.  For some individuals, the present value of additional benefits purchased is more than $1 for every extra dollar in taxes paid, for others it is less. While we have taken in more in the last five years than we have paid out, those dollars taken in have purchased more benefits, in present-value terms, than what we have collected.  Thus, the actual social security shortfall has risen by $33.9 billion over the same period even as we seemed to be accumulating $50 billion per year in the so-called \"surplus.\"  Things have been getting worse, not better.  If that is not bad enough, those extra dollars coming in have all been applied to reducing the federal budget deficit on which so much attention is focused, further obscuring any long-term problem.       The effect on growth and saving results because people act on the belief that they will actually receive the $5 trillion in excess promises to which the government has committed. People need not engage in private saving to cover this extra sum that the government is going to give them, a sum frequently referred to as \"social security wealth.\"  We might think of the difference between future promises and future tax liabilities as net social security wealth.  If you take a reasonable estimate of  3 percent as the marginal propensity to consume out of wealth, then the $5 trillion in net social security wealth is implicitly boosting current consumption by $150 billion per year.  Alternatively, one might express the same $150 billion as the reduction in personal saving caused by the unfunded social security liability currently outstanding.  That amounts to 2.7 percentage points on the personal saving rate, which is now about 4.5 percent.  It is hard to think of any government program which would be likely to boost the personal saving rate by that much.        Former CEA Chairman Michael Boskin has estimated that the average retiree in 1980 received a net wealth transfer from the social security system of $63,000.  By contrast, a worker retiring in 2025 will suffer a net wealth loss of $48,000, and those figures come solely from the pension side of our entitlement process.   Of course, the politicians who created the program years ago were all successfully elected and regularly re-elected by those voters who retired in 1980, or earlier.  The workers who will retire in 2025 could not even cast their vote until the 1980 Presidential election.  As with education, we are paying a social price well beyond the mere economic costs.  The embittering effect this has on our political process is already palpable and is likely to get worse over time.   A poll conducted in 1994 showed that more young people believed that UFOs existed than believed that social security would be there for their retirement.  Such disillusionment and cynicism about the motivations and commitments made by our political process is not helpful and undermines political support for our public institutions.       Again, I think that we're going to have to take a lesson from the private sector.  The public-sector pay-as-you-go scheme has some inherent flaws, and each of those flaws is going to be exacerbated by the workings of the political marketplace.  The move toward defined-contribution pension  plans IRAs, 401(k)s, and the like, where each individual has his or her own account and is responsible for the decisions affecting that account seems to get around these flaws.  One of the great fears that motivated social planners to begin social security was the fear that most individuals would not make the sacrifices necessary to cover their own retirement.  Whatever the merits of that case, the concern can easily be met by establishing a minimum mandatory contribution but retaining control of all other decisions at the level of the individual. Efficiency Criteria   Having discussed ways of improving both the supply of labor and the supply of capital to our economy and thus produce greater growth, let me turn to the third aspect of the growth equation: using existing resources more wisely.  Again, I would like to take some lessons from the private sector, where we have witnessed productivity gains, and apply them to the public sector.       Let me stress that this emphasis is quite different from the current focus on the fiscal deficit for determining the success of policy.  The key issue, I believe, is how the government uses the resources at its disposal.  How it raises those resources through taxation or borrowing is a secondary issue.  The extraction of dollars from the private sector is not costless to our society, whether it is accomplished through taxation or borrowing.  Taxation induces distortions in private behavior and likely reduces the supply of both capital and labor, in addition to the benefits lost in foregoing the private purpose toward which those dollars would otherwise be spent.  Borrowing raises other costs, tending to drive up the cost of capital in society and requiring either that fewer capital investments take place or that we borrow from abroad.  But substituting taxation for borrowing does not solve our national saving problem.  Compare, for example, the net saving rate in our society during the last three calendar years with the period 1983-1985.  During the earlier period, the net national saving rate was 5 percent and a matter of extensive national concern.  In the 1993-95 period, it was under 3.5 percent.  True, the deficit was lower.  Government borrowing constituted about 2/3 of 1 percent less of GDP.  This occurred largely because the tax share of GDP rose by 1 percent.  But net private saving fell by 2 1/4 percent of GDP.  As a country, we are saving less now than we did a decade ago.       So, we must compare the usefulness of keeping money in the private sector versus moving it to the public sector.  Presently the real return on corporate equity is roughly 9 percent.  One can think of that as a rough estimate for the value of dollars left in the private sector.  So, in addition to extraction costs, the opportunity cost to the economy of moving private dollars to the public sector is equivalent to about a 9 percent return.  Now, if the government were to invest those resources in projects which yielded a 15 percent rate of return, the economy would clearly be better off, and the rate of economic growth would accelerate.  If the dollars were not wisely used say, put in a project yielding 3 percent the economy would be worse off and economic growth would slow.       The analogy in the private sector is the hurdle rate of return.  Firms evaluate project proposals based on their likely yield to the bottom line, accepting only those projects which meet a certain criterion.  Now, the \"bottom line\" in government is measured somewhat differently, but the concept is still the same.  Instead of measuring a private rate of return, one must instead measure a social rate.  Evaluation requires asking the question: how much would society value the benefits it derives from the money being allocated.  Estimates will be necessarily inexact; I would note that private sector estimates of internal rates of return are similarly subject to some uncertainty.  I have already argued above that, at least at the margin, a dollar spent on public schools produces an output that compares unfavorably to the output obtained for 40 cents in the Catholic schools.  Even if my estimates of the value are off by a wide margin, there is a big enough difference between a hurdle return of plus 9 percent and minus 60 percent to allow substantial measurement error.       The analog to hurdle rates of return in spending is cost-benefit analysis in the imposition of regulations.  Now this may surprise you, but the use of cost-benefit analysis is actually prohibited by law in such areas as determining the acceptable level of carcinogenic substances.  Congressional attempts to institute cost-benefit analysis in the Food and Drug Administration and the Environmental Protection Agency were blocked.  Again, we should acknowledge that cost-benefit analysis will not be perfect.  A good deal of regulation will fall in the area of \"too close to call\" given the measurement error and variability in the set of assumptions used.  But, a good deal will not.  What we must end is the political habit of avoiding cost-benefit analysis in the name of the \"public interest.\" Conclusion   In sum, I do believe that the American economy can grow quicker and that the American people are right in demanding that it do so.  We have been blessed in America with a competitive market mechanism that encourages private-sector decisionmakers to greatly enhance the productivity of their operations.  Those productivity enhancements have costs.  But they are subject to a market test.  If the enhancements do not yield sufficient benefits to justify their costs, the firms which have undertaken them will not be in business in the 21st century.       In the last fifteen years, or so, we have successfully broken down the regulatory and protectionist walls which sheltered segments of the private sector from competition.   As a result, it is unlikely that policymakers will be successful in doing significantly better than the market in forcing the private sector to engage in practices which will accelerate our economic growth rate.  Political schemes to force firms to invest in \"training programs\" or use their pension funds for \"social investment\" are certainly not likely to help.        Rather, the political process must begin to look at itself and at the failures inherent in the political marketplace.  Significant resources perhaps one-third or more of all of those at society's disposal are directed politically in a more or less direct fashion.  At a minimum this is a share of social resources which cannot afford to be overlooked by any society which wishes to grow faster.  Furthermore, there are good theoretical and empirical reasons to believe that there are significant economic gains to be had in the public domain.  Rather than resort to the age-old palliative of printing money, our leaders must turn their sights onto those",
                  "1996-10-11 00:00:00"
                ],
                [
                  "11",
                  "Governor Lawrence B. Lindsey",
                  "Remarks by Governor Lawrence B. Lindsey At the Community Development Lending Conference, Dallas, Texas October 9, 1996 Here We Go Again?  Thank you.  It is a pleasure to be here today to discuss some of the challenges that lie ahead in the areas of economic opportunity and community development.   Frankly it's a pleasure to be anywhere but Washington D.C.   Actually though, in any year divisible by four the whole country gets to glimpse the craziness that has always been a way of life in our nation's capital.  One of the problems that we have in Washington is that our focus is short term, limited only to the next election.  Anything that could happen more than four years into the future doesn't register on the collective consciousness.  And frankly this time frame has gotten shorter and shorter in an age of nightly polling and focus groups.  But America's cities are a testament to the effects policies enacted in the rush to the next election can have, as well as proof positive that trends that occur in a single economic cycle can last a long time.  Our successes, like our failures, often occur over decades.   And if we are really to be successful in our community development activities, we must take a much longer view, bearing in mind the problems that may arise as unintended consequences in the years ahead result from the political and economic environment in which we find ourselves today.  Now is a particularly appropriate time to look ahead and make plans because a confluence of forces are providing an array of opportunities that are historically unprecedented.  The community development industry has finally gotten its legs and has the possibility to grow and make a lasting contribution to the revitalization of America at a magnitude heretofore unimagined.  But if community development is going to succeed in an area where real success is measured in decades, it had better look ahead to a period when times will not be as propitious as they are currently.  Let me begin with some good news.  Access to credit by those individuals and communities that are the target of our economic development efforts has reached unprecedented levels.  One can see this from a variety of sources.  This summer  the financial regulators again released their annual report on the number of home mortgages granted the preceding year.  The data for 1995 indicate that in a year when the number of conventional home purchase loans decreased overall from 1994, lending to African Americans, Hispanics, and Native Americans went up.  The 1995 figures are part of a four-year trend with mortgages granted to these groups on a steady upswing, including significant double-digit increases from 1992 to 1994.  While one can never tell for certain what the \"right\" number of home mortgages given in a particular year should be, even some simple adjustments for income and demographic factors suggest that the numbers show that we have reached a point where race or ethnic-based discrepancies seem to have largely disappeared.  For example, if one takes the market for conventional, non-government-assisted loans as being families who earned $50,000 or more in 1994, then the proportion of such families getting mortgages in 1995 was 9.6 percent for whites, 8.0 percent for blacks, and 11.6 percent for Hispanics.  Including all mortgages conventional and government-assisted and dropping the income threshold to $25,000,  shows that 6.4 percent of whites, 6.0 percent of blacks, and 7.2 percent of Hispanics got mortgages in 1995.  Confining the base to married families with children, those most likely to be in the market, produces an even more compelling case that disparities have largely disappeared.  But the large increases in homeownership possibilities are not the only evidence of widescale increases in the extension of credit to traditionally underserved markets.  While we do not directly collect racial and ethnic data on nonhousing extensions of credit, evidence from the Federal Reserve's Survey of Consumer Finances gives good reason to believe that the penetration of underserved markets in the credit card business was as dramatic and preceded the large-scale increases in mortgage credit.  The survey is taken every three years, including 1995.  The preceding two surveys, in 1989 and 1992, showed that the proportion of white families with outstanding credit card debt rose only slightly 42.5 percent in 1989 and 44.1 percent in 1992.  In 1995 this proportion was 47.5 percent.   But the growth in credit card use as a source of finance among nonwhites was substantial. The proportion of nonwhite families having outstanding credit card balances rose from 34.1 percent in 1989 to 42.9 percent in 1992 and to 48.8 percent in 1995.  Of course, the numbers of people actually having credit cards is much higher.  This suggests that a potentially debilitating economic burden has been lifted from a significant share of the population who can now meet economic emergencies and time their purchases with greater ease. A Confluence of Events Why has all of this occurred just now?  A part of me would like to conclude that this is the result of a permanent change in attitudes in America.  While I certainly believe that we are a more enlightened country than five or ten or twenty years ago, that our collective consciousness has been raised, if you will, I do not believe that this is the whole story.   And, there are particular pitfalls to the community development industry in believing that it can rely on an increased nobility of purpose to sustain its mission.  In the short term one can rely on a sense of guilt, or charity, or a fear of enforcement action to motivate behavior.  But it will not last.  The only permanent motivating force in this world is self-interest.  Individuals enter into, and stick with, long-term cooperative agreements only because they are mutually beneficial.  Recently we have enjoyed a set of both micro and macro economic conditions that set the stage for a whole new set of  mutually beneficial relationships to emerge.   But those fortuitous economic conditions will not last forever.  We will be successful only if we cement in place long-term mutually beneficial relationships that can survive an adverse turn in economic events.  Without any question the most important economic development has been a decline in the underlying rate of inflation and the consequent decline in medium- and long-term interest rates.  Let's do the standard math involved in any home financing decision.  In 1990, fixed thirty-year mortgage rates averaged 10 percent.  Recently they have been around 8 percent.  The principal and interest payments on a $100,000 mortgage declined from $878 to $734.  Using a standard set of assumptions regarding property tax and insurance payments and a PITI to income ratio of 28 percent, the annual qualifying income for this mortgage has fallen from $48,771 to $42,600.  That $6171 decline in qualifying income comes at a very dense part of the income distribution, particularly in the minority population.  And, when one considers mortgage market innovations that have eased traditional underwriting constraints, the increased opportunity that results from lower inflation and lower long-term rates is even more amplified.  Let me use these figures to stress something that I have learned as a Federal Reserve Governor and as someone active in promoting homeownership opportunities to low- and moderate-income Americans.  There is a school of thought among some politicians that fighting inflation is bad for low- and moderate-income people.  But the reduction in inflation during the 1980s and the continuation of that policy during the 1990s, has done more for homeownership opportunities among low- and moderate-income groups than any program administered by the government.  It is important to stress the differential impact of inflation between those who already have their homes and those who are seeking to buy.  Our system of long-term fixed interest rates and the home mortgage interest deduction makes increasing inflation highly profitable to those who already have financed their homes.  That is why we all grew up being taught that homes were a great inflation hedge.  If, however, you are simply in the market for physical shelter and not a tax shelter or inflation shelter, high inflation, and consequently higher long-term interest rates, prices you out of qualifying for a home.  Furthermore, if your income is fairly moderate, you may not even qualify for the home mortgage interest deduction.  Thus, a low-inflation environment is a key to maintaining homeownership opportunities.  While the commitment of the Federal Reserve to preserving a low-inflation environment is unwavering, I cannot assure you that all politicians feel the same way.  Nor can I guarantee you that sustaining the fight against inflation will not mean a temporary rise in interest rates at some time in the future.  The second major change has been a shift in attitudes among bankers and their regulators.  The regulatory environment has moved dramatically from an overarching concern for bad loans on the books of the nation's banks to one which focuses on regulatory concerns more friendly to community development such as CRA and fair lending.  Just four years ago, as we were working on the implementation of FDICIA legislation, the regulatory staff was proposing adopting maximum loan-to-value ratios for mortgages.  The Senate Banking Committee had recommended an 80 percent cap on such LTVs.  In essence, all home mortgages would have to have been accompanied by a 20 percent down payment.   Can you imagine the state of the community development industry if these ideas had been implemented?   Today of course, with the nation's banks enjoying unprecedented health, the focus of regulatory and political concern has changed.  We have recently completed an extended period of revamping and strengthening the Community Reinvestment Act regulations.  Detailed analysis of bank lending practices down to the census tract level is now a part of our regulatory mission.  Fair lending enforcement has been significantly enhanced and is now using statistical practices that are state-of-the-art in all of their technical, legal, and econometric aspects.  A similar change has occurred among the nation's banks.  As other lines of bank lending have seen increasing competition and entry by nonbank financial service providers, the focus of bank lending has moved to the consumer.  In 1980 just 33 percent of total bank loans were consumer debt based including mortgages.   That figure rose to 40 percent five years ago and is 44 percent today.  In addition, the securitization of consumer debt instruments for resale in the capital markets has increased both the willingness and the ability of banks to make such loans.  But just like the business cycle, the regulatory and banking cycle will not always be as favorable to consumer lending and community development as it is today.  The early signs are already in place.  Consumer debt-to-income ratios are now at record levels.  Debt-service ratios are back to the levels they reached just before the last recession.  Bankruptcies are at record highs.  As a result, for the first time in this business cycle, banks are no longer, on net, making consumer credit more accessible but are instead beginning to cut back.  The political tide has also turned.  Last December, Congressman Kennedy held a forum, at which I testified, in which his theme was that banks were extending too much credit.  Chairman Leach of the House Banking Committee held formal hearings last month on the consumer credit situation where bipartisan concern was expressed about the sustainability of existing consumer debt practices. Some Previous Cycles The reason that we should all be concerned is that history teaches us that these cyclical swings can have some pretty profound effects.  I have had other occasions to talk about some of the financial innovations that have played a role in shaping the urban landscape over the past century.  Today, I would like to broaden that analysis to look at swings in public policy and the related swings in the community development and housing markets.  I am going to focus on two particular cycles to give a flavor for the type of trends we should be looking for.  The first is the Urban Renewal cycle of the 1950s and early 1960s.  The second is the Great Society cycle of the late 1960s and early 1970s.  The Urban Renewal cycle started with the Housing Act of 1949.  It declared that, \"a decent home and a suitable living environment for every American family\" was to be a  national goal.  Title I of the act was labeled \"Urban Redevelopment,\" and it was designed to clear slums and deal with two perceived problems the high cost of land and the existence of parcels of land in cities that were considered too small to meet perceived modern needs.  More than half of the federal money spent on urban renewal in the first dozen years of the act went to the purchase of property.  While the urban planning theory behind the legislation may have seemed laudable, the actual implementation produced a very different result.  Between 1949 and 1968 some 425,000 units of housing, nearly all of them occupied by low-income households were torn down while only 125,000 new housing units were built on the sites.  Further, well over half of the new homes were for upper-income groups.  In its implementation, urban renewal was targeted at improving the commercial attractiveness of downtown areas.  The price paid for this gamble on redeveloping downtown was a reduction in the availability of low-income housing.  Ultimately this gamble on the commercial position of downtown proved a loser as commerce switched to the shopping centers located on the fringes of towns.  In large part, this was the inevitable result of suburbanization.  There is no question that widespread auto ownership, the baby boom, and the tastes of the public to achieve the American dream of a home in the suburbs were the main driving forces here.  But government policy helped.  The Depression Era housing legislation that established the savings and loan industry created a natural market niche for middle-income home lending.  Long-term mortgages at roughly 5-1/2 percent were common.  This system would work well from a financing point of view until the mid-sixties, primarily because of stable interest rates, favorable demographics, and general prosperity.  Of course, this was only true of the finance end of the delivery system.  In terms of social justice, the story was quite different.  The FHA's official manual of the 1930s and 1940s explicitly sought to keep neighborhoods occupied \"by the same social and racial classes\" in the name of neighborhood stability.  The manual even encouraged the use of a model covenant prohibiting the mixing of races.  Although restrictive covenants were outlawed in the late 1940s and the FHA would not insure properties covered by them by early 1950, this did not put an end to segregated developments.  The fact is that only 2 percent of the new FHA-insured houses were open to blacks between 1946 and 1959.  What one could call the \"Urban Renewal Cycle,\" or more aptly the \"Suburb Creation Cycle\" of housing policy came to an end in the second half of the 1960s.  Both economic and social trends changed to make the old cycle unsustainable.  On the social side, the political neglect of the inner cities was brought to an end.  Between 1965 and 1968, widespread urban disturbances occurred in many cities  in the United States.  The result was a spate of commissions and legislation to address urban needs.  For example, the Department of Housing and Urban Development was established.  The Model Cities Program was authorized in 1966.  A ten-year goal of 26 million new and rehabbed housing units was set.  On the economic side, the combination of inflation and government regulation of interest rates produced rapid disintermediation of funds out of the housing market in the late 1960s.  To ease those constraints, the savings and loan industry was allowed to offer a 50-basis-point premium over commercial banks to attract deposits.  But even this proved insufficient as the problem of housing access was hindered by the outmoded Depression Era delivery system of finance.   In 1967, which was otherwise a boom year for the U.S. economy, real residential investment ran 14 percent below its 1964 pace.  And for the entire period of the late 1960s, housing starts ran almost one-third below their 1959 peak.  Needless to say, this combination of social and economic forces created political pressure for change that became irresistible, and the Great Society cycle began.  In 1968 Congress allowed the FHA to adjust the ceiling mortgage rate above the statutory rate.  It also authorized section 235, allowing HUD to provide mortgage assistance to allow the interest rate paid by the buyer to be as low as 1 percent and the downpayment to be as low as $200.  For all intents and purposes, a flood of essentially free money began pouring into the housing market.  This rapid political response and flood of government money created problems of its own.  By December 1970, the natural abuses of section 235 became apparent.  A report to the House Banking Committee concluded, \"The Department of Housing and Urban Development and its Federal Housing Administration may be well on its way toward insuring itself into a national housing scandal... FHA has allowed real estate speculation of the worst type to go on.\"  Substandard homes bearing inflated mortgages coupled with the practice of \"flipping\" by unscrupulous speculators was the natural result of this virtually free access to funds.  A 1972 internal HUD audit indicated that HUD was paying substantial premiums for the design and construction of multifamily projects.  Press articles appeared that referred to HUD as the nation's largest slumlord.  So, the Great Society cycle of massive urban housing subsidies came to a crashing end with a de facto housing moratorium in 1973.  Donald Sullivan, in his article on housing in the 1970s contained in Gertrude Fish's The Story of Housing, summed up the lesson we should all learn very well:  \"In designing  programs to allow low and moderate income Americans to participate in the dream of homeownership, few realized that a tighter control or performance system would be necessary for monitoring purposes.  Federal money suddenly became available ... as well as FHA insurance.  The granting of FHA insurance to homes of such poor quality that they clearly would not survive the life of the mortgage was basically fraud.\"  The effect of this boom-bust cycle on our nation's cities was horrendous.  Chicago's Mayor Richard Daley told a Senate committee in 1975: \"Most major cities in the U.S. have been left with thousands of abandoned and vandalized structures in what had been desirable neighborhoods.\"  Les Coplan of the San Francisco Home Loan Bank testified: \"We had 2,000 foreclosures in Oakland.  Some of them were section 235 loans; the rest resulted from the breakdowns that followed 235.\"  The key fact that Coplan was on to was that if defaults and foreclosures reach a crucial level, not only those who default turn out to be losers.  A neighborhood cannot survive when a number of its homes become abandoned.  They quickly become targets for vandals, and now in the 1990s, become havens for the drug trade.  The result is a decline in the entire neighborhood as it becomes a less desirable place to live.  Deteriorating property values lead to increasingly risky lending conditions, a natural cutback in capital, and still further declines in property values. Here We Go Again? All of this history should lead us to some sobering reflection.  Are we now at another peak and about to enter another crash in the economic, political, and regulatory underpinnings of our urban redevelopment and homeownership efforts?   There is at least superficial resemblance to the two earlier cycles I discussed.  The economics most closely resembles the 1950s cycle of low interest rates coupled with low inflation.  The politics and regulatory environment most closely resembles the late 1960s when efforts to channel funds to urban redevelopment were most desirable.  My suspicion is that in spite of these comparisons we still have some time if we act prudently to prevent problems in the future.  I suggest three steps.  First, I think that it is vital for all of us to realize that a low-inflation environment is crucial to urban redevelopment and homeownership opportunities for low- and moderate-income individuals.  Unfortunately, some of those politicians who express the most concern about these issues do not understand this fact.  The political temptation to try to solve economic problems with the printing press is probably as old as government, but it simply does not work.  And bad as it is for the economy at large, it is a disaster for the stability required for financing homeownership opportunities to those on the first rung of  the economic ladder. ",
                  "1996-10-09 00:00:00"
                ],
                [
                  "12",
                  "Chairman Alan Greenspan",
                  "Remarks by Chairman Alan Greenspan U.S. Treasury securities market: Lessons from Alexander Hamilton At the Annual Public Service Awards Dinner of the Public Securities Association, New York, New York October 7, 1996  I thank the members of the Public Securities Association for bestowing upon me this award for distinguished public service.  I am particularly honored by the company that I keep as a winner of this award, as previous recipients have included Senators Daniel Patrick Moynihan, Christopher Dodd, and Kay Bailey Hutchison and my predecessor as Chairman of the Federal Reserve, Paul Volcker.  I trust that everyone in this audience would agree that the U.S. government securities market works as well as any on earth and generates widespread macroeconomic benefits.  In one sense, that is regrettable.  The market has become so efficient in part because of the  economies of scale associated with the large volume of Treasury debt issued over the years.  While the massive federal debt has allowed traders to refine their skills, it has also implied that much of the small pool of national saving has gone toward funding the government.  Moreover, the interest burden of this debt has kept tax rates higher than we might have wanted.  In another sense, though, the efficiency of the government securities market stands as testimony to decisions by policymakers in the formative days of our nation that convinced the world that the United States honored its commitments and valued the rule of law.  Every time I visit Secretary Robert Rubin, I am reminded of the power of the decisions of the first Secretary of the Treasury that laid the foundations for this nation's financial credibility.  Engraved at the base of the statue of Alexander Hamilton outside the Treasury building are the words of Daniel Webster: \"He touched the dead corpse of the public credit, and it sprung upon its feet.\"  Everyone knows the short version of the events that prompted that praise.  Hamilton convinced the new Congress to honor the debts of the Continental Congress.  Under his prodding, the federal government also assumed responsibility for the debts of the individual states incurred in fighting the War of Independence.  But there are five details of the debate at that time that we all would be well served to remember.  First, Hamilton insisted on full payment of the debt.  Many at that time counseled discrimination among those obligations perhaps by favoring vendors and veterans over bond holders or perhaps by paying original holders of debt more than those who purchased securities in the secondary market.  Hamilton recognized that an obligation was an obligation, no matter how it was incurred or who held it.  Repayment had both a moral and a practical dimension.  The debt, in Hamilton's words, was the \"price of liberty\" because it financed the successful completion of the War of Independence.  Those who extended aid at a time of peril, or supported the debt subsequently, deserved to be repaid.  But repayment would also send an important message to investors, particularly those abroad, that the United States could be trusted in the future.  Hamilton recognized, and we should never forget, that investors have many choices on world markets.  Even the whiff of the possibility that the United States would not honor its debt would push up the cost of borrowing for years to come.  Following Hamilton's lead, the Treasury has never defaulted on any debt security, notwithstanding the abrogation of the gold clauses in 1933.  Second, Hamilton was practical in his understanding that economic policymaking cannot be divorced from the broader discourse on public priorities.  The debate on the assumption of state debts generated arguments so heated as to make our weekend television talk shows appear as civil as tea parties.  Reflecting on those days in his later years, Thomas Jefferson by no means an admirer of the first Secretary of the Treasury was led to write that \"this measure produced the most bitter and angry contest ever known in Congress, before or since the Union of the States.\"  But those bitter enemies, Hamilton and Jefferson, compromised with an old-fashioned horse trade.  Jefferson threw his support behind the assumption of the state debts in return for Hamilton's advocacy of placing the nation's capital on the banks of the Potomac.  Political realities have not changed in that regard in the succeeding two centuries.  It is inevitable that consideration of the budget be included as part of a wider debate on public policies.  However, Alexander Hamilton drew a line that no one should cross:  The government of the United States must never default on its debt.   Third, Hamilton's plan to honor the old debt provided a sinking fund to help repay new debt as it came due.  The first Secretary saw that Treasury debt was a burden to future generations.  And it was his responsibility to provide the means to lighten that load.  In those simpler times, before we became too sophisticated for our own good, deficit financing was a necessity prompted solely by peril, not as a tool of active demand management or as an excuse to put off hard decisions.  In one sense, though, Hamilton's job of planning for the retirement of the debt he was issuing was easier than the problems confronting today's policymakers.  In 1789, government obligations could be measured by the amount of debt outstanding.  Today, debt comes in many forms, including promises to pay that have become embodied in unfunded entitlement programs.  Fourth, Hamilton's refunding scheme provided for the issuance of securities of long maturity that would be repaid in specie.  Thus, his Treasury locked in longer-term funding and did not have to test continually the market's willingness to finance the new government.  At the same time, investors were given some assurance that holding government securities would preserve their purchasing power.  Those same incentives have led our present-day Treasury to issue securities across a wide range of maturities and, I am pleased to note, to begin soon to offer debt indexed to consumer prices.  Fifth, and this should come as no surprise from one of the authors of the Federalist Papers, Hamilton explained his policies in well-written, logically constructed arguments that remain a pleasure to read, even two hundred years later.  Hamilton's lessons speak across the generations, both to policymakers in mature democracies and those coping, as he did, with financing newly independent states.  If we are to protect his creation, the U.S. Treasury market, we must remember two facts he could not afford to forget.  For one, buyers of Treasury securities do so through their own volition.  Investors have alternatives, and more so now than ever before.  For another, the issuer of those securities, the U.S. Treasury, must finance an amount, on net, that is determined by the political judgments of the congressional and executive branches of government.  If the government makes purchasing its debt harder by imposing onerous reporting or bookkeeping requirements or riskier by following capricious macroeconomic policies buyers will pull back and the cost of servicing the debt will rise.  We at the Federal Reserve will do our part to contribute to financial stability, which is to preserve the purchasing power of money over time.",
                  "1996-10-07 00:00:00"
                ],
                [
                  "13",
                  "Chairman Alan Greenspan",
                  "Remarks by Chairman Alan Greenspan Bank supervision, regulation, and risk At the Annual Convention of the American Bankers Association, Honolulu, Hawaii  October 5, 1996       You may well wonder why a regulator is the first speaker at a conference in which a major theme is maximizing shareholder value.  I hope that by the end of my remarks this morning it will be clear that we, the regulators, share with you ultimately the same objective of a strong and profitable banking system.  Such a banking system knows how to take and manage risk for profit.  The problem is what, if anything, regulators should do to constrain the amount of risk bankers take in trying to meet their corporate objectives.  I have given considerable thought to this issue over the years, and today I would like to address this theme once again. I.   The Changing Nature of Bank Supervision and Regulation      At the outset, it is critical to understand some key unintended implications  of the safety net our system of deposit insurance, payment guarantees, and discount window credit. First, since the safety net makes bank creditors feel safer, the banking system is larger, more stable, and more able to take risk and extend more credit than otherwise would be the case. In the process, banks have contributed significantly to the economic growth of the nation and continue to do so.       Second, since deposit insurance premiums do not, and probably cannot,  vary sufficiently with risk, the disconnect between bank portfolio risk-taking and a bank's cost of funding has made necessary a degree of regulation and supervision that would be unnecessary without the safety net.  That is, since the market signals that usually accompany excessive risk-taking are substantially muted, regulators are compelled to act as a surrogate for market discipline.       In addition, our preoccupation with prudential risk-taking has added to the pressures put on the entire banking and regulatory structure by technology and globalization.  Many of the activities that banks feel are necessary responses to these market pressures are either prohibited by statute or constrained by regulation because of our concerns about exposing the safety net to unacceptable risk.       These implications of the safety net highlight the dilemma of the regulator.  How do we avoid killing the goose that lays the golden egg an  innovative and flexible banking system without either exposing the taxpayer to excessive potential cost or the financial system to excessive systemic risk?       The answers to this question are critical.  First and foremost, as I have indicated many times before, the optimal failure rate in banking is not zero.  Risk-taking means that failures will occur, and, moreover, if we did not permit risk-taking, and therefore the possibility of failure, the banking system would not be in a position to foster economic growth.  The banking system would shrink because it would be unable to carry out its underlying economic function.       While failures will inevitably occur in a dynamic market, the safety net not to mention concerns over systemic risk requires that regulators not be indifferent to how banks manage their risks.  To avoid having to resort to numbing micromanagement, regulators have increasingly insisted that banks put in place systems that allow management to have both the information and procedures to be aware of their own true risk exposures and to be able to modify such exposures.  The better these risk information and control systems, the more risk a bank can prudently assume, although higher risk positions generally will require larger loan loss reserves and higher capital.       I might also note that risk management standards are increasingly an  important supplement to traditional supervisory techniques.  The use of new technology and instruments in rapidly changing financial markets means that some balance sheets are already becoming historical artifacts that are not even necessarily indicative of risk exposures of the next day. In such a context, the supervisor must rely on his evaluation of risk management procedures as a supplement to and in extreme cases, in lieu of balance sheet facts.  As the 21st century unfolds, the supervisors' evaluation of safety and soundness, of necessity, increasingly will be focused on process, and less on historical records.       Well-functioning risk management systems are necessary, but not sufficient, for taking on greater risk.  Banks must also have the capital resources to absorb the inevitable losses that result from risk-taking and still remain solvent.  Thus, banks are required to maintain both reserves consistent with expected losses and capital sufficient to absorb the vast majority of unexpected losses that experience and data suggest could occur, but whose timing and size are not predictable.       Determination of appropriate capital levels is not just a regulatory concern. Increasingly, bankers are treating the determination of proper capital levels as integral to the meeting of shareholder goals.  Shareholder value is maximized, almost surely, when long-run risk-adjusted return on equity is maximized.  One method of quantifying the risk-adjusted return is to measure returns net of expected losses against the capital that should be allocated to a transaction to reflect that transaction's risk.  As I will discuss in more detail shortly, some bankers are doing exactly that: quantifying risks, allocating sufficient capital to cover those measured risks, and then trying to focus on those lines of business for which risk-adjusted returns to allocated capital are the highest.  It does not matter whether the bank concentrates on low-risk, low-capital business, or on high-risk, high-capital business, only that it concentrates on businesses for which it has a comparative advantage, that is, businesses that earn an above-average rate on its internally allocated capital, after provisions for expected losses.  Regulators, in my opinion, should take notice of this emerging business philosophy  for a bank that properly measures its risks and allocates capital to those risks is well on its way to being a safe and sound bank, as well as one that meets its shareholders' objectives. II.  Implications of Technology for Shareholder Value and for Regulatory Policy       Many observers have commented on the increasing complexity of financial instruments and transactions.  However, these complexities would not have been possible in actual market circumstances without the technological advances that also allowed these risks to be measured and managed.  Indeed, as I noted earlier, banks can now quantify the dimensions of risks for instruments and transactions that we could only conceptualize a short time ago.  Consider just two examples of what risk quantification permits today:  securitization and the day-to-day control of market risk in a portfolio of complex derivative contracts.  In both of these cases, risk quantification is a prerequisite to informed risk-based pricing.  Moreover, the comparison of the risk-based price to current market conditions is critical to management decisions regarding withdrawing, cutting back, or expanding a bank's endeavor in specific credit markets.       A critical component of risk-based pricing, as I noted earlier, is the determination of an appropriate internal allocation of capital to the individual credit subportfolios.  For internal management purposes, banks for some time have been grouping their credits by risk class, modifying the classification of individual credits periodically.  Now, banks on the frontier are using historical data and advanced modeling techniques to determine formal estimates of probable losses for each loan classification.  Some of these banks have gone one step further, using these risk estimates to estimate the amount of capital that management should allocate against various loan classifications for internal pricing and other resource allocation purposes.      The widespread adoption of these techniques lies in the future, but, as I suggested earlier, some forms of risk quantification are now being used by banks to enhance shareholder values.  Unfortunately, some bankers believe that new technologies, such as credit scoring, and the growth of some activities, such as securitization, will reduce their franchise values by driving down spreads.  Indeed, the new technologies can be viewed as chipping away at banks' specialized knowledge of the local loan customer.  In effect, barriers to entry are lowered when the new technologies allow nonlocal competitors to offer standardized products through nationwide marketing campaigns using, for example, toll-free 800 telephone numbers. On the other hand, the byproducts of these new technologies include lower underwriting expenses and the more accurate estimation of probable losses.  These byproducts act to offset the effects of increasing competition created by the new technologies, both by raising profits on existing operations and by opening up opportunities with customers previously not served. Better and more quantifiable estimates of risk are tantamount to risk reduction.      More generally, and of much greater importance, rapidly changing technology is broadening and deepening financial markets while inevitably enhancing competitive pressures. In one sense this trend has been with us since the industrial revolution, but it has clearly accelerated in recent years in banking markets.  Because the hot hand of competition is always putting pressure on us, we in our darker moments wish it would just go away.  I very often succumbed to such melancholy when I was in the private sector.  But we are wrong. Competition is the force which keeps us on our toes, makes us better and more productive, and creates higher market values for our banking institutions, just as it does for other firms. Competition is what has raised our standards of living for generations and made this nation the world's preeminent economic power.      Technological change and the accompanying competition are irreversible, and those banks unwilling or unable to adapt to them will lose market share and suffer lower risk-adjusted rates of return.  But the banks that embrace the cost-cutting and risk-reducing effects of the technology will, in my judgment, tend to find it a rewarding experience.  Scale is not an issue.  Small banks can now purchase the software that will permit them to use the new procedures, and upstream correspondents and others will be there to buy the product. III. Regulatory Innovation      Technological change is not the sole province of the private sector.  Regulators too must adapt to the new technology, and, in this regard, some important lessons are being learned.  For example, the private sector, for a considerable time, has been accustomed to product planning cycles in which the planning of the replacement product is begun, if not well along, by the time a new product is being introduced.  Similarly, regulators are beginning to understand that the supervision of a financial institution is, of necessity, a continually evolving process reflecting the continually changing financial landscape.  This is not a fault but rather a description of an appropriate regulatory process.  Indeed, given our own long lead times, we must begin designing the next generation of supervisory procedures even while introducing the latest modification, much as you are forced to do for your own products.      Increasingly, the new supervisory techniques and requirements try to harness both the new technologies and market incentives to improve oversight while reducing regulatory burden, burdens that are becoming progressively obsolescent and counterproductive.  This is becoming especially true in evaluating the capital adequacy of banks.  One example is the recent decision by regulators to use internal model approaches for measuring market risks at banks and allocating regulatory capital to those risks.  In addition, the Federal Reserve Board has been studying an alternative capital allocation process for market risk, the so-called pre-commitment approach.  This methodology would provide market and other financial incentives for banks to choose their own capital allocations for trading risk that they believe are consistent with their own risk management capabilities as well as with regulatory objectives.      The range and extent of securities powers permissible for bank holding companies is another area where the Federal Reserve has attempted to modify its regulations to parallel changing market realities.  As you know, beginning in 1987 the Federal Reserve allowed increased securities powers in so-called section 20 subsidiaries.  Most recently, based on our favorable experience with these subsidiaries, we have proposed dismantling some of the limitations and restrictions that, in an abundance of caution, we originally imposed to constrain risk exposures of the insured bank affiliate.  Both that favorable experience and the changing structure of financial markets suggested that these modifications were desirable.      Similarly, both changing markets and our experience suggested the need to streamline the bank holding company application process and related provisions.  Accordingly, in August the Board requested comment on a wide ranging revision to its Regulation Y.  You will note that the expedited application procedures were proposed only for strong and well-managed entities that we believe, by definition, need less oversight.  This, too, is a simulation of the way the market would treat such financial institutions.      However, both the section 20 and Regulation Y examples illustrate another major problem in the current banking environment.  Both areas are still constrained by outdated and increasingly inefficient statutes.  Indeed, statutory provisions ultimately limit the Fed's ability to relax section 20 or Regulation Y limits.  Fundamental congressional reform of the Glass-Steagall  and the Bank Holding Company acts is still needed. IV.  Conclusion      If banks were unregulated, they would take on any amount of risk they wished, and the market would rate their liabilities and price them accordingly.  Ideally, banks should also face regulatory responses to their portfolio risks that simulate market signals.  And these signals should be just as tough as, but no tougher than, market signals in an unregulated world. Perfection would occur if bankers had a genuinely difficult choice deciding if they really wanted to remain an insured bank or become an unregulated financial institution.       While awaiting perfection, it is useful to underline that regulators and banks have a common interest in using the evolving new technologies to meet their own separate objectives:  maximizing shareholder value and maintaining a safe and sound banking system. One cannot be done without the other.  And as you increasingly apply these new technologies, we will be replacing our procedures with those that depend increasingly on risk management, risk quantification, market simulations, and within the confines of law reduced barriers.  Our \"best practice\" is to assure that regulatory restrictions are not a barrier to your \"best practice.\"  Your \"best practice\" is to employ improved risk management and all its tools in order to increase your risk-adjusted rate of return.  If you succeed in doing that, bank",
                  "1996-10-05 00:00:00"
                ],
                [
                  "14",
                  "Governor Lawrence B. Lindsey",
                  "Remarks by Governor Lawrence B. Lindsey At the Small Business Development Conference, Richmond, Virginia October 2, 1996 Small Business Is Big Business       It is my pleasure to be here today at the Federal Reserve Bank of Richmond's Small Business Development Conference.      A fair question might be, what is the nation's central bank doing sponsoring a conference on small business?   Well, let me be clear about one thing, neither I nor my colleagues from the Fed are going to say to the small business people of America   I'm from the government and I'm here to help.  If I even attempted such a claim you would all rightly laugh at me.      But that does not mean that small business is not an important area of concern for us; nor does it mean that we have no appropriate role to play.   Small business is vital to the U.S. economy in ways that go far beyond mere quantitative measures.  The small business sector is the market's laboratory of new products and new ideas.  Less than a century ago, Ford Motor Company was a small business   little more than a backyard operation.  Forty-one years ago, McDonald's was a single hamburger outlet in Des Plaines, Ill.  Twenty years ago, Microsoft had a similarly humble origin.  We do not know, nor can we ever tell which of the small businesses being formed today will become multi-billion dollar operations in the 21st century. But, we do know that some will and they will be part of the driving force which remakes the American economy.      But, even those businesses which do not become industrial behemoths still have a vital role to play.  Small businesses build our homes and unclog the drains when they get full, they monitor our health and repair our cars.  They provide these goods and service because in a market economy driven by consumer sovereignty, they have a better and more personal knowledge of the needs of the consumer than would a much larger enterprise.  I would add that 34.1 percent of the nation's roughly 10,000 banks employ fewer than 20 workers, and the combined assets of those that meet the widely used SBA definition of small business   fewer than 500 employees   have 26.1 percent of the nation's banking assets.      It goes without saying that a sector which employs half of the private work force is vital to our nation's economy.  But, when one considers what that sector does, it is clear that the other half of the economy could not function without it.  So, as a central bank we must monitor the health of the nation's small businesses because it is a central focus of the health of the American economy.      But we, the central bank, also have a responsibility to play the role of honest broker and information provider.  We are not here to make a loan, tell you who to hire, or tell you what a profitable line of business might be.  We are here to facilitate the flow of information in that regard. Small Business and the Economy      Let me begin by considering a unique characteristic about the U.S. economy that comes from its having one of the most robust small business sectors in the world.   If one visits Europe and talks to economic and political leaders there, talk invariably turns to the American Job Creation Miracle.  This is not a new phenomenon.  During both the 1970s and 1980s the economy added jobs at the rate of 19 million per decade.  So far in the 1990s we have come close to keeping up this pace, having so far added about 10 million jobs to the private economy.      The keys to this success are two closely related phenomenon.  First, we have a flexible and largely unregulated labor market.  To date government by and large has not imposed overly burdensome mandates on employers and made the process of hiring and firing overly difficult.  Of course, the political temptation to do so is always there, as it is in Europe, but to date we have not adopted the very rigid labor market structure that characterizes so much of Europe.  Of course, the price the Europeans are now paying for imposing high taxes, mandates, and regulations on their labor markets is double digit unemployment.   While our private sector has been increasing employment by 1.9 million per year for a quarter of a century, the European private sector has seen barely any net job creation over the same period.      The second, and related key, is that we have a vibrant small business sector in which entry and exit occurs at an almost breathtaking pace.  This involves a truly staggering rate of labor market turnover.  I mentioned earlier that the country has enjoyed private sector job creation of about 1.9 million per year.  But, research suggests that for every job created on net, roughly 10 new jobs were created and 9 jobs were lost.  For example, in one period studied by the SBA, 1988-1990, a period in which the U.S. economy was moving from a business cycle peak into the start of a recession, they estimate that 23.2 million jobs were created and over 20.5 million were lost, for a net change of 2.7 million jobs.  If one applies the 10 for 1 rule of thumb to get a measure of economic change, we find that nearly one job in six in America is \"new\" in any given year.  Any economy which can remake itself roughly every six years is a truly dynamic engine of opportunity and change.      Of course, this environment is both conducive to and in part results from the small business sector.  In a world in which employees are not tied to a single large employer throughout their working lives, economic opportunities and vibrancy naturally result.  New sectors, including trade, finance, business services and high tech areas such as software and electronics, can more easily emerge.  Last year,  1.7 million net new jobs were added in the United States, 75 percent of them in sectors that have a high share of small businesses.  The five fastest growing sectors were health care providers, engineering and accounting research firms, amusement and recreation services, advertising services, and equipment rental and leasing.   All of these have a high small business component. Financing of Small Business In addition to a vibrant labor market, small business needs access to capital in order to survive and prosper.  The Federal Reserve monitors the health of this sector on a regular basis through our bank Call Reports.  But, as we all know, a good deal of the capital which small businesses use originates outside the banking sector.  So, two years ago the Federal Reserve conducted our second extensive survey of small business access to and use of the financial sector.  This survey, combined with other data, indicates that the links between the small business and financial services industries continue to evolve in ways which are mutually beneficial.      This should not surprise us.  The National Federation of Independent Businesses conducts a regular survey of small businesses to ascertain the greatest problem they face.  In the latest survey only 4 percent of respondents cited a lack of access to or the cost of credit as their primary problem, to give it a rank of seventh on the list of small business concerns.  By contrast, 29 percent cited high taxes, 19 percent cited regulation and red tape and 12 percent cited the low quality of labor, a reflection of the problems which our public schools are having in meeting the needs of a growing economy.  You can see why I did not even try to claim that I'm from the government and here to help you.      Credit cost and availability has not always been of such minor concern.  As we came out of the high inflation period in the late 1970s and early 1980s, credit cost and availability was cited by more than one third of respondents as their biggest problem.  Similarly, in late 1989 and early 1990 as concerns about bank credit problems in the commercial real estate area caused a re-evaluation of regulation and banking behavior in this area, the cost and ease of access to credit was cited by 10 percent of respondents.      The diminished problem of credit access and its cost is also borne out by banking loan statistics.  Consider, for example, data from the June 30th Call Reports, which show a hefty rebound in small business lending by banks whose business loans are small.  The 1996 report showed a 12.9 percent increase over the previous year.  This followed a 13.2 percent increase in 1995 over 1994 and a 10.9 percent increase in 1994 over 1993.  Even if one looks at all domestic commercial banks, small business lending has maintained a 6.5 percent annual rate of growth for the past two years.  Regardless how one measures it, the access to bank credit by the U.S. small business sector has been growing much faster than the economy of late.      Our small business survey indicated that just over half of all firms reported outstanding credit in the form of a credit line, a loan, or a capital lease.   Lines of credit and motor vehicle loans were the two most commonly cited types of credit obtained.  In addition, the survey showed that borrowing against real estate was an important method of funding small business. Prospective Developments      There are a number of ongoing developments which are likely to continue and even further develop the relationship between the financial services industry and small businesses in our economy.   On the financial services side, we have witnessed many large institutions that previously had left the small business market to community banks, rushing to develop a wide array of loan products and services specific to small business needs.  Sweep accounts, tailored investment programs, affinity credit cards, smaller revolving credit lines, and improved lock box services are just some of the business services being offered in the new, more competitive small business market.      At the same time, new technologies and information flows are providing opportunities for banks and other lenders to more efficiently evaluate loan risks and lower the costs of small business lending.  One technique that is gaining broader acceptance is credit scoring.  Credit scoring is a statistical procedure that evaluates default risk based on the relationship between observed loan performance and specific characteristics of the loan and the borrower.  The development of score cards for businesses requires that lenders have a large amount of historical information on the  performance of loans with similar characteristics.  Given the huge diversity among business borrowers, it will take awhile to develop these databases.  To facilitate this process, lenders usually adopt more standardized loan terms and application forms.  Many large banks already have begun to probe the possibilities of credit scoring techniques for small business markets.      Once developed, credit scoring and loan standardization may offer significant cost advantages for evaluating the risks associated with lending.  And as credit scoring and loan standardization become more commonplace, the ability of banks to \"securitize\" small business loans likely will be greatly enhanced.  A key benefit of securitization is that it potentially increases the liquidity of small business lending and provides banks and other lenders with additional sources of funding.  One would expect the cost savings generated through lower origination costs, better risk assessment, and greater liquidity to be passed on, at least in part, to small business customers.  Clearly not all small business loans are going to be appropriate candidates for securitization, and not all banks will wish to adopt complex statistical models for managing risks.  There will continue to be a market for nonstandard small business lending and a role for regional and community banks.      In addition to bank financing, equity market developments have also produced a very favorable environment for small businesses.   The initial public offering market has seen enormous development.  More than $50 billion has been raised through IPOs in 1995 and 1996.  In particular there has been an explosive growth in the private equity markets.  This has become an important source of capital for start up firms, private middle market firms, and public firms seeking buy-out financing.  Between 1980 and 1995, venture capital outstanding increased ten fold, from $3 billion to more than $30 billion.  Non-venture private equity increased even more over this period   from $2 billion to $70 billion.  In addition, the development of the limited partnership form of organization, which began to really take hold in the 1980s, has spurred the development of a much more efficient delivery system for capital.      In sum, the reasons to be optimistic about the American small business sector can be found in the organization and structure of our capital and labor markets.  A comparatively lightly regulated set of markets, full of potential for innovation and exploration of market niches, has made the American small business sector a world leader.  In turn, the dynamism which is an inherent part of this sector has created the American job creation miracle.  The",
                  "1996-10-02 00:00:00"
                ],
                [
                  "15",
                  "Chairman Alan Greenspan",
                  "Remarks by Chairman Alan Greenspan Regulation of electronic payment systems At the U.S. Treasury Conference on Electronic Money & Banking: The Role of Government, Washington DC  September 19, 1996       You have heard many points of view today on electronic money and banking.  New products are being designed to challenge the use of currency and checks in millions of routine consumer transactions.  Other new systems may allow payments or banking instructions to be sent over networks such as the Internet, which is unprecedented in providing versatile, low-cost communication capabilities.  Again, as in the 1970s, articles are being written and conferences are being held to pronounce the end of paper.  They may again prove premature.      The payment systems of the United States present a paradox. Our systems and banking arrangements for handling high-value dollar payments are all electronic and have been for many years. Banking records, including those for loans and deposits, have been computerized since the 1960s.  Securities markets also now rely on highly automated records and systems, born out of necessity following the paperwork crisis of the 1970s.      Yet in transactions initiated by consumers, paper currency and checks remains the payment system of choice.  Debit and ATM cards, along with Automated Clearing House payments, account for a very small percentage of transactions.  Even the use of popular credit cards has only recently begun to challenge papers dominance.      Brand names used for many new electronic payment products are designed to suggest analogies to paper currency and coins. It is not surprising, therefore, that they sometimes evoke comparisons to an earlier period in U.S. history when private currencies circulated widely.  We should, of course, recognize the limitations of this particular experience for drawing policy conclusions relevant to the present.  Many of the new electronic payment products are more similar to conventional products, such as debit cards, than to currency.  And certainly, the U.S. financial system has evolved considerably since the era of private currency.  Thus the baseline from which innovation and experimentation is occurring is doubtless different today. Nonetheless, evaluations of that period can clearly add to our perspective.      Throughout much of the 19th century, privately issued bank notes were an important form of money in our economy.  In the pre-Civil War period, in particular, the federal government did not supply a significant portion of the nations currency.  The charter of the Bank of the United States had not been renewed, and there was no central banking organization to help regulate the supply of currency.  Notes issued by state-chartered banks were a major part of the money supply.  This was a result, in large part, of the \"free banking\" movement, a period when state chartering restrictions on banks were significantly loosened. Free banking dominated the landscape in most of the states in the Union starting in the 1830s, and lasted until the National Banking Act was adopted in 1863.      The free banking period was a controversial one in U.S. history.  The traditional view has been that this period gave rise to \"wildcat banking,\" in which banks were created simply to issue worthless notes to an unsuspecting public who would seek in vain among the \"wildcats\" for redemption in specie.  Non-par clearing of bank notes, along with suspension of specie payments by banks and outright defaults, did lead to risks and inefficiencies.      But more recently, some scholars have suggested that the problems of the free banking period were exaggerated. Retrospective analyses have shown, for example, that losses to bank note holders and bank failures were not out of line with other comparable periods in U.S. banking history.      The newer research also suggests that, to a degree, the problems of free banking had little to do with banking.  In particular, although free banking laws varied considerably by state, issuers of bank notes were often required to purchase state government bonds to back the notes they issued.  In some cases, these securities were valued at par rather than at market prices a structure that evidently did foster wildcat banking. Moreover, no matter what the regulatory valuation scheme, when the state government ran into financial problems, as many often did, both the bonds and the bank notes sank in value.  In some cases, this contributed to bank failures.      In the pre-Civil War period, when the general ethos of laissez faire severely discouraged government intervention in the market economy, private regulations arose in the form of a variety of institutions, which accomplished much of what we endeavor to do today with our elaborate system of government rule making and supervision.  In particular, scholars have noted that the period saw the development of private measures to help holders of bank notes protect themselves from risk.  As the notes were not legal tender, there was no obligation to accept the currency of a suspect bank, or to accept it at par value; accordingly, notes often were accepted and cleared at less than par.  As a result, publications bank note reporters were established to provide current information on market rates for notes of different banks based on their creditworthiness, reputation, and location, as well as to identify counterfeit notes.  Bank note brokers created a ready market for notes of different credit quality.  In some areas, private clearinghouses were established, which provided incentives for self-regulation.      Banks competed for reputation, and advertised high capital ratios to attract depositors.  Capital to asset ratios in those days often exceeded one-third.  One must keep in mind that then, as now, a significant part of safety and soundness regulations came from market forces and institutions.  Government regulation is an add-on that tries to identify presumed market failures and, accordingly, substitute official rules to fill in the gaps.      To be sure, much of what developed in that earlier period was primitive and often ineffectual.  But the financial system itself was just beginning to evolve.      From today's presumably far more sophisticated view of such matters, we may look askance at what we have often dismissed as \"wildcat banking.\"  But it should not escape our notice that, as the international financial system becomes ever more complex, we, in our regulatory roles, are being driven increasingly toward reliance on private market self-regulation similar to what emerged in more primitive forms in the 1850s in the United States.      As I have said many times in the past, to continue to be effective, governments' regulatory role must increasingly assure that effective risk management systems are in place in the private sector.  As financial systems become more complex, detailed rules and standards have become both burdensome and ineffective, if not counterproductive.  If we wish to foster financial innovation, we must be careful not to impose rules that inhibit it.  I am especially concerned that we not attempt to impede unduly our newest innovation, electronic money, or more generally, our increasingly broad electronic payments system.      To develop new forms of payment, the private sector will need the flexibility to experiment, without broad interference by the government.  The history of the Automated Clearing House provides a useful caution.  The Federal Reserve, in partnership with the banking industry, has taken a leading role in developing the ACH system for more than twenty years.  It was the advent of the ACH that led many economists to discuss money in a \"cashless society.\"  Although the ACH has allowed the automation of some important types of payments, it has never been widely used by consumers.      This experience suggests that creating new technology and providing an interbank electronic clearing system were easy.  But developing electronic payment products based on this technology that were more convenient and cost effective than paper, from the standpoint of both consumers and merchants, turned out to be difficult.  In our enthusiasm over new electronic payment systems, we significantly underestimated the convenience of paper for consumers and especially the cost and difficulty of building a broad-based infrastructure to support new electronic payment systems.  It is also possible that efforts by the government to choose and support a single technology the ACH in this case may have slowed efforts by the private sector to develop alternative technologies.      In the current period of change and market uncertainty, there may be a natural temptation for us and a natural desire by some market participants to have the government step in and resolve this uncertainty, either through standards, regulation, or other government policies.  In the case of electronic money and banking, the lesson from the ACH is that consumers and merchants, not governments, will ultimately determine what new products are successful in the marketplace.  Government action can retard progress, but almost certainly cannot ensure it.      Before we set in stone a series of rules for this emerging new medium, let us recall that, across many industries in the economy, forecasting the particular direction of innovation has proven to be especially precarious over the generations.  As Professor Nathan Rosenberg of Stanford has pointed out, even relatively mature technologies can develop in wholly unanticipated ways.      Our optimum financial system is one of free and broad competition that is presumed to calibrate appropriately the changing value of products to consumers so that the risk-adjusted rate of return on equity measures the success in providing what people want to buy.      This has turned out to be broadly true in practice and supplied regulators with some sense of which products were serving consumers most effectively.  This signal may not be so readily evident in the case of electronic money.  The problem is seigniorage, that is, the income one obtains from being able to induce market participants to employ one's liabilities as a money.  Such income reflects the return on interest-bearing assets that are financed by the issuance of currency, which pays no interest, or at most a below-market rate, to the holder.      Historically when private currency was widespread, banks garnered seigniorage profits.  This seigniorage increasingly shifted to the federal government following the National Bank Act, when the federal government imposed federal regulation on bank note issuance, taxed state bank notes, and ultimately became the sole issuer of currency.      Today, there continue to be incentives for private businesses to recapture seigniorage from the federal government. Seigniorage profits are likely to be part of the business calculation for issuers of prepaid payment instruments, such as prepaid cards, as well as for traditional instruments like travelers checks.  As a result, in the short term, it may be difficult for us to determine whether profitable and popular new products are actually efficient alternatives to official paper currency or simply a diversion of seigniorage from the government to the private sector.  Yet we must also recognize that a diversion of seigniorage may be an inevitable byproduct of creating a more efficient retail payment system in the long run.      The innovations being discussed today can be viewed from a very different perspective than that afforded by the financial system of the 1850s.  Unlike the earlier period, we have a well developed and tested set of monetary and payment arrangements and a strong national currency.  Yet, as in the earlier period, industry participants may find that self-policing is in their best interest.  We could envisage proposals in the near future for issuers of electronic payment obligations, such as stored-value cards or \"digital cash,\" to set up specialized issuing corporations with strong balance sheets and public credit ratings.  Such structures have been common in other areas, for example, in the derivatives and commercial paper markets.      In conclusion, electronic money is likely to spread only gradually and play a much smaller role in our economy than private currency did historically.  Nonetheless, the earlier period affords certain insights on the way markets behaved when government rules were much less pervasive.  These insights, I submit, should be considered very carefully as we endeavor to",
                  "1996-09-19 00:00:00"
                ],
                [
                  "16",
                  "Governor Laurence H. Meyer",
                  "Monetary Policy Objectives and Strategy  I want to share with you this evening my perspective on the challenges facing monetary policy in the current economic environment.  But I also want to emphasize the importance of setting monetary policy as part of a longer-run strategy that provides guidance of how to juggle multiple targets in the short run while maintaining a focus on achieving price stability in the long run.  I will begin with a brief discussion of the objectives of monetary policy, then turn to the outlook issues that are, in my judgment, central to near-term policy decisions, and end with a few comments on one aspect of longer-run strategic considerations. Identifying the Objectives I am used to delivering my intermediate macro lectures this time of year.  I always start out identifying the norms of good macroeconomic performance which, in turn, become the objectives for macroeconomic policy.  This is a good place to start. I include full employment, growth (meaning the growth in productive capacity), and price stability. This is familiar ground and I don't expect I need to defend this list to this group.  From my new perspective, it is important to appreciate that economic theory suggests some specialization among the objectives between monetary and fiscal policies. Understanding this specialization will prevent us from expecting more from monetary policy than it can promise to deliver and help us better appreciate the singular nature of the long-run objective for monetary policy.  Economic theory, in the form of the long-run neutrality of money, tells us that monetary policy cannot affect the level or growth rate of output in the long run.  So don't saddle monetary policy with responsibilities for stimulating the growth of productive capacity.  If it were easy to produce more long-run growth simply by printing money we would have monetized our way to dramatically higher living standards a long time ago. What monetary policy does do, according to economic theory, is set the rate of inflation in the long run.  As I said in my opening statement in my confirmation hearings, when it comes to assigning responsibility for inflation, the buck literally stops at the Federal Reserve. Price stability is therefore the singular and unique long-run objective for monetary policy.  Fiscal policy, on the other hand, can be an instrument of growth policy, through its effect on national saving via the structural budget deficit, through incentive effects on work, saving and investment via tax rates and tax structure, and through public investment in human capital and physical infrastructure.  While we should not overstate what fiscal policy can deliver on this score, we should remember where the levers for growth policy are located.  There is less agreement about what economic theory and empirical macroeconomics tell us about the potential for stabilization policy. My reading is that both monetary and fiscal policies, via their influence on aggregate demand, affect output and employment in the short run.  While we should not forget the lecture on inside and outside lags, parameter uncertainty, and other cautionary tales that preclude fine tuning, neither should we dismiss the stabilization role that can be played by some combination of the two policies.  In practice, recently and for the indefinite future, fiscal policy is dominated with the task of reducing the deficit, leaving the stabilization objective almost exclusively in the hands of the Federal Reserve. Outlook Issues Challenging Monetary Policy Today There are two questions related to the current economic outlook that, in my view, challenge monetary policy in the near term.  I expect you will focus on these issues in your outlook session tomorrow.  First, in the absence of policy adjustment, is the economy slowing or likely to slow to trend quickly enough to stabilize the unemployment rate at its current level?  Second, is the current unemployment already so low that remaining at this level would trigger a steady increase in the rate of inflation?  I note that most of the private sector forecasts I follow, along with the Blue Chip Consensus, all provide an affirmative answer to the first question.  All have growth near 2% in the second half of 1996 and through 1997.  I presume the NABE survey that you will present tomorrow is also consistent with this story.  Of course, one has to be careful interpreting these forecasts, because some of the private sector forecasts that have growth slowing to trend do so in the context of an assumed modest tightening of monetary policy, but many suggest a slowing to trend without such an adjustment.  But you appreciate the issue here.  Any answer, of course, is provisional, subject to adjustment to incoming data and therefore to be reviewed as appropriate over time.  I should note that growth itself does not cause inflation.  However,  above-trend growth, without an accompanying increase in participation rates, implies further decline in the unemployment rate which may already be at or even below its full employment level.  A further decline in the unemployment rate, from its current level, would, in turn, increase the risk of an acceleration of inflation.  That brings me to the second question. Are we already below NAIRU?  In that case, a slowdown to trend would not be sufficient to prevent an acceleration in inflation. The answer is, unfortunately, not that easy.  On the one hand, estimates of NAIRU from a data sample that covers the last 20 to 30 years suggest a value close to 6%.  This indicates we are below NAIRU and should expect a steady rise in the inflation rate going forward. The problem with this conclusion is that we would have expected, in this case, some upward pressure on prices over the past two years.  I do not want to ignore the possibility that transitory favorable supply shocks can, for a while, offset the effect of a below-NAIRU unemployment rate on inflation.  But I do not believe that special factors alone can explain away the tension between an unemployment rate persistently below traditional estimates of NAIRU and the stable to declining inflation over the past two years.  Indeed, I expect many don't appreciate how well behaved inflation has been over this period.  Over the year ended in the second quarter, most broad measures of inflation, both product and expenditure-side measures, have been near 2% and when measured net of food and energy, below 2%.  A couple of examples: For the chain-type GDP deflator, the inflation rate over this period was 2.2% and the last available reading, for the second quarter, was 2.2%.  For the Gross Domestic Purchases chain-type price index, the inflation rate over the last year was 2.0% and the rate in the second quarter was 2.1%.  In both of these cases, inflation was also lower in the year ended in the second quarter of 1996 than over the preceding year.  So inflation is quite modest, it has not evidenced any increase over the last year, and, in fact, has shown signs of further decline.  It might add that, net of food and energy, broad expenditure measures show inflation below 2% over the past year.  The CPI, the inflation measure which receives the most attention, is, admittedly, a bit of an outlier.  Its inflation rate is closer to 3% than to 2%, resulting in an unusually wide gap between the inflation rates for the CPI and other broad price indices.  Still, even in the case of the CPI, inflation is lower over the year ended in the second quarter than over the preceding year for both overall and core measures.  As a result of the recent inflation experience, estimation techniques which weight the current data more heavily (so-called time varying parameter estimation) suggest that NAIRU has declined recently and may be as low as 5 1 /2%.  So one of the challenges to monetary policy is how to operate when there is a higher degree of uncertainty about where NAIRU is.  I feel this tension more than most. I have emphasized throughout my career the importance of the expectations-augmented Phillips Curve in my view of the inflation process and its value as a forecasting tool.  The Phillips Curve played an important supporting role in the forecasting awards Joel, Chris and I won over the years.  But the tension is there and we have to weigh the risk of higher inflation if the longer-run estimate of NAIRU proves correct against the potential that the recent stability in inflation reflects a change in structure that will persist.  Tempering some of the optimism about NAIRU and recent inflation is evidence of at least a modest acceleration in wages and compensation.  This trend is of concern, although there are questions about whether or not it signals an upturn in price inflation.  Is the higher pace of wage change, for example, in part a passing through to workers of the slower rate of increase in benefit costs incurred over the last few years by firms? Labor costs, of course, are based on total compensation not wages, so we might want, especially given the slowdown in benefit cost inflation, to keep our focus on the broader compensation measure rather than on wage change alone.  The rate of increase in compensation, itself, is edging higher 2.9% over the year ended in the second quarter for the ECI, compared to 2.6% over the previous year.  The question here is whether the current rate of increase in compensation remains consistent with stable price inflation, either because it is being accompanied, at least for a while, by a compression in profit margins or because it still remains low relative to trend productivity. But we also have to be careful about making too many excuses.  At any rate, the developments related to wages, compensation and productivity deserve particular scrutiny.  Last week's labor market report underscores once again the considerable momentum of the economic expansion and highlights the issues I've been discussing.  The economy continued to generate jobs at an impressive clip last month indeed, at a pace faster than the trend growth of the labor force.  The unemployment rate dropped noticeably below the range over the past two years, to 5.1 %.  Moreover, average wage rates increased substantially, presumable reflecting the pressures that employers face in attempting to attract and retain workers in a relatively tight labor market.  We of course all welcome an improvement in earnings.  For some time now, many American workers have not fully shared in the fruits of our economic growth. But the question is whether the recent wage gains will be real in terms of greater effective purchasing power, or whether the associated increases in costs of production will only be mirrored in an offsetting acceleration of prices.  To date, firms have found ways to offset those costs or, in some cases, have been forced by competitive conditions to absorb some of them in their profit margins.  The question is whether this process will continue in the months ahead, holding inflation in check.  Certainly, there is still a widespread view that firms do not have so-called pricing leverage.  But, there is no question that the latest data reinforce the sense that Chairman Greenspan expressed a couple of months ago that we are in a circumstance in which a prudent central bank must exercise heightened surveillance of the inflationary risks and stand ready to respond if necessary. Juggling Multiple Targets in the Short Run But this is just a single episode for monetary policy.  Decisions made in this episode should be part of a longer-run strategy and should be understood in that broader context.  I want to turn my attention now to one aspect of a longer-term strategy that might help the Federal Reserve juggle multiple targets in a disciplined fashion and bridge from short-run policy to long-term objectives.  Let's assume, for the sake of the rest of my remarks, that growth slows to trend, the unemployment rate stabilizes at its current level, and inflation remains stable.  Humor me.  What then for monetary policy?  At this point we confront the dreaded trade-off.  There is, to be sure, no trade-off and hence no inconsistency between full employment and price stability in the long run. Therefore, maximum employment (at least if interpreted as full employment or being at NAIRU) and price stability, the statutory mandate of the Federal Reserve, are compatible  in the long run.  Full employment can be achieved either with price stability or with positive stable inflation.  So the mandate, in my interpretation, does dictate that we move to price stability, because this is only there that we can achieve both objectives simultaneously.  That still leaves us the strategic question of how to juggle the goals of full employment and price stability in the short run when the initial conditions do involve a conflict among the ultimate objectives for example, the current combination of modest, stable inflation and full employment.  Reasonable people can and do disagree about what to do in this case.  It is desirable that monetary policy respond to this challenge in a systematic way.  This would allow the private sector to both anticipate where monetary policy is headed and retain confidence that the Federal Reserve remains focused on its long-run objective as it carries out its meeting-to-meeting policies.  The Taylor Rule is a simple example of a strategy that juggles the two objectives in a disciplined manner without losing sight of the long-run price stability objective.  The Taylor Rule varies the real federal funds rate relative to some equilibrium level in response to both the deviation of output from its full employment level and of inflation from its long-run target.  This rule, in effect, worries continuously about both output relative to potential and inflation relative to price stability.  The Taylor Rule has stabilizing properties across a range of models, describes to a reasonable approximation recent Federal Reserve policy, and similar specifications describe the behavior of many other central banks in industrialized counties.  I do not want to mislead you about the degree to which I believe we can rely on any single rule in general or my commitment to the Taylor Rule in particular.  But the Taylor Rule helps illustrate some important aspects of monetary policy strategy.  The Taylor Rule would resolve the near-term conflict between objectives in the current economic environment by encouraging some slack in the economy and thereby ensuring downward pressure on inflation over time, as long as inflation were above the long-run inflation target, while still balancing along the way both the inflation and employment objectives. Opportunistic Disinflation A couple of years ago, I gave the name \"opportunistic disinflation\" to an alternative strategy for bridging between short-run policy and long-run goals, a strategy that I observed the Federal Reserve to be following at the time. I will use this strategy this evening to describe my own position.  But I want to make clear that I am not speaking for others on the FOMC or describing official policy.  Under this strategy, once inflation becomes modest, as today, Federal Reserve policy in the near term focuses on sustaining trend growth at full employment at the prevailing inflation rate.  At this point the short-run priorities are twofold: sustaining the expansion and preventing an acceleration of inflation.  This is, nevertheless, a strategy for disinflation because it takes advantage of the opportunity of inevitable recessions and potential positive supply shocks to ratchet down inflation over time.  Proponents of this strategy sometimes describe this approach as reducing inflation cycle-to-cycle or describe the economy as being one recession from price stability. Under this strategy, if growth were to slow to trend, the unemployment rate were to remain where it is, and inflation were to remain stable, monetary policy would remain on hold, ready to respond aggressively to any acceleration of inflation, but otherwise prepared to be patient and accept the lower inflation that will accompany the next recession or favorable supply shock. ",
                  "1996-09-08 00:00:00"
                ],
                [
                  "17",
                  "Governor Edward W. Kelley, Jr.",
                  "Remarks by Governor Edward W. Kelley, Jr. Developments in electronic money and banking At the CyberPayments '96 Conference, Dallas, Texas June 18, 1996                   It is a pleasure to be here this afternoon to provide      the Federal Reserve's perspective on recent developments in the      field of electronic money and banking.  To begin, let me remind      you that progress in the retail electronic banking sector so far      has been slow in the United States.  Twenty years ago, a national      Commission was appointed by the Congress to study many of the      issues surrounding emerging electronic funds transfer systems,      particularly as they were seen to affect consumers and the      general public.  The assumption at that time was that the use of      currency and checks in the United States would rapidly disappear.      Indeed, the creation of the Automated Clearing House system and      NACHA have their roots in this era of our history.  Yet today,      paper currency and checks are still used for the overwhelming      majority of consumer payments, while electronic transfers, such      as those made over the ACH, account for a very small fraction.      In contrast, for the major money and securities markets in this      country, electronic payments are the rule rather than the      exception.  Settlements for these markets generate many of the      electronic funds transfers over the Federal Reserve's Fedwire      system and the New York Clearinghouse CHIPS system, which total      more than $2 trillion per day and represent most of the daily      dollar value of payments in this country.                 With this background in mind, the Federal Reserve has      adopted a view toward the development of new electronic money and      banking products that emphasizes the need for innovation,      particularly in the retail sector, supported by a realistic      approach to regulation.  It is the private sector that must play      the pivotal role in identifying which services consumers and      businesses want, and are willing to pay for, in areas such as      stored-value   or \"smart\"   cards and payments over the      Internet, and in the development of new home-banking products.      If the past is any guide, consumer acceptance and use of new      payment and banking technologies will grow slowly, and we can be      certain that many of the new products will not succeed      commercially.  But those products that do prove to reduce costs      and improve the choices available to consumers and businesses in      conducting their economic activities could gain widespread      acceptance in the longer term.                 Competition in these efforts is healthy, particularly      in areas where new technologies must be turned into practical      products that, in many cases, will compete with older,      established payment methods and delivery channels.  Although I      would expect that banks will continue to serve as the core of the      payment system, non-banking organizations, which traditionally      have been active in this field, appear to be contributing to the      competitive environment and serving as an impetus to innovation.      Heavy-handed, preemptive attempts at regulating these products      and the competitive process before significant social risks have      been demonstrated would likely handicap innovation for no      compelling reason.  On the other hand, history also suggests      that, if significant problems affecting the economic interests      and well-being of a wide group of our citizens were to arise in      the future, there would be a corresponding legislative and      regulatory response.  While we do not see the need for new      substantive regulations at this time, there is an on-going need      to review existing regulations and supervisory practices in order      to adapt to technological as well as financial innovations, as I      will mention later.                 Let me now turn to the Federal Reserve's views of the      potential impact of retail electronic banking and payments on the      three primary central banking functions:  monetary policy,      banking supervision, and the payment system.  In these as well as      related areas, such as consumer privacy and industry competition,      the policy issues being raised in the current debate about      electronic payments are the same as those analyzed in the 1970s      by the national EFT Commission.  In fact, in many cases the      striking parallels give the distinct impression that \"we've been      here before.\"                 As for the conduct of monetary policy, in hindsight, it      may seem surprising that there were concerns at that time about      the impact of the ACH.  Then as now, the potential impact on      monetary policy of new electronic payment products has been      greatly exaggerated.  As with the use of the ACH, we would not      expect that the expansion of electronic delivery of existing      banking services will have appreciable effects on the money      supply or the money markets.  In contrast, \"electronic cash\" or      other new electronic payment products, if successful, could      gradually lead to shifts among different forms of money held by      consumers and thus potentially affect the behavior of the      monetary aggregates.  Yet concerns about loss of \"control\" of the      money supply are misdirected.  In the last twenty years, major      shifts caused by other financial innovations have led to some      changes over time in the ways in which monetary policy is      formulated, with the monetary aggregates now playing a lesser      role.  Moreover, financial innovation has not seriously      undermined central banks' ability to implement policy, although      adaptations have sometimes been called for.                 Although growth rates of the money supply are no longer      the central focus of monetary policy making, the Federal Reserve      still needs to monitor the monetary aggregates carefully in the      policy process, and it will remain important that the aggregates      accurately measure the various instruments that are being used as      money.  Accordingly, we do expect to include any significant      amounts of new general-purpose payment instruments, such as      balances on stored-value cards, in the monetary aggregates, and      the Federal Reserve has the statutory authority to require any      necessary reports from depository institutions.  If new payment      instruments were issued by nonbanks, we would expect to obtain      voluntary reports from issuers, as we traditionally have done      with travelers checks.                 Before I move on to the topic of banking supervision,      I would like to touch on the question of \"seigniorage,\" a term      often used for income that governments generate through issuance      of non-interest bearing coin and currency.  First, the amount of      currency displaced by new payment products relative to the amount      outstanding, and the corresponding impact on federal revenues in      the near term, is likely to be very small in percentage terms.      For example, in a scenario in which every resident of the United      States held $150 on a stored-value card or electronic cash      account, which I view as highly optimistic over a near-to-medium-      term horizon, the total value outstanding would amount to less      than $50 billion, or only about 10 percent of the currency stock.      Moreover, estimates are that as much as two-thirds of the value      of U.S. currency circulates abroad, a market where holders may be      even more resistant to giving up Federal Reserve notes for      privately issued electronic products.  Second, even if there is      some erosion of federal revenues due to declining demand for      currency, this should not be a governing factor in public policy      toward innovative payment products.  Indeed, existing products      such as credit and debit cards, along with checking accounts,      have probably reduced the use of currency over time relative to      what it would otherwise have been, which is a natural outcome of      innovation and improvement in banking and payment systems.                 Second, banking supervision.  While any substantial      implications for monetary and fiscal policy are well into the      future, new electronic banking services could require changes in      the way that banking supervision is conducted in the relatively      near term.  The Federal Reserve is responsible for examining and      assessing the safety and soundness of bank holding companies,      state-chartered Federal Reserve member banks, and U.S. branches      and agencies of foreign banks.  These examinations include a      review of institutions' information systems, including security      controls and contingency arrangements.  Internet-based home      banking services, as well as new payment products such as stored-      value cards, have the potential to expose institutions to      significant liability if security measures were breached for      fraudulent or malicious purposes.  Of course, institutions have      strong incentives to protect themselves against these risks, and      early indications are that the more sophisticated are investing      considerable resources in doing so.                 The Federal Reserve is actively monitoring developments      in this area so as to be in a strong position to address any      supervisory concerns that may arise.  We are reviewing the way      that we examine banks' information systems to address      developments in electronic banking, among other things.  However,      banking regulators cannot possibly assess the adequacy of every      Internet firewall or smart card.  Rather, the role of regulators      is to require policies and procedures to be in place within      banking organizations to ensure that risks are identified and      managed.  For example, the Board recently approved the first      application of a bank holding company for a subsidiary to engage      in data processing activities that support the provision of      banking and financial services over the Internet.  In this      approval order, involving the widely publicized Security First      Network Bank, which is offering retail banking services primarily      over the Internet, the Board noted that it expects banking      organizations considering providing such services to analyze      carefully the associated risks and to evaluate whether those      risks are consistent with their policies relating to the security      of customer information and other data.  Of course, banks may      first need to assure themselves that their existing information      security policies and procedures are adequate for an expanding      range of electronic banking activities.  I would hope and expect      such safety evaluations to be demanded by customers, as well as      regulators.                 The third main area of central bank responsibility is      the payment system.  It may be helpful to begin by considering      the nature of payment systems and how they might be affected by      new electronic payment products.  First, all payment systems      consist of money and the means of transferring money from one      individual or organization to another.  New electronic payment      methods that can be envisioned do not change this fact, although      they may result in different forms of money and new technology      for executing transfers.  Second, the payment system comprises      several main sectors, ranging from large financial institutions      that play a major role both as users and providers of many      different payment services, to consumers and small businesses      that primarily use smaller value payment systems.  Of course, the      Federal Reserve also plays a unifying role in the payment system      as the provider of currency, interbank clearing and settlement      services, and, in some cases, regulator.                 New electronic payment products, such as stored-value      cards and Internet payment services, are designed primarily to      automate the billions of relatively small-value transactions      involving consumers and non-financial businesses.  The      transactions involved are as diverse as the commercial economy of      the United States, and the future needs for payment systems, both      in traditional face-to-face business and in commerce over open      networks such as the Internet, are evolving daily.                 While the Federal Reserve's interbank payment services,      such as Fedwire and ACH, have been highly automated for years, we      are examining areas where we can make use of new technology where      appropriate.  For example, we are continuing to keep abreast of      new developments in areas such as encryption, electronic      communications, and data security to ensure that our existing      payment systems take full advantage of any improvements.  As a      side point, I might mention that we are also making use of the      Internet to provide public information services; the Reserve      Banks and the Board of Governors now maintain home pages on the      Internet's World Wide Web, where we provide up-to-date      information that may be useful to the general public, such as      monetary and economic statistics and Federal Reserve      publications.                 As I have mentioned on previous occasions, however, I      do not anticipate that the Federal Reserve will seek to provide a      new retail electronic payment product in this emerging industry.      In the 1970s, the Federal Reserve took a central role in      developing the ACH system on behalf of the banking industry, and      then explicitly subsidized operation of the ACH for some time.      Now, twenty years later, circumstances are sufficiently different      that we do not believe that a similar approach would be necessary      or desirable to advance the efficiency and effectiveness of the      payment system.  There is no lack of private sector investment in      providing new products and new means of delivering services to      consumers.  Experimentation is needed to determine which products      best fit consumers' needs, but history has shown that the private      sector, rather than government, is best able to perform this      role.                 The Federal Reserve is, however, examining ways in      which we can support industry initiatives where appropriate.  For      example, we are currently reviewing our existing interbank net      settlement services for check clearinghouses and private ACH      operators and considering whether similar services could be      provided for other monetary instruments that the banking industry      may offer to their customers.                 The Federal Reserve also has specific regulatory      responsibilities as well as a general interest in the continuing      integrity of the payment system.  Some have raised concerns that      new electronic payment products, such as those that could be used      over the Internet or are offered by unregulated entities, could      create new avenues for criminal financial activities or threaten      the integrity of the payment system.  Although the Federal      Reserve, as well as other authorities, will be vigilant in      monitoring developments, we believe that these concerns are      premature.  Until new payment products gain widespread      acceptance, their usefulness in criminal activities will      necessarily be limited.  Moreover, the measures that prudent      institutions will impose to limit the security risks in offering      new products, such as relatively low monetary limits and      transaction record keeping where practical, will also limit their      impact on the payment system more broadly.  Of course, if these      instruments were to spread more quickly than expected and were      provided by organizations that did not have due regard for the      safety of funds entrusted to them, concerns would be greater, as      would the likelihood of regulatory actions.  But we do not see      this prospect on the horizon at this stage.                 We have focused attention recently on modernizing      existing regulations in the context of our regulatory planning      and review process as well as clarifying how they apply to new      technologies; these efforts should serve to reduce any latent      regulatory barriers or uncertainty that might hinder development      of electronic payment products and services.  For example, the      Board recently adopted changes to Regulation E that would permit      consumers to provide appropriate electronic authorization for      electronic funds transfers, in place of a written signature.  We      have also proposed additional changes to Regulation E under which      required information, such as certain notices and disclosures,      could be transmitted electronically, for example, in home banking      systems.                 As you probably know, the Federal Reserve Board also      recently issued a request for public comment on the treatment of      stored-value cards under the Electronic Fund Transfer Act and      Regulation E.  The proposal would exempt many stored-value cards      from Regulation E provisions, such as liability limits for      unauthorized transfers, error resolution procedures, and printed      receipts and account statements.  Cards with maximum balances of      less than $100 would be wholly exempt, while issuers of most      larger-value cards would need to disclose the terms and      conditions of the cards to customers, a practice that would be      prudent for any new product.  I hope industry participants as      well as potential users will provide comments to help us refine      the proposal over the coming months and ensure that it provides      the appropriate level of consumer protection without unnecessary      and costly regulatory burdens or undesirable incentives.                 History has shown that technological innovations can      provide widespread benefits across society.  The Federal Reserve      welcomes private-sector investment and innovation to improve      efficiency and effectiveness in all areas of banking and payments      activities, while at the same time preserving the safety and      soundness of the financial system.  We are always open to      discussions and suggestions from the industry in this respect and      on any other issues involving emerging money and banking",
                  "1996-06-18 00:00:00"
                ],
                [
                  "18",
                  "Chairman Alan Greenspan",
                  "Remarks by Chairman Alan Greenspan Bank supervision in a world economy At the International Conference of Banking Supervisors, Stockholm, Sweden June 13, 1996          I am honored to present the William Taylor Memorial      Lecture to such a distinguished group of senior bank supervisors      from around the world.  I am especially delighted to have with us      Bill's wife, Sharon, and daughter, Claire.  This visit gives them      the opportunity to meet more of Bill's colleagues and to      appreciate, once again, the great importance of the work he did.                  Those of you who had the opportunity to know Bill can      recall him as a dedicated bank supervisor and an outstanding      public servant.  We in the United States were certainly fortunate      to have had him lead our bank supervisory functions at the      Federal Reserve and the FDIC while the U.S. banking system was      experiencing quite difficult times.  To me, no individual      displayed the characteristics necessary for a successful senior      bank supervisor better than Bill Taylor.  Well known for this      integrity, tenacity, and professional dedication, Bill demanded      the best from himself and from those around him.  He understood      that a safe and sound banking system was essential to a healthy      market system, and he was committed to maintaining such a system.                  His contributions extended outside the United States      and into the efforts of the Basle Committee on Banking      Supervision and beyond.  Indeed, he as much as anyone       recognized that the changes occurring in our international      banking system increased the importance of supervisors from      around the world communicating and working together.  It is most      fitting, therefore, that we remember him at this conference.   A Period of Change                 The dual themes of this year's conference of cross-      border banking and qualitative supervision are highly relevant to      our responsibilities as bank supervisors in a world economy that      is becoming increasingly integrated and complex.  Banking has      become more sophisticated; the volume of transactions has      multiplied; and competitive pressures have grown.  These      developments reflect the increased efficiency of financial      markets worldwide, which have helped to bring about expanded      international trade and economic growth.                  However, by strengthening the interdependencies among      markets and market participants, they may also have increased the      potential for significant, adverse events to spread quickly to      other markets.  As bank supervisors, we must deal with both the      positive and the potentially negative effects of rapid innovation      and change.  We should also take the opportunity that change      provides to promote sound risk management practices within our      banking systems.  Meeting these challenges will be a daunting      task.                 During my comments this evening I will suggest ways      supervisors can address these challenges and prepare for      undoubtedly greater changes in the years to come.  First, though,      I would like to discuss the interaction of governments and      central banks with private commercial banks in free economies in      terms of risk sharing.  By articulating and understanding that      relationship, we may have a better framework for considering how      to supervise and regulate our financial institutions.   A Leveraged Banking System          In addressing these issues it is important to remember      that many of the benefits banks provide modern societies derive      from their willingness to take risks and from their use of a      relatively high degree of financial leverage.  Through leverage,      in the form principally of taking deposits, banks perform a      critical role in the financial intermediation process, providing      savers with additional investment choices and borrowers with a      greater range of sources of credit, thereby facilitating a more      efficient allocation of resources and contributing importantly to      greater economic growth.  Indeed, it was the evident value of      intermediation and leverage that has shaped the development of      our financial systems from the earliest times certainly since      Renaissance goldsmiths discovered that lending out deposited gold      was feasible and profitable.  Stockholm, itself, recognized the      value of intermediation with the founding of the Riksbank more      than 300 years ago as a private institution.                 Of course, this same leverage and risk-taking also      greatly increases the possibility of bank failure.  Indeed,      without leverage, losses from risk-taking would be absorbed by      the bank's owners, virtually eliminating the chance that the bank      would be unable to meet its obligations in a \"failure\".  Some      failures can be of a bank's own making, resulting, for example,      from poor credit judgements.  For the most part, these failures      are a normal and important part of the market process and provide      discipline and information to other participants regarding the      level of business risks.  Other failures, can result from, and      contribute to, the rare episodes of severe economic or market      turmoil that affects broad segments of an economy and is not the      consequence of the imprudence of individual banks.  Because of      important roles banks and other financial intermediaries play in      our financial systems, such failures could have large ripple      effects that spread throughout business and financial markets at      great costs.   The Distribution of Risks         Over time, societies concluded that leverage and      intermediation were essential to economic performance, but also      that some bank failures could have unacceptable economic costs.      In response, central banks were created and were accorded new      responsibilities, and what we now call prudential regulation      evolved.  In the United States, these initiatives took the shape      of the creation of the Federal Reserve in 1913 after several      financial panics in the late 19th and early 20th centuries, and      of federal deposit insurance and a broadened role for bank      supervisors in the 1930's.  While the responses in other      countries were often less overt, they were generally still      significant in their effects.                 This expanded role of governments, central banks, and      bank supervisors implies a complex approach to managing and even      sharing the risks of failure between governments and privately      owned banks.  Some of what central banks do might be termed      \"shaping\" or reducing some kinds of risks, primarily by providing      liquidity in certain situations to reduce the odds of extreme      market outcomes, in which uncertainty feeds market panics.      Traditionally this was accomplished by making discount or Lombard      facilities available, so that depositories could turn illiquid      assets into liquid resources and not exacerbate unsettled market      conditions by selling such assets or calling loans.  Similarly,      open market operations, in situations like that which followed      the 1987 stock market crash, satisfy increased needs for      liquidity that otherwise could feed cumulative, self-reinforcing,      contractions across many financial markets.                 But guarding against systemic problems also has      involved, on very rare occasions, an element of more overt risk-      sharing, in which the government or more accurately the      taxpayer is potentially asked to bear some of the cost of      failure.  Activating such risk sharing quite appropriately occurs      at most maybe two or three times a century.  The willingness to      do so arises from society's judgment that some bank failures may      have serious adverse effects on the entire economy and that      requiring banks to carry enough capital to avoid any risk of      failure under any circumstances itself would have unacceptable      costs in terms of reduced intermediation.                 If banks had to absorb all financial risk, then the      degree to which they could leverage, of necessity, would be      limited, and their contribution to economic growth, modest.      Risk-sharing encourages leverage and intermediation.  Eliminating      risk-sharing and asking banks to remove the possibility of      failure would lead to a much smaller banking system.  To attract,      or at least retain equity capital, a private financial      institution must earn at a minimum the overall economy's rate of      return, adjusted for risk.  The rate of return banks would need      in order to compete for a large amount of extra equity capital      would seriously constrain the assets they could hold.  In their      management of market or credit risk, well-run banks  carefully      consider potential losses from most possible market outcomes, and      they hold sufficient capital to protect themselves from all but      the most extreme situations.  But banks and other private      businesses recognize that to be safe against all possible risks      implies a level of capital on which it would be difficult, if not      impossible, to earn a competitive rate of return.                 On the other hand, if central banks or governments      effectively insulate private institutions from the largest      potential losses, however incurred, increased laxity could be      costly to society as well.  Leverage would escalate to the outer      edge of prudence, if not beyond.  Lenders to banks (as well as      their owners or managers) would learn to anticipate central bank      or government intervention and would become less responsible,      perhaps reckless, in their practices.  Such laxity would hold the      potential of a major call on taxpayers.  And central banks would      risk inflationary instabilities from excess money creation if      they acted too readily and too often to head off possible market      turmoil.                 In practice, the policy choice of how much, if any, of      the extreme market risk that government authorities should absorb      is fraught with many complexities.  Yet we central bankers make      this decision every day, either explicitly or by default.      Moreover, we can never know for sure whether the decisions we      made were appropriate.  The question, though, is not whether our      actions to support entire financial systems or to require major      changes at specific institutions are seen to have been necessary      in retrospect.  The absence of a fire does not mean that we      should not have paid for fire insurance.  Rather, the question is      whether, ex ante, the probability of a systemic collapse was      sufficient to warrant intervention.  Often, we cannot wait to see      whether, in hindsight, the problem will be judged to have been an      isolated event and largely benign.   Supervisory Approach                 Thus, governments have been given certain      responsibilities related to their banking and financial systems      that must be balanced.  We have the responsibility to prevent      major financial market disruptions through development and      enforcement of prudent regulatory standards and, if necessary in      rare circum- stances, through direct intervention in market      events.  But we also have the responsibility to assure that      private sector institutions have the capacity to take prudent and      appropriate risks, even though such risks will sometimes result      in bank losses or even bank failures.                 Providing institutions with the flexibility that may      lead to failure is as important as permitting them the      opportunity to succeed.  By its nature, all business investment      is risky.  The role of banks to assist in the financing of      such risk thus implies the taking of risk by the bank itself.      Indeed, this is the economic role of banking in a market economy.      The purpose of risk management is not to eliminate risk, but to      manage it in a prudent manner.                 Our goal as supervisors, therefore, should not be to      prevent all bank failures, but to maintain sufficient prudential      standards so that banking problems do not become widespread.  We      try to achieve the proper balance through official regulations,      formal and informal supervisory policies and procedures.                 To some extent, we do this over time by signalling to      the market, through our actions, the kinds of circumstances in      which we might be willing to inter- vene to quell financial      turmoil, and conversely, what levels of difficulties we expect      private institutions to resolve by themselves.  The market, then,      responds by adjusting the cost of capital to banks.  Throughout      most of this century, we have made our decisions largely in a      domestic context.  However, in recent decades that situation has      changed markedly for many countries and is rapidly changing for      all.                 With financial instruments and markets becoming more      complex and closely linked, it is essential that bank supervisors      around the globe get to know and trust one another and      communicate openly, as necessary, when banking problems and      potential crises emerge.  In recognition of such common      interests, major industrial countries have worked together for      years through the Basle Committee on Banking Supervision.      Conferences like this one also clearly help advance the goal of      interaction.  International coordinating and educational efforts      doubtless also help supervisors cope with the growing complexity      of supervisory matters by providing them with a forum for dealing      with issues of mutual interest and concern.  The Caribbean      Banking Supervisors Group, the SEANZA Forum of Banking      Supervisors, and other regional associations of bank supervisors      in the Middle East, Africa, and elsewhere help to move us in the      right direction.                 We have also made and continue to make significant      progress in developing prudent international supervisory      standards that are both quantitative and qualitative in nature.      Bill Taylor played a critical role in crafting and negotiating      the Basle Accord of 1988 for credit risk that helped greatly to      strengthen capital standards worldwide and to provide a more      equitable basis for international competition.  More recently,      the internal models approach for measuring market risks in      trading activities, adopted by the Basle Committee late last      year, builds upon that framework and may illustrate how      supervisory rules and practices can evolve.                 As financial markets change, supervision must be      prepared to adjust.  We have to adapt continuously to changing      technologies, changing bank practices and changing market forces.      Supervision is an ever evolving process.  We must be careful,      however, not to alter our modalities too often for fear of      creating supervisory uncertainty.  To maintain a proper balance      in the years ahead will be one of our greatest challenges.                 The decision to craft a bank's capital requirements for      trading activities around accepted and verifiable internal risk      measures was an important step in the supervision and regulation      of large, internationally active banks.  It is all the more      noteworthy because it recognizes the importance of both      quantitative and qualitative criteria in the measurement and      management of trading risks.  As risk management techniques      evolve for other bank activities, supervisors will need to      understand the new procedures and how they affect overall banking      risks.                 Time and again, though, events are demonstrating that      despite the complexity of transactions and the alleged      sophistication of management systems, it is poor qualitative      factors that is, the lack of basic policies and controls that      so often undermine banks.  Fortunately, in many cases, the      technology that has enabled institutions to design complex new      products also provides the techniques with which the resulting      risks can be identified, measured, and controlled.  Management      also must have the knowledge and motivation to employ these      techniques to ensure that the risks are adequately contained.  We      must never forget that no matter how technologically complex our      supervisory systems become, the basic unit of supervision on      which all else rests remains the human judgment of the degree of      risk on a specific loan, based on the creditworthiness and      character of a borrower.  If those credit judgments are      persistently flawed, no degree of complexity of supposed risk      dispersion or elegance of credit models will help.                 As the Barings and other episodes illustrate, proper      controls include such basic elements as adequate management      oversight and separation of duties.  Those of us who supervise      banks with worldwide operations must recognize that, with today's      telecommunications, management must extend its policies,      procedures, and controls to all offices that have the ability to      take risks.  In this respect, coordination and cooperation      between home and host countries become not only important, but      essential in maintaining financially sound institutions and      financial markets.                 Within the United States, the Federal Reserve and other      bank supervisors are placing growing importance on a bank's risk      management process and are strengthening our supervisory      procedures, where necessary, to assist examiners in identifying      management weaknesses and strengths.  We are also working to      develop supervisory tools and techniques that utilize available      technology and that help supervisors perform their duties with      less disruption to banks.  These improvements range from software      designed to download data about a bank's loan portfolio to an      examiner's personal computer, to simply more thoughtful reviews      of internal management reports.  Such automation enhancements      will permit examiners, themselves, to analyze more efficiently      the various concentrations within loan or investment portfolios      and, therefore, help them to identify the underlying risks and      discuss those risks with bank management.                 Countries in which supervisors conduct on-site      examinations or otherwise review specific loans or loan      portfolios may find such technology particularly useful.  Within      the United States, the growing volume and complexity of      transactions, particularly at the largest institutions, is      requiring such productivity enhancements and other modifications      to our supervisory procedures.  For example, rather than      evaluate a high percentage of a bank's loans and investment      products by reviewing individual transactions, we will      increasingly seek to ensure that the management process itself is      sound, and that adequate policies and controls exist.  While      still important, the amount of transaction testing, especially at      large banks, will decline.                 However, supervisors everywhere should expect bank      boards of directors and senior managements to perform their      leadership and oversight roles.  By themselves supervisors cannot      expect to detect or prevent every unsound practice, nor to ensure      that all weak management processes are improved.  We can expect      our banking systems to be sound only by ensuring that directors      and managers provide guidance regarding their appetite for risk;      that they bring to the bank, personnel with the integrity and      skills to do the job; and that they monitor compliance with their      own directives.                 Encouraging and promoting sound qualitative risk      management and internal controls has been and should remain a      high priority of bank supervisors. Indeed, it is as important, in      my view, as the development of quantitative prudential standards.   Conclusion          Thus, despite all the changes and innovations, commercial      banking remains a business largely of extending credit and      managing the related risks.  To prosper, bankers must be risk-      takers, but risk-takers to an appropriate degree.  Banking is      special in all of our countries because of its role in financial      intermediation.  Accordingly, the industry has been given      important privileges, including the direct or implicit support of      a national safety net in most countries that effectively protects      it from the most severe economic events.  If relied on too      heavily, however, that safety net can be abused by banks, which      then become undercapitalized and too willing to take on      inappropriate risk.                 In the decades ahead, supervisors will have to adjust      to growing technologies and increasingly sophisticated markets.      A generation ago a month-old bank balance sheet was a reasonable      approximation of the current state of an institution.  Today, for      some banks, day-old balance sheets are on the edge of      obsolescence.  In the 21st century that will be true of most      banks.                 Future supervision will of necessity have to rely far      more on a bank's risk management information system to protect      against loss.  We supervisors will be appreciably more involved      in evaluating individual bank risk management processes, than      after-the-fact results.  In doing so, however, we must be assured      that with rare and circumscribed exceptions we do not substitute      supervisory judgments for management decisions.  That is the road      to moral hazard and inefficient bank management.  Fortunately,      the same technology and innovation that is driving supervisors to      focus on management processes will, through the development of      sophisticated market structures and responses, do much of our job      of ensuring safety and soundness.  We should be careful not to      impede the process.                 Bank supervisors play an important role in encouraging      the proper balance of risk-taking by developing prudent standards      and enforcing sound practices at banks.  Bill Taylor understood      that role and worked vigorously to address the weaknesses he saw.      The approach we take will convey our views regarding to what",
                  "1996-06-13 00:00:00"
                ],
                [
                  "19",
                  "Governor Edward W. Kelley, Jr.",
                  "Remarks on the \"Millennium Bug\"  I am pleased to appear before the Professional Banker's Association to discuss the Millennium Bug from a public sector perspective.  The Millennium Bug, or Year 2000 problem, has the potential to seriously disrupt the infrastructure of computer systems and telecommunications that the world community depends upon for the free flow of funds and payments and hence, virtually all of everyday commerce.  The Year 2000 problem is a business continuity issue that requires a coordinated effort by public and private business and information technology management.  Although the problem itself is not technically difficult, ensuring that information systems are Year 2000 compliant is a management challenge of enormous scale and complexity.  While this matter will impact every organization everywhere, my talk today will focus specifically on the key areas of public sector finance and banking.  The global nature of today's financial services industry relies upon the interconnection of computer systems world-wide.  My purpose today is to identify the serious nature of the problem and the urgent need for immediate action by the government of every nation.  As it will impact every country with which you interact, I believe that you of the Professional Banker's Association are in a unique position to be a catalyst for promoting attention to the Year 2000, stimulating action, and promulgating best practices in developing nations.  This afternoon, after sketching out the critical nature of the problem, I will focus on plans and actions being taken by the Federal Reserve System to address the Millennium Bug in its own internal operation, as a case study of what an organization like ours must do.  Then on to our efforts within the U.S. financial services industry and the international financial community, and finally a few words on how you can help. The Millennium Bug  What is this problem all about?  Most computer operating systems and applications in use today register dates as two digits.  Consequently, such computer systems, software programs, or embedded chip devices can not distinguish the year 2000 from 1900, when both dates are registered as \"00.\"  When the clock rolls over the next millennium, computations based on two digit dates will produce errors.  Those relatively few systems using four digit date fields will have different problems, but they will have problems, nonetheless.  While the situation can be stated simply, its scope is vast and fixing it is enormously time consuming.  As this audience knows, banking systems and financial services rely heavily on computer systems to manage and deliver services electronically.  With the linkage of payment systems globally, a failure of any linked system could have waterfall effects to other systems and a disastrous result to the world economy.  The scope of the Millennium Bug extends far beyond financial services and beyond the traditional notion of large mainframe processing systems.  Computer systems that control telecommunications, electric utilities, transportation services, and a host of other critical infrastructure systems are vulnerable.  The Gartner Group estimates 50 million embedded-system devices worldwide will exhibit Year 2000 problems.  Embedded chips are used to control elevators, environmental systems, navigational devices, household appliances, safes and vaults, and on and on.  The pervasive reliance on computer systems is not constrained to large industrialized countries; developing countries are also vulnerable, particularly those with older computer systems and software.                         I think that some \"what if's\" cited by the Computer Information Center in the UK brings a practical perspective of the effect of what could happen in our everyday life as the millennium arrives. The computers in financial services organizations, etc. cannot deliver payments to counter parties, or receive funds from them.  Gridlock ensues.  There's a collapse in financial markets because of the bad news coming from companies about their inability to trade normally. The power fails, and it is mid-winter in the Northern hemisphere and mid-summer in the Southern hemisphere.  The power company's production is controlled by innumerable computer chips, which were installed many years ago and no one knows what they do, how they work, nor dare they touch them, because the whole of the plant might come irreparably to a standstill. ",
                  "1997-12-15 00:00:00"
                ],
                [
                  "20",
                  "Chairman Alan Greenspan",
                  "   I welcome the opportunity to lecture today at Syracuse University because I believe that the education community has a crucial role to play in the current era of rapid economic change.  Our businesses and workers are confronting a dynamic set of forces that will influence our nation's ability to compete worldwide in the years ahead.  Our success in preparing workers and managers to harness those forces will be an important element in the outcome.  One of the most central dynamic forces is the accelerated expansion of computer and telecommunications technologies, which can be reasonably expected to appreciably raise our standard of living in the twenty-first century.  In the short run, however, fast-paced technological change creates an environment in which the stock of plant and equipment with which most managers and workers interact is turning over more rapidly, creating a perception that human skills are becoming obsolete at a rate perhaps unprecedented in American history.  I shall endeavor to place this most unusual phenomenon in the context of the broader changes in our economy and, I hope, to explain why education, especially to enhance advanced skills, is so vital to the future growth of our economy.  Wealth has always been created, virtually by definition, when individuals use their growing knowledge to interact with an expanding capital stock to produce goods and services of value.  Assisted by the whole array of market prices, entrepreneurs seek to identify the types of products and services that individuals will value.  More specifically, they seek the added value that customers place on products and services tailored to their particular needs, delivered in shorter time frames, or improved in quality.  A century ago, much, if not most, of our effort was expended in producing food, clothing, and shelter.  Only when crop yields increased, steam power was developed, and textile fabrication became more efficient were available work hours freed for the production and consumption of more discretionary goods and services.  We manufactured cars and refrigerators and learned how to produce them with ever less human effort.  As those products found their way into most homes, human effort moved on to the creation of values that were less constrained by limits of physical bulk, such as smaller, transistor-based electronics, and beyond to a wide variety of impalpable services medical care, education, entertainment, travel, to name just a few.  The demand for a virtually infinite array of impalpable values is, to a first approximation, insatiable.  Understandably, today's efforts to create new values for consumers concentrates on these impalpables, which offer the highest potential value added relative to costs in physical resources and human effort.  Unbundling the particular characteristics of each good or service facilitates maximizing its value to each individual.  Some individuals place more value on, and are willing to pay more for, style y rather than style x, whereas others prefer x.  Producing both styles, x and y, enhances overall consumer well-being.  Fifty years ago, only x was feasible.  This striving to expand the options for satisfying the particular needs of individuals inevitably results in a shift toward value created through the exploitation of ideas and concepts or, more generally, information from the more straightforward utilization of physical resources and manual labor.  Thus, it should come as no surprise that, over the past century, by far the largest part of the growth in America's real gross domestic product is the result of new insights and, more broadly, new information about how to rearrange physical reality to achieve ever-higher standards of living.  The amount of physical input into our real GDP, measured in bulk or weight, has contributed only modestly to economic growth since the turn of the century.  We have, for example, dramatically reduced the physical bulk of our radios, by substituting transistors for vacuum tubes.  Thin fiber optic cable has replaced huge tonnages of copper wire.  New architectural, engineering, and materials technologies have enabled the construction of buildings enclosing the same amount of space, but with far less physical material than was required, say, 50 or 100 years ago.  Most recently, mobile phones have become significantly downsized as they have been improved.  As it became technologically possible to differentiate output to meet the increasingly calibrated choices that consumers now regularly make, the value of information creation and its transfer was expanded.  Hence, it is understandable that our advanced computer and telecommunications products have been accorded particularly high value and, thus, why computer and telecommunications companies that successfully innovate in this field exhibit particularly elevated stock market values.  Breakthroughs in all areas of technology are continually adding to the growing list of almost wholly conceptual elements in our economic output.  These developments are affecting how we produce output and are demanding greater specialized knowledge.  We could expect the widespread and effective application of information and other technologies to significantly increase productivity and reduce business costs.  Certainly, we can already see dramatic improvements in quality control that have sharply reduced costly product rejects and lost time, while computer and satellite technology has markedly improved the efficiencies of moving goods through even more sophisticated, just-in-time, inventory systems.  With computer-assisted design, experiments can be evaluated in a virtual reality setting, where mistakes can be readily corrected without the misuse of time and materials.  And new technologies have had extensive applications in the services sector for example, in health services, where improvements in both diagnosis and treatment have been singularly impressive; in airline efficiency and safety; and in secretarial services now dominated by word processing, faxes, and voice and electronic mail.    The accelerated pace of technological advance has also interacted with the rapid rise in financial innovation, with the result that business services and financial transactions now are transmitted almost instantaneously across global networks.  Financial instruments have become increasingly diverse, products more customized, and markets more intensely competitive.  The scope and size of our financial sector has grown rapidly because of its ability to facilitate the financing of products and services that are themselves valued highly in the marketplace.  Our nation's financial institutions, as a consequence, are endeavoring to find more effective and efficient ways to deliver their services.  In this environment, America's prospects for economic growth will depend greatly on our capacity to develop and to apply new technology.  Unfortunately, we have found that we never can predict with any precision which particular technology or synergies of technologies will add significantly to our knowledge and our ability to gain from that knowledge.  For instance, Alexander Graham Bell initially viewed the telephone solely as a business instrument merely an enhancement of the telegraph for use in transmitting very specific messages.  Indeed, he offered to sell his telephone patent to Western Union for only $100,000, but he was turned down.  Similarly, Marconi, at first, overlooked the radio's value as a public broadcast medium, instead believing its principal application would be in the transmission of point-to-point messages, such as ship-to-ship, where communication by wire was infeasible.  Moreover, we must recognize that an innovation's full potential may be realized only after extensive improvements or after complementary innovations in other fields of science.  According to Charles Townes, a Nobel Prize winner for his work on the laser, the attorneys for Bell Labs initially, in the late 1960s, refused to patent the laser because they believed it had no applications in the field of telecommunications.  Only in the 1980s, after extensive improvements in fiber optics technology, did the laser's importance for telecommunications become apparent.  America's continued success in garnering the benefits of technological advance will depend on the ability of our businesses to deal with risk and uncertainty.  Moreover, our ability to remain in the forefront of new ideas and products will be ever more difficult because of the rapid international diffusion of technology.  Nonetheless, to date, we have not fallen behind in converting scientific and technological breakthroughs into viable commercial products.     Even if the most recent, tentative indications that productivity growth may be speeding up were to turn out to be less than we had hoped, it is possible that the big increases in efficiency growing out of the introduction of computers and communications systems may still lie ahead.  Past innovations, such as the advent of electricity or the invention of the gasoline-powered motor, required the development of considerable infrastructure before their full potential could be realized.  Electricity, when it substituted for steam power late last century, was applied to production processes that had been developed for steam.  For example, gravity was used to move goods vertically in the steam environment, and that setup did not initially change with the advent of electric power.  Only much later when horizontal factories, newly designed for optimal use of electric power, began to dominate our industrial system did productivity clearly accelerate.  Similarly, only when highways and gasoline service stations became extensive was the lower cost of motor vehicle transportation achieved.  In addition, full effectiveness in realizing the gains from technological advance will require a considerable amount of human investment on the part of managers and workers who have to implement new processes and who must be prepared to adapt, over their lifetimes, to the ongoing change that innovations bring.  The growth of the conceptual component of output has brought with it accelerating demands for workers who are equipped not simply with technical know-how, but with the ability to create, analyze, and transform information and to interact effectively with others.  A popular term for the type of human capital that firms are today employing to a greater degree is \"functional literacy,\"1 which perhaps sounds deceptively simple when one considers the complex of attributes necessary to transform information into economic value.    Indeed, the debate about whether the introduction of technology would upgrade or \"deskill\" the workforce is as old as Adam Smith.  Certainly, one can point to some very routine types of jobs, such as those for telephone operators, that have lower skill requirements in today's world of automated communications systems than when more labor-intensive manual phone systems were in place.  But, on the whole, the evidence suggests that across a wide range of industries, employers have upgraded their skill mix.2  Importantly, these changes represent not simply a shift in the occupational mix, but, to a larger degree, an upgrading of skill requirements of individual jobs, for which the range and complexity of tasks and the scope for problem-solving and decisionmaking has expanded.   This process appears to have occurred more rapidly in those businesses with greater computer utilization.3  However, this is not to argue that growing use of technology alone can explain the accelerated demand for more skilled workers.  A 1994 survey of employers conducted by the Census Bureau for the National Center on the Educational Quality of the Workforce found that rising skill requirements also are more common in firms that have introduced more flexible production systems, adopted team management practices, or reduced the layers of management in the organization.  More generally, at the root of both the rise in the demand for workers who embody greater human capital and the increasing application of technology is the realization by businesses that remaining competitive in today's world requires unprecedented flexibility to adapt to change.  Traditionally, broader human capital skills have been associated with higher education, and, accordingly, the demand for college-trained workers has been increasing rapidly.  The result is that, over the past 15 years, a wide gap has opened up between the earnings of college graduates and those of workers who stopped their formal schooling with a high-school diploma or less.  But the dispersion of pay outcomes has also increased within groups of workers with the same levels of education, which suggests that broader cognitive skills and conceptual abilities have become increasingly important on a wide scale, and that basic credentials, by themselves, are not enough to ensure success in the workplace.  Clearly our educational institutions will continue to play an important role in preparing workers to meet these demands.  And, responding to the strong signals that the returns to formal education have been rising, the supply of college-trained labor has been increasing.  School enrollment rates among traditional college-age young people, which were little changed in the 1970s, have moved up sharply since then.  At the same time, enrollment rates have picked up noticeably among individuals aged 25 and over.  Presumably, many of these older students are striving to keep pace with the new demands evolving in the job market.  Indeed, an important aspect of the changing nature of jobs appears to be that an increasing number of workers are facing the likelihood that they will need retooling during their careers.  The notion that formal degree programs at any level can be crafted to fully support the requirements of one's lifework is being challenged.  As a result, education is increasingly becoming a lifelong activity; businesses are now looking for employees who are prepared to continue learning, and workers and managers in many kinds of pursuits have begun to recognize that maintaining their human capital will require persistent hard work and flexibility.  Economists have long argued that more than half of the market human capital produced in a worker's lifetime is produced on the job.4  Several decades ago, much of that on-the-job training was acquired through work experience; today we are seeing greater emphasis on the value of formal education and training programs for workers.  Developing human capital is perceived by many corporations as adding to shareholder value.  If idea creation is increasingly the factor that engenders value-added, then training and education are crucial to the growth of company value-added and profitability.  In the private sector, a number of major corporations have invested in their own internal training centers so-called corporate universities.  Some labor unions have done the same.  More broadly, recent surveys by the Bureau of Labor Statistics and by the Department of Education indicate that the provision of education on the job has risen markedly in recent years.  In 1995, the BLS report showed that 70 percent of workers in establishments with 50 or more employees received some formal training during the twelve months preceding the survey.  Most often this training was conducted in house by company personnel, but larger firms also relied to a great extent on educational institutions.  The information collected by the Department of Education indicated that the percentage of employed individuals who took courses specifically to improve their current job skills rose between 1991 and 1995; by 1995, four of every ten full-time workers aged 35 to 54 had sought to upgrade their skills.  The survey shows that growing proportions of workers with a high-school education or less and of those in production and craft jobs sought additional training; however, college graduates and those in professional occupations still reported the highest incidence of additional coursework almost 50 percent.  Thus, learning does seem to beget perhaps both a capacity as well as a desire for more learning.  This finding should underscore the need to begin the learning process as early as possible.  In the long run, better child-rearing and better basic education at the elementary and secondary school level are essential to providing the foundation for a lifetime of learning.  At the same time, we must be alert to the need to improve the skills and earning power of those who appear to be falling behind.  We must also develop strategies to overcome the education deficiencies of all too many of our young people, and to renew the skills of workers who have not kept up with the changing demands of the workplace.  The recognition that more productive workers and learning go hand-in-hand is becoming ever more visible in both schools and in the workplace.  Expanded linkages between business and education should be encouraged at all levels of our education system.  Building bridges between our educational institutions and the private business sector should have payoffs in how well graduates are prepared to meet the challenges of an increasingly knowledge-based global economy.  Indeed, a recent study argues that we need not rely on colleges and universities to teach \"the new basic skills\" to prepare workers for jobs in a knowledge-based economy; that foundation could be built in high schools if only more high schools were to ensure that graduates left with not only essential basic reading and computational skills, but also with training in how to solve semi-structured problems, how to make oral presentations, and how to work in diverse groups.5  Those researchers argue for a better connection between secondary school curricula and business needs \"vocational education\" in a very broad sense rather than the traditional narrow one.  While many debate how to make our elementary and secondary schools more effective in preparing students particularly compared with those in other developed countries there is little question about the quality of our university system, which for decades has attracted growing numbers of students from abroad.  The payoff to advanced training remains high, and even with higher rates of enrollment, the supply of college-trained labor does not appear likely to outstrip the growing demands of a rapidly changing economy.  The linkages between the private sector and our colleges and universities have a long tradition, and many schools are endeavoring to extend those connections.  Your new technology building here at the Maxwell School will be a valuable asset in that effort.   The advent of the twenty-first century will certainly bring new challenges and new possibilities for our businesses, our workers, and our educational system.  We cannot know the precise directions in which technological change will take us.  As in the past, our economic institutions and our workforce will strive to adjust, but we must recognize that adjustment is not automatic.  All shifts in the structure of the economy naturally create frictions and human stress, at least temporarily.  However, if we are able to boost our investment in people, ideas, and processes as well as in machines, the economy can readily adapt to change, and support ever-rising standards of living. Footnotes 1 Frederic L. Pryor and David Schaffer, \"Wages and the University Educated: A Paradox Resolved,\" Monthly Labor Review (July 1997), pp. 3-14.        2 Peter Cappelli, \"Are Skilling Requirements Rising?  Evidence from Production and Clerical Jobs,\" Industrial and Labor Relations Review (April 1993), pp. 515-30; and \"Technology and Skill Requirements: Implications for Establishment Wage Structures,\" Federal Reserve Bank of Boston, New England Economic Review, Special Issue on Earnings and Inequality (May/June, 1996), pp. 139-54.         3 David H. Autor, Lawrence F. Katz, and Alan B. Krueger, \"Computing Inequality: Have Computers Changed the Labor Market?\" National Bureau of Economic Research, Working Paper 5956 (March 1997).         4 Jacob Mincer, \"On-the-Job Training: Costs, Returns, and Some Implications,\" Journal of Political Economy, vol. 70, Supplement (October 1962), pp. 50-79; and James Heckman, Lance Lochner, and Christopher Taber, \"Estimating and Evaluating Human Capital Policies in a General Equilibrium Environment,\" working paper (University of Chicago, 1997). ",
                  "1997-12-03 00:00:00"
                ],
                [
                  "21",
                  "Chairman Alan Greenspan",
                  "  Dramatic advances in the global financial system have enabled us to materially improve the efficiency of the flows of capital and payments.  Those advances, however, have also enhanced the ability of the system to rapidly transmit problems in one part of the globe to another.  The events of recent weeks have underscored this latter process.  The lessons we are learning from these experiences hopefully can be applied to better the workings of the international financial system, a system that has done so much to foster gains in living standards worldwide.   The current crisis is likely to accelerate the dismantling in many Asian countries of the remnants of a system with large elements of government-directed investment, in which finance played a key role in carrying out the state's objectives.  Such a system inevitably has led to the investment excesses and errors to which all similar endeavors seem prone.   Government-directed production, financed with directed bank loans, cannot readily adjust to the continuously changing patterns of market demand for domestically consumed goods or exports.  Gluts and shortages are inevitable.  The accelerated opening up in recent years of product and financial markets worldwide offers enormous benefits to all nations over the long run.  However, it has also exposed more quickly and harshly the underlying rigidities of economic systems in which governments or governments working with large industrial groups exercise substantial influence over resource allocation.  Such systems can produce vigorous growth for a time when the gap between indigenous applied technologies and world standards is large, such as in the Soviet Union in the 1960s and 1970s and Southeast Asia in the 1980s and 1990s.  But as the gap narrows, the ability of these systems to handle their increasingly sophisticated economies declines markedly.  In western developed economies, in contrast, market forces have been allowed much freer rein to dictate production schedules.  Rapid responses by businesses to changes in free-market prices have muted much of the tendency for unsold goods to back up, or unmet needs to produce shortages.  Recent improvements in technology have significantly compressed business response times and enhanced the effectiveness of the market mechanism.  Most Asian policymakers, while justly proud of the enormous success of their economies in recent decades, nonetheless have been moving of late toward these more open and flexible economies.  Belatedly perhaps, they have perceived the problems to which their systems are prone and recognized the unforgiving nature of the new global market forces.  Doubtless, the current crises will hasten that trend.  While the adjustments may be difficult for a time, these crises will pass.  Stronger individual economies and a more robust and efficient international economic and financial system will surely emerge in their wake.  While each of the Asian economies is unique in many important respects, the sources of their spectacular growth in recent years, in some cases decades, and the problems that have emerged are relevant to a greater or lesser extent to nearly all of them.  Following the early post World War II period, policies generally fostering low levels of inflation and high rates of savings and investment including investment in human capital through education contributed to a sustained period of rapid growth.  In some cases this started in the 1960s and 1970s, but by the 1980s most economies in the region were expanding vigorously.  Foreign net capital inflows grew, but until recently were relatively modest.  The World Bank estimates that net inflows of long-term debt, foreign direct investment, and equity purchases to the Asia Pacific region were only about $25 billion in 1990, but exploded to more than $110 billion by 1996; less comprehensive data suggest that inflows rose to a still higher rate earlier this year.   Sustained, spectacular growth in Asian economies fostered expectations of high returns with moderate risk.  Moreover the global stock market boom of the 1990s provided the impetus to seek these perceived high returns.  As that boom progressed, investors in many industrial countries found themselves more heavily concentrated in the recently higher valued securities of companies in the developed world, whose rates of return, in many instances, had reached levels perceived as uncompetitive with the earnings potential in emerging economies, especially in Asia.  The resultant diversification induced a sharp increase in capital flows into those economies.  To a large extent, they came from investors in the United States and western Europe.  A substantial amount came from Japan, as well, owing more to a search for higher yields than to rising stock prices and capital gains in that country.  The rising yen through mid-1995 also encouraged a substantial increase in direct investment outflows from Japan.  In retrospect, it is clear that more investment monies flowed into these economies than could be profitably employed at reasonable risk.  It may have been inevitable in those conditions of rapid growth, ample liquidity, and an absence of sufficient profitable alternatives, that much investment moved into the real estate sector, with an emphasis by both the public and private sectors on conspicuous construction projects that had little economic rationale.  These real estate assets, in turn, ended up as collateral for a significant proportion of the assets of domestic financial systems.  In many instances, those financial systems were already less than robust, beset with problems of poor lending standards, weak supervisory regimes, and inadequate capital.  At the same time, rising business leverage added to financial fragility.  Businesses were borrowing to maintain high rates of return on equity and weak financial systems were poorly disciplining this process.  In addition, explicit government guarantees of debt or, more often, the presumption of such guarantees by the investment community, encouraged insufficient vigilance by lenders and hence greater leverage.  But high debt burdens allow little tolerance for rising interest rates or slowdowns in economic growth, as recent events have demonstrated.  Moreover, the rapidly growing foreign currency denominated debt, in part the result of pegged exchange rates to the dollar, put pressure on companies to earn foreign exchange.  But earning it became increasingly difficult.  The substantial rise in the value of the dollar since mid-1995, especially relative to the yen, made exports of the Southeast Asian economies less competitive.  In addition, in some cases, the glut of semiconductors in 1996 and the accelerated drop in their prices suppressed export earnings growth, exerting further pressures on highly leveraged businesses.  In time, the pressures on what had become fixed exchange rate regimes mounted as investors, confronted with ever fewer profitable prospects, slowed the pace of new capital inflows.  Fearing devaluation, many domestic Asian businesses sought increasingly to convert domestic currencies into foreign currencies, or, equivalently, slowed the conversion of export earnings into domestic currencies.  To counter pressures on exchange rates, countries raised interest rates.  For fixed-exchange-rate, highly leveraged economies, it was only a matter of time before slower growth and higher interest rates led to difficulties for borrowers, especially those with fixed obligations.  Particularly troublesome over the past several months has been the so-called contagion effect of weakness in one economy spreading to others as investors perceive, rightly or wrongly, similar vulnerabilities.  This is an age old phenomenon.  When investors are unsettled by uncertainties and fears, they withdraw commitments on a broad front; the finer distinctions between countries and currencies are lost.  There is a flight to safe-haven investments, many of which are in developed nations.     Perhaps, given the circumstances, it was inevitable that the impressive and rapid growth experienced by the economies in the Asian region would encounter a temporary slowdown or pause.  I say temporary because there is no reason that above-average growth in countries that are still in a position to gain from catching up with the prevailing technology cannot persist for a very long time, provided their markets are opened to the full force of competition.  Nonetheless, free-market, even partially free-market, economies do periodically run into difficulties because investment mistakes invariably occur.  And, as I noted earlier, many of these mistakes arose from government-directed or influenced investments.  When this happens, private capital flows may temporarily turn adverse.  In these circumstances, individual companies should be allowed to default, private investors should take their losses, and government policies should be directed toward laying the macroeconomic and structural foundations for renewed expansion.  New growth opportunities must be allowed to emerge.  Although the economies of the troubled Asian countries were usually characterized by a combination of current account deficits, large net foreign currency exposures, and constraints on exchange rate fluctuations, one cannot generalize that these are always signs of impending difficulties.  Large current account deficits, per se, are not dangerous if they result from direct investment inflows that are not subject to rapid withdrawal and that generate an increase in income sufficient to compensate the investors.  Foreign currency exposures need not be a problem if positions are properly managed and the risks are recognized.  Fixed exchange rates, also, are not necessarily a problem.  Indeed, if they can be sustained, they yield extensive benefits in lower risk and lower costs for all international transactions.  But a small open economy can maintain an exchange rate fixed to a hard currency only under certain conditions.  Both Austria and the Netherlands, for example, have been able to lock their currencies against the deutsche mark because their economies are tightly linked through trade with Germany, they mirror the Bundesbank's monetary policies, and they are perceived to engage in prudent fiscal policies.  Were it not for issues of national identity and seignorage, they could just as readily embrace the DM as their domestic currency without any economic disruption.  Other economies, such as Argentina and Hong Kong, have fixed their exchange rates essentially through currency boards.  Changes in dollar reserves directly affect the monetary base of those economies.  But when exchange rates are fixed, with or without currency boards, should monetary and fiscal policies diverge significantly from those of the larger economy, the currency lock of the smaller economy would be difficult to hold irrespective of the size of reserves.  Large reserves can delay adjustment.  They cannot prevent it if policies are inconsistent, or prices in the smaller country are inflexible.  A well-functioning international financial system will seek out anomalies in policy alignments and exchange rates and set them right.  In such a system, the exploitation of above normal profit opportunities, that is, arbitrage, will force prices to change until expected returns have been equalized.  To policymakers in the country whose currency is not appropriately aligned, capital outflows are too often seen as attacks by marauding currency speculators.  There have no doubt been some such attempts on occasion.  But speculators rarely succeed in dislodging an exchange rate that is firmly rooted in compatible policies and cost structures.  More often, speculation forces currencies through arbitrage into a closer alignment with underlying market values to the benefit of the international economic and financial system as a whole.  We used to describe capital flight as \"hot money.\"  But we soon recognized that it was not the money that was \"hot,\" but the place it was running from.  The prodigious expansion of cross-border financial transactions in recent years has tightened and refined the arbitrage process significantly.  But, to repeat, the inestimable advantages that it brings to trade and standards of living also carry a price.  The inevitable investment mistakes and governmental policy failures are more rapidly transmitted to other markets by this process than was the case say twenty, or even ten, years ago.  Moreover, there is little evidence to suggest that the rate of increase of financial transactions will slow materially in the years immediately ahead.  Technology will continue to reduce the costs of finding and exploiting perceived differences in risk-adjusted rates of return around the world, helping to direct capital even more to its most efficient use.  Already, covered rates of return on actively traded interest-rate instruments have been equalized among many industrial countries.  But the broader merging of world savings and investment markets, clearly, has not been achieved, largely because investors are fearful of investing in countries they do not understand to the extent that they do their own, or are uninformed of the opportunities.  One measure of this so-called home bias in world investments is the degree that portfolios remain substantially local.  Foreign investments, on average, represent less than 10 percent of U.S. portfolios, for example.  The percentage of Japanese portfolios is only slightly higher, and 15 percent of German portfolios is in foreign assets.  The partial exception is Great Britain, where, with a longer history of global financial involvement, one-third of portfolios is invested in foreign assets.  Home bias in investments is considerably less than it was ten years ago, but we are still far from full globalization.  Unless government restrictions inhibit the expansion of ever more sophisticated financial products that enable savers in one part of the world to reduce risk by investing in another, the bias will continue to diminish and the size of the international financial system will continue to expand at a significant pace.  It is this overall diversification, and hence lowering of risk, that an effective international financial system offers.  It facilitates the ever more efficient functioning of the global economic system and, hence, is a major contributor to rising standards of living worldwide.  Nonetheless, there are those who ask whether the price of so sophisticated a financial system is too high.  Would it not be better to slow it down a bit, and perhaps achieve a system somewhat more forgiving of mistakes, even recognizing that such a slowing may entail some shortfall in long-term economic growth?  Even if we could implement such a tradeoff, with only minor disruption, should we try?  For centuries groups in our societies have railed against, and endeavored on occasion to destroy, new inventions.  Fortunately for us the Luddites and their ilk failed, and recent generations have enjoyed the fruits of those technologies.  Moreover such a slowdown may not even be possible at least without major disruption and cost.  Newer technologies, especially advanced telecommunications, make it exceptionally difficult for open markets, with associated opportunities, to be suppressed.  Price and capital controls, which might have been feasible a half century ago, would be very difficult to implement in today's more technologically advanced environment.  Tinkering at the edges of our system in order to produce a less frenetic pace of change would be easily circumvented.  Arguably, it would take massive government controls to substantially slow the advance toward greater efficiency of our systems.  This would surely produce a far more negative impact on economic growth than would be acceptable to even the most ardent advocates of reigning in the rapid expansion of our international financial system.  If, as I suspect, it turns out after due deliberation and analysis, that slowing in the pace of financial modernization is not in fact seen as a feasible alternative, what policy alternatives confront the international financial community to contain the periodic disruptions that are bound to occur in any free market economy?   A financial system, like all structures, is as strong as its weakest link.  As the international financial system has become even more complex, the particular areas of weakness to be addressed have changed.  At the risk of oversimplification, let's examine some of the key links of our current infrastructure.   Today the organized exchanges and over-the-counter markets of industrial countries can handle massive volumes of transactions.  Even in emerging countries exchanges are developing and expanding.  In contrast, during the world-wide stock market crash of October 1987, the transactions systems were under severe stress and, indeed, some broke down, incapable of handling the enlarged volumes.  At that time, the Hong Kong stock exchange could not open for several days.  The New York Stock Exchange was straining badly under the near 400 million daily share volume of late October 1987, with long reporting delays creating uncertainties that, doubtless, exaggerated the price declines.  Those weaker links have since been strengthened by large infrastructure investments.  Almost 1.2 billion shares traded on the NYSE on October 28 of this year, three times the 1987 volumes with no evident problems or delays.  Our equity, debt, and foreign exchange trading systems, and their peripheral futures and options markets have functioned well under stress recently.  These systems are not weak links in the developed economies, nor, for the most part are they in other economies.  Neither is the payment system, that complex network, which transfers funds and securities in huge and growing volumes domestically and internationally, rapidly and efficiently.  The private and public sectors across the globe have endeavored diligently for years to expand the capacity of the system to meet the increasing demands put upon it.  And they have initiated and strengthened procedures for reducing risk in settling transactions, and diminishing uncertainties.  That they have generally succeeded is evident from the smoothness with which huge volumes of funds produced under recent stressed market conditions were transferred and settled with finality, through various netting and clearing arrangements.  Banks are another matter.  These are highly leveraged institutions, financed in part by interbank credits and, hence, prone to crises of confidence that can quickly spread.  In most developed nations banking systems appear reasonably solid.  Japan has been somewhat of an exception, but there have been some positive signs there, as well.  Banks have been recognizing losses, and the government seems finally to be appropriately addressing their problems.  In a large number of emerging nations, as I indicated previously, banks are in poor shape.  Lax lending has created a high incidence of nonperforming loans, supported by inadequate capital, leaving banks vulnerable to declines in collateral values and nonperformance by borrowers.  How can such deficient institutions be elevated to a level that would allow their economies to function effectively in our increasingly sophisticated international financial system?  Certainly, improved cost and risk management and elimination of poor lending practices are a good place to start.   But these cannot be accomplished overnight.  Loan officers with experience judging credit and market risks are in very short supply in emerging economies.  Training will require time.  The same difficulties confront bank supervision and regulation.  Important efforts in this area have been underway for several years through the auspices of the Bank for International Settlements, the International Monetary Fund, and the World Bank.  But again, it will take time to develop adequate systems and trained personnel.  Moreover, robust banking and financial systems require firmly enforced laws of contract, and transparent, market oriented systems of corporate reporting and governance.  The current crisis in Asia is, to a much greater extent than many previous crises, one of private not public debts, at least de jure.  Arguably, the absence of efficient and transparent work-out arrangements for troubled private borrowers makes the problems more difficult to deal with.  Efficient bankruptcy arrangements reduce disruptions to economic activity that often arise when losses have to be imposed on creditors.  Many developing countries do not have good work-out arrangements for troubled debtors, and, as a result, governments in these countries often feel compelled to bail them out rather than accept the consequences of defaults.  The most troublesome aspect of many banking systems of emerging countries, to expand on the issue I raised earlier, is the widespread prevalence of loans driven by \"industrial policy\" imperatives rather than market forces.    What is wrong with policy that is, politically driven loans?  Potentially nothing if they were made to firms to finance expansions that just happened to coincide with a rise in consumer or business or overseas demand for their newly produced products.  In these circumstances, the loan proceeds would have been profitably employed and the loan repaid at maturity with interest.  Unfortunately, this is often not the case.  Policy loans, in too many instances, foster misuse of resources, unprofitable expansions, losses, and eventually loan defaults.  In many cases, of course, these loans regrettably end up being guaranteed by governments.  If denominated in local currency, they can be financed with the printing press though with consequent risk of inflation.  Too often, however, they are foreign-currency denominated, where governments face greater constraints on access to credit.  Restructuring of financial systems, while indispensable, cannot be implemented quickly.  Yes, the potential risks to the banking systems of many Asian countries and the potential contagion effects for their neighbors, and other trading partners, should have been spotted earlier and addressed.  But flaws, seen clearly in retrospect, are never so evident at the time.  Moreover, there is significant bias in political systems of all varieties to substitute hope (read, wishful thinking) for possibly difficult preemptive policy moves, both with respect to financial systems and economic policy.  There is often denial and delay in instituting proper adjustments.  Recent propensities to obscure the need for change have been evidenced by unreported declines in reserves, issuance by the government of equivalents to foreign currency obligations, or unreported large new forward short positions against foreign currencies.  It is very difficult for political leaders to incur what they perceive as large immediate political costs to contain problems they see as only prospective.  Reality eventually replaces hope, and the cost of the delay is a more abrupt and disruptive adjustment than would have been required if action had been more preemptive.  Increased transparency for businesses and governments is a key ingredient in fostering more discipline on private transactors and on government policymakers.  Increased transparency can counter political bias in part by exposing for all to see, the risks of current policies to stability as they develop.  Under such conditions, failure to act would also be perceived as having political costs.  We should strongly stress to the newer members of the international financial system the emerging economies that they should accelerate the restructuring of their financial systems in their own interests.  But having delayed timely restructuring, many now find themselves with major shortfalls in bank liquidity and equity capital that put their systems at severe risk of collapse before any full restructuring is feasible.  The IMF, the World Bank, and their major shareholders, the developed countries, may wish to facilitate adjustment through temporary loans to governments and the encouragement of private equity infusions to these banking systems.  Since any severe breakdown can have contagion effects on a world-wide basis, it is in our interest to do so.   These loans must be judged in their entirety.  They transform short-term obligations into medium-term loans, but they do so contingent on the country using the time to reform financial systems as well as adopt sound economic policies.  Such conditionality accelerates the adjustments in financial systems needed to lay the foundation for resumption of robust, sustainable, growth, while cushioning to some degree the economic effects of the immediate crisis.  Assistance without further reform of financial systems and economic policies would be worse than useless since it would foster expectations of being perpetually bailed out.  That, in turn, could induce perverse  behavior on the part of emerging nations' governments and of private sector investors in emerging nations.  Believing that the international financial community will support these economies, in part by backstopping the obligations they incur, induces investors to commit more than they would otherwise.  This has tended in the past to push the expansion of investment beyond prudence given the limit of profitable opportunities.  As the international financial system becomes ever larger and more efficient, the size of the financial response whether to help banks or to add to foreign currency reserves may have to be correspondingly larger per unit of crisis, if I may put it that way unless we alter our approach.  While it is precarious to generalize from one observation, it is likely that the Mexican financial crisis of the 1980s was broader than in 1994-95, but the size of the assistance program, to set things right, was much larger in the latter than in the former case.  The reason appears to be that the increased efficiency of the financial system created a larger negative spillover, which had to be contained.  Among other developments, the marked shift from bank credits in the earlier crisis, to a more securitized, anonymous, set of liabilities made workouts far more complex.  It is, hence, all the more essential that the weaker links in our international financial system, the banking systems of the emerging nations, be strengthened.  Preventive programs should be accelerated sufficiently far in advance of the next crisis to effectively thwart or contain it.  Moreover, it is incumbent on governmental policymakers to insure that unstable economic environments do not induce or exacerbate international financial disruptions.  But governments and international financial institutions should be brought on the scene only rarely.  To do otherwise risks the perverse incentives I spoke of earlier.  Markets should be allowed to work. ",
                  "1997-12-02 00:00:00"
                ],
                [
                  "22",
                  "Governor Laurence H. Meyer",
                  "New Approaches to Small Business Development Partnerships   Before I joined the Federal Reserve Board, I spent some quite enjoyable time teaching economics at a university and I must say, I welcome the opportunity to be back on a college campus again.  But as reflected by the title of my talk today,  I'm not here to present a formal lecture on the intricacies of macroeconomics, monetary policy or interest rates, though I'm certain that some of you would find it quite exciting and hang on to every word.  And I'm certainly not here to share with you any insights about political struggles inside the Beltway and the general travails of our nation's capital, Washington, D.C.  In fact quite the opposite.  Instead of looking at the world of national policy or macroeconomics, I would like to focus my remarks today on the \"micro\" level specifically the world of community development and the roles banks are playing in this growing field.  From time to time, we can all lose sight of how our day-to-day economic life unfolds and how basic economic activities, those that contribute to the long-term economic health and growth of our communities and our nation, play out.  Those activities unfold not in  Washington, but at the local level, where housing is developed, businesses grow, people save and work, and communities renew themselves.    Community development is uniquely local.  It's an effort to reestablish functioning markets in neighborhoods and communities in economic distress.  It's also a process used to revitalize these communities through affordable housing development and rehabilitation, commercial revitalization and the creation of jobs for low- and moderate-income persons.  And it is necessary in both good times and bad.  Even in a growing economy characterized by fast-paced technological change and shifting resources, capital investment strategies in the broader economy may bypass lower-income communities.    For many urban neighborhoods and rural communities, collaborative partnerships that include participation of financial institutions are the hallmark of the community development process.  The community development process is designed specifically to increase capital flows to and within lower-income communities.  In discussing community development with you here today, I want to cover roles banks are playing in partnerships to support small business development, especially those partnerships that are part of overall efforts to help revitalize communities.   The Federal Reserve's Multiple Roles Some of you might be puzzled about why a member of the Federal Reserve Board, an economist selected to serve on the Board because he was considered adept at economic forecasting, would be concerned about community development in low- and moderate-income neighborhoods.  The answer is that I come to this subject as a direct result of my responsibilities as a member of the Federal Reserve Board.  I learned very early in my tenure on the Board that this is no \"ivory tower\" operation where economists spend all of their time poring over economic data in isolation from the \"real world.\"    Although many of you are familiar with the Federal Reserve's role as a central bank in conducting monetary policy and ensuring the viability of the payments system, many are less familiar with our role in bank supervision.  The Federal Reserve supervises about 1,000 state-chartered banks who are members of the Federal Reserve System and supervises the activities of all bank holding companies.  The Federal Reserve conducts regular examinations of these banks and regularly considers all types of applications from banks and bank holding companies wishing to open branches, create new subsidiaries, or acquire other financial institutions.  Many of you also may be unaware that as part of our supervisory responsibilities, the Fed is also quite an important consumer protection agency.  In addition to examining banks to ensure that they are operating on a safe and sound basis, we also look at their compliance with consumer laws.  Additionally, Congress has given the Fed a quite specific leadership role in writing regulations and policies for a dozen key consumer protection laws.  Many of these laws govern the credit relationships of consumers with all types of creditors, from banks to mortgage companies, and from Sears to auto dealers to pawn shops.  These laws include, for example, the Truth-in-Lending Act, which requires certain disclosures about loan rates and fees; the Equal Credit Opportunity Act, which prohibits discrimination based on race, color, religion, national origin,  sex, age and  marital status, in the extension of credit; and laws governing how terms and conditions of consumer leases are to be disclosed.   The regulations touch virtually everyone who has a mortgage, credit or debit card, any type of loan or lease, anyone that has a  financial relationship with a depository institution.   The result of all this is that on a daily basis, we can be knee deep in issues related to how the banking system works, how to promote and protect fair financial dealings for consumers, and how the finances of consumers and small businesses are related to the broader performance of the economy.  One of the laws we help administer is the Community Reinvestment Act, or CRA for short.  Passed in 1977, the CRA reminds financial institutions that they have a continuing obligation to help meet the credit needs of their entire community, including those of low- and moderate-income neighborhoods.  These obligations stem from bank charters which say that banks should meet the convenience and needs of the communities they serve.  The Federal Reserve, as do other banking agencies, conducts CRA assessments of financial institutions and issues publicly available CRA ratings that reflect our judgement about their CRA performance.  We are also required to consider the CRA performance of each financial institution when reviewing its applications for expansion of depository facilities through branching, mergers, or acquisitions.  One of the ways banks meet their CRA obligations is through a variety of working partnerships that facilitate community development lending and investment.  These are public- private partnerships that involve the participation of community-based development groups, local and state agencies, financial intermediaries, including banks and thrifts, and other private sector groups, from insurance companies to utilities to foundations.  As part of my other duties as a member of the Board of Directors of the Neighborhood Reinvestment Corporation, I have had the pleasure of visiting with a number of community development organizations throughout the country and have toured dozens of their projects.   These projects are vastly different, ranging from multifamily rental housing that includes comprehensive social services on site, to row-house rehabilitation, to development of new neighborhood shopping centers.  But they all have one common denominator:  They are the product of public-private partnerships that brought together representatives of government, nonprofit groups, business, banking and others, to develop solutions to community problems that could not be addressed by any one of these groups working alone.  Evolution of Community Development Public policy now reflects this partnership approach, based on tailored programs that help meet the needs of localities and neighborhoods.  This was not always the case.  The huge federal urban renewal programs of the 1960s gave way to equally huge federal housing programs of the 70s and 80s.  The money came from Washington, along with direction from Washington.  Local government agencies and community organizations were reduced to chasing federal dollars that were used to subsidize projects that often were ill-advised because they were conceived to meet federal policies and requirements.  Current forms of community development activity had their origins in efforts to meet the needs for affordable housing and revitalize housing in lower-income areas.  What began in neighborhoods and communities across the country with a few community-based groups working with banks, foundations, and local government agencies to rehabilitate housing has blossomed into a vibrant community development industry.  Today, there are over 2,500 community-based development corporations that have produced thousands of units of affordable housing.  These nonprofit community development corporations, called CDCs, serve as developers and rehabbers, provide housing and mortgage counseling assistance, operate their own revolving loan funds, and arrange financing with others.  New state and local government loan programs are responding to the need for neighborhood based revitalization.  Additionally, there is a new set of increasingly effective intermediaries that have greatly influenced the direction and output of the affordable housing industry.  These range from new-age affordable housing builders, such as Habitat for Humanity, to national intermediaries that help local groups to plan, develop and finance affordable housing projects, such as the Local Initiatives Support Corporation, the Enterprise Foundation and the Neighborhood Reinvestment Corporation.  On the financing side, lenders, government agencies and community organizations have created a wide variety of special loan products.  Institutions, often with help from their community partners, have pioneered new approaches to looking at appraisals, debt-to-income ratios and the employment and credit histories of borrowers.  Additionally, bankers have helped create new intermediaries, including multi-bank lending consortia, community development corporations, equity pools, and revolving loan funds to help finance affordable housing.  The interest of financial institutions and the secondary market agencies has made some of the private mortgage insurance companies more willing to participate in the affordable housing market.  Low down payment/low closing cost loans have helped families become home owners who never would have dreamed it possible.    Over the years, more direct and sophisticated mechanisms involving public-private financing arrangements, joint ventures, use of special tax incentives, and other techniques have become the modus operandi of the community development process.  The results have been impressive.  The home ownership rate reached an all time high of 66 percent in the third quarter.  Underlying this number is the fact that record numbers of minority and female-headed households have been participants in the new home ownership boom, especially in predominantly minority areas where strong community development organizations have been active.  Overall, minorities have accounted for almost a third of new home owners in the last few years.  Clearly part of the increase in home ownership is a direct result of the activities of the community development industry to supply affordable housing, develop special financing and counseling programs that make it possible for low- and moderate-income households to enter the home ownership market.  Home Mortgage Disclosure Act data confirm that the number of home loans made by private lenders in lower-income neighborhoods and communities has increased at a dramatic rate over the last five years.  In addition, much of the increase can be attributed to households who previously were excluded from the home ownership market. Need for Economic Development While the results in helping stimulate the market for affordable housing and home ownership in lower-income areas and markets have been in many respects remarkable, it has become clear over the years, that housing is not enough.  It is not enough to revitalize distressed communities.  It is not enough in many cases to reinvigorate neighborhood life.  And it is usually not enough to create the kind of economic value that helps sustain revitalization efforts in ways that continue to benefit low- and moderate-income residents.  While housing rehabilitation and new housing development may be necessary in successful community development, it is hardly sufficient.    There has been growing recognition that to sustain revitalization efforts, community developers must address the capital and income gaps in lower-income areas.  What is needed, in addition to affordable housing, is economic development.  By that I mean business development, especially small business development, job creation, and commercial revitalization that makes neighborhoods more convenient and attractive places to live, work, and shop.   I do not want to suggest that this is an abrupt change in direction for the community development industry, because it really is a change that evolved over the last 25 years.  Some community-based economic development has been around for a long time, and in a number of larger cities, quite sophisticated economic development partnerships have been successful over a number of years.  For example, over 20 years ago in Chicago there were over a dozen nonprofit CDCs specializing in neighborhood economic development.  But there is a much greater emphasis on the economic development side of community revitalization now.  One reflection of this new emphasis is that in many communities around the country, community development groups that may have started out as essentially housing organizations, are moving resources into economic development activities.   Most successful programs are taking a comprehensive approach that includes planning, job training, commercial real estate development, entrepreneurship training, and a wide variety of small business assistance. Small Business Financing in the Community Development Milieu Although discussion of any one of these activities could take our entire day, I want to focus my remaining remarks on the financial side of economic development, particularly on how banks are participating in small business development and neighborhood-scale commercial development.  Just as bank financing has been critical in helping fuel affordable housing partnerships, bank participation, on both the debt and equity sides of the equation, is equally important in economic development.   In general, the growth and diversity of the small business market have not been lost on bankers, in both small and large institutions.  Across the country, many large institutions that previously had left the small business market to their community bank brethren, have been quite busy developing a wide array of products and services specific to small business needs.  Sweep accounts, tailored investment programs, affinity business credit cards, smaller revolving credit lines, term loans and improved lock-box services are just some of the business services being offered in the new, more competitive small business financial services marketplace.  The world of small business financing has gotten a lot bigger, as well as  access to loans, and even the regional and national capital markets continue to grow for many small businesses.  Commercial banks are by far the most important supplier of credit and financial services to the small business market.  The Federal Reserve's National Survey of Small Business Finances found that 84 percent of small and medium sized businesses identified a commercial bank as their primary source of financial services, though 20 percent also had financial relationships with nondepository institutions.  Importantly, the survey also suggested that the use of nonbank sources of financial services increases with firm size.  Very small businesses rarely use nondepository sources, but for firms with over 50 employees, about 40 percent said they used at least one nondepository source.  In the community development context, I believe these findings are quite important, because they suggest that the types of businesses that would be represented in community development areas, primarily very small and young firms, are generally those that would be most dependent on banks for financing.  On the other hand, banks traditionally have had myriad problems in lending to such businesses.  The small business market is quite diverse and the term \"small business\" can mean quite different things to different bankers.  Most banks tend to focus on mature, growing businesses those with more than $5 or $10 million in sales.  Other bankers typically refer to the small business market as the \"middle\" market, perhaps including firms with $25 to $50 million or more in sales, that are still dependent on bank loans because they are not quite large enough to float their own debt securities in the national capital market.    Usually, that is not the small business market on which community developers focus.  And generally, with the exception of supermarket or drug store chains, those are not the types of businesses you would usually find or attract in smaller commercial strip shopping centers in urban neighborhoods or even rural areas.   Bank Approaches To Key Issues Nonetheless, I think the community development industry has helped reshape bank perceptions of the small business market by perfecting new tools and techniques that enable banks to support financing for a broad range of small businesses from small manufacturers to very small, and even start-up firms and to facilitate neighborhood commercial revitalization.  Many of these tools and techniques are quite similar to those used in the affordable housing arena and are designed to address key issues that make it difficult for banks to lend to very small firms.  One of the primary difficulties, of course, is credit risk. Very small and start-up businesses generally lack the operating history and often have inadequate record keeping.  They typically lack equity that can be valued or collateral that gives lenders the confidence they will be repaid if problems arise.  The failure rate of small, newer firms is high and recoveries of principal are rarely achieved.  A second major set of difficulties involve the typically high transaction costs associated with making small loans, especially those under $25,000.  If banks price to compensate for these costs, they risk making the financing unaffordable for the small firm.  Additionally, many of these firms do not have traditional business plans, pro formas, and need far more advice and technical assistance than other small businesses.  A third difficulty, typical of all types of community development loans, is lack of liquidity, especially for term loans.  Very small loans to new untested businesses, or longer term but small commercial mortgages,  cannot be sold to investors; lenders must keep these in their portfolios, preventing loan funds from being replenished by limiting the amount of lending that can be done.   By adopting new financing tools and partnership approaches, many banks are learning to overcome these difficulties and increase their support for small business development. Specialized Lending Units A number of banks now have separate small business lending units that specialize in making longer-term loans, including loans that utilize federal and state loan guarantees.   Guaranteed loans from the SBA, the rural development arm of USDA, and state economic development agencies, for example, continue to help banks make longer-term loans needed for new facilities, equipment and permanent working capital that often make small business expansion possible.  These loans can be sold to investors and the proceeds used to make additional loans as a result of the government guarantee.  Thus, the use of loan guarantees not only helps banks manage credit risks, but it also helps them leverage their capital to sustain and expand lending to small businesses.  In addition, by specializing in particular types of loans, bankers can develop efficient systems that help minimize the normally high transaction costs for smaller commercial loans. Consortium Lending Corporations and Loan Pools A growing number of multi-bank loan consortia are helping banks share risks and costs associated with small business finance.  These loan consortia may also be called community reinvestment corporations or simply \"loan pools.\"   Although many are organized primarily by banks, they often have nonbank participants such as insurance companies, utilities, other business corporations, religious institutions and others.  Loan consortia can be organized as nonprofit or for-profit corporations, and while some operate on a statewide basis, most focus on particular local areas.  Statewide multi-lender consortium organizations in Massachusetts, Indiana, California, Washington State and West Virginia, among many others, reflect the growing interest in this approach.    But consortia can also be particularly useful for smaller banks at the local level.  Here in Milwaukee, the Lincoln Fund is a multi-bank loan pool that provides a variety of types of financing for businesses located in the Lincoln Avenue neighborhood of the city.  By providing loans as small as $5,000, the fund helps stabilize and preserve the economic viability of the neighborhood.  Two smaller commercial banks a savings bank and the Wisconsin Community Capital Corporation are participants.   Community Development Investments Small and minority businesses are often undercapitalized and need additional equity as well as debt financing.  Under both federal and state laws that govern the activities and powers of financial institutions, banks and bank holding companies can be granted permission by their primary regulators to make equity investments in small businesses under certain conditions.  Typically, one or more banks or bank holding companies form a community development corporation, limited liability company, or invest in a limited partnership or equity pool, which in turn makes debt and equity investments in small businesses that are in low- and moderate-income areas.  To use this equity investment authority, the bank must certify that the majority of the jobs and services provided by the assisted business must benefit low- and moderate-income persons.  Most bank CDCs focused on small business also provide specialized loans and technical assistance.   One example is the Birmingham (Alabama) CDC, created through a partnership of  city government and local financial institutions as a multi-bank community development corporation, that provides start-up and expansion loans for small minority-owned businesses in the inner-city.  Loans are funded from a  $2.5 million pool created by the banks.  Under the program, the maximum loan amount of $150,000 is available for a variety of loan types:   start-up, term financing for equipment, gap financing, and credit enhancement for new bank financing.  A unique attribute of this approach is that the City of Birmingham guarantees  50-75 percent of all loans using part of its allocation of federal Community Development Block Grant funds. Support for Nonprofit Small Business Finance Organizations Another fruitful technique used by banks is support of other lenders who are more adept in providing the specialized financing needed by very small firms.  Banks have assisted a wide variety of nonprofit small business finance organizations by providing them loans, investments and contributions.  For example, banks support the activities of SBA Certified Development Companies which are nonprofit corporations specializing in small business finance.  They are \"certified\" by the SBA to issue SBA guaranteed long-term debentures that are used to help fund small businesses.  A typical financial package includes a combination from at least three sources:  50 percent of the package must be funded by a private financial institution; 40 percent is funded by issuance of an SBA guaranteed debenture; and 10 percent from business owner equity or other private funds that may be from foundation grants or corporate contributions.  Usually, the certified development company provides technical assistance to the small businesses and develops the financing package.  Banks also can provide loans and contributions to support small business revolving loan funds operated by community-based nonprofit organizations.  The advantage here is that the community organization often provides technical assistance and training for the entrepreneur, handles loan servicing, and absorbs other transaction costs that would make small loans unprofitable if the bank made them directly. Community-Based Micro-Enterprise Loan Funds Micro-enterprise loan funds represent a growing part of the small business lending supported by financial institutions.  Community developers recognize that micro-enterprises very small businesses initially created by self-employed individuals can help bolster the economies of distressed areas and neighborhoods.  Community-based nonprofit organizations and state and local governments throughout the country have created a wide variety of  loan funds to help micro-enterprises get started or expand.  These funds provide very small loans ranging from $1,000 to $25,000 to individuals and families starting businesses.  The typical micro-enterprise fund also provides intensive training and technical assistance to the new entrepreneurs.    A recent survey by the Aspen Institute looked at 328 micro-enterprise programs throughout the country.  The average number of loans per program was 29 and the average loan size was just over $9,200.  Of the micro-entrepreneurs supported by these micro funds, 62 percent were from a minority, ethnic or racial group, and 78 percent were women. ",
                  "1997-12-01 00:00:00"
                ],
                [
                  "23",
                  "Chairman Alan Greenspan",
                  " The remarkable progress that has been made by virtually all of the major industrial countries in achieving low rates of inflation in recent years has brought into sharper focus the issue of price measurement.  As we move closer to price stability, the necessity of measuring prices accurately has become an especial challenge.  Biases of a few tenths in annual inflation rates do not matter when inflation is high.  They do matter when, as now, a debate has emerged over whether our economies are moving toward price deflation.  In today's advanced economies, allocative decisions are primarily made not by governments but by markets, and the central guide to the efficient allocation of resources in a market economy is prices.  Prices are the signals through which tastes and technology affect the decisions of consumers and producers, directing resources toward their highest valued use.  Of course, this signaling process would work with or without government statistical agencies that measure individual and aggregate price levels, and in this sense, price measurement probably is not fundamental for the overall efficiency of the market economy.  Indeed, vibrant market economies existed long before government agencies were established to measure prices.    Nonetheless, in a modern monetary economy, accurate price measurement is of considerable importance, increasingly so for central banks whose mandate is to maintain financial stability.  Accurate price measures are necessary for understanding economic developments, not only involving inflation but also involving real output and productivity.  If the general price level is estimated to be rising more rapidly than is in fact the case, then we are simultaneously understating growth in real output and productivity.  Real incomes and living standards are rising faster than our published data suggest.  Under these circumstances, policymakers must be cognizant of the shortcomings of our published price indexes to avoid misguided actions that will provoke unintended consequences.  Clearly, central bankers need to be conscious of the problems of price measurement as we gauge policies designed to promote price stability and maximum sustainable economic growth.  Moreover, many economic transactions, both private and public, are explicitly tied to movements in some published price index, most commonly a consumer price index; and some transactions that are not explicitly tied to a published price index may nevertheless take such an index into account less formally.  If the price index is not accurately measuring what the participants in such transactions believe it is measuring, then economic transactions will be skewed.  The measured price indexes have played an especially prominent role in Germany, both in terms of public perceptions of inflation performance and as a guide for policymakers.  The Bundesbank's long-standing commitment to price stability and the public's support for that commitment derive at least to some extent from Germany's experiences with hyperinflation earlier this century.  Given this experience with the devastation that such inflation can bring to the economy and to people's lives, it comes as no surprise that your public and your policymakers give such careful scrutiny to the available measures of inflation.  Germany has a reputation for special vigilance in guarding the stability of the price level and has achieved an admirable record of success in maintaining low inflation over the postwar period.  From the standpoint of monetary policy, this very success makes accurate price measurement all the more important.  When measured inflation is high, we can be confident that the proper direction of monetary policy is to bring inflation lower.  But when measured inflation is low, the proper direction of monetary policy, as I indicated, could depend crucially on the accuracy of those measurements.   The importance of accurate price measurement was particularly apparent during unification, when it became necessary to gauge productivity in East and West Germany on a comparable basis.  Initial estimates of East German productivity relative to that of the West were considerably higher than later, more accurate estimates showed to be the case.  These differences, we are told, owed largely to the difficulties in adjusting the prices of East German products to take into account that they were, on average, of lower quality than the equivalent items produced in the West.   In thinking about the problems of price measurement, a distinction must be made between the measurement of individual prices, on the one hand, and the aggregation of those prices into indexes of the overall price level, on the other.  The notion of what we mean by a general price level or more relevantly, its change is never unambiguously defined.  Moreover, in practice, aggregation can be complicated because standard price indexes frequently assume that individuals and businesses purchase the same basket of goods and services over time whereas, in fact, people substitute some goods for others when relative prices change and as new goods are introduced.  How one aggregates individual prices, of course, depends on the purpose of the measure.  Still, the problems of aggregation are well understood by economists, and workable solutions are within reach.  Many countries have made progress in utilizing aggregation formulas that do take into account product substitutions, and further progress in this area seems likely in the years ahead.    It is the measurement of individual prices, not the aggregation of those prices, that is so difficult conceptually.  At first glance, observing and measuring prices might not appear especially daunting.  After all, prices are at the center of virtually all economic transactions.  But, in fact, the problem is extraordinarily complex.  To be sure, the nominal value in dollars or deutsche marks, for example of most transactions is unambiguously exact and, at least in principle, is amenable to highly accurate estimation by our statistical agencies.  But dividing that nominal value change into components representing changes in real quantity versus price requires that one define a unit of output that is to remain constant over time.  Defining such a constant-quality unit of output is the central conceptual difficulty in price measurement.    Such a definition may be clear for unalloyed aluminium ingot of 99.7 percent purity for the vast proportion of transactions; consequently, its price can be compared over time with a degree of precision adequate for virtually all producers and consumers of aluminium ingot.  Similarly, the prices of a ton of cold rolled steel sheet, or of a linear meter of cotton broad woven fabric, can be reasonably compared over a period of years.    But when the characteristics of products and services are changing rapidly, defining the unit of output, and thereby adjusting an item's price for improvements in quality, can be exceptionally difficult.  These problems are becoming pervasive in modern economies as service prices, which are generally more difficult to measure, become more prominent in aggregate price measures.  One does not have to look to the most advanced technology to recognize the difficulties that are faced.  To take just a few examples, automobile tires, refrigerators, winter jackets, and tennis rackets have all changed in ways that make them surprisingly hard to compare to their counterparts of twenty or thirty years ago.  The continual introduction of new goods and services onto the markets creates special challenges for price measurement.  In some cases, a new good may best be viewed as an improved version of an old good.  But, in many cases, new products may deliver services that simply were not available before.  When personal computers were first introduced, the benefits they brought households in terms of word processing services, financial calculations, organizational assistance, and the like, were truly unique.  The introduction of heart bypass operations literally prolonged many lives by decades.  And, further in the past, think of the revolutionary changes that automobile ownership, or jet travel, brought to people's lives.  In theory, economists understand how to value such innovations; in practice, it is an enormous challenge to construct such an estimate with any precision.   The area of medical care, where technology is changing in ways that make techniques of only a decade ago seem archaic, provides some particularly striking illustrations of the difficulties involved in measuring quality-adjusted prices.  Cures and preventive treatments have become available for previously untreatable diseases.  Medical advances have led to new treatments that are more effective and that have increased the speed and comfort of recovery.  In an area with such rapid technological change, what is the appropriate unit of output?  Is it a procedure, a treatment, or a cure?  How does one value the benefit to the patient when a condition that once required a complicated operation and a lengthy stay in the hospital now can be easily treated on an outpatient basis?    Although there is considerable uncertainty, the pace of change and the shift toward output that is difficult to measure are more likely to quicken than to slow down.  How, then, will we measure inflation in the future if our measurement techniques become increasingly obsolete?  We must keep in mind that, difficult as the problem seems, consistently measured prices do exist in principle.  Embodied in all products is some unit of output, and hence of price, that is recognizable to those who buy and sell the product if not to the outside observer.  A company that pays a sum of money for computer software knows what it is buying, and at least has an idea about its value relative to software it has purchased in the past, and relative to other possible uses for that sum of money in the present.    Furthermore, so long as people continue to exchange nominal interest rate debt instruments and contract for future payments in terms of dollars or other currencies, there must be a presumption about the future purchasing power of money no matter how complex individual products become.  Market participants do have a sense of the aggregate price level and how they expect it to change over time, and these views must be embedded in the value of financial assets.    The emergence of inflation-indexed bonds, while providing us with useful information, does not solve the problem of ascertaining an economically meaningful measure of the general price level.  By necessity, the total return on indexed bonds must be tied to forecasts of specific published price indexes, which may or may not reflect the market's judgment of the future purchasing power of money.  To the extent they do not, of course, the implicit real interest rate is biased in the opposite direction.  Moreover, we are, as yet, unable to separate compensation for inflation risk from compensation for expected inflation.  Eventually, financial markets may develop the instruments and associated analytical techniques for unearthing these implicit changes in the price level with some precision.  In those circumstances, then at least for purposes of monetary policy these measures could obviate the more traditional approaches to aggregate price measurement now employed.  They may help us understand, for example, whether markets perceive the true change in aggregate prices to reflect fixed or variable weight indexes of the components or whether arithmetic or logarithmic weighting of the components is more appropriate.  But, for the foreseeable future, we shall have to rely on our statistical agencies to produce the price data necessary to assess economic performance and to make economic policy.  In that regard, assuming further advances in economic science and provided that our statistical agencies receive adequate resources, procedures should continue to improve.  To be sure, progress will not be easy for estimating the value of quality improvements is a painstaking process.  It must be done methodically, item by item.  But progress can be made.    One improvement that has been made in recent years is a better ability to capture quality differences by pricing the underlying characteristics of complex products.   With an increasingly wide range of product variants available to the public, product characteristics are now bundled together in an enormous variety of combinations.  A \"personal computer\" is, in actuality, an amalgamation of computing speed, memory, networking capability, graphics capability, and so on.  Computer manufacturers are moving toward build-to-order systems, in which any combination of these specifications and peripheral equipment is available to each individual buyer.  Other examples abound.  Advancements in computer-assisted design have reduced the costs of producing multiple varieties of small machine tools.  The variety of commercial aircraft is much larger now than it was twenty years ago.  And in services, witness the plethora of products now available from financial institutions, which have allowed a more complete disentangling and exchange of economic risks across participants around the world.  Although hard data are scarce, there can be little doubt that products are tailor-made for the buyer to a larger extent than ever.  Gone are the days when Henry Ford could say he would sell a car of any color \"so long as it's black.\"  In such an environment, when product characteristics are bundled together in so many different combinations, defining the unit of output means unbundling these characteristics and pricing each of them separately.   The so-called hedonic technique is designed to do precisely that.  This technique associates changes in a product's price with changes in product characteristics.  It therefore allows a quality comparison when new products with improved characteristics are introduced.    Not surprisingly, one area in which this approach has been especially useful is in computer technology.  In the United States, prior to the mid-1980s, computer prices simply were held constant in the national accounts.  Now, with the introduction of hedonic techniques, the accounts show computer prices declining at double-digit rates, surely a more accurate estimate of the true quality-adjusted price change.  The few other countries that have introduced these techniques France being the most recent show computer prices declining much more rapidly than in the majority of countries that have not yet done so.    But hedonics are by no means a panacea.  First of all, this technique obviously will be of no use in valuing the quality of an entirely new product that has fundamentally different characteristics from its predecessors.  The benefits of cellular telephones, and the value they provide in terms of making calls from any location, cannot be measured from an examination of the attributes of standard telephones.    In addition, the measured characteristics may only be proxies for the overall performance that consumers ultimately value.  In the case of computers, the buyer ultimately cares about the quality of services that computer will provide word processing capabilities, database services, high-speed calculations, and so on.  But, in many cases, the number of message instructions per second and the other easily measured characteristics may not be a wholly adequate proxy for the computer services that the buyer values.  In these circumstances, the right approach, ultimately, may be to move toward directly pricing the services we obtain from our computers that is, word processing services, database management services, and so on rather than pricing separately the hardware and software.  The issues surrounding the appropriate measurement of computer prices also illustrate some of the difficulties of valuing goods and services when there are significant interactions among users of the products.  New generations of computers sometimes require software that is incompatible with previous generations, and some users who have no need for the improved computing power nevertheless may feel compelled to purchase the new technology because they need to remain compatible with the bulk of users who are at the frontier.  Even if our techniques allow us to accurately measure consumers' valuation of the increased speed and power of the new generation of computer, we may miss the negative influence on some consumers of this incompatibility.  Therefore, even in the case of personal computers, where we have made such great strides in measuring quality changes, I suspect that important phenomena still may not be adequately captured by our published price indexes.   Despite the advances in price measurement that have been made over the years, there remains considerable room for improvement.  In the United States, a group of experts empaneled by the Senate Finance Committee the Boskin commission concluded that the consumer price index has overstated changes in the cost of living by roughly one percentage point per annum in recent years.  About half of this bias owed to inadequate adjustment for quality improvement and the introduction of new goods, and about half reflected the manner in which the individual prices were aggregated.  Researchers at the Federal Reserve and elsewhere have come up with similar figures.  Although the estimates of bias owing to inadequate adjustment for quality improvements surely are the most uncertain aspect of this calculation, the preponderance of evidence is that, on average, such a bias in quality adjustment does exist.  The Boskin commission, along with most other estimates of bias in the U.S. CPI, have taken a microstatistical approach, estimating separately the magnitude of each category of potential bias.  Recent work by staff economists at the Federal Reserve Board has added corroborating evidence of price mismeasurement, using a macroeconomic approach that is essentially independent of the microstatistical exercises.  Specifically, employing disaggregated data from the national income and product accounts, this research finds that the measured growth of real output and productivity in the service sector is implausibly weak, given that the return to owners of businesses in that sector apparently has been well-maintained.  Indeed, the published data indicate that the level of output per hour in a number of service-producing industries has been falling for more than two decades.  It is simply not credible that firms in these industries have been becoming less and less efficient for more than twenty years.  Much more reasonable is the view that prices have been mismeasured and that the true quality-adjusted prices have been rising more slowly than the published price indexes.  Properly measured, output and productivity trends in these service industries might be considerably stronger than suggested by the published data.  Assuming, for example, no change in productivity for these industries would imply a price bias consistent with the Boskin commission findings.  Of course, the United States is not the only country that faces challenges in constructing an accurate measure of inflation.  Other countries Germany among them confront similar issues.  In a recent survey of consumer price indexes in its member countries, the OECD found that most countries felt that measurement bias was smaller in magnitude in their own countries than in the United States.  Certainly regarding quality adjustment, however, I doubt that this is generally the case.  Many countries' responses were prepared by the countries' statistical agencies, which tend to take a somewhat more sanguine view of the adequacy of the existing price statistics than do outside economists.  But, in any case, the OECD survey did indicate that many countries reported that measurement bias was a concern and that most countries do not adequately adjust their statistics for quality improvements.  Indeed, as I noted previously, most European countries still have yet to adopt the most up-to-date techniques for measuring computer prices in their national accounts.  As the OECD survey recognized, the challenges presented by rapid technological advances have affected all of us not just the United States.  Thus, potential sources of measurement bias should be seriously examined in all countries.    Indeed, issues of price measurement may be especially important for the European countries entering into monetary union.  For a region with a single monetary policy, a single, consistently estimated measure of inflation is necessary to gauge the region's economic performance.  Toward that end, as you know, Eurostat publishes harmonized indexes of consumer prices that are constructed using a common basket of goods and services for each EU member state and using similar statistical methodology.  These measures should go a long way toward providing a conceptually sound basis for judging convergence of EU member states in the selection of countries to participate in monetary union.  Subsequent to monetary union, harmonized consumer prices can be used as the best available measure of inflation in the Euro area.    However, as it now stands, the harmonized measures do not contain a broad coverage of consumer services.  Most notably, the costs of owner-occupied housing a sizable share of consumer expenditures are excluded from the harmonized indexes.  In the United States, for example, the CPI calculated on this harmonized basis would have increased three or four tenths of a percentage point more slowly than the published CPI, on average, over the past few years, largely because prices of owner-occupied housing have been rising more rapidly than the other components.  Arguably, the published index, with broader coverage, is more relevant to assessing inflation trends in the United States than would be the harmonized index.  As long as relative prices can and do diverge across countries, the harmonized indexes need to contain as broad a range of items as is practical.    As monetary union proceeds, then, it would be to the advantage of monetary authorities in the Euro area to have a consistent measure of inflation defined over a broad basket of goods and services that is measured according to established statistical methods.  Most useful would be for the member countries to continue the harmonization process until the national statistical agencies are truly working on a consistent basis.  Indeed, measuring prices consistently across countries could be an important step toward making price measurement more accurate everywhere, if harmonization results in each country's best practices being adopted throughout the monetary union.  Moreover, different prices of the same tradable good across the community might signal inefficiencies of distribution which were not evident from other sources.  Harmonization of CPIs in Europe is just one of many examples demonstrating why price measurement techniques cannot be static.  With innovation constantly leading to new products, greater variety, and higher quality, the statistical agencies must work ever harder just to stay in place.  A government official in the United States once compared a nation's statistical system to a tailor, measuring the economy much as a tailor measures a person for a suit of clothes with the difference that, unlike the tailor, the person we are measuring is running while we try to measure him.  The only way the system can succeed, he said, is to be just as fast and twice as agile.  That is the challenge that lies ahead, and it is, indeed, a large one.  There are, however, reasons for optimism.  The information revolution, which lies behind so much of the rapid technological change that makes prices difficult to measure, may also play an important role in helping our statistical agencies acquire the necessary speed and agility to better capture the changes taking place in our economies.  For example, computers might some day allow our statistical agencies to tap into a great many economic transactions on a nearly real-time basis.  Utilizing data from store checkout scanners, which the United States is now investigating, may be an important first step in that direction.  But the possibilities offered by information technology for the improvement of price measurement may turn out to be much broader in scope.  Just as it is difficult to predict the ways in which technology will change our consumption over time, so is it difficult to predict how economic and statistical science will make creative use of the improved technology.",
                  "1997-11-07 00:00:00"
                ],
                [
                  "24",
                  "Governor Susan M. Phillips",
                  " Good morning.  It is a pleasure to be here to discuss the Federal Reserve's perspective on risk management.  As you know, advances in the methods and techniques in this area are having wide ranging effects on the corporate decision making process in all types of business.  The effects on banking institutions have been especially profound.  Clearly, financial engineering and improvements in risk management have helped banks to expand product lines, offer more efficient services, and control the risks of ever more complex financial instruments and the growing volume of financial transactions.  For some institutions, the application of new risk management techniques to specific areas is leading the way to a broader, firm-wide risk consciousness that is completely, and appropriately, transforming the entire corporate culture.  This is particularly important since the very essence of banking and financial intermediation is the acceptance and management of risk.  Adopting a \"risk-focused\" corporate culture from the highest levels of senior management down through business line personnel represents the ultimate product quality assurance program for individual customers and the financial system more generally.  From the Federal Reserve's perspective, effective risk management at financial institutions plays a critical role in helping to achieve our central bank responsibilities of: promoting an efficient and effective financial system that adequately finances economic growth, and ensuring that financial institutions do not become a source of systemic risk, or pose a threat to the payment system or burden taxpayers with losses arising from the federal safety net.  Advances in risk management clearly help reduce potential systemic disruptions.  The Federal Reserve, along with other supervisors both here and abroad, have focused increasing resources on encouraging developments in this area.  Indeed, just as financial engineering and advances in risk management are changing the operating methods and business cultures of financial institutions, they are also transforming both the operations and the corporate culture of bank supervisors.  While ultimate goals and objectives remain the same, over the past several years, supervisors have been moving to more \"incentive-compatible\" approaches to  1) foster sound risk management within the institution rather than comliance with narrow rules and regulations, 2) minimize burden through the use of new examination approaches and internal risk measurement systems, and 3) reinforce market discipline.  Fostering Sound Risk Management  Key to almost all of these initiatives has been an increasing effort by supervisors to avoid locking themselves into formulaic, one-size-fits-all approaches to supervision and regulation.  Too often financial engineering has been targeted at regulatory arbitrage that is, the exploitation of loopholes in  narrow regulatory policies are based on old traditional instruments, activities or business lines.  Supervisors are increasingly recognizing that the underlying risk characteristics of a financial instrument, activity or business line are of primary importance and not what they are called or officially labeled.  To be sure, financial engineering can create derivative instruments which can combine component risks (including market, credit, liquidity, operational and reputational risks) in complex ways.  But seemingly simple traditional cash instruments can actually have  higher risk profiles than many instruments that are formally labeled \"derivatives.\"  In fact, the categorization of financial instruments and activities without regard to their underlying risk and economic functions can actually handicap sound management.  Thus, Federal Reserve and other supervisors have increasingly issued supervisory guidance that emphasizes managing the risks involved in bank activities and de-emphasizes the supervisory focus on specific instruments or traditional products.   Most recently, the FFIEC, published for industry comment a new policy statement that would eliminate the 1992 interagency policy that instituted the FFIEC high risk test.  The older policy statement placed significant constraints on a depository institution's holding of certain \"high-risk\" mortgage securities that met specific market risk sensitivity tests.  The new policy would replace the high risk test with broader guidance on sound practices for managing all investment and end-user activities.  In essence, the new statement would allow an institution to hold any bank-eligible instrument as an investment as long as the institution had an adequate risk management process commensurate with the scope, complexity, and sophistication of its investment and end-user holdings.    The old FFIEC high-risk tests offer an excellent case study of the potential pitfalls of narrow formulaic supervision in an age of dynamic financial engineering.  By requiring a pre-purchase price sensitivity analysis, the high risk test successfully helped institutions better understand the interest rate risk of certain mortgage securities.  It effectively constrained many smaller financial institutions from acquiring certain types of securities that subsequently created large losses for other investors.  However, while protecting some institutions, the tests may also have distorted the investment decision making process at other depository institutions. Concerns about burden and heightened examiner review of all types of mortgage securities may have led institutions to blindly eliminate them as potential investments regardless of the merits of their risk/return profiles.  Also, by focusing only on certain products, the test provided incentives for institutions to acquire other types of securities with embedded options that required no testing.  Such instruments were thought to have a supervisory \"stamp of approval,\" but in fact often had risk characteristics similar to or greater than those designated as \"high risk.\"       Assuming positive industry comments, the FFIEC hopes to implement the proposed new policy in early 1998.  The comment period extends through November 17, and I encourage all of you to comment.  I might mention that the new policy will apply to all investment and end-user derivatives activities.  It illustrates that supervisors are increasingly emphasizing risk management on a portfolio rather than an instrument specific basis.  Although this is arguably the first principle of finance and is widely appreciated by bankers and regulators, putting this principle into practice in banking has not been easy.  Past banking crises have, in part, reflected a failure to recognize or to prudently limit concentrations of risk.  However, technology and financial innovation are now enabling financial theories and conceptual techniques that have been around for decades to be put into practice to manage  market, credit and liquidity risks.  Moreover, these risks are increasingly being managed across activities and in some cases on a global basis.  This move to a broad portfolio or \"macro\" approach to managing risk has influenced bank supervisory efforts in several ways.  All three of the U.S. banking agencies now take a more \"risk-focused\" approach to bank supervision. Bank exams are no longer exhaustive reviews of all of a bank's specific activities.  Instead, they now take a more targeted approach to identifying and reviewing the sources of risk within a bank's \"portfolio\" of activities.  Exam resources are now targeted at evaluating the soundness of a bank's processes for managing risks and our supervisory tools have been enhanced in this direction.  Increased Use of Internal Measurement and Management Systems In addition, supervisors increasingly are relying on internal risk management systems, including increasingly sophisticated risk measurement systems used by banks to manage their businesses.  The objectives here are two fold to help improve the effectiveness of our examinations and to reduce burden on banking organizations.   Examinations now involve significant off-site, pre-planning, analysis and fact finding.  Then the on-site examination activities include spot checks to determine the reliability of the bank's internal risk management system.  To the extent examiners gain confidence in the bank's risk management process, they will place greater emphasis on the findings of the bank's internal auditors at an earlier stage in the examination process and focus resources in other areas.   An area of bank risk management systems that has been particularly useful to supervisors is risk measurement.  No better example exists than the banking agencies' adoption of a risk assessment approach for evaluating capital adequacy for interest rate risk.     Early on in that rulemaking process, supervisors recognized that a number of banking institutions had internal models for measuring interest rate risk that were much more sophisticated than any possible standardized regulatory model.  However, at the same time, supervisors were acutely aware that many other institutions had limited capabilities in this area and that many banks may have been hesitant to develop more sophisticated internal measurement systems prior to the determination of a supervisory approach.  Accordingly, in 1993, supervisors proposed to use the results of internal models for evaluating the quantitative level of interest rate risk exposure at individual institutions.  While the rulemaking process was ultimately longer than desired, it did demonstrate the clear intent of supervisors to encourage and provide incentives for improvements in risk management and to take full advantage of such advances when possible.  I think most banks would agree that the discovery process and comment periods supervisors convened from 1993 through 1995, and the ensuing dialogue, spurred significant industry development and refinement of interest rate risk models.    A similar process evolved in developing the international capital standard for market risk in the trading activities of internationally active banks.  Beginning next January, banks that meet certain qualitative and quantitative standards for risk management will calculate market risk capital charges for their trading activities on the basis of their own internal Value at Risk (VaR) measures.  Here again, supervisors recognized early developments in the quantitative measurement of market risks, encouraged industry progress, and sought to build on the VaR concept when developing a supervisory approach.   During the discovery and rulemaking process the supervisory attention paid to VaR techniques led to more robust modeling and has helped spread the use of VaR techniques worldwide.   Moving forward, perhaps such supervisory/private sector synergies can be gained in other areas of risk management, as well.  The quantification of credit risks, by far the most important risk in banking, may be a candidate.  At present, some institutions are making significant strides on a number of fronts to better quantify and manage credit risk.  In addition to major developments in credit scoring and the use of artificial intelligence in underwriting various types of consumer loans, a few banks are beginning to use historical data to estimate probability loss distributions for the credit risk of different quality commercial loans.  In some banks, credit risk adjusted returns to capital are being used to construct a portfolio management framework for credit risk.  This, in turn, is providing a proving ground for a risk-adjusted pricing of loans as well as a myriad of new instruments such as credit derivatives.  While industry efforts to quantify credit risks are still in the early stages of evolution, recent progress holds promise for reducing both institutional and systemic risks. Indeed, these efforts might eventually lead to new supervisory regimes for addressing credit risk.  Better methods of quantifying credit risk have significant potential for reducing the time examiners spend in on-site examinations.  Moreover, advances in credit risk measurement may ultimately allow supervisors to design regulatory capital standards around internal models.  We recognize the inadequacy of the existing risk-based capital regime where such assets as loans are all treated as having the same risk.  We are actively encouraging the development of more quantitative approaches to credit risk management.  However, better regulatory tools are not yet available.  While supervisors can prod developments in risk management, ultimately it will be up to the industry to find other ways to better measure and manage credit risk.  Strengthening Market Discipline Harnessing market forces to reinforce supervisory objectives is another important goal in the changing culture of supervisors.  Reliable financial information and adequate disclosure of risk exposures is an essential ingredient to achieving this goal.  Market participants can benefit from enhanced disclosure by being in a better position to understand the financial condition of counterparties and competitors.  Investors have an obvious interest in being able to make meaningful assessments of a firm's performance, underlying trends, and income-producing potential.  Sound, well-managed firms can benefit if better disclosure enables them to obtain funds at risk premiums that accurately reflect  lower risk profiles. Inadequate financial disclosures, on the other hand, could penalize well-managed firms if market participants are unable to assess fundamental financial strength.   It is this desire to see market discipline play a greater role in influencing banking activities that has prompted the Federal Reserve Board to join the debate about the derivative accounting standards that are being developed by the Financial Accounting Standards Board (FASB).  Everyone agrees that a critical function of financial statements is to reflect in a meaningful way underlying trends in the financial performance and condition of the firm as well as the economic substance of its activities.  However, the Board believes that the application of market value accounting to business strategies where not appropriate, and particularly when applied on a piecemeal basis, or when market prices are not readily available, may lead to increased volatility or fluctuation in reported results.  Such accounting practices may actually obscure underlying trends or developments affecting a firm's condition and performance.  Requiring companies to adopt market value accounting where it is not consistent with business strategies can cause them to incur significant costs to provide information that may not realisticly reflect way underlying circumstances or trends in performance.  Moreover, from the standpoint of financial statement analysts and other users, having to make adjustments to remove the effects of meaningless accounting volatility from income statements and balance sheets can also impose significant costs without offsetting benefits.   The Board believes that these problems can be minimized by having large firms with active trading portfolios place market values in supplemental disclosures  rather than by forcing their use in the primary financial statements.  Such an approach would give analysts the information they need, without imposing costs on an unnecessarily wide range of firms and without imposing the broader costs of having to reverse or \"back out\" the distorting effects of the proposed accounting standard.     Emerging Challenges to Risk Management Without a doubt, banking institutions have made significant progress in implementing new techniques and methods in risk management.  To date, most work in this area has centered around the \"science\" of risk management that is, the quantitative measurement of risk.   However, quantitative measurement is only one element of the overall process of financial risk management.  Other elements such as board and senior management oversight, internal controls, and the role of internal and external audits are just as important.  Given the pace of technological and financial innovation, inadequate internal controls can expose an institution to significant risk.  Indeed, inadequate management oversight, combined with a lack of internal controls, has been the primary cause of the losses experienced by several high profile major international banking organizations.  In some cases basic time-honored internal controls such as segmentation of duties and independent risk assessment had been ignored.  In others, internal management processes have failed to keep pace with technological development, financial innovation, and global expansion.  It is these \"low tech\" areas that pose continued challenges to risk management.    Some institutions are beginning to address these challenges in their attempts to identify, monitor and control the operating risks of various business lines.  Indeed, operating risk is quickly emerging as the next frontier of risk management.  While no clear standardized definition of operating risk has yet emerged, several progressive institutions are expending significant resources to address the operating risks inherent in particular business lines.  For some, this involves conducting extensive risk assessments throughout business and product lines to identify both the types of processing, information, and personnel risks that exist and the potential measures that can be taken to mitigate them.  Others, are buttressing these assessments with attempts actually to quantify and  charge internal capital for operating risk exposures.     Supervisors can also be expected to more closely monitor banks' efforts to identify and manage operating risks.  One very important operating risk that all banking institutions face is the challenge of addressing the  Year 2,000 issue.  U.S. banks appear to be taking this matter seriously and are generally well underway toward identifying individual needs and developing action plans.  The Federal Reserve and the other federal bank supervisors are reviewing the relevant efforts of every insured depository institution in order to determine whether adequate progress on this issue is being made.  Meeting the demands of this review and ensuring proper remedies both before and after the Year 2000 will be a significant and costly task to both the industry and the banking agencies.    However, even within the context of banking, the scope of the Year 2000 problem extends far beyond U.S. banks to foreign banks, bank borrowers, depositors, vendors, and other counterparties.  Banks and others need to address Year 2000 system alterations, not only because of the potential effects on overall markets, but also as a threat to individual firm viability.  At a minimum, banks should be concerned about their ability to provide uninterrupted service to their customers into the next millennium.  If nothing else, it is simply good business. Summary In summary, advances in computerization and communications have created a paradigm shift for financial markets, the financial services industry, and the management of financial risks.  In response, supervisors are also moving to a new more \"incentive compatible\" regime of greater reliance on banks' own risk measures and internal controls.   This transformation may be slow and will be challenging for all.  Supervisors can encourage innovation, but the private sector must do much of the development work.   As always, a transition to an improved framework will work best with cooperative, open dialogue between the financial industry and its regulators, so that compatible and efficient answers are found.  In today's markets, institutions and financial systems are linked as never before, and such connections are likely to grow in the years ahead.   How effectively institutions manage their risks and allocate their capital, will have substantial consequences for economic growth.",
                  "1997-11-04 00:00:00"
                ],
                [
                  "25",
                  "Governor Laurence H. Meyer",
                  " I am very pleased to be here in Chicago to discuss community development with you.  The theme of the conference   \"The New Mosaic: New Partners, New Ventures\"   is especially appropriate here in the seventh Federal Reserve District, where there has been invaluable, pioneering work in community development partnerships reflective of this theme.  In my time with you, I would like to explore how we got to this point, both here and nationally, and share some thoughts on where we might be headed with new ventures and new partners.   Let me begin by saying a few words about the Community Reinvestment Act.  This is fairly unusual for me, especially in a speech that's focused on community development, since I do not believe that the community development activities of financial institutions necessarily should or must flow from their obligations under the CRA.  I mention it first in this instance because the CRA is having its 20-year anniversary.  At this milestone, I believe it is not inappropriate to recognize the role CRA has played in the community development process.  I am sure that many believe that the types of community development initiatives highlighted here at this conference became possible, at least in part, due to the evolution of CRA and responses to CRA by financial institutions.  This view is not without credence, as I shall discuss later.  But I also would suggest that the success of CRA has been dependent to a quite large extent on progress on a host of other fronts, the importance of which can easily be underestimated.  The progress I'm talking about is reflected in four interrelated trends that I would like to briefly review: (1) the maturation of the concept of community development; (2) the evolution of public policy and programs; (3) the growth in number, diversity and sophistication of participants; and most importantly, (4) the development of a powerful set of diverse partnerships at the local and state level. The Changing Community Development Environment   I think it's instructive to take a moment to look at the community development environment of 1977, the year CRA was passed.  The concept of community development was limited, though some changes were beginning to take shape that would later become the major trends I am highlighting.  The primary focus was on development of community infrastructure projects, such as street improvements, water and sewer projects, and recreational facilities.  There were large, nationally driven and financed housing programs and some housing rehabilitation resources.  A number of communities were using public community development funds for downtown malls or traditional industrial development projects.  Most of the funds used were public funds and most of the key players were governmental, especially local and state housing or economic development agencies.  LISC was barely a dream and most foundations didn't even have community development, at least as we know it today, on their radar screens.  Here in 1977, NHS of Chicago was in only its second year of operation, working in three neighborhoods with a small staff, and it was one of the pioneers of the NHS movement.  The Community Investment Corporation, one of the first effective multi-bank loan consortia in the country, did begin operations in 1974, and its first ten years were as a 1-4 unit, single family housing rehab lender.  In 1977, there were very few community-based CDCs, and there was no CANDO.  Here and throughout the country, most partnerships entailed local groups going begging to the local or state housing and economic development agencies for grants or use of tax-exempt revenue bonds.    Policy was primarily dictated from Washington because that's where the big money came from.  There was little attention to specific local needs, and most federal programs were ill-designed to respond to the diverse needs of neighborhoods.  But now, let's flash forward to 1997.  The juxtaposition is startling.  First, the concept of community development is starkly different.  Yes, construction of public facilities, the rehabilitation of buildings, the production of affordable housing, and commercial and industrial development remain important, but they are now considered hardly sufficient.  Community development now encompasses \"community building\" with,  by, and for people, not just development of bricks and mortar.  Community development now requires community leadership and participation, right down to, and perhaps especially, the neighborhood level.  It is not just about finding public subsidy dollars, but leveraging those funds with significant private sector investment and expertise.  In short, the concept of community development now encompasses much more comprehensive strategies; it includes the fundamental notion that rebuilding neighborhoods and communities, by necessity, entails helping create economic value and economic opportunity through job creation, training, and services for those of limited means.  Second, where the concept of community development has gone, public policy and programs have followed.  Federal programs have shrunk, but many have become much more flexible and responsive to local needs.  Many, such as the CDBG and HOME programs, have been purposefully structured so that they can and must be used to leverage private sector involvement.  And leveraging private sector resources was certainly the impetus for the new Community Development Financial Institutions program, which has demonstrated that a small national program can have a significant local impact.   We should also not lose sight of the fact that state and local governments have been creating a growing variety of community development funding programs that incorporate the attributes of flexibility and leveraging.  Third, there has been an explosive growth in the number, diversity, and sophistication of community development organizations.  Unlike 1977, today there really is a quite identifiable community development industry, complete with a diverse set of production \"companies,\" financial intermediaries, and other support mechanisms.  The production side of the industry is led by a growing network of over 2,500 nonprofit community-based development corporations producing a variety of housing, commercial and other economic development projects.   The financing side of the industry is equally impressive and, unlike in 1977, includes a remarkable array of private financial institutions, corporations and foundations, in addition to the public financing programs I've mentioned.  Community development has become a line of business for many banks and thrifts, and use of a highly creative and diverse set of financial tools and techniques is commonplace.  Institutions have created new vehicles, such as multi-bank lending consortia, bank and thrift community development corporations, and limited partnerships and equity pools.  Add to them participation by the secondary market agencies, the Federal Home Loan Bank System, national intermediaries, such as LISC and the Enterprise Foundation, and revolving loan funds run by nonprofit groups.   Fourth, and finally, the current environment differs significantly from that of 1977 in that all of the players recognize that they must work together in local partnerships.  The power of these working partnerships as reflected in their results is, perhaps, the single most distinguishing factor in any review of changes since 1977.  There are hundreds, perhaps thousands, of examples, but let me cite one that recently came to fruition here in Chicago.  It was the development of a $9.1 million, 78,000 square-foot shopping center in the city's south side community of North Kenwood-Oakland, the first such development there in over 50 years.  And it was the community development industry using public/private partnership techniques that produced it.  Participants included a local CDC, a private planning and development firm, LISC, and its funding program The Retail Initiative, the City of Chicago, and Harris Bank.  The depth of the partnership is also reflected in the fact that one of the key players, The Retail Initiative, itself is funded by a diverse group of 10 corporations, including the Prudential Corporation, the General Electric Capital Corporation, as well as banks and thrifts, such as J.P. Morgan & Company, Bankers Trust New York, Bank of America, and Home Savings of America.  This and other types of partnerships are the hallmark of community development in the 1990s.  Challenges    In providing this overview, let me assure you that I am no Pollyanna.  Community development is a tough business under any circumstances and, certainly, we have learned that efforts targeting low- and moderate-income persons or areas raise a multitude of problems and issues.  The evolving community development industry continues to face a number of significant challenges that could slow or derail its progress.  Let me touch on just a few. Declining Public Subsidies   One issue that is troubling many community developers is the  declining level of public subsidy funding, especially from federal programs.  We are all quite aware that fiscal policy in the 1990s has focused on an ongoing effort to reduce the federal budget deficit. Spending cuts have been a necessary and critical part of the process, and the debates will continue to focus not only on how much can be cut, but also specifically, which programs to cut.  Housing, community, and economic development program resources continue to be threatened.  But as important, the ongoing budget debates also have brought into focus the question of how to continue progress on important national goals by using federal spending more effectively.  One objective is to obtain the most public benefit for the least federal dollars.  Consequently, the premium now placed on any public program that helps leverage private spending and investment will continue to be an important factor.  That means that at the local level, where federal funds are used, the need for collaborative, public/private partnerships that can demonstrate that they can deploy these limited subsidy funds wisely remains a priority.  Given these realities, I think I have come to appreciate even more the essential roles that the private sector, and especially financial institutions, can... and... must, continue to play in community development and reinvestment.  The Evolving Structure of Banking   The consolidation of banking presents another set of challenges to which the community development industry must respond.  No one can deny that banking's commitment to community development has grown dramatically since 1977.  Banks and thrifts have learned the community development business and committed the personnel and resources needed to participate as effective partners.  Institutions have developed targeted marketing programs, specialized loan and investment products, and organizational units devoted exclusively to all aspects of community development finance.   Consolidation of the financial services industry, however, is raising concerns among community developers that the resources and personnel devoted to community development activities may be decreasing in proportion to the increasing size of institutions.  When two institutions with active community development programs merge, the resulting combined organization, though larger, may have fewer lending officers, relative to total institution assets, devoted to affordable housing, or fewer loan programs.  A bank-owned community development corporation operating in one community or state may be serving multiple communities or states following a merger, with the same or only slightly more in resources.  Also, in lieu of having lending officers working at the grassroots level, some institutions are placing more emphasis on standardized loan products, and are adopting credit scoring systems on a regional and national basis for many types of loans, including affordable mortgage loans.  This may reflect efforts to streamline the affordable housing loan process and generate loan volumes.  But there are some concerns that it is a one size fits all approach that may not be as responsive to neighborhood needs as when two competing organizations offered community development loan products in the same market.  Whether increasingly larger institutions can maintain the level of commitment to affordable housing and community development, consistent with their increased market power, will remain a challenge, both for banks and the communities they serve. Jobs and Housing   Another issue that is affecting the community development industry is the increased emphasis on economic development and jobs, as part of the more comprehensive approach to community development I mentioned earlier.  The rising tide created by economic growth does not necessarily lift all boats, though it certainly helps most.  Community developers know better than anyone that even when the economy is doing quite well, some people and places in America are still left behind.    Although there has been a renewed emphasis on encouraging home ownership in lower-income neighborhoods, community-based development practitioners have long recognized that this strategy often cannot succeed unless jobs are created for neighborhood residents, and commercial and retail services are restored.  As illustrated by the shopping center example I previously noted, there is an emerging movement to focus increased public and private resources on economic development, job creation, and commercial revitalization in lower-income neighborhoods.  In communities around the country, neighborhood organizations that may have started out as essentially housing organizations are moving resources into economic revitalization activities, creating balanced, comprehensive strategies and programs.  These strategies have great merit,  but their impact in the short run may be to create heavier burdens on community-based groups, as projects become more complex and require more resources from a broader variety of public and private sources.  This challenge will be played out at the neighborhood level, and it is likely that resources will continue to be stretched thin.  CRA Redux   In the context of these changes and emerging challenges, let me conclude by returning momentarily to CRA.  There may seem to be no economic rationale for a law like the CRA.  Encouraging banks to enter any particular market   low- and moderate-income  neighborhoods   does not, after all, seem to square with an economist's fundamental notions about how free markets function most efficiently.  We know, however, that some potential markets may go unnoticed or at least unexplored due to perceived risks, or insufficient information about market participants and potential.  That, I believe, was part of the genesis of CRA.  As an economist, I subscribe to the principle that free markets work best when information about the economic performance of participants, including their problems and opportunities, is readily available.  The more and better the information about market opportunities, or unmet needs, the more likely it is that someone will find a way to fill them, at least if there are no external barriers preventing action.  That general principle is certainly applicable to the banking industry and its relationships with low- and moderate-income and minority communities.  The more the banking community has learned about low- and moderate-income areas   largely as a result of their response to CRA obligations   the more it has been able to find economically viable ways to meet the financial needs of consumers and businesses located there.  For any individual business or investor, there is a general reluctance to jump alone into any market perceived as  treacherous or unprofitable.  Lending in new areas involves much uncertainty.  A few may see opportunity and take the plunge, but most wait on the sidelines to see what happens.  What CRA did, in this context, was to make all banks jump in together.  That accelerated the information flow and the learning curve, and has made possible the development of successful lending and investment strategies that two decades ago might have seemed unthinkable.  In that regard, CRA has made a contribution to the strengthening of the community development industry and its capacity to access critical financing from the private sector.  The rest, as I've tried to demonstrate here this morning, is history.  Conclusion ",
                  "1997-10-31 00:00:00"
                ],
                [
                  "26",
                  "Governor Susan M. Phillips",
                  "Trends and Challenges in Federal Reserve Bank Supervision  I am pleased to be here today to talk with you about some of the important, fundamental changes taking place within the U.S. banking system and the effects those changes are having on the Federal Reserve's supervisory process.  As you know, the U.S. economy and banking system have enjoyed more than half a decade of improving strength and prosperity in which U.S. banks have become better capitalized and more profitable than they have been in generations.  Moreover, in the past 13 months not a single insured bank has failed, and the Bank Insurance Fund is now capitalized at a level requiring most banks to pay only nominal fees for their insurance.    While this situation is a vast improvement over conditions in earlier years, experience has demonstrated that at times like these if we are not vigilant risks can occur that set the stage for future problems.  That's what makes supervising banks so interesting and such a challenge.    When the economy and the banking industry are in difficulty, supervisors must identify and address immediate problems in an effort to protect the U.S. taxpayer and the federal safety net.  When conditions are good, as they are today, supervisors have the opportunity to review their oversight process and promote sound practices for managing banking risks in an effort to avert or mitigate future problems.  This and keeping up with the pace of financial innovation and industry change that has occurred in the past 5 to 10 years has been a challenge, indeed.   As I begin my remarks, I would like to point out that no system of supervision or regulation can provide total assurance that banking problems will not occur or that banks will not fail.  Nor should it.  Any process that prevents all banking problems would be extremely invasive to banking organizations and would likely inhibit economic growth.  As financial intermediaries, banks must take risks if they and their communities are to grow.  As risk-takers, some banks will necessarily incur losses, and some will eventually fail.  The objective is to contain the costs of risk-taking, both to individual institutions and to the safety net, more generally.  Therefore, our goal as regulators is to help identify weak banking practices so that small or emerging problems can be addressed before they become large and costly.  To do that in today's markets, and in an environment in which technology and financial innovation can lead to rapid change, the Federal Reserve is pursuing a more risk-focused supervisory approach.    We are well underway toward implementing this new supervisory framework, and initial indications about it from both examiners and bankers have been favorable.  This risk-focused approach to supervision is seen as a necessary response to a variety of factors:  the growing complexity and pace of change within the industry, the increasingly global nature of U.S. and world financial markets, and the methods available today for managing and controlling risk.  As banking practices and markets continue to evolve, I believe this emphasis on risk-focused supervision will be even more necessary in the years to come.   What is \"Risk-Focused\" Supervision? With that introduction, let me clarify what I mean by risk-focused supervision.   How does it differ from the way supervisors have traditionally done their job?  What does it mean to the banking system?  What is it?   In short, risk-focused supervision simply means that in conducting bank examinations and other supervisory activities, we will seek to direct our attention and resources to the areas that we perceive pose the greatest risk to banks.  In many respects, that would seem rather obvious and hardly earth shaking, and in many ways it is, indeed, nothing new.  The Federal Reserve and the other banking agencies have long sought to identify exceptions and to prioritize examination activities.    In the past, though, the business of bank supervision has focussed on validating bank balance sheets, particularly the value of loan portfolios, which have been historically the principal source of problems for banks.  Much of the prior emphasis was on determining the condition of a bank at a point in time.  In the process, we would go through the balance sheet, assuring ourselves that a bank's assets and liabilities were essentially as stated and that its reserves and net worth were real.  As part of the process, there was a review of sound management practices, internal controls, and strong internal audit activities, but that review was not the initial or primary focus.  In earlier times that approach was adequate, since bank balance sheets were generally slow to change.  Banks held their loans to maturity; they acquired deposits locally and at a pace similar to local economic growth; their product lines were stable; and management turnover, itself, was typically low.  By tracking the quality of loans and other assets, examiners could generally detect deterioration and other business problems through their periodic on-site examinations.  If done often enough, those examinations typically gave authorities sufficient time to take action and to either close or sell a bank before the losses became significant to the deposit insurance fund.   Developments Driving Change During the past decade, though, the U.S. banking system experienced a great deal of turmoil, stress, and change.  Ten years ago, many of the country's largest banks announced huge loan loss provisions, beginning the process of reducing the industry's overhang of doubtful developing country loans.  At the same time, many of these institutions and smaller regional banks were struggling with energy and agricultural sector difficulties or accumulating commercial real estate problems.  I am sure that many of you here today can easily recall those times, and that these and other difficulties took a heavy toll-if not in your own banks, in those of your competitors.  By the end of the 1980s, more than 200 banks were failing annually, and there were more than 1,000 banks on the FDIC problem list.    This experience provided important lessons and forced supervisors and bankers, alike, to reconsider the way they approached their jobs.  For their part, bankers recognized the need to rebuild their capital and reserves, strengthen their internal controls, diversify their risks, and improve their practices for identifying, underwriting, and managing risk.  Supervisors were also reminded of the need to remain vigilant and of the high costs that bank failures can bring, not only to the insurance fund but to local communities as well.  The FDIC Improvement Act of 1991 emphasized that point, requiring frequent examinations and prompt regulatory actions when serious problems emerge.  Beyond these mostly domestic events, banks and businesses throughout the world were dealing in the 1980s and 1990s with new technologies that were leading to a multitude of new and increasingly complex financial products that changed the nature of banking and financial markets.  These technologies have brought about an endless variety of derivative instruments, increased securitization, ATMs, and a broader range of banking products.  By lowering information costs, they have also led to dramatic improvements in risk management and have expanded the marketing and service capabilities of banks and their competitors.   In large part, these changes and innovations are unequivocally good for society and have produced more efficient markets and, in turn, greater international trade and economic growth.  They have also, however, greatly increased the complexity of banking and bank supervision.  In both cases, these developments have spurred the demand for highly trained and qualified personnel.   Within the United States, our banking system has also experienced a dramatic consolidation in the number of banking institutions, due not only to technology and financial innovation, but also to legislative changes allowing interstate banking.  The number of independent commercial banking organizations has declined 40 percent since 1980 to 7,400 in June of this year.  While possibly stressful to many bankers and bank customers, this dramatic structural change has also contributed to industry earnings by providing banks with greater opportunities to reduce costs.  A challenge now for many institutions may be to manage their growth and the continuing process of industry consolidation.  This challenge may be greatest as banking organizations expand into more diverse or nontraditional banking activities, particularly through acquisitions.  Growth into a wider array of activities is especially important if banks are to meet the wide-ranging needs of their business and household customers, while competing effectively with other regulated and unregulated firms.   As you know, the Congress has been wrestling with the issue of banking powers for years and with the exception of interstate branching has yet to make much progress.  The Federal Reserve has long believed that legislation is needed and that the industry can best move forward if this issue is resolved by lawmakers, rather than by regulators in a piecemeal fashion.  Nevertheless, with or without legislation, we must all deal with changing markets and with the opportunities and pressures they present.    Utilizing existing legislative authority, regulators have been able to approve new banking products that were not available a decade ago, as financial markets and products have evolved.  However, whether future expansion comes through new laws or merely through new interpretations of current laws and regulations, it is important that the banking industry use its powers wisely and that its performance remain sound.   Supervisory Challenges Ahead In supervising this \"industry-in-transition,\" the Federal Reserve has no shortage of tasks, despite the virtually unprecedented strong condition of the U.S. banking system today.   We, too, must deal with the evolving financial markets and advances in technology.  At the same time, we must ensure that our own supervisory practices, tools, and standards take advantage of improving technology and financial techniques so that our oversight is not only effective, but also as unobtrusive and as appropriate as possible.  These tasks are wide ranging, extending from our own re-engineering of the supervisory process to the way supervisors approach such issues as measuring capital adequacy and international convergence of supervisory standards.  Constructing a sound supervisory process while minimizing regulatory burden has been a long-standing and on-going effort at the Federal Reserve and an objective we have sought to advance with our emphasis on risk-focused examinations.  Particularly in the past decade, the development of new financial products and the greater depth and liquidity of financial markets have enabled banking organizations to change their risk profiles more rapidly than ever before.  That possibility requires that we strike an appropriate balance between evaluating the condition of an institution at a point in time and evaluating the soundness of the bank's on-going process for managing risk.  The risk-focused approach, by definition, entails a more formal planning phase that identifies those areas and activities at risk that warrant the most extensive review.  This pre-planning process is supported by technology, for example, to download certain information about a bank's loan portfolio to our own computer systems and then, through off-site analysis, target areas of the portfolio for review.  This revised process should be less disruptive to the daily activities of banks than earlier examination procedures and has the further advantage of reducing our own travel costs and improving examiner morale.  Once on-site, examiners analyze the bank's loans and other assets to ascertain the organization's current condition, and also to evaluate its internal control process and its own ability to identify and resolve problems.  As a result, the Federal Reserve is placing greater reliance than before on a bank's internal auditors and on the accuracy and adequacy of bank information systems.  The review of a bank's information flow extends from top to bottom, and with the expectation that bank senior management and boards of directors are actively involved in monitoring the bank's activities and providing sufficient guidance regarding their appetite for risk.   As in the past, performance of substantive checks on the reliability of a bank's controls remains an important element of the examination process, albeit in a more automated and advanced form.  For example, we are pursuing ways to make greater use of loan sampling in order to generate statistically valid conclusions about the accuracy of a bank's internal loan review process.  To the extent we can validate the integrity of a bank's internal controls more efficiently, we can place more confidence in them at an earlier stage and can also take greater comfort that management is providing itself an accurate indication of the bank's condition.  Moreover, as examiners are able to complete loan reviews more quickly, they will have more time to review other high priority aspects of the institution's operations.   A significant benefit of the risk-focused approach is its emphasis on ensuring that the bank's internal oversight processes are sound and that communication between the bank and Federal Reserve examiners occurs between examinations.  That approach is generally supported by institutions we supervise and provides a more comprehensive oversight process that complements our annual or 18-month examination cycle.  It also strengthens our ability to respond promptly if conditions deteriorate.  Importantly, the Federal Reserve's examination staff indicates that this risk-focused process may be reducing on-site examination time by 15-30 percent in many cases and overall examination time of Reserve Bank personnel by perhaps 10 percent.  While those results are tentative, partial, and unscientific, they are certainly encouraging in terms of resource implications.  Complementing the risk-focused approach to supervision are enhancements to the tools we use to grade a bank's condition and management.  Since 1995, we have asked our examiners to provide a specific supervisory rating for a bank's risk management process.  This Fed initiative preceded, but is quite consistent with, the more recent interagency decision to add an \"S\" to the end of the CAMEL rating.  That \"S,\" as you know, addresses sensitivity to market risk and reflects in large part a bank's ability to manage that risk.  Any managers in the audience who are with U.S. offices of foreign banks may appreciate that these rating changes simply highlight the importance of risk management that the Federal Reserve has for some time emphasized in its review of foreign banks.  How effective is the risk-focused process?  Since economic and industry conditions have been so favorable in recent years, there has not been a sufficiently stressful economic downturn to provide a robust test.  The market volatility beginning in 1994 offered some insights about supervisory judgments of the risk management systems of large trading banks, but there have been few other indications.  Even the rise to record levels of delinquencies and defaults on credit card debt may reflect factors other than the ability of supervisors to ensure that management has all the important bases covered.  The real test, of course, would come with a major economic downturn.  Even then, though, it will be hard to know what might have occurred had our oversight procedures not changed.    Nevertheless, there are indications that both banking and supervisory practices are materially better now than they were in the 1980s and early 1990s.  Because of technology and lower computer and communications costs, information is much more readily available than in earlier decades, and sound management practices are more widespread.  Risk measurement and portfolio management techniques that were largely theoretical when some of us were in college are now fully operational in many banks.    Moreover, the costly experience with bank and thrift failures in the early 1990s has not been forgotten.  As a result, most bankers and business managers today have a greater appreciation, I believe, for the value of risk management and internal controls.  To that point, we are finding, with increased frequency, that banks are designing personnel compensation systems to provide managers with greater incentives to control risk.   Implementing a risk-focused supervisory approach has not been an easy task.  It has required significant revisions to our broad and specialized training programs, including expansion of capital markets, risk assessment information technology, and global trading activities as well as courses devoted exclusively to internal controls.  These education programs will, of course, need to be continually updated as industry activities and conditions evolve.    With the greater discretion examiners now have to focus their efforts on areas of highest risk, it has also become more important that we ensure the consistency and overall quality of our examinations.  To address that point, we have developed automated examination tools, based on a decision-tree framework, that will help guide examiners through the procedures most relevant to individual banks, given their specific circumstances and risk profiles.    Moreover, both domestically and abroad, the Federal Reserve is working with other bank supervisors and with the banking industry to develop sound practices for management for a variety of bank activities.  Initiatives in recent years include guidance on disclosure and on managing interest rate risk and derivative activities.  Such efforts, and the growing worldwide recognition of the value of market forces, should lead to clearer expectations of supervisors, greater reliance on market discipline, and less intrusive regulation.    In that connection, the Federal Reserve in recent years has worked closely with the FDIC and with state banking departments to coordinate our examination procedures and supervisory practices.  A prime example of these efforts is the adoption last year of the State and Federal Protocol, through which we all seek to achieve a relatively seamless supervisory process for banks operating across state lines.  We are also working together on a variety of automation efforts, some of which I have referred to already.   The Year 2000 Under the category of \"problems we don't need,\" I find it difficult to talk with bankers these days without raising the \"Year 2000\" problem.  Fortunately, most U.S. banks appear to be taking this matter seriously and are generally well underway toward identifying their individual needs and developing action plans.  Nevertheless, the Federal Reserve and the other federal banking agencies are actively reviewing the efforts of banks to address this vital issue.    Some banks, particularly large ones, have stated, themselves, that if an institution is not already well underway toward resolving this problem, then it is already too late.  I hope that all of you are giving this matter adequate attention, and are taking the steps necessary to ensure that changes are being made within your banks, and also by your vendors and customers.    A critical aspect of the year 2000 problem is that we are all so inter-linked.  Not only are we exposed to our own internal computer problems, but also to those with whom we do business.  This matter has far reaching implications for banks, covering not only operating risk, but also credit risk, liquidity risk, reputational risk, and others if material problems emerge.  This is yet another illustration of the many challenges faced by bankers today.  Conclusion In conclusion, the history of banking and of bank supervision shows a long and rather close relationship between the health of the banking system and the economy, a connection that reflects the role of banks in the credit intermediation process.  We can expect that relationship to continue and for bank earnings and asset quality to fluctuate as economic conditions change. ",
                  "1997-10-30 00:00:00"
                ],
                [
                  "27",
                  "Governor Susan M. Phillips",
                  "Black Monday:  10 Years Later  Thank you for inviting me to participate in this program sponsored by the Financial Women's Association.  We are drawing very close to the tenth anniversary of the stock market crash.   It is useful to reassess that event in the context of subsequent market and regulatory changes.   The crash was one of those (fortunately rare) events that serve as a watershed for our discussion of markets and public policies.  Considerations of regulatory approaches now almost always use the crash as a reference point.  Panels such as this one provide a vehicle for evaluating not only what we have learned from the event but also the various actions taken following the crash.  But it is also appropriate to look forward.   Changes in financial markets and the risk management capability of firms have been significant in the intervening years.  The crash may no longer be as useful a reference point for judging events and evaluating public policy responses.   I suppose everyone can remember what they were doing on the day of the crash.  I had the good fortune to have left the CFTC prior to the crash.  Thus, I got to watch events unfold from the cornfields of Iowa.  Later, however, I participated in several  post-crash evaluations.  Even now, at the Federal Reserve Board, the crash periodically comes up in supervisory discussions about  bank risk.  (Regrettably, the crash is now part of a pantheon of financial market \"problems\" that include Barings, Daiwa, Metallgesellschaft, Orange County, and Sumitomo.) The Legacy of the Crash The legacy of the crash is both tangible and intangible.  An impres-sive number of studies of the crash were done.  The more noteworthy ones take up about three linear feet on my bookshelf, a very tangible reminder.  More seriously, the studies done after the crash were wide-ranging and examined events through the eyes of many different market participants, many different regulators, and a host of academicians.  They identified weaknesses in trading and clearing systems that have resulted in tangible changes to those systems.  These changes have been very positive.  Exchanges have greatly expanded their ability to handle surges in volume, for example.   The capitalization of market makers has been bolstered as well.    Numerous changes also have been implemented in clearing systems.  Doubts that emerged about the soundness of clearing systems were some of the most frightening aspects of the crash.  The changes to clearing systems have received far less attention than those to trading systems, but their long-term consequences likely are more profound.  Such critical parts of the \"plumbing\" as the agreements between the futures clearing houses and the settlement banks have been clarified and put on a much sounder footing.  In addition, many clearing organizations have established back-up liquidity facilities that will enable them to make payments to clearing members in a timely fashion even if a clearing member has defaulted.  In both our evaluation of trading mechanisms and our evaluation of clearing systems, an important intangible outcome of the crash is that we now have a better understanding of the way these systems work.  During ordinary trading days, market participants rarely if ever question counterparties' ability and willingness to perform on obligations.  In the months following the crash, policy makers and market participants began to examine those payment conven-tions more closely.  The bulk of the changes to risk management systems that flowed from the crash related to efforts to clarify or make more rigorous the responsibilities and obligations of market participants that previously had been left ambiguous or were part of the lore of \"normal\" market practice.   Another very important intangible legacy of the crash is our better understanding of the need for cooperation and coordination among commodity, securities, and banking market authorities.  The crash vividly illustrated the extent to which markets are intertwined and the extent to which large financial firms have lines of business that cut across many markets.  The forums for coordination are almost too numerous to mention, not least of which is the President's Working Group on Financial Markets.  The Working Group com-prises the heads of the Treasury, SEC, CFTC, and Federal Reserve, and in addition, other banking supervisory agencies, the National Economic Council, and the Council of Economic Advisers participate.   Prospect Looking forward, we are better positioned today to absorb market shocks than we were prior to the 1987 crash.  We undoubtedly, however, will have many different problems in future periods of volatility.  Responses to events such as the 1987 crash tend to be crisis specific.  One of our challenges is to make public policy responsive to changing market conditions rather than let it be driven solely by the most recent crisis.  The circuit breakers put in place after the crash offer an interesting example of this phenomenon.   Circuit breakers are trading halts coordinated across the equity and equity derivatives markets.  They were first suggested by the Brady Task Force, and they are one of the more notable recommendations of that report.   As stated in the report, the purpose of this (and the other recommendations) was \"[t]o help prevent a repetition of the events of mid-October and to provide an effective and coordinated response in the face of market disorder.\"    Circuit breakers are widely cited today as one of the successes of the crash post-mortems.  But  I, for one,  question this evaluation.  Circuit breakers have never actually been triggered, in contrast to some of the so-called \"speed bumps\" which affect particular trading strategies and are now tripped routinely.  (In contrast to circuit breakers, which are coordinated across the equity and derivative markets, speed bumps are trading restrictions that have been put in place by individual market places.)  If circuit breakers have never been used to halt trading, it follows that we have never had the experience of trying to re-start trading either.  To an economist such as myself, some of the scariest times during the market crash were those in which trading was not occurring.  Our tendency to worry more about stopping trading than re-starting it is mystifying.  (I realize that there has been some discussion about the rules for the resumption of trading but the overwhelming attention has been on the halt.)    Recent re-assessments of circuit breakers have focused on increasing the magnitude of price declines necessary to trigger coordinated trading halts.   If we are going to continue having circuit breakers, I am supportive of this action and feel that a periodic evaluation of circuit breakers is valuable to ensure that trading halts only occur during very unusual market conditions.  Nonetheless, I think that we also should broadly re-evaluate circuit breakers in light of current market conditions.  Are circuit breakers fulfilling the goal articulated by the Brady Task Force of providing an effective and coordinated response in the face of market disorder?  Do circuit breakers continue to be the best public policy response to market volatility?         Many features of financial markets have changed over the last ten years, not least of which is the continuing growth in international activity.  Circuit breakers are much more difficult to impose when trading activity can move to markets that do not participate in the trading halt.  As I noted earlier, one of my main concerns is the restarting of trading following a halt.  If liquidity has moved to over-the-counter markets or foreign venues, how does one get that liquidity back in the domestic, exchange-traded market when the trading halt ends?  What kinds of problems might domestic specialists and market makers have in restarting if the market has moved away from them during the halt?  Recent changes to shorten the duration of  the circuit breakers likely would ameliorate these concerns somewhat, but the worry remains.   Another important change in the financial landscape in the years since the crash has been a greater focus on risk management by both market participants and supervisors.  Developments of new instruments, both on and off exchanges, and of new methods for evaluating risk, have given market partici-pants powerful new tools to allow them to absorb market shocks.  Similarly, risk management tools have been enhanced at clearing organizations.     Regulators must respond to these new tools.  To fully utilize their benefits, regulators will need to approach regulation and supervision in different ways.   A good example is to be found in the approach by banking supervisors to developing a capital requirement for market risk.  After initial fits and starts, the Basle Supervisor's Committee embraced the concept of using banks' internal models as a basis for a capital requirement for market risk.  The Federal Reserve has taken this process of employing new approaches to regulation a step further with its pre-commitment proposal.  Pre-commitment allows banks to commit to the maximum loss they will experience over the next quarter in their trading portfolio; this commitment becomes their capital requirement.  The proposal gives banks incentives to establish the commitment in a prudent fashion through fines and disclosures if it is violated.   Economists in the audience will recognize this proposal as an application of an incentive-compatible approach to regulation.   I suspect that there are far more areas in our regulatory structure in which incentive-compatible approaches could be implemented.   Self-regulatory organizations also may find such an approach beneficial, particularly in this era in which SROs are being asked to assume more and more regulatory responsibili-ties.  Incentive-compatible regulation essentially tries to harness the self-interest of market participants to achieve broader public policy goals.  By using such an approach, our overall goal is to make individual market participants more resilient and better able to withstand shocks.  This, after all, is the most basic (and probably the most effective) protection for firms faced with events such as the 1987 crash.  ",
                  "1997-10-15 00:00:00"
                ],
                [
                  "28",
                  "Governor Laurence H. Meyer",
                  " World trade has increased much faster than world output over the last 30 years and international capital flows have expanded at a still more rapid pace.  As a result, forecasting and modeling the national economic developments and the conduct of domestic policy has increasingly required more careful attention to the global context.  My focus is on how globalization has affected the conduct of U.S. monetary policy. I begin by documenting the trend toward increased openness of the U.S. economy.  With that background in place, I turn to the implications of increased openness for the conduct of U.S. monetary policy.  The views I present here about the conduct of monetary policy are my own.  They should not be interpreted as official policy positions of the Board of Governors or the FOMC.  Some of the questions that I address along the way are: Does an open economy introduce either new objectives or new instruments for monetary policy?  How does an open economy affect the monetary policy transmission mechanism?  Does the rapid growth in cross-border capital flows limit or even eliminate the ability of domestic monetary policy to affect domestic interest rates?  How does U.S. monetary policy affect economic conditions in other countries?  How does globalization affect the cyclical properties of the U.S. economy, the inflation process, and longer-term trends in the economy?  My conclusion is that, while the increasing openness has resulted in some important changes to how the U.S. economy operates, it has not fundamentally altered the determination of output and inflation, introduced new objectives of monetary policy, or offered new instruments to pursue those objectives.  Nevertheless, it has importantly affected the monetary policy transmission mechanism and increasingly subjected the domestic economy to the effects of changes in economic conditions abroad.  Documenting the trend toward increased openness of the U.S. economy The increased openness has two dimensions   expanded trade in goods and services and expanded cross-border capital flows.   A related indicator of openness is the volume of foreign exchange transactions, since both goods and financial asset transactions typically are preceded by currency conversions.  U.S. trade in goods and services has increased about twice as fast as the growth in U.S. GDP over the last 3 ½ decades.  This reflects the effect of both trade liberalization and technological advance, as well as the rapid growth of emerging markets recently.  Trade liberalization   including both a series of multi-lateral efforts through GATT and regional efforts such as NAFTA   has involved both reduction in tariffs and the elimination of many non-tariff barriers to trade.  Technological gains have reduced transportation costs and improved the flow of information about goods around the world.  A measure of the openness of the U.S. economy in terms of trade in goods and services is the ratio of the sum of U.S. imports and exports to U.S. GDP.  This ratio has almost tripled over the last 3 1/2 decades, from 9% in 1960 to 24% in 1996.  Even more striking is the expansion of international capital flows. Financial liberalization, deregulation, and technology, including the information revolution, have contributed to the globalization of asset markets.  A measure of the net result of cross-border capital flows, the combined U.S. holdings of foreign securities and foreign holdings of U.S. securities, has increased more than tenfold just from 1980 to 1996.  Foreigners now hold 33% of U.S. government securities, 17% of U.S. corporate bonds, and 7% of U.S. corporate stocks.  U.S. holdings of foreign securities have also increased.   Foreign stocks now make up about 10% of U.S. residents' equity holdings and foreign bonds make up about 4% of U.S. bond holdings.  While the increase in cross-border capital flows is impressive, it is nevertheless clear that \"home bias,\" the concentration of domestic wealth in domestic assets, still exists.  Another indicator of the increased openness of the U.S. and other economies is the volume of foreign exchange transactions, since these transactions are often the first step in effecting both foreign trade and cross-border capital flows.  The daily volume of foreign exchange transactions surveyed in major financial centers doubled over the period from 1989 to 1995 to about $1.2 trillion, and more than 4/5 of these transactions involve dollars. The daily volume of foreign exchange transactions, however, is an imperfect measure of openness of the U.S. economy, because many transactions among other countries involve dollars.    Monetary policy in a global economy: responding to external shocks One implication of a global economy is that external shocks, those arising from outside the country, become an additional source of disturbance to the U.S. economy and therefore an additional challenge to which monetary policy must respond.  I will consider three types of external shocks: demand, supply, and exchange rate shocks.  An example of a demand shock would be an unexpected change in the overall level of economic activity abroad, which would affect the demand for U.S. exports.  For example, in the early 1970s, the latter 1970s, and late 1980s, global expansions and the resulting sharp increase in world commodity prices and demand for U.S. exports contributed to the mounting inflationary pressures and overheating in the United States.   In the three episodes just noted, commodity price booms were exacerbated by a run-up in oil prices resulting from the disruption of supplies from the Middle East.  In the mid-1980s, oil prices plummeted, contributing to a transitory decline in inflation and easing of monetary conditions.  Such changes in world oil prices are an example of a supply shock, a change in the price of goods unrelated to the balance between supply and demand in the domestic market.  Energy and food prices, in particular, are subject to volatile swings, due to political decisions, weather, or other developments unrelated to overall domestic economic conditions.  The United States is vulnerable to oil price shocks both because we have a very high consumption of oil and because we import about 50% of crude petroleum.  The rise in oil prices not only has a sharp effect on overall prices in the United States, but, given the relatively inelastic demand for energy, results in an increase in real imports and hence a decline in aggregate demand for domestic output.  Even much smaller shocks have had clearly visible effects on the U.S. economy, including the $5 dollar a barrel increase over 1996 and the $5 decline over 1997.  Exchange rates move in response to both domestic and foreign economic developments and at times appear to move for reasons not clearly linked to economic fundamentals.  The movements that are tied to changes in domestic economic fundamentals are part of the process of income and price determination in open economies, and I will have something to say about this below.  But movements related to developments abroad or movements not clearly tied to economic fundamentals are another source of shock to national economies.  This is especially important because the empirical linkages between exchange rates and fundamentals are weak, or not as well understood as we might like, so that movements in exchange rates often appear to be exaggerated relative to or seemingly unrelated to changes in fundamentals. Do cross-border capital flows reduce the effectiveness of monetary policy? One of the dimensions of increased openness is the rapid increase in the volume of cross-border capital flows.  If foreign and domestic securities are perfect substitutes, the liberalization of cross-border financial transactions could, in principle, result in a single world financial market.  This might appear to imply that the interest rate at which citizens and governments of a nation could borrow and lend would then be set on world markets, with little or at least limited influence by national policymakers.  A small country, for example, would have no ability to influence world interest rates in this case.  A very large country, such as the U.S., would retain some influence, but the influence would be diminished relative to the closed-economy case and would result from its ability to affect the world interest rate.  If a country's exchange rate is pegged to the currency of another country (or countries), then its interest rates will move closely in line with those in the country or group of countries to which it is pegged.  But for countries with flexible exchange rates, domestic interest rates can move quite independently of interest rates abroad.   However, if countries care about the level of their exchange rates, which have implications for aggregate demand and inflation, and adjust monetary policy accordingly, interest rates will, to a degree, move in common across countries.  Greater integration of global capital markets does in fact mean that expected returns for holding different assets, with appropriate compensation for differences in risk, should increasingly converge.  However, as long as exchange rates can adjust, this does not imply that interest rates across countries must move together.  Instead, it is movements in exchange rates which insure convergence of holding period yields across the countries.   Before turning to the connection between interest rates and exchange rates, let me note that the evidence does not confirm an increase in correlations in interest rate movements across world asset markets, at least in the 1990s compared to the 1980s.  It is true that the levels of long-term interest rates in major industrial countries have tended to converge since the early 1980s.  But this is largely accounted for by a convergence of inflation rates.  On the other hand, there is little evidence to suggest that correlations between changes in long-term interest rates across these countries have increased over this period.  These correlations are a little higher in the 1980s and 1990s than they were in the 1970s, but again have shown no tendency to increase since the early 1980s.  At any rate, the correlations between U.S. interest rates and those of major industrial countries suggest that there remains ample room for real interest rates to move differently across the world financial markets and implies that domestic monetary policies remain important tools of macroeconomic policy, at least in countries with flexible exchange rates.    While the correlations among changes in interest rates have not increased, changes in interest rates between the U.S. and major industrial counties are correlated.  Correlations tend to be about 0.5.   This leaves open the question of causality and source of the correlations.  It does not mean that higher U.S. interest rates directly raise foreign interest rates by this amount.  First, some of the co-movement could reflect synchronous business cycles.  Second, some of the co-movement could reflect the spillover effects of a cycle in one country on aggregate demand and hence interest rates in the other countries.  In addition, some of the correlation may reflect the effect of the response of monetary policy to exchange rate developments.  Perhaps reflecting the latter influence, the correlation between interest rates in the United States and Canada is higher, about 0.8, while that between the United States and Europe is lower, about 0.4. The transmission mechanism in a open economy While cross-border capital flows do not interfere with the ability of U.S. monetary policy to influence the broad spectrum of interest rates in the United States, they do quickly transmit pressures from changes in U.S. interest rates to the exchange rate and thereby broaden the channels through which monetary policy affects aggregate demand.  In the closed economy setting, the transmission mechanism runs from increases in the federal funds rate, the short-term interest rate targeted by monetary policy, first to longer term interest rates and equity prices and then to aggregate demand.  Several components of aggregate demand depend importantly on interest rates, particularly longer-term interest rates (specifically, business fixed investment, housing, spending on consumer durables); consumer spending also depends on the net wealth of households and is therefore affected by equity prices.  Under floating exchange rates, net exports become another interest sensitive component of aggregate demand.  Higher U.S. (real) interest rates, relative to foreign rates, raise the demand for dollar-denominated assets, and bring about an appreciation of the dollar which, in turn, stimulates imports and restrains exports.  Net exports as a result become inversely related to U.S. interest rates.  Evidence suggests that the response of net exports to interest rates (via exchange rates) has become larger over time.  The open economy version of the monetary policy transmission mechanism involves three steps: from U.S. interest rates to nominal exchange rates; from nominal exchange rates to the absolute and relative prices of imports and exports; and from the prices of imports and exports to the real volumes of imports and exports and domestic prices. From U.S. interest rates to the exchange rate We begin with the link between interest rates in the U.S. and exchange rates.  A policy-initiated increase in U.S. short-term rates would, as noted above, generally result in higher U.S. long-term interest rates.  At initial levels of foreign interest rates and equity prices, the movement in U.S. rates would make dollar-denominated assets more attractive compared to foreign currency-denominated assets, resulting in shifts in asset demands and either incipient or actual cross-boarder capital inflows to the U.S. and outflows from foreign economies.  These shifts result in an appreciation of the dollar.  Indeed, the single most important determinant of short-term movements in exchange rates is the change in real interest rate differentials across countries.  A 1% point increase in U.S. long-term (10-year) interest rates, with unchanged foreign rates, will typically induce a 10% increase in the U.S. trade-weighted exchange rate.  After the initial jump in the dollar, there will be an expectation of a decline in the dollar by about 1% each year for the next 10 years.  The result of the rise in the dollar and the expectations of gradual reversal is what is referred to as international interest rate parity.  The holding period yields of U.S. and foreign assets, each denominated in their home currency, are thereby equated, eliminating the incentive for further changes in asset demands or capital flows.  That is, the higher interest rate yield on U.S. assets (measured in dollars) is just offset by the expected depreciation in the value of the asset, measured in the foreign currency.  This is the mechanism by which holding period yields are equated across countries via international capital flows.  By the end of the 10-year period, according to this framework, both interest rates and exchange rate would have returned to their original levels.  Evidence suggests that the response of the exchange rate to changes in U.S. interest rates (relative to foreign rates) has increased over time.  This likely reflects the removal of capital controls by many major industrial countries during the 1970s and early 1980s that in turn contributed the sharp rise in international capital flows documented above.  So increased integration of financial markets across countries appears to have had a more important effect in raising the responsiveness of exchange rates to interest rate developments than in directly connecting interest rates across countries. From the exchange rate to the relative prices of imports and exports The next step in the transmission mechanism is the pass-through of the exchange rate to the dollar prices of imports and the foreign currency price of U.S. exports.  The evidence suggests that the pass-through is much more complete for U.S. exports than for imports, but there is no evidence that these pass-throughs have changed over time.  An appreciation of the dollar will be gradually partially passed through over time to the price of imports, lowering their price relative to U.S. produced goods.  The corresponding depreciation in other countries currencies will result in a gradual increase in the foreign currency price of U.S. exports, compared to the prices of foreign produced goods.    The result is movements in relative prices that encourage imports and discourage exports. From relative prices to real import and export volumes The final step in the process is from the relative price of imports and exports to the volumes of real imports and exports.  This depends on the elasticity of the demands for imports and exports with respect to their relative prices and the size of trade flows relative to GDP.  The elasticities of imports and exports with respect to their respective relative prices are estimated to be about unity, and there is no evidence of a shift in this elasticity over the past several decades.  A one percentage point increase in the real exchange rate would increase real imports by one percentage point over a three year period and decrease real exports by a similar percentage.  The absolute effect on aggregate demand also depends on initial levels of imports and exports.  As import and export volumes have been increasing rapidly, the absolute effect of exchange rate changes on aggregate demand and the contribution of the exchange rate channel to the monetary transmission mechanism has been growing over time. Trends in interest sensitivity If the magnitude of other channels in the transmission mechanism remained unchanged, the growing importance of imports and exports and the increase in the responsiveness of exchange rates to interest rate differentials would have raised the overall responsiveness of aggregate demand to interest rates.  However, it appears that the interest sensitivity of residential construction has moderated over time, beginning with the repeal of Regulation Q, and continuing with innovations in housing finance, including adjustable rate mortgages, the broadening of the sources of mortgage lending, and the development of securitization and secondary markets for mortgages.  The net result is that the interest responsiveness of aggregate demand appears to have remained reasonably stable over time, although the sectoral distribution of the overall effect of interest rates has shifted toward net exports and away from housing.  The response of net exports to changes in U.S. interest rates, via exchange rates, contributes about one-third of the total interest sensitivity of U.S. aggregate demand over both a one-year and three-year interval.  It is therefore a very important part of the monetary policy transmission mechanism. How does U.S. monetary policy affect other countries? Just as developments abroad affect the U.S. economy, changes in U.S. economic conditions impact on foreign economies, although the effects are not necessarily symmetric.  Because of the large relative size of the U.S. economy, changes in U.S. economic conditions have relatively larger effects on foreign economies, compared to the effect of changing conditions in any one country abroad on the U.S. economy.  A change in U.S. monetary policy affects foreign economies in three ways   via exchange rates, interest rates, and income in the United States.  The effects depend critically on the nature of the foreign exchange regime in the foreign country.  If the foreign country's currency is pegged to the dollar, for example, there will, of course, be no exchange rate effect vis-à-vis the United States.   An increase in U.S. interest rates, however, would put downward pressure on the foreign currency and require the country to raise domestic interest rates to maintain the fixed exchange rate.  Therefore, foreign interest rates are very likely to have to rise with U.S. rates in this case.   The restraining effect of the rise in foreign interest rates will be reinforced by the effect of the deceleration in U.S. demand for foreign goods induced by the slowdown in U.S. income.  As a result, a tightening of monetary policy is likely to have an unambiguously restrictive impact on those countries whose exchange rates are pegged to the dollar.    For countries with floating exchange rates, on the other hand, the exchange rate and income effects of rising U.S. interest rates are likely to be offsetting.  The appreciation of the dollar, of course, implies a depreciation in other countries' exchange rates; the depreciation will stimulate foreign aggregate demand by raising net exports.  Offsetting this will be the effect of the decline in U.S. income on the demand for foreign countries' exports.  The net effect, for countries with floating exchange rates, is likely to be small. That is, floating exchange rates tend to insulate a country from monetary shocks abroad. Other effects of globalization on the U.S. economy The increased openness of the U.S. economy has also focused attention on the possible effects of globalization on the macroeconomic performance of the U.S. economy, beyond the effects on the transmission of monetary policy that I have already addressed.  I want to focus my attention in this section on the implications of globalization for wage-price dynamics because this has a direct bearing on the conduct of monetary policy.  Some have argued that increased global competition has made the United States (and presumably other countries) less inflation prone, so that the U.S. economy can operate at a higher degree of resource utilization without the threat of rising inflation.    It is useful to distinguish three ways in which global developments might recently be contributing to restraining inflation in the United States.  First, the significant appreciation of the dollar over the last two years has clearly had an important restraining effect on U.S. inflation, both via the direct effect on the prices of imported goods and on the pricing power of domestic firms producing import-competing goods.  Second, the absence of synchronous expansions among the major industrial countries - specifically the much weaker expansions in continental Europe and the still weaker condition of the Japanese economy - has prevented the pressures on worldwide commodity markets that often accompany U.S. expansions and has perhaps also encouraged greater price competitiveness than would otherwise have been the case.   Third, increased international competitive pressures, associated with growing openness of the U.S. economy, might be restraining inflation.  But I wonder whether we would be talking about the contribution of globalization to U.S. inflation performance if the dollar had been stable for the last several years and the expansions in Europe and Japan were as robust as in the U.S.  I doubt it. Are there additional objectives for monetary policy in a global environment? An interesting question is whether the increased openness of the U.S. and other economies suggests new objectives for domestic monetary policies.  It is certainly true that increased globalization has encouraged a proliferation of information-sharing exercises around the world and some increased attention to the coordination of policies across counties.  I will comment on this briefly below.  Let's start with objectives appropriate in the closed economy context.  Congress has set dual objectives for monetary policy in the Federal Reserve Act: price stability and full employment.  These objectives relate directly to the performance of the domestic economy and they are also objectives that monetary policy has the ability to pursue in the closed economy setting.    The first question is whether the open economy environment reduces the ability of domestic monetary policy to achieve these objectives.   I have argued that globalization has not reduced the ability of countries with flexible exchange rates to carry out independent monetary policies and therefore pursue domestic objectives.   On the other hand, countries that fix exchange rates do give up much of the independence in their domestic monetary policies.     The second issue is whether the open economy setting introduces new objectives, beyond those that motivate policy in the closed economy context.  Three possibilities come to mind: the current account and/or trade balance, the exchange rate (or pattern in exchange rates around the world), and economic performance abroad.    Even thinking of the external measures as domestic objectives raises questions.  With respect to the current account, we should begin by separating cyclical and structural movements.  Cyclical movements in net exports contribute the economy's built-in stability and are therefore quite desirable.  Changes in the structural current account balance may contribute to or interfere with broader domestic objectives, depending on circumstances.  The fundamental source of a structural current account deficit is domestic spending in excess of domestic production.  Is this good or bad?  The answer is: it depends.  An excess of spending over production used to finance business fixed investment could have a payoff in terms of higher future output large enough to service the increased international indebtedness and still leave the country better off.  An increase in the current account deficit as a result of increased private or public consumption would, in contrast, require lower future consumption as some of future production would have to be used to service the higher level of foreign debt.  In addition, there is an issue of sustainability.  International indebtedness can become so large in relation to current production, depending in part on the relationship between the real interest rate on foreign debt and the economy's trend rate of growth, that the current account deficit could increase explosively.  If the current account is an objective, durable changes in the structural deficit can only be achieved by fiscal policy.  A cut in the structural federal budget deficit for example would increase national saving, lower real interest rates, lead to a depreciation of the dollar, boost net exports, and lower the current account deficit.  It is even more difficult to talk about the exchange rate as an objective.  The exchange rate is, after all, basically a relative price.   We might say that we prefer that an exchange rate that reflect fundamentals.  But other than that the exchange rate is a symptom, rather than an outcome.  If the current account deficit is wide because of a high dollar, the appropriate question is why is the dollar so high.  If the answer is because the federal budget structural deficit is high and has raised real interest rates in the U.S., the offender is not the exchange rate, but the federal budget deficit.  If the problem with exchange rates is fundamentals, then it is the fundamentals that need to be changed.  Monetary policy can, via its effect on interest rates, influence exchange rates in the short run.  But, for monetary policy to target exchange rates, it must give reduced weight to its domestic objectives.   When fundamentals are the issue, it is the mix of monetary and fiscal policies that must answer the call.  Stabilization policy, for example, calls for a level of aggregate demand consistent with full employment.  That level of aggregate demand can be produced by a variety of combinations of monetary and fiscal policies, varying from a very tight fiscal and loose monetary policy to a tight monetary and loose fiscal policy.  The difference among these options is interest rates.  If fiscal policy, for example, moves to a higher deficit, monetary policy will have to offset the effect on aggregate demand by tightening.  The result is higher interest rate, a higher dollar, and ultimately a wider current account deficit.  If this outcome is viewed as undesirable, the way to unwind it is by lowering the deficit, accompanied by more accommodative monetary policy.  It takes two to do this tango!  But I always view fiscal policy as having the first move.  Monetary policy's job is to follow the lead of fiscal, so that the resulting mix is appropriate to the requirements of stabilization policy.  I am occasionally asked whether I worry about the effect on other countries of changes in U.S. monetary policy.  While I do keep in mind the potential international repercussions of U.S. monetary policy actions, I believe that the best way for the U.S. to contribute to the health of the world economy is to pursue prudent domestic policy and achieve maximum sustainable employment and price stability and accommodate the maximum sustainable growth in the U.S. economy. Are there new policy instruments in a global economy? Another question about the conduct of monetary policy in an open economy is whether the open economy offers monetary policy a new instrument that it did not have in the closed economy world.  In a closed economy context, monetary policy has a single instrument: open market operations, used to target a short-term interest rate.  The obvious candidate for an additional instrument in the open economy case is the exchange rate.  I have already argued that monetary policy cannot be used to target the exchange rate.  The issue here is whether there are opportunities to exercise direct control of the exchange rate.  The obvious option is intervention.  Intervention refers to a government buying or selling foreign currency in order to influence the exchange rate.  One can identify two reasons for intervening.  The first is to calm disorderly markets.  That is, an increase in volatility in the foreign exchange market might be damped by intervention.  However, most intervention is about affecting the level of the exchange rate, not its volatility, though the rhetoric of disorderly markets often is employed to justify the action.  Actions to affect the level can be intended to prevent a further decline (or increase) or to encourage a change in the level.  With a daily volume of $1.2 trillion in the foreign exchange markets, and underlying stocks of financial assets that are substantially larger, there is ground for skepticism that intervention, which seldom ranges into the billions of dollars in daily volume, can have more than a marginal and transitory effect.  Still, there are examples of modest \"successes,\" especially when intervention is coordinated across countries and well timed.  The major opportunity for intervention to succeed is when the exchange rate has diverged to a significant degree from fundamentals and the intervention induces a reconsideration of the market or a refocus of the market on fundamentals.  The management of foreign exchange interventions varies around the world.  In the United States, this management is shared by the Federal Reserve System and the Treasury Department.  In principle, intervention can be initiated by either party, although when the Treasury opts to intervene it is the Federal Reserve Bank of New York that actually does the buying or selling of foreign currency, albeit from an account held in the name of Treasury and at the direction of Treasury.  Similarly, when the FOMC makes a decision to intervene, it directs the Federal Reserve Bank of New York to do so, from the account in the name of the Federal Reserve System.  The traditional practice is that U.S. intervention exercises are carried out jointly, half from the Federal Reserve's account and half from the Treasury's account.  However, in principle, either party could intervene on its own. International information exchange, policy coordination, and crisis management Give the growing interdependence of national economies and macroeconomic policies, the coordination of (or more accurately, mutual consultation about) these policies has taken on increased importance.  The Federal Reserve takes part in many international forums to exchange information on economic developments and discuss global economic issues.  Examples include the 10 meetings each year among G-10 central bank Governors, under the auspices of the BIS; the twice a year meetings of the Economic Policy Committee of the OECD, meetings of the G-7, IMF, and regional meetings, such as APEC and Governors of the Central Banks of the American Continent. ",
                  "1997-10-14 00:00:00"
                ],
                [
                  "29",
                  "Chairman Alan Greenspan",
                  " I welcome the opportunity to inaugurate your economic seminar series because I believe that the education community has a crucial role to play in the current era of rapid economic change.  Our businesses and workers are confronting a dynamic set of forces that will influence our nation's ability to compete worldwide in the years ahead.  Our success in preparing workers and managers to harness those forces will be an important element in the outcome.  One of the most central dynamic forces is the accelerated expansion of computer and telecommunications technologies, which can be reasonably expected to appreciably raise our standard of living in the twenty-first century.  In the short run, however, fast-paced technological change creates an environment in which the stock of plant and equipment with which most managers and workers interact is turning over more rapidly, creating a perception that human skills are becoming obsolete at a rate perhaps unprecedented in American history.  I shall endeavor to place this most unusual phenomenon in the context of the broader changes in our economy and, I hope, to explain why education, especially to enhance advanced skills, is so vital to the future growth of our economy.  Wealth has always been created, virtually by definition, when individuals use their growing knowledge to interact with an expanding capital stock to produce goods and services of value.  Assisted by the whole array of market prices, entrepreneurs seek to identify the types of products and services that individuals will value.  More specifically, they seek the added value that customers place on products and services tailored to their particular needs, delivered in shorter time frames, or improved in quality.  A century ago, much, if not most, of our effort was expended in producing food, clothing, and shelter.  Only when crop yields increased, steam power was developed, and textile fabrication became more efficient were available work hours freed for the production and consumption of more discretionary goods and services.  We manufactured cars and refrigerators and learned how to produce them with ever less human effort.  As those products found their way into most homes, human effort moved on to the creation of values that were less constrained by limits of physical bulk, such as smaller, transistor-based electronics, and beyond to a wide variety of impalpable services medical care, education, entertainment, and travel, to name just a few.  The demand for a virtually infinite array of impalpable values is, to a first approximation, insatiable.  Understandably, today's efforts to create new values for consumers concentrates on these impalpables, which offer the highest potential value-added relative to costs in physical resources and human effort.  Unbundling the particular characteristics of each good or service facilitates maximizing its value to each individual.  Some individuals place more value on, and are willing to pay more for, style y rather than style x, whereas others prefer x.  Producing both x and y enhances overall consumer well-being.  Fifty years ago, only x was feasible.  This striving to expand the options for satisfying the particular needs of individuals inevitably results in a shift toward value created through the exploitation of ideas and concepts or, more generally, information from the more straightforward utilization of physical resources and manual labor.  Thus, it should come as no surprise that, over the past century, by far the largest part of the growth in America's real gross domestic product is the result of new insights and, more broadly, new information about how to rearrange physical reality to achieve ever-higher standards of living.  The amount of physical input into our real GDP, measured in bulk or weight, has contributed only modestly to economic growth since the turn of the century.  We have, for example, dramatically reduced the physical bulk of our radios, by substituting transistors for vacuum tubes.  Thin fiber optic cable has replaced huge tonnages of copper wire.  New architectural, engineering, and materials technologies have enabled the construction of buildings enclosing the same amount of space, but with far less physical material than was required, say, 50 or 100 years ago.  Most recently, mobile phones have become significantly downsized as they have been improved.  As it became technologically possible to differentiate output to meet the increasingly calibrated choices that consumers now regularly make, the value of information creation and its transfer was expanded.  Hence, it is understandable that our advanced computer and telecommunications products have been accorded particularly high value and, thus, why computer and telecommunications companies that successfully innovate in this field exhibit particularly elevated stock market values.  Breakthroughs in all areas of technology are continually adding to the growing list of almost wholly conceptual elements in our economic output.  These developments are affecting how we produce output and are demanding greater specialized knowledge.  We could expect the widespread and effective application of information and other technologies to significantly increase productivity and reduce business costs.  Certainly, we can already see dramatic improvements in quality control that have sharply reduced costly product rejects and lost time, while computer and satellite technology has markedly improved the efficiencies of moving goods through even more sophisticated, just-in-time, inventory systems.  With computer-assisted design, experiments can be evaluated in a virtual reality setting, where mistakes can be readily corrected without the misuse of time and materials.  And new technologies have had extensive applications in the services sector for example, in health services, where improvements in both diagnosis and treatment have been singularly impressive; in airline efficiency and safety; and in secretarial services now dominated by word processing, faxes, and voice and electronic mail.    The accelerated pace of technological advance has also interacted with the rapid rise in financial innovation, with the result that business services and financial transactions now are transmitted almost instantaneously across global networks.  Financial instruments have become increasingly diverse, products more customized, and markets more intensely competitive.  The scope and size of our financial sector has grown rapidly because of its ability to facilitate the financing of products and services that are themselves valued highly in the marketplace.  Our nation's financial institutions, as a consequence, are endeavoring to find more effective and efficient ways to deliver their services.  In this environment, America's prospects for economic growth will depend greatly on our capacity to develop and to apply new technology.  Unfortunately, we have found that we never can predict with any precision which particular technology or synergies of technologies will add significantly to our knowledge and our ability to gain from that knowledge.  For instance, Alexander Graham Bell initially viewed the telephone solely as a business instrument merely an enhancement of the telegraph for use in transmitting very specific messages.  Indeed, he offered to sell his telephone patent to Western Union for only $100,000, but he was turned down.  Similarly, Marconi, at first, overlooked the radio's value as a public broadcast medium, instead believing its principal application would be in the transmission of point-to-point messages, such as ship-to-ship, where communication by wire was infeasible.  Moreover, we must recognize that an innovation's full potential may be realized only after extensive improvements or after complementary innovations in other fields of science.  According to Charles Townes, a Nobel Prize winner for his work on the laser, the attorneys for Bell Labs initially, in the late 1960s, refused to patent the laser because they believed it had no applications in the field of telecommunications.  Only in the 1980s, after extensive improvements in fiber optics technology, did the laser's importance for telecommunications become apparent.  America's continued success in garnering the benefits of technological advance will depend on the ability of our businesses to deal with risk and uncertainty.  Moreover, our ability to remain in the forefront of new ideas and products will be ever more difficult because of the rapid international diffusion of technology.  Nonetheless, to date, we have not fallen behind in converting scientific and technological breakthroughs into viable commercial products.     Even if the most recent, tentative indications that productivity growth may be speeding up were to turn out to be less than we had hoped, it is possible that the big increases in efficiency growing out of the introduction of computers and communications systems may still lie ahead.  Past innovations, such as the advent of electricity or the invention of the gasoline-powered motor, required the development of considerable infrastructure before their full potential could be realized.   Electricity, when it substituted for steam power late last century, was applied to production processes that had been developed for steam.  For example, gravity was used to move goods vertically in the steam environment, and that setup did not initially change with the advent of electric power.  Only much later when horizontal factories, newly designed for optimal use of electric power, began to dominate our industrial system did productivity clearly accelerate.  Similarly, only when highways and gasoline service stations became extensive was the lower cost of motor vehicle transportation achieved.  In addition, full effectiveness in realizing the gains from technological advance will require a considerable amount of human investment on the part of managers and workers who have to implement new processes and who must be prepared to adapt, over their lifetimes, to the ongoing change that innovations bring.  The growth of the conceptual component of output has brought with it accelerating demands for workers who are equipped not simply with technical know-how, but with the ability to create, analyze, and transform information and to interact effectively with others.  A popular term for the type of human capital that firms are today employing to a greater degree is \"functional literacy,\"1 which perhaps sounds deceptively simple when one considers the complex of attributes necessary to transform information into economic value.    Indeed, the debate about whether the introduction of technology would upgrade or \"deskill\" the workforce is as old as Adam Smith.  Certainly, one can point to some very routine types of jobs, such as those for telephone operators, that have lower skill requirements in today's world of automated communications systems than when more labor-intensive manual phone systems were in place.  But, on the whole, the evidence suggests that across a wide range of industries, employers have upgraded their skill mix.2  Importantly, these changes represent not simply a shift in the occupational mix, but, to a larger degree, an upgrading of skill requirements of individual jobs for which the range and complexity of tasks and the scope for problem-solving and decisionmaking has expanded.   This process appears to have occurred more rapidly in those businesses with greater computer utilization.3  However, this is not to argue that growing use of technology alone can explain the accelerated demand for more skilled workers.  A 1994 survey of employers conducted by the Census Bureau for the National Center on the Educational Quality of the Workforce found that rising skill requirements also are more common in firms that have introduced more flexible production systems, adopted team management practices, or reduced the layers of management in the organization.  More generally, at the root of both the rise in the demand for workers who embody greater human capital and the increasing application of technology is the realization by businesses that remaining competitive in today's world requires unprecedented flexibility to adapt to change.  Traditionally, broader human capital skills have been associated with higher education, and, accordingly, the demand for college-trained workers has been increasing rapidly.  The result is that, over the past 15 years, a wide gap has opened up between the earnings of college graduates and those of workers who stopped their formal schooling with a high-school diploma or less.  But the dispersion of pay outcomes has also increased within groups of workers with the same levels of education, which suggests that broader cognitive skills and conceptual abilities have become increasingly important on a wide scale, and that basic credentials, by themselves, are not enough to ensure success in the workplace.  Clearly our educational institutions will continue to play an important role in preparing workers to meet these demands.  And, responding to the strong signals that the returns to formal education have been rising, the supply of college-trained labor has been increasing.  School enrollment rates among traditional college-age young people, which were little changed in the 1970s, have moved up sharply since then.  At the same time, enrollment rates have picked up noticeably among individuals aged 25 and over.  Presumably, many of these older students are striving to keep pace with the new demands evolving in the job market.  Indeed, an important aspect of the changing nature of jobs appears to be that an increasing number of workers are facing the likelihood that they will need retooling during their careers.  The notion that formal degree programs at any level can be crafted to fully support the requirements of one's lifework is being challenged.  As a result, education is increasingly becoming a lifelong activity; businesses are now looking for employees who are prepared to continue learning, and workers and managers in many kinds of pursuits have begun to recognize that maintaining their human capital will require persistent hard work and flexibility.  Economists have long argued that more than half of the market human capital produced in a worker's lifetime is produced on the job.4  Several decades ago, much of that on-the-job training was acquired through work experience; today we are seeing greater emphasis on the value of formal education and training programs for workers.  Developing human capital is perceived by many corporations as adding to shareholder value.  If idea creation is increasingly the factor that engenders value-added, then training and education are crucial to the growth of company value-added and profitability.  In the private sector, a number of major corporations have invested in their own internal training centers so-called corporate universities.  Some labor unions have done the same.  More broadly, recent surveys by the Bureau of Labor Statistics and by the Department of Education indicate that the provision of education on the job has risen markedly in recent years.  In 1995, the BLS report showed that 70 percent of workers in establishments with 50 or more employees received some formal training during the twelve months preceding the survey.  Most often this training was conducted in house by company personnel, but larger firms also relied to a great extent on educational institutions.  The information collected by the Department of Education indicated that the percentage of employed individuals who took courses specifically to improve their current job skills rose between 1991 and 1995; by 1995, four of every ten full-time workers aged 35 to 54 had sought to upgrade their skills.  The survey shows that growing proportions of workers with a high-school education or less and of those in production and craft jobs sought additional training; however, college graduates and those in professional occupations still reported the highest incidence of additional coursework almost 50 percent.  Thus, learning does seem to beget perhaps both a capacity as well as a desire for more learning.  This finding should underscore the need to begin the learning process as early as possible.  In the long run, better child-rearing and better basic education at the elementary and secondary school levels are essential to providing the foundation for a lifetime of learning.  At the same time, we must be alert to the need to improve the skills and earning power of those who appear to be falling behind.  We must also develop strategies to overcome the education deficiencies of all too many of our young people and to renew the skills of workers who have not kept up with the changing demands of the workplace.  The recognition that more productive workers and learning go hand-in-hand is becoming ever more visible in schools and in the workplace.  Expanded linkages between business and education should be encouraged at all levels of our education system.  Building bridges between our educational institutions and the private business sector should have payoffs in how well graduates are prepared to meet the challenges of an increasingly knowledge-based global economy.  Indeed, a recent study argues that we need not rely on colleges and universities to teach \"the new basic skills\" to prepare workers for jobs in a knowledge-based economy; that foundation could be built in high schools if only more high schools were to ensure that graduates left with not only essential basic reading and computational skills, but also with training in how to solve semi-structured problems, how to make oral presentations, and how to work in diverse groups.5  Those researchers argue for a better connection between secondary school curricula and business needs \"vocational education\" in a very broad sense rather than the traditional narrow one.  While many debate how to make our elementary and secondary schools more effective in preparing students particularly compared with those in other developed countries there is little question about the quality of our university system, which for decades has attracted growing numbers of students from abroad.  The payoff to advanced training remains high, and even with higher rates of enrollment, the supply of college-trained labor does not appear likely to outstrip the growing demands of a rapidly changing economy.  The linkages between the private sector and our colleges and universities have a long tradition, and many schools are endeavoring to extend those connections.  Your university's plans for the Connecticut Information Technology Institute embodies this reality.  You and your partners in the business community clearly appreciate the mutual benefits that will accrue as technologically advanced learning is grounded in real-world curricula beginning with students and continuing for workers seeking to renew their skills.   The advent of the twenty-first century will certainly bring new challenges and new possibilities for our businesses, our workers, and our educational system.  We cannot know the precise directions in which technological change will take us.  As in the past, our economic institutions and our workforce will strive to adjust, but we must recognize that adjustment is not automatic.  All shifts in the structure of the economy naturally create frictions and human stress, at least temporarily.  However, if we are able to boost our investment in people, ideas, and processes as well as in machines, the economy can readily adapt to change, and support ever-rising standards of living. Return to top Footnotes 1 Frederic L. Pryor and David Schaffer, \"Wages and the University Educated: A Paradox Resolved,\" Monthly Labor Review (July 1997), pp. 3-14.        2 Peter Cappelli, \"Are Skilling Requirements Rising?  Evidence from Production and Clerical Jobs,\" Industrial and Labor Relations Review (April 1993), pp. 515-530; and \"Technology and Skill Requirements: Implications for Establishment Wage Structures,\" New England Economic Review, Special Issue on Earnings and Inequality (May/June, 1996), pp. 139-154.        3 David H. Autor, Lawrence F. Katz, and Alan B. Krueger, \"Computing Inequality: Have Computers Changed the Labor Market,\" National Bureau of Economic Research Working Paper 5956 (March 1997).        4 Jacob Mincer, \"On the Job Training: Costs, Returns, and Some Implications,\" Journal of Political Economy, vol. 70, Supplement (October 1962), pp. 50-79; and James Heckman, Lance Lochner, and Christopher Taber, \"Estimating and Evaluating Human Capital Policies in a General Equilibrium Environment\" (Working Paper, University of Chicago, 1997).",
                  "1997-10-14 00:00:00"
                ],
                [
                  "30",
                  "Chairman Alan Greenspan",
                  "Globalization of Finance  As a result of very rapid increases in telecommunications and computer-based technologies and products, a dramatic expansion in cross-border financial flows and within countries has emerged.  The pace has become truly remarkable.  These technology-based developments have so expanded the breadth and depth of markets that governments, even reluctant ones, increasingly have felt they have had little alternative but to deregulate and free up internal credit and financial markets.  In recent years global economic integration has accelerated on a multitude of fronts.  While trade liberalization, which has been ongoing for a longer period, has continued, more dramatic changes have occurred in the financial sphere.  World financial markets undoubtedly are far more efficient today than ever before.  Changes in communications and information technology, and the new instruments and risk- management techniques they have made possible, enable an ever wider range of financial and nonfinancial firms today to manage their financial risks more effectively.  As a consequence, they can now concentrate on managing the economic risks associated with their primary businesses.  The solid profitability of new financial products in the face of their huge proliferation attests to the increasing effectiveness of financial markets in facilitating the flow of trade and direct investment, which are so patently contributing to ever higher standards of living around the world.  Complex financial instruments derivative instruments, in one form or another are being developed to take advantage of the gains in communications and information technology.  Such instruments would not have flourished as they have without the technological advances of the past several decades.  They could not be priced properly, the markets they involve could not be arbitraged properly, and the risks they give rise to could not be managed at all, to say nothing of properly, without high-powered data processing and communications capabilities.    Still, for central bankers with responsibilities for financial market stability, the new technologies and new instruments have presented new challenges.  Some argue that market dynamics have been altered in ways that increase the likelihood of significant market disruptions.  Whatever the merits of this argument, there is a clear sense that the new technologies, and the financial instruments and techniques they have made possible, have strengthened interdependencies between markets and market participants, both within and across national boundaries.  As a result, a disturbance in one market segment or one country is likely to be transmitted far more rapidly throughout the world economy than was evident in previous eras.    In earlier generations information moved slowly, constrained by the primitive state of communications.  Financial crises in the early nineteenth century, for example, particularly those associated with the Napoleonic Wars, were often related to military and other events in faraway places.  An investor's speculative position could be wiped out by a military setback, and he might not even know about it for days or even weeks, which, from the perspective of central banking today, might be considered bliss.  As the nineteenth century unfolded, communications speeded up.  By the turn of the century events moved more rapidly, but their speed was at most a crawl by the standard of today's financial markets.  The environment now facing the world's central banks and, of course, private participants in financial markets as well is characterized by instant communication.    This morning I should like to take a few minutes to trace the roots of this extraordinary expansion of global finance, endeavor to assess its benefits and risks, and suggest some avenues that can usefully be explored in order to contain some of its potentially adverse consequences.  A global financial system, of course, is not an end in itself.  It is the institutional structure that has been developed over the centuries to facilitate the production of goods and services.  Accordingly, we can better understand the evolution of today's burgeoning global financial markets by parsing the extraordinary changes that have emerged, in the past century or more, in what we conventionally call the real side of economies: the production of goods and services.  The same technological forces currently driving finance were first evident in the production process and have had a profound effect on what we produce, how we produce it, and how it is financed.  Technological change or, more generally, ideas have significantly altered the nature of output so that it has become increasingly conceptual and less physical.  A much smaller proportion of the measured real gross domestic product constitutes physical bulk today than in past generations.  The increasing substitution of concepts for physical effort in the creation of economic value also has affected how we produce that economic output; computer-assisted design systems, machine tools, and inventory control systems provide examples.  Offices are now routinely outfitted with high-speed information-processing technology.  Because the accretion of knowledge is, with rare exceptions, irreversible, this trend almost surely will continue into the twenty-first century and beyond.  Value creation at the turn of the twenty-first century will surely involve the transmission of information and ideas, generally over complex telecommunication networks.  This will create considerably greater flexibility of where services are produced and where employees do their work.  The transmission of ideas, or more broadly information, places it where it can be employed in maximum value creation.  A century earlier, transportation of goods to their most value creating locations served the same purpose for an economy whose value creation still rested heavily on physical, bulky output.    Not unexpectedly, as goods and services have moved across borders, the necessity to finance them has increased dramatically.  But what is particularly startling is how large the expansion in cross-border finance has become, relative to the trade it finances.  To be sure, much cross-border finance supports investment portfolios, doubtless some largely speculative.  But at bottom, even they are part of the support systems for efficient international movement of goods and services.  The rapid expansion in cross-border banking and finance should not be surprising given the extent to which low-cost information processing and communications technology have improved the ability of customers in one part of the world to avail themselves of borrowing, depositing, or risk-management opportunities offered anywhere in the world on a real-time basis.  These developments enhance the process whereby an excess of saving over investment in one country finds an appropriate outlet in another.  In short, they facilitate the drive to equate risk-adjusted rates of return on investments worldwide.  They thereby improve the worldwide allocation of scarce capital and, in the process, engender a huge increase in risk dispersion and hedging opportunities.    But there is still evidence of less than full arbitrage of risk adjusted rates of return on a worldwide basis.  This suggests the potential for a far larger world financial system than currently exists.  If we can resist protectionist pressures in our societies in the financial arena as well as in the interchange of goods and services, we can look forward to the benefits of the international division of labor on a much larger scale in the twenty-first century.  What we don't know for sure, but strongly suspect, is that the accelerating expansion of global finance may be indispensable to the continued rapid growth in world trade in goods and services.  It is becoming increasingly evident that many layers of financial intermediation will be required if we are to capture the full benefits of our advances in finance.  Certainly, the emergence of a highly liquid foreign exchange market has facilitated basic forex transactions, and the availability of more complex hedging strategies enables producers and investors to achieve their desired risk positions.  This owes largely to the ability of modern financial products to unbundle complex risks in ways that enable each counterparty to choose the combination of risks necessary to advance its business strategy, and to eschew those that do not.  This process enhances cross-border trade in goods and services, facilitates cross-border portfolio investment strategies, enhances the lower-cost financing of real capital formation on a worldwide basis, and, hence, leads to an expansion of international trade and rising standards of living.    But achieving those benefits surely will require the maintenance of a stable macroeconomic environment.  An environment conducive to stable product prices and to maintaining sustainable economic growth has become a prime responsibility of governments and, of course, central banks.  It was not always thus.  In the last comparable period of open international trade a century ago the gold standard prevailed.  The roles of central banks, where they existed (remember the United States did not have one), were then quite different from today.   International stabilization was implemented by more or less automatic gold flows from those financial markets where conditions were lax, to those where liquidity was in short supply.  To some, myself included, the system appears to have worked rather well.  To others, the gold standard was perceived as too rigid or unstable, and in any event the inability to finance discretionary policy, both monetary and fiscal, led first to a further compromise of the gold standard system after World War I, and by the 1930s it had been essentially abandoned.  The fiat money systems that emerged have given considerable power and responsibility to central banks to manage the sovereign credit of nations.  Under a gold standard, money creation was at the limit tied to changes in gold reserves.  The discretionary range of monetary policy was relatively narrow.  Today's central banks have the capability of creating or destroying unlimited supplies of money and credit.  Clearly, how well we take our responsibilities in this modern world has profound implications for participants in financial markets.  We provide the backdrop against which individual market participants make their decisions.  As a consequence, it is incumbent upon us to endeavor to produce the same noninflationary environment as existed a century ago, if we seek maximum sustainable growth.  In this regard, doubtless, the most important development that has occurred in recent years has been the shift from an environment of inflationary expectations built into both business planning and financial contracts toward an environment of lower inflation.  It is important that that progress continue and that we maintain a credible long-run commitment to price stability.    While there can be little doubt that the extraordinary changes in global finance on balance have been beneficial in facilitating significant improvements in economic structures and living standards throughout the world, they also have the potential for some negative consequences.  In fact, while the speed of transmission of positive economic events has been an important plus for the world economy in recent years, it is becoming increasingly obvious, as evidenced by recent events in Thailand and its neighbors and several years ago in Mexico, that significant macroeconomic policy mistakes also reverberate around the world at a prodigious pace.  In any event, technological progress is not reversible.  We must learn to live with it.  In the context of rapid changes affecting financial markets, disruptions are inevitable.   The turmoil in the European Exchange Rate mechanism in 1992, the plunge in the exchange value of the Mexican peso at the end of 1994 and early 1995, and the recent sharp exchange rate adjustments in a number of Asian economies have shown how the new world of financial trading can punish policy misalignments, actual or perceived, with amazing alacrity.  This is new.  Even as recently as fifteen or twenty years ago, the size of the international financial system was a fraction of what it is today.  Contagion effects were more limited, and, thus, breakdowns carried fewer negative consequences.  In both new and old environments, the economic consequences of disruptions are minimized if they are not further compounded by financial instability associated with underlying inflation trends.    The recent financial turmoil in some Asian financial markets, and similar events elsewhere previously, confirm that in a world of increasing capital mobility there is a premium on governments maintaining sound macroeconomic policies and allowing exchange rates to provide appropriate signals for the broader pricing structure of the economy.  These countries became vulnerable as markets became increasingly aware of a buildup of excesses, including overvalued exchange rates, bulging current account deficits, and sharp increases in asset values.  In many cases, these were the  consequence of poor investment judgments in seeking to employ huge increases in portfolios for investment.  In some cases, these excesses were fed by unsound real estate and other lending activity by various financial institutions in these countries, which, in turn, undermined the soundness of these countries' financial systems.  As a consequence, these countries lost the confidence of both domestic and international investors, with resulting disturbances in their financial markets.   The resort to capital controls to deal with financial market disturbances of the sort a number of emerging economies have experienced would be a step backwards from the trend toward financial market liberalization, and in the end would not be effective.  The maintenance of financial stability in an environment of global capital markets, therefore, calls for greater attention by governments to the soundness of public policy.    Governments are beginning to recognize that the release of timely and accurate economic and financial data is a critical element to the maintenance of financial stability.  We do not know what the appropriate amount of disclosure is, but it is pretty clear from the Mexican experience in 1994 and the recent Thai experience that the level of disclosure was too little.  More comprehensive public information on the financial condition of a country, including current data on commitments by governments to buy or sell currencies in the future and on nonperforming loans of a country's financial institutions, would allow investors both domestic and international to make more rational investment decisions.  Such disclosure would help to avoid sudden and sharp reversals in the investment positions of investors once they become aware of the true status of a country's and a banking system's financial health.  More timely and more comprehensive disclosure of financial data also would help sensitize the principal economic policymakers of a country to the potential emerging threats to its financial stability.  Thus, as international financial markets continue to expand, central banks have twin objectives: achieving macroeconomic stability and a safe and sound financial system that can take advantage of stability while exploiting the inevitable new technological advances.  The changing dynamics of modern global financial systems also require that central banks address the inevitable increase of systemic risk.  It is probably fair to say that the very efficiency of global financial markets, engendered by the rapid proliferation of financial products, also has the capability of transmitting mistakes at a far faster pace throughout the financial system in ways that were unknown a generation ago, and not even remotely imagined in the nineteenth century.  Today's technology enables single individuals to initiate massive transactions with very rapid execution.  Clearly, not only has the productivity of global finance increased markedly, but so, obviously, has the ability to generate losses at a previously inconceivable rate.    Moreover, increasing global financial efficiency, by creating the mechanisms for mistakes to ricochet throughout the global financial system, has patently increased the potential for systemic risk.  Why not then, one might ask, bar or contain the expansion of global finance by capital controls, transaction taxes, or other market inhibiting initiatives?  Why not return to the less hectic and seemingly less threatening markets of, say, the 1950s?  Endeavoring to thwart technological advance and new knowledge and innovation through the erection of barriers to the spread of knowledge would, as history amply demonstrates, have large, often adverse, unintended consequences.  Suppressed markets in one location would be rapidly displaced by others outside the reach of government controls and taxes.  Of greater importance, risk taking, so indispensable to the creation of wealth, would undoubtedly be curbed, to the detriment of rising living standards.  We cannot turn back the clock on technology and we should not try to do so.  Rather, we should recognize that, if it is technology that has imparted the current stress to markets, technology can be employed to contain it.  Enhancements to financial institutions' internal risk-management systems arguably constitute the most effective countermeasure to the increased potential instability of the global financial system.  Improving the efficiency of the world's payment systems is clearly another.  The availability of new technology and new derivative financial instruments clearly has facilitated new, more rigorous approaches to the conceptualization, measurement, and management of risk for such systems.  There are, however, limitations to the statistical models used in such systems owing to the necessity of overly simplifying assumptions.  Hence, human judgments, based on analytically looser but far more realistic evaluations of what the future may hold, are of critical importance in risk management.  Although a sophisticated understanding of statistical modeling techniques is important to risk management, an intimate knowledge of the markets in which an institution trades and of the customers it serves is turning out to be far more important.",
                  "1997-10-14 00:00:00"
                ],
                [
                  "31",
                  "Chairman Alan Greenspan",
                  "Consumer Credit and Financial Modernization  I am pleased to be able to share some thoughts with you on the conference's topic of economic justice in the context of our changing financial system.  My meetings with Greenlining over the years have been most informative, covering a wide range of topics regarding how our markets function and the appropriate forms of banking regulation.  Although issues related to the CRA and fair lending often have been the focal point of our discussions, today I would like to extend the dialogue by looking at consumer credit availability from a somewhat broader perspective.  With respect to credit availability, I believe there is general convergence of viewpoints on one critical matter.  That is   that all of our citizens should be treated equitably in our credit markets and have access to credit regardless of their race, sex, ethnic origin, or the location or make-up of neighborhoods in which they live.  This view responds not only to a sense of fair play but also to the necessities of the financial marketplace.  At least one area of continuing concern is whether some groups of our citizenry, especially low- and moderate-income families, do have fair access.  In exploring that issue, perspective is quite important, so I want to put this issue into a broader historical context.  The roots of our present financial system and the evolution of financial innovation in America, especially throughout the 20th century, provide valuable perspectives and lessons related to many of the issues we now face.  So in exploring the notion of credit availability and its relationship to today's changing banking structure and regulation, I believe it is useful to step back for a moment and review a little history. The Early Consumer Credit Marketplace Our nation's experience with consumer credit is long, but at least in its earliest periods, not always illustrious.  From colonial times through the early 20th century, access to credit for most people was quite limited, and where available at all, quite expensive.  Purchase of durable goods, clothes, and even property for working-class people was done mostly on a cash or barter basis.  Only the economic elite were able to obtain personal loans from commercial banks, and then only on an accommodation basis because they were prominent merchants or landowners.  Commercial banks did not make consumer loans to the general public.  To the extent that any type of installment credit was used by ordinary consumers its primary sources were local pawnbrokers or unlicensed lenders who even then were called loan sharks.  Other than short-term credit provided by neighbors or shopkeepers, only pawnbroking and lending on the security of personal possessions such as furniture, clothes, jewelry and other personal items were the sources of credit for most consumers.  Generally, the only credit extended to working-class consumers carried very high rates, commonly reaching 120 per cent and often as high as 240 per cent per year, and collection practices were often harsh.    Attempts to regulate these lenders by some states in the mid- to late 19th century largely failed, primarily because most regulation was based on usury laws that limited interest rates to levels that were uncompetitive, making profitable consumer lending difficult for more legitimate, licensed lenders.  Consequently, unlicensed, illegal, high-rate lenders continued operation in response to the persistent demands of the marketplace of the day.  One study estimated that in American cities with populations of over 25,000, about one family in five was the victim of loan sharks.  Subject to wage assignments to these lenders for these burdensome payments, many lower-income wage earners were reduced to virtual serfdom. Market Demand and Structural Change Alternatives did, however, begin to surface.  More intense industrialization and urbanization during the late 19th and early 20th centuries dramatically changed the market for small consumer loans.  Urban wage-earners needed loans not only to help smooth out bumps in the their economic fortunes, but also to help them purchase the vast new array of durable goods being produced by the new industrial economy.  Automobiles, washing machines, refrigerators, and other items carried costs that made lump-sum cash purchases difficult for working families.  It was this growth in demand that fostered increased competition for less risky and hence, more profitable consumer loans, and, most importantly, the development of new intermediaries to supply it.   Beginning around 1910, new organizations that focused exclusively on the needs of consumers entered the field and the structure of consumer finance began to change dramatically.  Semi-philanthropic groups, called remedial loan societies, were formed to combat the high-rate lenders.  But incomes were low and losses were high.  Hence, remedial groups, by limiting their dividends and underwriting their risks carefully, were able to make loans at average rates as low as 30 percent per year.  Soon followed  \"Morris Plan\" banks, which made loans based on savings plans by borrowers, and the first credit unions, tied exclusively to consumers with a common place of employment.   By the 1930s, a wide array of consumer lenders, including credit unions, small local savings banks and a nationwide network of consumer finance companies were licensed by the states.  Savings and loans were created, in large part, because commercial banks and other local lenders would not make home mortgage loans, which they perceived as too risky.  Hundreds of sales finance companies were formed to help manufacturers and retailers of automobiles and durable goods provide credit to their customers.  Although commercial banks remained largely on the sidelines, sticking to financing merchants, manufacturers and farmers, they were forced by the collapse of their primary businesses during the Depression to turn more seriously to consumer lending.   Market Innovations As these structural changes continued to evolve, market demand and growing competition among this wider variety of lenders also spawned considerable financial innovation.  One such innovation had its roots as early as 1900, when some hotels began experimenting with an innovative way to help their regular customers.  It was called a credit card, and by 1914 gasoline companies and large retail department stores were also issuing credit cards to their most valued patrons.  These first cards had to be paid in full monthly and were simply a  convenient way for good customers to \"run a tab\" with a particular retail business concern.  Later versions, spearheaded by retail giants Sears Roebuck and Montgomery Ward, added the innovative option allowing customers to pay their bills in installments, with interest charged on unpaid outstanding balances.  This shift to revolving credit, and another innovation allowing one card to be used at multiple businesses, later induced increasing competition in the card industry and entry of commercial banks into the credit card business in the 1950s.   Though commercial loans secured by real estate have been made by all types of lenders since colonial times, home mortgage loans, at least as we know them today, are a fairly recent innovation.  Most home purchase mortgage loans were made only to persons of significant means, and they typically carried very short terms of one to five years, with interest-only payments, and large balloon payments at the end.  Loan-to-value ratios were typically quite low, owing to the vicissitudes of the market.   By the 1920s it was also not unusual for home buyers to need several mortgage loans to finance a home purchase, since the first mortgage typically financed only half of the value.   Obviously, this was not a financing scheme conducive to creation of a broad home purchase market for average consumers.    Because this system utterly collapsed during the Great Depression, the housing finance system underwent radical change.  One of the most significant changes was creation of the Federal Housing Administration, or FHA, which instituted an innovative type of mortgage loan   the long-term, fixed-rate, self-amortizing mortgage   that became a model for transformation of conventional home mortgage lending.  A whole industry, thrift institutions, grew up around this one product innovation.  But development of a broad-based secondary market for mortgage loans was an equally important innovation that greatly expanded consumer access to credit.  By  reducing the risk of making long-term, fixed-rate loans and ensuring liquidity for mortgage lenders, the secondary market helped stimulate widespread competition in the mortgage business.  Competition spawned diversification of the mortgage lending industry and helped create specialized mortgage banking companies and specialists in originating, funding, or in servicing mortgage loans.  Further efficiencies were created when the secondary market agencies began experiments in the securitization of mortgages.  The mortgage-backed security helped create a national and even international market for mortgages, and market support for a wider variety of home mortgage loan products, such as home equity loans, second mortgages, adjustable-rate mortgages, and reverse mortgages, became commonplace.   This led to securitization of a variety of other consumer loan products, such as auto and credit card loans. Effects of the Consumer Finance \"Evolution\" This has been a brief overview of just a few of the more salient changes in our consumer finance system.  I recount them, however, because I believe it is instructive in several ways.  First, the present market for consumer credit is fiercely competitive and highly innovative, but we should be mindful that it evolved to its present form slowly but inexorably.   There were critical structural changes along the way, which included entry or expansion through new players.  From remedial loan societies to local savings banks and credit unions, from thrift institutions, to commercial banks, to a nationwide network of consumer finance companies, the organizations providing and supporting consumer credit have become increasingly diverse and include highly specialized lenders.  More recently,  innovative public-private partnership financing arrangements and new community development intermediaries, in which many of you have played direct roles, have helped low- and moderate-income families purchase and repair homes, start small businesses and repair credit problems to enable them to participate more fully in our economy.    Second, we should note that these structural changes heightened competition, resulting in market efficiencies that continued to help drive down costs.  Where early institutions specialized in only certain types of consumer credit products, such as installment loans, or in mortgage loans, virtually all institutions entered the wide variety of business lines that previously had been occupied only by specialists.  That process increased competition and created cost reductions that helped make possible the development of innumerable innovative processes, products, and services.  Most of these had the effect of vastly expanding the opportunity of ordinary Americans to enjoy the benefits of having access to consumer credit.  At least one lesson here is that we should not only welcome but encourage the continuing evolution of our financial system as it responds to changes in the marketplace.  Third, it is important to remember that most of the financial innovations I've touched on   from the self-amortizing mortgage loan, to the universal credit card with revolving credit features, to the home equity line of credit   evolved from previous forms and were primarily market driven.  They were responses to consumer demand and private efforts to collect and direct capital in a way that could meet that demand on a profitable basis.  This suggests that we should be quite cautious in enacting legislation or creating regulations that unnecessarily fetter market development.  Fourth, where government played a positive role, it was primarily an ameliorative one, to help create a fair playing field for both lenders and consumers.  Those government interventions in consumer credit relationships that were successful were those that facilitated market development by providing maximum flexibility for private initiative and innovation along with appropriate protections that supported consumer confidence.  Those that failed, such as uncompetitive usury restrictions, did so because of failure to consider and respond to the strength, and the mutability, of the marketplace.   What has been the effect of this process?  In less than 100 years, this evolving structure and chain of financial innovations have dramatically improved consumer access to credit, transforming the American economy and stimulating the flow of capital around the world.  In 1900, there were no consumer installment loans available at reasonable rates, no credit cards, no affordable home mortgage loans for working people, and certainly no home equity lines of credit.  Consumers had virtually no access to reliable, affordable forms of credit.   By 1995, the year of the most recent Federal Reserve Survey of Consumer Finances,  75 percent of all households carried some form of consumer debt, 41 percent had home mortgages or home equity lines of credit and about 48 percent had credit card debt outstanding.  As important, the distribution of debt holders by income level has been significantly  altered as the marketplace continued to provide increasing access to low- and moderate-income households.  In 1962, the Federal Reserve's initial consumer finance survey indicated that, of households in the lowest income quintile, 36 percent had outstanding consumer loans; by 1995, 50 percent of  lower-income households, those with incomes of less than $10,000, carried some form of consumer debt.  Overall, we have to conclude that at no time in American history has credit of all kinds been so available to so many.   Recent Developments But what about the future?  A variety of lenders are now regularly experimenting with new, innovative ways to assess and mitigate risk for borrowers who in the past might have been considered uncreditworthy.  This rapid pace of change is creating new mortgage products with ever-lower down-payment requirements.  Acceptable loan-to-value ratios and debt-to-income ratios continue to rise.  Some lenders are even offering loan products that will provide home-secured financing far exceeding a home's value.   The drive to stretch traditional underwriting criteria is intensifying.  Recently, there has been a boom in so-called \"subprime\" lending, offering a variety of types of mortgage and other loans to borrowers who have less than good credit; such lending is priced for risk and the favorable pricing of securities backed by subprime loans have found acceptance with investors.  Just last month, a few lenders announced plans to offer home owners with impaired credit a credit card secured by home equity, with part of the rationale being that responsible use of such credit cards could help such consumers repair their credit ratings.  And some lenders are aggressively marketing loans in the form of checks that can be cashed to activate the credit line.  Improved access to credit for consumers, and especially these more recent developments, reflects a good news/bad news story.  The good news is that market specialization, competition, and innovation have vastly expanded credit availability to virtually all income classes.  Access to credit is essential to help families purchase homes, deal with emergencies, and obtain goods and services that have become staples of our daily lives.  Home ownership is at an all-time high, and the number of home mortgage loans to low- and moderate-income families has risen at a rapid rate over the last 5 years.  Credit cards and installment loans are available to the vast majority of households.   The bad news is that under certain circumstances this may not be entirely good news, either for consumers in general or for lower-income communities.  Along with unprecedented credit access, some problems are occurring that should alert us all to potential dangers.  While every potential problem doesn't result in disaster, it's important to recognize the risks and take protective steps.  Some loans to low- and moderate-income families with multiple underwriting flexibilities, layered subsidies, and high loan-to-value ratios have been showing unfavorable delinquency and default trends.  Large mortgage lenders, secondary market agencies, and private mortgage insurers are conducting studies of their portfolios to determine how more-relaxed underwriting standards are affecting delinquencies and defaults.  Although more study is required to determine which risk factors are most important in particular lending situations, the results of these portfolio studies bear watching.     Although legitimate lenders may be able to manage the risks associated with the overall expansion of lending, the same may not be true of many consumers, especially those with limited means to weather a storm or who have been encouraged to borrow improvidently.  Should economic or personal difficulties occur, such as the temporary loss of a job, illness, or unexpected car or house repairs, those with limited incomes and without significant savings may easily find themselves in financial trouble.  Last quarter, credit card delinquencies racheted up to just short of the all-time high, and consumer bankruptcies continue at a record pace.  We also have heard first hand at the Federal Reserve about the use of \"equity stripping\" by some unscrupulous mortgage lenders who have made loans to lower-income homeowners that have no reasonable prospects of repayment.   So while we should applaud the \"democratization\" of our credit markets over the years, we must be vigilant to the risks of excess, both by lenders and by consumers.   Conclusion",
                  "1997-10-11 00:00:00"
                ],
                [
                  "32",
                  "Chairman Alan Greenspan",
                  " Good Morning.  It is always with mixed feelings of pleasure and trepidation that I accept an invitation to speak at the American Bankers Association annual convention.  I still have a disconcerted remembrance of my acceptance of your first invitation, which had been scheduled for October 20, 1987.  That speech had to be scratched at the last minute as the result of a certain adversity in stock price adjustments the day before.  Experience suggests, however, that history does not repeat with a fixed periodicity and, besides, I have crossed my fingers.  The theme of your convention this year is timely.  It is exactly when rapid innovation and institutional and technological change are taking place that market participants should take time to contemplate the opportunities and the risks, what to retain and what to change.  Only then can the banking industry create the most value-added for customers, employees, and society, and as a consequence, for shareholders.  As in recent years, the future role of banks and other providers of financial services will surely be significantly affected by the same basic forces that have shaped the real and financial economy world-wide:  relentless technological change.  This morning, I would like to describe some of the effects of technological change in both the financial and nonfinancial sectors and discuss a few of their more important implications.  I will begin with the real economy. Technological Change and the Real Economy The most important single characteristic of the changes in U.S. technology in recent years is the ever expanding conceptualization of our Gross Domestic Product. We are witnessing the substitution of ideas for physical matter in the creation of economic value a shift from hardware to software, as it were.  The roots of increasing conceptualization of output lie deep in human history, but the pace of such substitution probably picked up in the early stages of the industrial revolution, when science and machines created new leverage for human energy and ideas.  Nonetheless, even as recently as the middle of this century, the symbols of American economic strength were our outputs of such physical products as steel, motor vehicles, and heavy machinery items for which sizable proportions of production costs reflected the exploitation of raw materials and the sheer manual labor required to manipulate them.  However, today's views of economic leadership focus increasingly on downsized, smaller, less palpable evidence of weight and bulk, requiring more technologically sophisticated labor input.  Examples of this trend permeate our daily lives.  Radios used to be activated by large vacuum tubes; today we have elegantly designed pocked-sized transistors to perform the same function but with the higher quality of sound and greater reliability that consumers now expect.  Thin fiber optic cable has replaced huge tonnages of copper wire. Owing to advances in metallurgy, engineering, and architectural design, we now can construct buildings that enclose as much or more space with fewer materials.  A number of commentators, particularly Professor Paul David of Stanford University, have suggested that, despite the benefits we have seen this decade, it may be that the truly significant increases in living standards resulting from the introduction of computers and communications equipment still lie ahead.  If true, this would not be unusual.  Past innovations, such as the introduction of the dynamo or the invention of the gasoline-powered motor, required considerable infrastructure investment before their full potential could be realized.  Electricity, when it substituted for steam power late last century, was initially applied to production processes suited to steam.  Gravity was used to move goods vertically in the steam environment, and that could not immediately change with the advent of electric power.  It was only when horizontal factories, newly designed for optimal use of electric power, began to dominate our industrial system many years after electricity's initial introduction, that national productivity clearly accelerated.  Similarly, it was only when modern highways and gasoline service stations became extensive that the lower cost of motor vehicle transportation became evident. Technological Change and the Financial Economy It is surely not news to a group of bankers that the same forces that have been reshaping the real economy have also been transforming the financial services industry.  Once again, perhaps the most profound development has been the rapid growth of computer and telecommunications technology.  The advent of such technology has lowered the costs, reduced the risks, and broadened the scope of financial services, making it increasingly possible for borrowers and lenders to transact directly, and for a wide variety of financial products to be tailored for very specific purposes.  As a result, competitive pressures in the financial services industry are probably greater than ever before.  As is true in the real economy, it is difficult to overestimate the importance of education and ongoing training to the advancement of technology and product innovation in the financial sector.  I doubt that I need to tell any of you about the importance of education and training for employees.  But the same is almost surely true for your customers.  Surveys repeatedly indicate that users of electronic banking products are typically very well educated.  For example, data from the Federal Reserve Board's Survey of Consumer Finances suggest that a higher level of education significantly increases the chances that a household consumer will use an electronic banking product.  Indeed, this survey indicates that, in late 1995, the median user of an electronic source of information for savings or borrowing decisions had a college degree a level of education currently achieved by less than one-third of American households.   Technological innovation and more sophisticated users have accelerated the second major trend financial globalization which has been reshaping our financial system, not to mention the real economy, for at least three decades.  Both developments have expanded cross-border asset holding, trading, and credit flows and, in response, both securities firms and U.S. and foreign banks have increased their cross-border operations.  Once again, a critical result has been greatly increased competition both at home and abroad.  A third development reshaping financial markets deregulation has been as much a reaction to technological change and globalization as an independent factor.  Moreover, the continuing evolution of markets suggests that it will be literally impossible to maintain some of the remaining rules and regulations established for previous economic environments.  While the ultimate public policy goals of economic growth and stability will remain unchanged, market forces will continue to make it impossible to sustain outdated restrictions, as we have recently seen with respect to interstate banking and branching.  In such an environment, I share your frustration with the pace of legislative reform and revision to statutorily mandated regulations.  Nonetheless, we should not lose sight of the remarkable degree of re-codification of law and regulation to make banking rules more consistent with market realities that has occurred in recent years.  Deposit and other interest rate ceilings have been eliminated, geographical restrictions have been virtually removed, many banking organizations can do a fairly broadly based securities underwriting and dealing business, many can do insurance sales, and those with the resources and skill are authorized to virtually match foreign bank competition abroad.  Moreover, it seems clear that there is recognition by the Congress that the basic financial framework has to be adjusted further.  The process, as you know, is not easy when the results of regulatory relief create both a new competitive landscape and new supervisory and stability challenges.  Change will, I believe, ultimately occur because the pressures unleashed by technology, globalization, and deregulation have inexorably eroded the traditional institutional differences among financial firms.  Examples abound.  Securities firms have for some time offered checking-like accounts linked to mutual funds, and their affiliates routinely extend significant credit directly to business.  On the bank side, the economics of a typical bank loan syndication do not differ essentially from the economics of a best-efforts securities underwriting.  Indeed, investment banks are themselves becoming increasingly important in the syndicated loan market.  With regard to derivatives instruments, the expertise required to manage prudently the writing of over-the-counter derivatives, a business dominated by banks, is similar to that required for using exchange-traded futures and options, instruments used extensively by both commercial and investment banks.  The writing of a put option by a bank is economically indistinguishable from the issuance of an insurance policy.  The list could go on.  It is sufficient to say that a strong case can be made that the evolution of financial technology alone has changed forever our ability to place commercial banking, investment banking, insurance underwriting, and insurance sales into neat separate boxes.  Nonetheless, not all financial institutions would prosper as, nor desire to be, financial supermarkets.  Many specialized providers of financial services are successful today and will be so in the future because of their advantages in specific areas.  Moreover, especially at commercial banks, the demand for traditional services by smaller businesses and by households is likely to continue for some time.  And the information revolution, while it has deprived banks of some of the traditional lending business with their best customers, has also benefitted banks by making it less costly for them to assess the credit and other risks of customers they previously would have shunned.  Thus, it seems most likely that banks of all types will continue to engage in a substantial amount of traditional banking, delivered, of course, by ever improving technology.  Community banks, in particular, are likely to provide loans and payments services via traditional on-balance sheet banking.  Indeed, smaller banks have repeatedly demonstrated their ability to survive and prosper in the face of major technological and structural change by providing traditional banking services to their customers.  The evidence is clear that well-managed smaller banks can and will exist side by side with larger banks, often maintaining or increasing local market share.  Technological change has facilitated this process by providing smaller banks with low cost access to new products and services.  In short, the record shows that well-managed smaller banks have nothing to fear from technology, globalization, or deregulation.  For all size entities, however, technological change is blurring not only traditional distinctions between the banking, securities, and insurance business, but is also having a profound effect on historical separations between financial and nonfinancial businesses.  Most of us are aware of software companies interested in the financial services business, but some financial firms, leveraging off their own internal skills, are also seeking to produce software for third parties.  Shipping companies' tracking software lends itself to payment services.  Manufacturers have financed their customers' purchases for a long time, but now increasingly are using the resultant financial skills to finance noncustomers.  Moreover, many nonbank financial institutions are now profitably engaged in nonfinancial activities.  Current facts and expected future trends, in short, are creating market pressures to permit the common ownership of financial and nonfinancial firms. In my judgment, it is quite likely that in future years it will be close to impossible to distinguish where one type of activity ends and another begins.  Nonetheless, it seems wise to move with caution in addressing the removal of the current legal barriers between commerce and banking, since the unrestricted association of banking and commerce would be a profound and surely irreversible structural change in the American economy.  Were we fully confident of how emerging technologies would affect the evolution of our economic and financial structure, we could presumably develop today the regulations which would foster that evolution.  But we are not, and history suggests we cannot, be confident of how our real and financial economies will evolve.  If we act too quickly, we run the risk of locking in a set of inappropriate rules that could adversely alter the development of market structures.  Our ability to foresee accurately the future implications of technologies and market developments in banking, as in other industries, has not been particularly impressive.  As Professor Nathan Rosenberg of Stanford University has pointed out, \". . . mistaken forecasts of future structure litter our financial landscape.\"  Indeed, Professor Rosenberg suggests that even after an innovation's technical feasibility has been clearly established, its ultimate effect on society is often highly unpredictable.  He notes at least two sources of this uncertainty.  First, the range of applications for a new technology may not be immediately apparent.  For instance, Alexander Graham Bell initially viewed the telephone as solely a business instrument merely an enhancement of the telegraph for use in transmitting very specific messages, such as the terms of a contract.  Indeed, he offered to sell his telephone patent to Western Union for only $100,000, but was turned down.  Similarly, Marconi initially overlooked the radio's value as a public broadcast medium, instead believing its principal application would be in the transmission of point-to-point messages, such as ship-to-ship, where communication by wire was infeasible.  A second source of technological uncertainty reflects the possibility that an innovation's full potential may be realized only after extensive improvements, or after complementary innovations in other fields of science.  According to Charles Townes, a Nobel Prize winner for his work on the laser, the attorneys for Bell Labs initially refused, in the late 1960s, to patent the laser because they believed it had no applications in the field of telecommunications.  Only in the 1980s, after extensive improvements in fiber optics technology, did the laser's importance for telecommunications become apparent.  It's not hard to find examples of such uncertainties within the financial services industry.  The evolution of the over-the-counter derivatives market over the past decade has been nothing less than spectacular.  But as the theoretical underpinnings of financial arbitrage were being published in the academic journals in the late 1950s, few observers could have predicted how the scholars' insights would eventually revolutionize global financial markets.  Not only were additional theoretical and empirical research necessary, but, in addition, several generations of advances in computer and communications technologies were necessary to make these concepts computationally practicable.  All these examples, and more, suggest that if we dramatically change the rules now about banking and commerce, with what is great uncertainty about future synergies between finance and nonfinance, we may well end up doing more harm than good.  And, as with all rule changes by government, we are likely to find it impossible to correct our errors promptly, if at all.  Modifications of such a fundamental structural rule as the separation of banking and commerce accordingly should proceed at a deliberate pace in order to test the response of markets and technological innovations to the altered rules in the years ahead.  The need for caution and humility with respect to our ability to predict the future is highly relevant for how banking supervision should evolve.  As I proposed to this audience last year, regulators are beginning to understand that the supervision of a financial institution is, of necessity, a continually evolving process reflecting the continually changing financial landscape.  Increasingly, supervisory techniques and requirements try to harness both the new technologies and market incentives to improve oversight while reducing regulatory burden, burdens that are becoming progressively obsolescent and counterproductive.  Concerns about setting a potentially inappropriate regulatory standard were an important factor in the decision by the banking agencies several years ago not to incorporate interest rate risk and asset concentration risk into the formal risk-based capital standards.  In the end, we became convinced that the technologies for measuring and managing interest rate risk and concentration risk were evolving so rapidly that any regulatory standard would quickly become outmoded or, worse, inhibit private market innovations.  Largely for these reasons, ultimately we chose to address the relationship between these risks and capital adequacy through the supervisory process rather than through the writing of regulations.",
                  "1997-10-05 00:00:00"
                ],
                [
                  "33",
                  "Governor Edward W. Kelley, Jr.",
                  "The Role of the Federal Reserve in the Payments System  It is a pleasure to be here today to discuss the Federal Reserve's role in the evolving U.S. payments system, a role which is now under careful review.  A great deal is going on in the payments industry and, of course, the Federal Reserve is squarely in the middle of the action.  You are, too, and we all need to work together to shape the future of our payments systems to ensure that they are as strong as possible.  Understanding where we have been and where we are today is an essential foundation for addressing where we wish to go in the future.  Accordingly, I will briefly review the history of the role of the Federal Reserve in the payments system, share with you in some detail our ongoing review of that role, and outline some possible directions for the future.   All individuals, businesses, and government entities in this country rely upon the smooth functioning of the payments system to purchase goods, pay for services, receive payments, and make investments.  Today, all of us can be confident that the payments we initiate will be satisfactorily completed.  Tomorrow, technology and regulatory changes will alter the face of the payments system.  Interstate banking, which spread nearly nationwide this past June, consolidation in the banking industry, legislation that mandates that most government payments be made electronically by 1999, the opportunities provided by the Internet, and other technological developments, will also contribute to the continued evolution of payment options, payment choices, and payment needs.  We, at the Federal Reserve, have been studying what our role in that evolution should be and how best to ensure that all users of payment services will continue to have confidence that their payments will be completed reliably and efficiently and that all banks will have access to payment services on a fair and equitable basis.  Before I address the Federal Reserve's future role in the payments system, I would like to review how and why the Federal Reserve came to play its current role.  In the 50 years following the Civil War, a series of severe financial crises swept the country, disrupting and undermining the national economy.  During the financial panic of 1907 cash payments were largely suspended throughout the country because many banks and clearinghouses refused to clear checks drawn on certain other banks.  Otherwise solvent banks failed.     The 1907 crisis and the lessons of failing to ensure a stable national economy were still fresh in the minds of Congress when they created the Federal Reserve System.  Thus, when Congress passed the Federal Reserve Act in 1913, it directed the Federal Reserve to provide an elastic currency that is, a supply of currency in the quantities demanded by the public and gave it the authority to establish a nationwide check collection system.  In 1917, Congress amended the Federal Reserve Act to prohibit banks from charging the Federal Reserve Banks presentment fees.    These Congressional actions launched the Federal Reserve as an active participant in the payments system.  Initially, the Reserve Banks fulfilled their role by providing check collection services and permitting member banks to issue transfer drafts to make payments anywhere in the country, which were paid in immediately available funds by any Reserve Bank.  Gradually, as needs were identified and as technologies developed, the Reserve Banks added new payments services, beginning with the Fedwire funds transfer system in 1918, the book-entry securities service in 1968, and, finally, the automated clearing house (ACH) in the early 1970s.  For much of the time, the Reserve Banks provided payment services to member banks without charge other than required reserves, and nonmember banks had access to these services only through member banks.   Everything changed in 1980, when Congress enacted the Monetary Control Act (MCA).  A primary purpose of the MCA was to promote an efficient payments system by encouraging competition between the Federal Reserve and private-sector providers of payment services.  The Act requires the Federal Reserve Banks to charge fees for their payment services, which must, over the long run, be set to recover all direct and indirect costs of providing the services.  In addition, the MCA requires the Federal Reserve Banks to recover imputed costs, such as taxes and the cost of capital, and imputed profits that would have been earned if the services were provided by a private firm.  Importantly, the MCA also extended reserve requirements to nonmember banks and granted all banks equal access to the Fed's payment services.       Congress further expanded the role of the Federal Reserve in the payments system in 1987 when it enacted the Expedited Funds Availability Act (EFAA).  For the first time, this act gave the Fed the authority to regulate check payments that were not processed by the Federal Reserve Banks.  Thus, the EFAA significantly broadened the System's ability to ensure that the nation's check collection system is efficient and accessible.  It also limited the time that a bank may hold funds before making them available to customers for withdrawal and directed the Federal Reserve to improve the process used to return unpaid checks to banks of first deposit.    Thus, Congress has directed the Federal Reserve to ensure that the payments system in this country is efficient and effective, that it supports the economic needs of its citizens, and that it is available to all banks so that they can provide for the payment needs of their customers the end users of the payments system.  To achieve these goals, Congress cast the Federal Reserve in the often difficult position of providing payment services, thereby competing with some of the institutions it regulates, and regulating the payments system in which it is an active participant.  We are very mindful of these sometimes conflicting responsibilities and take great pains to ensure that each responsibility is addressed fairly and equitably.  As service providers, the Federal Reserve Banks strive to operate in an efficient and cost effective way.  The Reserve Banks continually upgrade their computer and telecommunications systems so that increasing proportions of funds, book-entry, and ACH transactions can be processed without human intervention and, therefore, more accurately, rapidly, and cost effectively.  Striving to serve their customers, the Reserve Banks offer a variety of products to meet the differing business requirements of large, mid-sized, and small institutions with widely divergent processing capabilities.  For example, banks may obtain payment services from the Federal Reserve Banks using personal computers connected via switched, dial-in communications links or they may connect their mainframe computers to those in the Federal Reserve via dedicated high-speed telecommunications lines.  Similarly, banks typically the larger ones may select check deposit products that require little sorting by the Reserve Banks and they pay relatively low fees.  Smaller banks may deposit checks in ways that meet their relatively greater sorting needs, thereby incurring higher fees, and many banks use a mix of these products.  Importantly, because the Reserve Banks must compete for customers, they must provide services that meet or exceed the quality of other providers and must ensure that internal operations are efficient.    As a regulator, the Federal Reserve has taken steps to improve the efficiency and effectiveness of the payments system, often with the full awareness that it was moving contrary to its own narrow competitive interests as a service provider.  The Expedited Funds Availability Act of 1987, which was implemented through Regulation CC, included provisions designed to speed the processing of dishonored checks.  In developing procedures to implement those provisions, the Federal Reserve, working with the banking industry, created a means to process returned checks on high speed equipment, which shortened return times by reducing the number of banks that might handle dishonored checks.  More recently, in 1994, the Board modified Regulation CC to implement the same-day settlement rule, which broadened banks' ability to present checks to collecting banks directly and receive same-day funds in settlement.  Direct presentments reduced the role of intermediaries, including the Reserve Banks, but it improved the efficiency of the payments system.  As expected, the volume of checks collected through Reserve Banks has declined.    This summarizes the history of our involvement in payments to date, and the situation on the surface looks quite stable.  Why, then, is the Federal Reserve undertaking a fundamental review of its role?  There are several reasons.  First, as I have noted, the banking industry is in the midst of significant change.  These changes are primarily evolutionary   driven by advances in technology, by industry consolidation, and by regulations that now permit interstate branch banking.  They do, however, provide the opportunity for revolutionary responses that may, with time, dramatically alter the face of the payments system.  We need to understand and help to beneficially shape these forces.   Second, from time to time, and certainly in a period of change such as this one, it is appropriate for any organization to reassess its mission and how it fulfills that mission.  As you know, the United States remains far more dependent on paper checks for making payments than any other industrialized country, even though electronic transactions appear to be more efficient and less costly.  As you also know, the Federal Reserve is the only institution that presents checks to all depository institutions nationwide.  We suspect that industry consolidation and electronic technology may change the impact of our nationwide reach, but exactly how and when that might happen, and what would be appropriate responses, are not clear.  Careful self-scrutiny is clearly timely.  Finally, there are significant differences of opinion in the industry, and our society more generally, as to the appropriate payments role of the Federal Reserve.  As a public service entity, the Federal Reserve should address these concerns.  In light of all this, in October 1996, Chairman Greenspan asked me to serve on a committee that is led by Vice Chair Rivlin to examine the Federal Reserve's role in the payments system.  The committee has been at work all year, and we expect to complete our task shortly.  Let me now outline what we have done, how we have gone about it, and where it is leading us.  To begin the study, the committee reviewed the general environment in which payments services are offered.  The committee analyzed the economic factors influencing the supply of and demand for wholesale services that is, for the large-value and securities transfers that support the interbank market and retail services, primarily small dollar payments.  We studied current trends in the financial services industry, including the development of new and emerging payment services, and our role in those markets.  And, we examined how the Federal Reserve's participation in the  payments system affects our ability to implement monetary policy decisions and to regulate and supervise banks.  Based on its internal review, the committee decided to focus its study on the Federal Reserve Banks' retail payment services check and ACH.  The committee excluded the wholesale systems because (1) these systems are efficient and effective now, (2) they are an important vehicle for controlling systemic risk, requiring very close monitoring, (3) they are an integral part in implementing monetary policy decisions, (4) they play an important role in providing every day liquidity to financial markets, and (5) they provide certainty to payments system participants in times of financial stress.  It is worth noting that most central banks in major economies, like the Federal Reserve, provide large-value funds transfer services to banks and many also provide some form of securities settlement and safekeeping services.  This is not to imply that we are complacently satisfied with all aspects of our country's wholesale payment arrangements, but rather that we do not feel that a review of the Federal Reserve's role in them is needed at this time.   The committee felt that it was critically important to this study that we draw on the insights and expertise of the banking industry and other payments system participants.  We wanted to understand fully the dynamics of the payments system and the changes that the industry envisions over the next five to ten years, as well as the reasoning behind the varying views about the Federal Reserve's payments activities.  Thus, the committee developed a series of hypothetical scenarios for Federal Reserve participation in the retail payments system that we discussed with industry representatives in a series of forums that were conducted last May and June. Some of you may have attended one of those forums.    In total, we held ten national and fifty-two regional forums.  Attendees represented a diverse group of payments system participants, including representatives from large and small banks, private payments system providers, corporations, trade associations, academicians, consultants, and emerging payments system service providers.  In total, over 500 representatives from 473 organizations participated.   To obtain the thoughts of these payments system participants, the Committee developed five hypothetical scenarios for the Federal Reserve's future role in the check and ACH payment services.  These scenarios were not developed specifically as policy options but rather were intended solely to stimulate discussion.  Because many of you are familiar with these scenarios, I will review them only briefly.  In two scenarios the Federal Reserve would withdraw from participation in the check and ACH markets and in the remaining three scenarios, the Federal Reserve would continue to provide those services.  In the first withdrawal scenario, the Federal Reserve would announce its intention to liquidate its check and ACH services, although we would take steps to provide for a smooth transition for our customers.  In the second, the Federal Reserve envisioned selling its check and ACH services to a private-sector entity that would retain no privileged ties to the Federal Reserve.   The three scenarios under which the Federal Reserve would continue to provide retail payment services to banks varied considerably.  These scenarios envisioned future roles in which the Federal Reserve would (1) merely ensure that all banks had access to our existing check and ACH services, which many saw as a de facto exit strategy, (2) use our operational presence to stimulate development of more cost-effective and efficient payment methods, or (3) take aggressive steps to expedite the movement to an electronic-based retail payments system.   To stimulate discussion about each scenario and its effect on the provision of retail payments, several key questions were introduced.  For example, we asked  what would happen to the prices and availability of retail payments in times of relative economic stability and in times of financial stress, such as in the Texas banking crisis.  Another question asked was what participants thought would be the best way to transform our largely paper-based system to a more electronic one.  What have we heard?  As you would guess, there are various perspectives on the fundamental question of the appropriate role for the Federal Reserve in the payments system.  Some believe that it is inappropriate for the Federal Reserve to provide payment services and that the private sector could provide essentially the same services at a lower cost and perhaps greater efficiency.  Many others believe that, by providing payment services, the Federal Reserve ensures that all payments system participants will be able to access competitively priced payment services.  While some believe that it is inappropriate for the Federal Reserve to regulate the industry in which it competes, others believe that by providing payment services, the Federal Reserve gains operational experience that makes it a better regulator.    More specifically, participants had differing views on various aspects of these issues and the consequences of each scenario.  Many were concerned that, if the Federal Reserve withdrew from these services, it would result in short-term service disruptions with few long-term benefits.  Many indicated that prices for retail services would rise, and smaller banks and remotely located banks were concerned that they would have difficulty obtaining check and ACH services. Concern was expressed that without an operational presence, the Federal Reserve would have to regulate the retail payments system more extensively to ensure that all banks had access to the services.     While, not unanimous, there was strong support from institutions of all sizes for continued Federal Reserve provision of retail payment services.  Some stated that because check payments would continue to dominate the U.S. payments system for the foreseeable future, the Federal Reserve should maintain its check services while consumers adapt to the use of electronic payments mechanisms.  Others indicated that by establishing a more aggressive operational presence in the check and ACH services, the Federal Reserve could undertake initiatives to promote efficiency, in general, and to encourage the use of electronics to collect checks, in particular.   Some indicated that private-sector service providers would prefer to invest in developing new markets and devising new technologies rather than in expanding their capacity to collect paper checks.  They also indicated that they face significant resource demands to address other operational issues, such as the federal government's initiative to deliver almost all payments electronically by 1999 and preparation for the year 2000.  No matter what their view about the Federal Reserve's continued presence in the retail payments market, virtually all participants believed that the Federal Reserve could play an important role in educating consumers about the benefits of electronic payments.    While the committee has not reached detailed final conclusions, it is clear that the Federal Reserve can best ensure the safety and effectiveness of the Nation's payments system by continuing to provide its existing retail payment services for check and ACH, and we will so recommend.  We agree with a recurring theme at the forums that there would likely be significant disruptions in the payments system if the Federal Reserve withdrew, with little net societal benefit.  Currently, the banking industry is trying to grapple with a variety of technological issues, an effort that is requiring a great deal of resources.  Banks are adopting the latest technological innovations to provide their customers with new and improved services and preparing to be century date change compliant.  By continuing to provide payment services, the Federal Reserve would enable banks and service providers to continue to focus on these future oriented efforts.  This would be far more productive, for example, than attempting to restructure an efficient, but dated, paper-based check collection system.   But, as yet, the Committee has not decided on its specific recommendations for Federal Reserve involvement in retail payment services.  Many issues identified and needing resolution are still \"open.\"  They include considering whether the Federal Reserve should assume a very aggressive operational and regulatory posture to convert all payments to electronics and whether we should launch an intensive public education campaign to inform consumers of the benefits of electronic transactions.  We are also considering suggestions that we establish a regulatory regime that encourages electronic payments and discourages paper, that the Federal Reserve take the lead in establishing standards for electronic payments, and that we work toward a revised legal structure more suitable to an electronic environment. ",
                  "1997-09-23 00:00:00"
                ],
                [
                  "34",
                  "Governor Susan M. Phillips",
                  " Thank you for inviting me to speak in this symposium on derivatives and risk management, sponsored by the Institute on Law and Financial Services.  These two topics have attracted wide attention among the public, market participants, and government over the past several years, and will probably continue to do so for many years.  Clearly, financial engineering and improvements in risk management have helped the financial industry offer products to their clients to better control various business risks.  At the same time, financial institutions also benefit from these innovations in that they can better manage the risks associated with increasingly complex financial instruments and the growing volume of financial transactions.  As you know, risk management is a process for identifying, measuring, reporting, and controlling risks.  While the term has been recently popularized in the financial press, the root concepts of risk management are not new to the financial industry.  Indeed, by taking risk, or acting as an intermediary in transferring risk, the financial industry fulfills a role that has been and continues to be vital for economic growth.  It is fair to say, however, that the process of risk management is becoming increasingly quantitative.  Turning to derivatives, this is also not a recent innovation.  Derivative markets, such as those for futures contracts, have existed for decades, indeed even centuries for some kinds of price risks.  The trends in financial engineering that we have been seeing in recent years are really the fruits of technological progress:  Reduced costs of product innovation and increased feasibility of applying financial theories that require intensive computational power.  Along with the technological progress that has made it possible, financial engineering has profoundly changed the structure of many leading banks.  These processes continue to reverberate throughout the industry.  Banks engineer new products to shift business risks to others that had been borne routinely in the past.  The reverse side of the coin is that market participants can assume risks through alternatives to the traditional lending and investing avenues.  For example, credit derivatives, which are in a nascent stage of development, may someday lead to banks being able to trade credit risk associated with commercial bank loans as easily as they can alter the risk profile of their bond portfolios.  Prior to these innovations, institutions could be generally compartmentalized into market segments that did not directly compete with one another.  Government regulation mirrored and reinforced this segmentation.  With financial innovation came new levels of competition, which then caused pressure for government to change the rules of play.  As a result, the legal strictures preventing banks from engaging in certain businesses are being loosened.  Banks are increasingly in direct competition with securities firms and insurance companies.  New technology and financial innovation have clearly affected the way in which many firms manage their business.  They have also put stress on many aspects of traditional legal, regulatory, and accounting frameworks. Over the past decade bank supervisors have learned some important lessons in this regard.  These lessons propel our efforts to adapt supervisory and regulatory regimes to better accommodate the changes under way in the financial services sector   to move to a new supervisory paradigm.  Today, I would like to briefly summarize some of these lessons, illustrate how they are shaping the evolution of bank supervision, and some thoughts of how they may affect international supervision, as well. Lessons Learned by Bank Supervisors  Perhaps the most basic lesson we have learned from our experience in supervising trading and derivatives activities is that the underlying risk of a financial instrument is more important than what an instrument is called.  Although two instruments that differ in name only may have entirely different treatment under existing (and outmoded) legal and regulatory frameworks, the market, credit, liquidity, operational, and reputational risks embodied in them can be identical.  To be sure, financial engineering can create derivative instruments that combine risks in complex ways.  But, upon analysis, traditional cash instruments that appear simple may have greater risk than the complex instruments that are labeled \"derivative.\"  Indeed, placing financial instruments in pigeonholes without regard to their true risks and economic functions can create disincentives for prudent risk management   often with unfortunate results.  The structured note phenomenon of 1993 and 1994 is an important example.  Many institutions shunned \"derivatives\" in favor of these seemingly low-risk securities issued by federal agencies, only to find out later that these instruments had significant price volatility from embedded options. The reaction of many was to label structured notes as derivatives as well, rather than understanding that it was the underlying risk characteristics that had been poorly managed.  In its supervisory role, the Federal Reserve is increasingly emphasizing the need for managing the risks of banking and de-emphasizing a focus on specific instruments.  For example, in 1993 we issued examiner guidance on trading and dealer activities.  This guidance covered a large spectrum of financial instruments, including derivatives.  The risk management principles under examination applied whether or not the institution used derivatives.  We addressed structured notes in similar fashion in 1995 with guidance on the risk management of bank investment and end-user activities.  More recently, the Federal Reserve issued examiner guidance on the risks relating to banks' management of secondary credit market activities, including securitization activities, the extension of various types of off-balance-sheet credit enhancements, and the use of credit derivatives.  The guidance stresses the importance of internal capital allocation schemes and risk management systems that accurately reflect the economic substance of transactions.  A second lesson that has been reinforced over the past several years is that risk must be measured and managed comprehensively.  That is, the focus should be on the dynamics of the portfolio rather than on specific instruments, which can ignore the interplay among various instruments.  Although portfolio theory is widely appreciated by bankers and regulators, putting its principles into practice in banking has not been easy.  Past banking crises have, in part, reflected a failure by some institutions to recognize and limit concentrations of risk within their portfolios.  However, technology and financial innovation are enabling banks to put theories and conceptual techniques into practice to manage the market and credit risks involved in trading, investment, and lending activities.  Most dealer banks now routinely employ value-at-risk (VaR) measures to manage the market risks of their trading portfolios and significant strides are being made in the quantitative measurement and management of credit risk.  The move to a portfolio-based approach to managing risk has influenced bank supervisory efforts in several other ways.  All three of the U.S. banking agencies now take a more risk-focused approach to supervision.  This is simply allocating more supervisory resources to a bank's activities that pose greater risk.  For example, bank examiners no longer exhaustively review all of a bank's activities.  Instead, the examination approach is now to identify and review the sources of risk within a bank's various lines of business.  The need to measure risk on a portfolio basis has also begun to be reflected more explicitly in our capital guidelines and our reporting requirements.  Beginning next year, internationally active banks meeting certain criteria for risk management will calculate the amount of capital necessary to support the market risk of their trading activities using their own internal VaR measures.  This approach allows banks to make use of empirical correlations among risk factors when computing the VaR.  A third lesson that our experience with derivatives and other financial innovations has driven home is the critical importance of firms' internal processes for controlling risk.  This, of course, is the most obvious lesson from several spectacular losses that the press has put under the rubric of \"derivatives debacles.\"  Supervisors, both here and abroad, are focusing more on reviewing the adequacy of internal controls and management processes, such as enforced risk limits.  These are the key to gaining maximum benefit from financial innovation, while at the same time avoiding missteps.  The final lesson that I will highlight is the need for supervisory and regulatory polices that are more \"incentive-compatible\" in the sense that they foster sound risk management within the institution rather than narrow adherence to rules and regulations; minimize burden by using internal risk measurement systems; and are reinforced by market forces and the performance incentives of bank owners and managers.  Too often financial engineering is targeted at regulatory arbitrage   that is, exploiting loopholes in narrowly focused regulatory policies that are based on old, traditional instruments or business lines.  Also, potential new products may not be introduced because their regulatory treatment is viewed as too burdensome or uncertain.  This situation demonstrates all too clearly the differing reaction times of public and private entities.  Regulatory policies and standards often take a long time to change whereas, in the private sector, market forces can quickly remedy outmoded standards.  The resulting distortions of resources that arise when supervisory standards are slow to change is an unfortunate, albeit predictable, outcome.  Policymakers can reduce this potential for distortion by structuring policies to be more \"incentive-compatible.\"  This involves harnessing market forces and market discipline to achieve supervisory objectives.  Increasingly, supervisors are trying to avoid locking themselves into formulaic, one-size-fits-all approaches to supervision and regulation.  The use of internal VaR models for calculating capital charges for trading activities is an important step in this direction.  Risk-focused supervision emphasizing sound practices and internal controls is another.  A significant effort that could increase supervisory reliance on market discipline in the future is the Federal Reserve's so-called \"pre-commitment\" approach to determining capital for market risk.  It seeks to provide banks with stronger regulatory and market incentives to improve all aspects of market risk management.  This approach is currently being studied and tested by a group of U.S. banks organized by the New York Clearing House.  What will be the eventual outcome of incorporating the lessons learned into banking supervision?  I see two themes in the evolution in the supervision of financial institutions:  First is providing strong regulatory incentives for banks to exercise prudence in taking and managing risk, and to develop ever better systems and processes for risk management.  I believe the best evidence of this thinking is illustrated by the recent moves to align regulatory capital requirements for market risk with individual institutions' systems for allocating economic capital based on their own internal models.  Supervisory oversight then concentrates on the performance of each institution's risk management process rather than devising regulatory capital schemes that may not fit every institution, and inevitably have loopholes or inconsistencies that can be exploited.  Second, greater reliance will be placed   particularly for nonbank business lines   on the discipline the market can exert on individual participants.  The latter element to our supervisory approach depends on market participants acting in their own self interest when dealing with counterparties.  That involves understanding the risks of engaging in business and properly pricing transactions.  Reliable financial information is an essential ingredient to efficient market discipline.  Such information would clearly convey the risk profile of the institution it represents.  In its absence, markets are more susceptible to distortions caused by rumors, misinformation, or failures to disclose.  Many believe the dearth of information on risk profiles reflects the market's reliance on the federal safety net.  Such information would be available if participants were not, to a large extent, indemnified from loss.  It is this desire to see market discipline taking a greater role in regulating the affairs of banking organizations and others that has motivated the Federal Reserve Board to voice its opinions about accounting standards that are being developed by the Financial Accounting Standards Board (FASB).  As in regulation, an important consideration to setting accounting standards should be the benefits of a particular standard outweighing its cost.  The Federal Reserve's opinion is that the accounting for derivatives (and other financial instruments for that matter) should be consistent with the approach to risk management the firm takes in its business.  This consistency can yield cost savings by reducing the need for two sets of books:  one for financial reporting and another that supports internal management decisions.  Moreover, it avoids the possibility of regulatory reports diverging from financial reporting, thereby helping to ensure that supervisory information and capital requirements appropriately reflect the institution's economic risks. Globalization of these Lessons and Future Prospects The challenges of supervision in a rapidly changing financial and technological environment are compounded by global integration of the marketplace.  To the extent that regulation in one country is deemed too restrictive, firms can avoid it by simply booking business in another country.  The ease with which firms can circumvent national borders and regulatory jurisdictions is a challenge of one dimension.  If circumvention results in unsafe or unsound banking practices, it is a problem of another dimension.  The problem may end up back in the United States after all.  It is for these reasons that the Federal Reserve and the other U.S. banking agencies have been advocating that international agreements on banking supervision have a risk focus.  For example, the Basle Committee on Supervision (under the Bank for International Settlements) recently agreed to embrace a portfolio-based, risk-sensitive approach to setting capital requirements for market risk.  Instead, supervisors will be building upon the processes banks use to measure trading risks.  This should substantially reduce regulatory burden and make standards more compatible with industry practice.  In addition, the Basle Committee has agreed to common frameworks for gaining information on the derivatives activities of supervised institutions.  A major task before us is to work with emerging-market countries to strengthen and unify banking supervision.  Greater consistency should reduce the risk of systemic problems arising from a financial disruption in any particular market.  While most of these efforts have focused on market risk, I think it is fair to point out that the major exposure for most banks is credit risk.  Looking to the future, will the risk-based capital approach for credit risk ever evolve into an internal models approach?  The answer is probably yes; however, with credit-risk modeling in such an early stage of development, it is premature to predict just when credit modeling and the supporting data will develop to the point that they can be relied upon as effective management tools.  I am, however, encouraged by progress in modeling credit risk.  The risk-based capital accord has worked well in the past and remains useful today.  It was an excellent vehicle for bringing about a convergence in bank capital standards worldwide.  But it does illustrate the problems of a standardized scheme.  For example, banks have an incentive to securitize low-risk assets to avoid regulatory capital charges that unregulated competitors need not meet.  Alternatively, market participants can get a false sense of security about a bank's condition if the risk-based capital ratios understate the true risks of the bank's portfolios.  Recognizing these shortcomings, we regulators need to continually review and revise our standards, as we have proposed in connection with certain securitizations of assets.",
                  "1997-09-19 00:00:00"
                ],
                [
                  "35",
                  "Governor Laurence H. Meyer",
                  "The Economic Outlook and Challenges Facing Monetary Policy  Recent economic performance has been hailed on Wall Street as \"paradise found\" and the \"best of times.\"  And, on Main Street, there is ample survey evidence suggesting that consumers are feeling very upbeat about the prospects for the economy.  I call the remarkable combination of healthy growth, low unemployment, low inflation, a soaring stock market, and declining federal budget deficit the \"good news\" economy.  But there are challenges even in the \"good news\" economy and I want to focus on three of them this afternoon.  The first challenge is to avoid complacency and appreciate the policy challenges that remain.  The second is to explain how we have been able to achieve such favorable performance, given that it is better than almost anyone predicted and better than historical regularities suggested was even possible.  And the third challenge is to assess the risks in the current environment and determine how monetary policy should be positioned to keep the good news coming.  Two themes will become evident as I address these challenges.  First, there are limits   limits on what policy can accomplish and limits on what the economy can achieve.   Second, in assessing the current environment and its implications for monetary policy, uncertainties require us to balance historical regularities and newer possibilities.   Expansions, to an important degree, have common properties, what I shall refer to as regularities.  Both forecasters and policymakers rely on these.  Forecasters make predictions about future developments based on regularities.  The same regularities allow policymakers to act preemptively   changing policy today in anticipation of developments tomorrow.  Yet each expansion has its own signature that reflects the specific set of transitory influences and longer-lasting structural changes in play at the time.  The current episode features the following players.  Cyclical regularities clearly in evidence include accelerator effects, changing tolerances for risk, and cyclical swings in the unemployment rate and in profits.  Two other regularities that I especially want to focus on today are the Phillips Curve and the trend growth in output.  The latter regularities define limits   limits to the sustainable level of output, at any moment, and, once that level of capacity is reached, to the growth of output over time.  If these limits are exceeded, as typically happens during a cyclical expansion, the economy eventually overheats, inflation increases, and the expansion is undermined as policy is forced to rein in demand.  Transitory influences, clearly among the stars of the current episode, feature a coincidence of favorable supply shocks that have restrained inflation.  Finally, structural adjustments, in this episode, hint at a decline in NAIRU and/or an increase in trend growth.  The central question in interpreting the recent experience is whether the old limits on economic performance are no longer binding, having been replaced by new possibilities, or are just being temporarily overruled by transitory influences.  Before moving to the substance of my talk, let me remind you that my remarks on the outlook and monetary policy, today and always, are my views.  I do not speak for the FOMC.  Near-Term Prospects in the Good News Economy Before addressing the challenges and developing these themes, let me briefly review the surprisingly favorable features of recent economic performance and comment on the near-term outlook.  For this audience, I can summarize recent performance in a single sentence.  We have been recently blessed with relatively strong cyclical growth, the lowest unemployment rate in 24 years, the lowest inflation in 31 years, an impressive investment boom, soaring equity prices and a 5-year decline in the federal budget deficit that may take the deficit to below 1/2% of GDP in fiscal 1997.  But this conference is about the next chapter in this story.  And the key in the near term may be crosscurrents that appear likely to both moderate output growth and keep inflation relatively well contained.     In the case of output growth, the crosscurrents are the continued strength in demand and the expected slowing in inventory investment. In the second quarter, the economy slowed to an upward revised 3.6% rate, from a 4.9% rate in the first quarter, a much more modest slowing than originally reported and widely anticipated during the quarter.  This, by the way, has been a recurring pattern in the expansion   every time I thought the economy had or was about to slow to trend, it has surprised with its continued strength.   The fundamentals continue to look very positive.  In particular, households as a group are wealthy and optimistic, businesses are profitable and confronted with dramatic technological opportunities, and financial conditions remain supportive.  There appear to be few imbalances that are a threat to continued expansion.  As a result, demand is expected to remain strong in the second half of the year, paced by a rebound in consumer spending and complemented by continued strength in business fixed investment.  Forecasters know, however, that the composition or mix of output in one quarter   specifically the mix between final demand and inventory investment   often provides an important hint of what is to come.  While I interpret the strength of inventory investment in the first half   including the upward revised rate of about $78 billion in the second quarter   as largely voluntary, principally reflecting a response to the strength in past and prospective sales, the flow rate of accumulation in the second quarter is almost certainly unsustainable.  That is, stocks may be in equilibrium, but the flow rate will have to slow to keep them there.  The resulting slowdown in inventory investment is likely, therefore, to be a significant drag on production in the second half of this year, offsetting, at least in part, the expected rebound in final demand.   On the inflation side, there are also important crosscurrents at work.  I have been concerned about two considerations that suggest that inflation may well rise over time: the possibility that the economy is operating today beyond its sustainable capacity and the likelihood that the transitory factors that have, on balance, been restraining inflation will diminish in importance over time.  However, three other influences that, in my view, have gradually become more significant considerations, are likely to moderate the tendency for inflation to rise in the near term.  First, lower-than-expected overall and core inflation and continued modest pace of wage change over this year will encourage more restrained increases in wages and prices over the coming year.  Lower inflation leads to lower inflation expectations, reinforcing the prospect for low inflation ahead.  In this case, inertia is our friend and the result is a virtuous wage-price spiral, at least for a while.  Second, some of the transitory factors, especially the appreciation of the dollar and resulting decline in import prices, appear to have longer legs and are likely to contribute more toward restraint on inflation in coming quarters than earlier appeared likely.  Third, the upward adjustment to profits in the July NIPA revisions suggests there is more of a profit cushion that could delay the pass-through of higher compensation to price increases.  While these crosscurrents suggest moderation in both output growth and inflation, crosscurrents don't necessarily balance.  With respect to output growth, the crosscurrents do point toward slower growth in the second half compared to the first half, but is important whether the slower growth turns out to be near trend, holding utilization rates constant, or above trend, pushing utilization rates still higher.  At the very least, the slowdown in inventory investment is likely to be accommodated with minimal disturbance to the continued expansion.  But there is a risk that growth will continue to be above trend, pushing utilization rates up, from already high levels.     With respect to inflation, the netting of the crosscurrents suggests a modest increase in inflation in 1998, albeit from a steadily downward-revised and very low rate in 1997.  I will pay very close attention to the source of any rebound in inflation, specifically the degree to which it reflects simply the dissipation of some of the favorable supply shocks that have contributed to the very low inflation this year and the degree to which it reflects the more persistent effect of high utilization rates.   As a result, I will be focusing more on core than overall inflation rates and paying particularly close attention to labor costs, given that labor markets appear tighter than product markets and therefore more likely to be the source of any increase in inflation pressures.  Still, any increase in inflation would begin from a lower base and may be more modest than previously appeared likely.  The bottom line is that past performance, in several important dimensions, has been extraordinary and that prospects look favorable for continued expansion and relatively low inflation.  Still, monetary policy must be alert to the potential of a developing upward trend in inflation in an economy that may already be operating beyond its sustainable capacity and possibly still growing at an above-trend rate.  And, as always, there are challenges, even in the good news economy. Limits on What Monetary Policy Can Do The first challenge is to avoid becoming complacent.  Even as there are good reasons for celebrating recent economic performance, there are good reasons for avoiding complacency. Specifically, there are dimensions of economic performance which are less stellar, such as the slow average growth rate in GDP in the 1990s, a continuation of the effects of the productivity slowdown that began in the early 1970s.  There are, in addition, obvious longer-run problems that deserve to be confronted today, such as those related to the aging of the population and resulting pressures on entitlement programs.  And there remain lingering social strains associated with a gradual increase in income inequality, interacting with the low average growth rate in productivity to produce a long period of relatively stagnant real income for the median income family.  This less rosy perspective on the current state of the economy was suggested by several members of Congress during the recent oversight hearings on monetary policy.  I think the point is an important one and I agree that we should not let the recent favorable performance of inflation, unemployment and equity prices distract our attention from the importance of confronting a slow average rate of increase in living standards and lingering social problems that both reflect and are exacerbated by a widening in income inequality.  However, other than through its pursuit of its legislative mandates of price stability and maximum sustainable employment, monetary policy cannot make a major contribution to the resolution of these problems.  Monetary policy, in particular cannot remedy increases in income inequality, raise the trend rate of increase in living standards, or combat inadequate opportunities for upward mobility out of poverty.  It is, as always, important that we carry out our traditional responsibilities well, accommodating the maximum sustainable growth and achieving the maximum sustainable level of employment.  But we cannot do more. Regularities The second challenge is to explain why performance has been so favorable, at least in terms of inflation and unemployment.  Before exploring explanations of the puzzle, I want to focus on common features of cyclical expansions.  In doing so, I will focus on cyclical expansions that have not been dominated by dramatic external shocks, such as the two episodes that were marked by steeply rising world oil prices   first in the early 1970s and again in the late 1970s and early 1980s.  While even these expansions share many of the patterns I emphasize later, their endings are dominated by the effects of the powerful supply shocks and policy responses to the shocks.  Expansions, by definition, begin with considerable economic slack, inherited from the previous recession.   The economy typically makes a rapid transition from declining output (the definition of recession) to above-trend growth.   In a loose way, trend growth refers to the growth in the economy's productive capacity.  When growth is above trend, production is expanding faster than the economy's productive capacity and, as a result, resource utilization rates rise.  Rising capacity utilization rates and falling unemployment rates are thus a typical feature of an expansion period.  The natural dynamic of an expansion is for above-trend growth to continue until demand overtakes capacity, despite the best efforts of policy to avoid cyclical excesses.  The end of the story is particularly important.  Expansions do not die of old age or lethargy, a spontaneous weakening of aggregate demand, but rather of an accumulation of imbalances, specifically with demand outstripping the limits of sustainable level of input utilization and growth of output.  The resulting rise in inflation becomes a threat to the continued expansion.  Preventive medicine is therefore the best course of treatment.  In this story, NAIRU sets a limit to how far the economy can expand before overheating sets in and inflation rises, and the Phillips Curve traces out an important part of the dynamics of inflation, how fast it responds to excess demand.  Of course, the Phillips Curve framework has always been much easier to describe than to implement, given uncertainties about the estimates of NAIRU, given the fact that empirical regularities between inflation and unemployment always left much of the variation in inflation unexplained, and given the importance of supply shocks with significant, though transitory, effects on the inflation-unemployment nexus.  Nevertheless, the regularity in the cyclical sensitivity of inflation, as embedded in the Phillips Curve, has proved to be an important guide to both forecasters and monetary policymakers in the past.   Transitory Influences The consensus estimates of NAIRU as this expansion began   about 6%   did not prepare us for the recent surprisingly favorable performance.  It is possible that the Phillips Curve and NAIRU is simply the wrong analytical framework, but I doubt it and am not aware of another model of inflation dynamics that is ready to take its place.  So my response is to update my estimate of NAIRU and add other explanations consistent with this framework, but not to abandon this concept.  One possible explanation is that one or more transitory factors, for the moment, are yielding a more favorable than usual outcome. A coincidence of favorable supply shocks is clearly, in my judgment, an important part the answer to the puzzle.  I won't talk at length about these factors, as I have done so in previous talks.   I would just note that these favorable supply shocks include an appreciation of the dollar and consequent decline in import prices; a slowing in the rate of increase in benefit costs, concentrated in a slowdown in costs for health care insurance; a faster rate of decline in computer prices than earlier, reflecting the quicker pace of innovation; and more recently, a decline in oil prices and a slower rate of increase in food prices. A Cyclical Anomaly Let me include in my list of explanations for the current favorable economic performance an intriguing cyclical anomaly.  One regularity of past expansions has been the close relationship between two widely used measures of resource utilization   the capacity utilization and unemployment rates.  They have traditionally moved together over a cycle and tended to mirror one another.  In this case, it did not matter which one was used as a proxy for excess demand; and the unemployment rate could be used interchangeably as a measure of labor market demand pressures and overall economy-wide demand pressures.  In the current episode, however, these two measures are sending different signals.  The unemployment rate is flashing a warning of a very tight labor market.  The capacity utilization rate, in contrast, suggests a reasonably balanced configuration of production and capacity in the product market, at least in the manufacturing sector.   Why has this divergence developed and what are its implications for the relationship between inflation and unemployment?  The divergence mirrors one of the other defining features of this expansion   the boom in business fixed investment.  The result is a high level of net investment, a more rapid rate of increase in the capital stock and hence in industrial capacity.  The resulting absence of excess demand in the product market is, in my view, an important factor explaining the frequently reported absence of pricing leverage by firms.  Nothing gives a firm pricing leverage like excess demand.  In addition, the resulting inability of firms to pass on higher costs in higher prices likely has altered the way firms operate in the labor market, making them more reluctant to bid aggressively for workers, contributing to a slower rate of increase in wages than we would otherwise have expected at prevailing labor utilization rates.  It is possible that the gap that has opened between the unemployment and capacity utilization rates may be a factor that has, in effect, lowered NAIRU in this expansion.  This explanation has potential, but there is no historical precedent and it is, therefore, difficult to judge its importance.   Possibilities The most intriguing explanations for the recent favorable performance are structural changes, which may have relaxed the capacity constraints that are the core of the cyclical regularities story, or made these constraints more flexible than in the past, or tempered the ability and/or willingness of firms to respond to excess demand by raising wages and prices.  I refer to these collectively as \"possibilities,\" as they suggest an optimistic period of improved economic performance, contrasting with both the pessimism of the previously perceived limits in the cyclical regularities story or the grudging \"for the moment\" concession of explanations relying on transitory influences.  There are two possibilities that have been widely discussed: that the economy can now sustain a lower unemployment rate without rising inflation (i.e., that NAIRU has declined) and that, once capacity has been reached, the economy is now capable of faster growth, compared to the estimates of trend growth reported earlier.  A lot of the discussion about this episode focuses on sorting out the relative importance of the two possibilities   specifically, whether the recent favorable performance is due more to labor market structural change, as reflected in a lower NAIRU, or to product market structural change, as reflected in a higher rate of growth in productivity. Has there been a decline in NAIRU? Time varying parameter estimates of the Phillips Curve and the more casual eye both suggest a decline in NAIRU.  Robert Gordon's work, for example, suggests a decline in NAIRU, from 6% in the decade prior to 1994, to about 5 ½% by the end of 1995, with NAIRU stabilizing at this level since that time.   One possible explanation for the more moderate rate of increase in compensation per hour than would have been expected from historical experience is an increase in worker insecurity as a consequence of the rapid pace of technological change and/or the rapid pace of restructuring and downsizing.  As a result, workers may have been willing to trade off some real wages for increased security, resulting in a more modest increase in compensation per hour than otherwise would have been expected.  The result is a slower rate of increase in compensation at any given level of unemployment, equivalent to a decline in NAIRU.  Another possible explanation is the divergence between the unemployment and capacity utilization rates in this expansion that I discussed earlier.  Although a decline in NAIRU is a story of relaxed limits, the worker insecurity explanation is not itself an optimistic story.  Some workers, to be sure, gain, by opportunities for employment that otherwise would have been denied.  But a broader group of workers suffer a slower increase in living standards, relative to what otherwise would have been \"possible.\" Has there been an increase in trend productivity? Another possibility is that the trend rate of increase in productivity   and hence the economy's sustainable rate of growth in GDP   has recently increased.     There is some confusion in many discussions of productivity growth about the implications of measurement bias.  It is widely accepted that there is a downward bias in measured productivity growth, the mirror image of the upward bias in measured inflation.  But it is also widely accepted that a similar bias has been present over the entire postwar period.  The measurement issue is relevant to explaining the inflation-unemployment experience in the current episode only if the bias has recently become more serious.  An increase in measurement bias could be under way, perhaps related to an acceleration in technical change, but it will be a long time before we are able to establish this with a reasonable degree of certainty.  Note also that if the measurement bias has increased, this would imply that both actual and potential output growth are higher than reported, with no obvious implication for the gap between actual and potential output, and hence for inflation pressures.  Sources of higher productivity growth, all of which should show up in measured productivity, include a return on years of corporate restructuring and the increase in capital per worker associated with the current investment boom, much of which is linked to technological change, specifically the information revolution.    There are a couple of reasons why this is an attractive explanation.  No other explanation has the ability to explain as many features of the current experience as an increase in trend productivity.  Technological change, according to this view, has resulted in new profit opportunities which in turn have resulted in an investment boom (heavily concentrated in high technology equipment), increased corporate earnings, and a soaring stock market.   In addition, this explanation is consistent with many anecdotes from businesses about efficiency gains as new technology is put into place.   There are, however, some problems with this story as the principal explanation for the favorable inflation performance.  First, a productivity explanation would resonate better if the puzzle were why higher wage change was not being passed on in higher prices.  But the greater puzzle is the slow pace of increase in compensation per hour at prevailing unemployment rates.   This is more clearly the case after the downward revision in compensation in the July NIPA revisions, bringing that measure of compensation per hour more in line with the Employment Cost Index.  Given the rate of increase in compensation, an unchanged trend growth in productivity of 1.1%, for example, seems quite consistent with recent price performance.   Although not without some serious shortcomings, the published productivity data provide little encouragement to the view that there has been a significant improvement in underlying productivity growth.  The growth in measured productivity over this expansion has, in fact, been disappointing.  Over 1994 and 1995, in particular, measured productivity was nearly flat.  Although it has accelerated over the last two years, this is consistent with another cyclical regularity, the tendency for productivity to accelerate with economic activity.  And the rate of growth over the last year, even with the sharp upward revision in the second quarter, is 1.2%, just above the 1.1% average rate of increase over the period from the early 1970s up to the beginning of this expansion.  Still, there are other pieces of data and interpretations of the published data that provide some support to a more optimistic assessment.  For example, the acceleration in productivity to a 1.2% rate over the last year, at a time when the unemployment rate was dropping to a level that would suggest less productive workers were being drawn on, leaves open the possibility that the productivity trend has quickened.  Perhaps the strongest case for an increase in the productivity trend comes from the higher rate of growth over the past two years if productivity is measured from the income side of the national accounts.   Balancing regularities and possibilities In my testimony at the Congressional oversight hearings, I presented a range of estimates for NAIRU and trend growth from the CBO, Council of Economic Advisers, DRI, Macroeconomic Advisers and Professor Robert Gordon.  The range for NAIRU was 5.4% to 5.9% and for trend growth, 2.1% - 2.3%.  Since my testimony, both DRI and Macroeconomic Advisers have revised down their estimates of NAIRU - DRI from 5.8% to 5.6% and Macroeconomic Advisers from 5.8% to 5.4%.  The range of estimates is now therefore more tightly concentrated around 5 ½%.  I presented these estimates in my testimony to emphasize the continuing importance the profession attaches to NAIRU, the central tendency of current NAIRU estimates, and the absence of significant upward adjustments to estimates of trend growth.    In short, some updating in the regularities may be appropriate, especially in the case of NAIRU, but continued attention to their message of limits remains critical for disciplined policy.  We should remain open minded and alert to the possibility of structural change, but cautious about reaching the conclusion that the regularities that have been so important in the past no longer set limits that policy must respect. The Challenge for Monetary Policy Some day we shall look back on this episode with historical perspective and perhaps   and only perhaps   have a better ability to sort out what contributed to the favorable outcome and the extent to which the prevailing coexistence of low unemployment and stable low inflation proved permanent or transitory.  Monetary policy, however, is made in real time.    The appropriate stance of monetary policy should reflect both the increased uncertainty surrounding the failure of historical regularities to predict the better-than-expected outcome in terms of inflation and unemployment and the best judgment about regularities as we update our estimates of NAIRU and trend growth in response to current data.  At one extreme, the uncertainty about the source of the recent performance might be viewed as so great that the best course for monetary policy is a reactive posture, waiting for clear signs that inflation is rising and only tightening in response to such evidence.    I agree that the current uncertainty encourages caution, but not to the point of paralysis. ",
                  "1997-09-17 00:00:00"
                ],
                [
                  "36",
                  "Governor Laurence H. Meyer",
                  "Monetary Policy and the Bond Market:  Complements or Substitutes?  It is a pleasure to speak this afternoon at the Fixed Income Summit.  To some analysts, a meeting of the heads of the top fifty government securities dealers would represent a concentration of influence over the U.S. economy that perhaps even surpasses that of the meeting I will attend on September 30.  Indeed, some have argued that the activities of traders and investors in the bond market have become a major stabilizing force in the economy, even to the point of making the FOMC redundant.  This premise suggests an interesting theme for my address this afternoon   the connection, or maybe more appropriately the symbiosis, between policy makers and market participants. The Importance of Market Mechanisms The Federal Reserve has been most successful over the years when it has relied on market mechanisms to carry out its policy intent.  Regulation Q, in its fixing of ceilings on deposit rates, distorted incentives and led to sudden and large swings in the pattern of intermediation.  Selective credit controls, in retrospect, were a blunt instrument that was too unpredictable and extreme to use effectively.  And the Board of Governors has found that reserve requirements, which represent a tax on depositories because our reserves do not bear interest, are best held steady at the lowest level consistent with the efficient implementation of policy.  Instead, the Federal Reserve controls its balance sheet to influence a rate quoted by market participants any time that the reserve market is open   the overnight federal funds rate.  In truth, as you all know, movements in that rate have little direct significance, except to reserve managers and those relatively few others concerned with the overnight cost of funds.  But how that rate gets transmitted along the term structure to yields on longer maturity instruments has broad significance that ultimately affects everyone in the economy.  And that is where market participants come in.  Policymakers' influence is focused on the current short rate.  It is the job of traders and investors to read our intentions from the public record, form their own judgments as to the course of economic activity and inflation that are based on, in addition to monetary policy, current and prospective fiscal policies and demand and supply shocks, and translate all that into action as expressed in the prices of a bewildering array of debt, equity, and derivative instruments. Varieties of Errors While the market activities of traders and investors can importantly reinforce and strengthen the actions taken by the FOMC in the pursuit of its broad macroeconomic objectives, they cannot replace the FOMC.  Sometimes, believe it or not, they turn out to complicate, rather than advance, the cause of monetary policy.  Before I turn to the good the market does in complementing policy action, let me start by deflating the notion that an omniscient bond market always gets it right so as to render the FOMC redundant.  Because many of the instruments in which you deal have long maturities, the judgments that have to be made to price them by necessity stretch well into the future.  The scope for error can be large and the consequences costly.  I think it is useful to separate the grounds for mistakes into two groups: market participants could be wrong about the economy, or wrong about policymakers' objectives.  Two examples can make this distinction clearer.  For one, we know, after the fact, that most analysts misjudged the full extent to which unusual restraint on credit was exerting a drag on spending from around 1989 to 1993.  Essentially, both households and firms recoiled from the explosion of debt in the 1980s.  They were burdened by high interest service and took steps to bring their balance sheets into a more sustainable configuration.  Lenders, too, had their own imbalances, brought on importantly by the real estate bust.  Among them, banks drew back from extending loans to a wide variety of borrowers, including businesses.  In this environment, spreads of private over public rates widened in the market, and borrowers and lenders who went to depositories were confronted with far less favorable terms than they had grown accustomed to.  While Chairman Greenspan and his fellow policymakers identified the credit crunch in a fairly timely fashion, it took some time to appreciate the full force of its power.  By my reading, in the aggregate, market participants were slower on the uptake.  Thus, the policy easings of 1991 and 1992 were greeted with some skepticism as market participants apparently interpreted those actions as reflecting a lessened concern about inflation on the part of the Federal Reserve, rather than the appropriate response to a softening in aggregate demand.  The effect of those misassessments was to produce a stunning steepening of the yield curve.  The spread between long and short-term rates is often viewed as one of the most reliable cyclical indicators and a widening as a measure of the increased stimulus of monetary policy.  But I viewed the widening in this episode as evidence of the reduced effectiveness of monetary policy in an environment where actions by bond-market participants were preventing long-term interest rates from adjusting in response to the policy-induced decline in short-term rates.  At its peak in mid-1992, the long-term Treasury bond yielded 475 basis points over the three-month bill rate, about three times the average for the prior three decades.  True, as the full dimension of the effects of the credit crunch became apparent, yields fell from those heights.  But in the interim, monetary policy's intentions were blunted by the market's misreading of the economy.  This probably prolonged the need for ease and further accentuated the required easing of the federal funds rate.   As another example, I have spent enough of my career projecting near-term economic trends to be familiar with a forecaster's favorite friend   momentum.  But momentum can easily be misjudged.  It is easy to fall into the trap of presuming that what an economic actor did last is what that actor will do next.  Thus, market prices tend to extrapolate that changes in monetary policy cluster in the same direction.  This is a rule that works often enough, but, as a look back to 1994 and 1995 reminds us, not always.  By mid-1994, the FOMC had substantially raised its intended federal funds rate, but market prices seemed to say that enough was not enough.  The tightenings in May and August of that year, for example, were greeted by a roughly parallel shift up in money market futures rates, implying that the actions had not gotten the Federal Reserve any closer to the goal line   instead, the goal line had been pushed back.  And the Fed indeed did continue to tighten through early 1995.  But by late 1994 and early 1995, the term structure spreads in financial markets remained very wide, implying an expectation of still significant further tightening.  As a result, the restraint associated with the policy action was amplified.  In retrospect, a tighter focus on fundamentals   that policy was acting in a pre-emptive fashion to contain inflation, rather than an extrapolation of the sequence of recent policy actions   would have helped to cap the rise in longer-term yields.  The Benefits of Market Mechanisms While I have been speaking about all manner of misjudgments, I actually do have an economist's inherent confidence in market mechanisms.  Market participants do, on average, get it right and are rewarded accordingly, to the benefit of economic efficiency.  Indeed, the pattern of those rewards sharpens skills in trading and forecasting, ensuring that these benefits will continue to accrue.  For that reason, policymakers are well advised to heed the message from markets that are expressed in prices.   What I find most intriguing is the notion that markets can carry some, and, in the extreme view, all of the load for monetary policymakers.  To push it to an extreme, it's as if the actions of the Federal Open Market Committee, of which I am a member, can be anticipated, augmented, and, perhaps, even replaced, by meetings of the Private Open Market Committee, of which you are members.    There are two main advantages of these meetings of the Private Open Market Committee.  First, members meet twenty-four hours a day, every business day of the year, so that the POMC can respond to every scrap of information on the economy, whether it be an official data release, a statement by an official, or a rumor about the future course of policy.  Second, every participant can express the strength of his or her belief in a particular view by the amount of capital committed to the trade.    Because of the inclusiveness of the market, a broad assortment of views about the workings of the economy can be reflected in prices.  While the design of the FOMC fosters a similar diversity of views, virtually nonstop market trading allows prices to move before official policymakers can react.  Of course, the FOMC delegates authority to the Chairman and, in this age of instantaneous communication, conference calls are always possible.  But, practically, with a fixed calendar of FOMC meetings, a desire on our part for a systematic review of the situation to help our deliberations, and some inertia in decision making, markets will almost always be better positioned to react more quickly to news than the Federal Reserve.  This speedy response, when right, puts in place stimulus or restraint sooner, perhaps lessening the need for us, ultimately, to move our policy instrument as much.  In general, the more forward looking the bond market is with respect to future policy action, the shorter will be the lag from policy action to intended economic effect.  In the absence of such a forward-looking response of long-term rates, short-term interest rates may have to move by more to achieve the same near-term impact on long-term interest rates and economic activity.  Indeed, in those circumstances, the Federal Reserve would have to weigh carefully the effects on long rates of both the current and lagged levels of short rates so as to avoid the potential for an overshooting of short-term interest rates that would have adverse consequences for the economy.  However, if long-term rates move swiftly in response to correctly anticipated policy, the required rise in short-term rates will be smaller and there will be less risk of overshooting. Thus, for the same reasons the Federal Reserve attempts to be pre-emptive in its monetary policy decisions, we would welcome pre-emptive pricing by market participants.  But we must recognize that what markets are pricing is anticipated Federal Reserve action.  If the prices are right, we will act to validate them.  If the prices are wrong   built on the base on an incorrect view of the economy or Federal Reserve intentions   we will prove them wrong and provide an anchor for the market to adjust to.  It is also important to appreciate that the anticipatory contribution of the markets cannot be sustained unless the FOMC ratifies well-timed moves of the market.  If the FOMC were to fail to do so, it would disconfirm the expectations on which the market move was based, making it less likely in the future that the market would play a constructive anticipatory role.  Therefore, while forward-looking markets may change what we policy makers need to do, they will never eliminate the need for the FOMC to respond to changing economic developments. Some Lessons for Markets and Policymakers I hope that the important question that this discussion has been pointing to is obvious by now: How can we   the Federal and the Private Open Market Committees   operate to deliver the greatest good for the American economy while you respect your obligation to stakeholders to maximize their return? I think that there are two parts to the answer: We should work at arm's length but with full information.  By arm's length, I mean that the information markets provide works best as an independent check on monetary policy decisions.  If the FOMC were to tie mechanically our actions to market prices, then we would be placed in the sorry position of validating whatever whim that currently struck investors' fancy.  If you were to take our reading of the economy as if from a sacred text, the unique sources of information and skills that you have refined would go untapped.  It is far better that we should treat each other warily so as to keep each other sharp.    By full information, I mean that the Federal Reserve should do its best to read signals from markets and to communicate to markets its policy intentions.  The Domestic and Foreign Open Market Desks of the Federal Reserve Bank of New York are virtually in constant communication with market participants and routinely distill that information for their policy-making principals.  My fellow governors and I routinely receive from our staff a translation of the term structure of Treasury yields into implied forward rates, volatility inferred from options prices, and paths for expected monetary policy action consistent with futures prices.  Of late, the information we receive has included inferences drawn from quotes on the Treasury's inflation protected securities.  In principle, such information should be helpful in interpreting all manner of economic behavior, including the pricing of financial instruments and wage setting.  As yet, I must admit that, in the eight months since the first issue, the volume of trade and the apparent lack of interest in related contracts on the futures market has been somewhat disappointing.  The Treasury's strong commitment to this product, reflected in the range of maturities that have and will be sold and the volume of securities sold, should do much to foster this market, as will the growing realization by market participants that indexed debt will represent an increasing share of the nation's debt obligations.  But even after we have reliable quotes on a more complete indexed term structure, considerable analysis must still be done before we can cull readings of inflation expectations and inflation risk from market prices.  As you well appreciate, the spread of the yield on a nominal instrument over its inflation-protected counterpart includes compensation for expected inflation, inflation uncertainty, and differential risk characteristics.  Until we have a long enough history to be more certain of the relative contributions of each, we must watch, wait, and learn.  Communication must flow two ways.  Over the past few years, I am pleased to say, the FOMC has significantly enhanced the information it provides to the public.  That list includes announcing actions   and the reasons underlying them   within the day that the decisions are made and providing complete transcripts of meetings with a five year lag.  We continue to release a comprehensive record of policy discussions six to eight weeks after each meeting.  We now report the daily size of reserve operations within minutes of their completion, and we have lifted the last veil covering the inner sanctum of policy: Rather than speaking in tongues about \"slight\" or \"somewhat\" changes in reserve pressures, the FOMC now announces the intended federal funds rate when it is changed.  In one respect, the distance covered in that change was not all that great, in that for most of this decade, the Federal Reserve has been rather explicit in signaling through its choice of open market operations whenever the FOMC elected to alter its intended rate.  But compared to the borrowed reserves operating period of the latter half of the previous decade, the change has been dramatic.  Rather than rely on Fed watchers employed by primary dealers to read the tea leaves of our daily interventions, we inform everyone, openly, and take responsibility for the level of short-term interest rates.  By my reading, this is one circumstance in which virtue has proved more than its own reward.  Over the past 3-1/2 years, a financial innovation   sweeps from retail deposits   has complicated reserve operations.  On average, depositories that have adopted sweeps have been able to reduce their effective reserve requirements by 80 to 90 percent.  When aggregated over the entire banking system, the scale is staggering.  By year-end, transactions deposits will probably have been reduced by nearly $1/4 trillion as the result of the cumulative effect of retail sweeps, which is big even by Washington standards.  Going by a simple rule of thumb, required reserves will be lower by about one-tenth that total.  This innovation has made the technical job of implementing monetary policy from day to day more difficult.  Simply, reserve requirements are no longer necessarily the binding determinant of reserve demand for many banks.  When reserve requirements are in excess of clearing balances, volatile movements in clearing balances will have a small effect on the reserves market.  However, when desired clearing balances dictate short-run movements in the demand for reserves, the reserve market, and therefore the federal funds rate, may become a bit more volatile late in the trading day.  However, to the credit of my colleagues charged with determining daily open market operations and of market participants who have adjusted operations to the new environment, that volatility has been quite muted.  Still, if markets had only daily open market operations to discern the FOMC's intentions, the scope for misimpressions in this environment would be large.  Because you can read press releases to learn our policy stance rather than the pattern of reserve additions or drains, there is much less chance for confusion.  For pricing any instrument beyond overnight, market participants apparently find the intended federal funds rate to be more informative than the noisy effective federal funds rate. ",
                  "1997-09-12 00:00:00"
                ],
                [
                  "37",
                  "Chairman Alan Greenspan",
                  " I welcome the opportunity to join Dean Fulton, President Broad, President Emeritus Spangler, Chancellor Hooker, Hugh McColl, and the many other distinguished guests on the podium today.  It isn't every day that we have the opportunity to dedicate a new building devoted to the research and training that our young people need for conducting business in a global setting.  This new facility the McColl Bulding has been equipped with state-of-the-art information technology that will enhance the ability of the faculty and students of Kenan-Flagler to prepare for an exciting future in our global economy. The University has made this important commitment at a time when our businesses and workers are confronting a dynamic set of forces that will influence our nation's ability to compete worldwide in the years ahead.  One of the most central of these forces is the rapid acceleration of computer and telecommunications technologies, which can be reasonably expected to appreciably raise our standard of living in the twenty-first century.  In the short run, however, the fallout from rapidly changing technology is an environment in which the stock of plant and equipment with which most managers and workers interact is turning over increasingly rapidly, rendering a perception that human skills are becoming obsolete at a rate perhaps unprecedented in American history.  I shall endeavor to place this most unusual phenomenon in the context of the broader changes in our economy and, hopefully, explain why the value of education, especially to enhance advanced skills, is so vital to the future growth of our economy. Wealth has always been created, virtually by definition, when individuals use their growing knowledge to interact with an expanding capital stock to produce goods and services of value.  Assisted by the whole array of market prices, entrepreneurs seek to identify the types of products and services that individuals will value, especially the added value placed on products and services that customers find better tailored to their particular needs, delivered in shorter time frames, or improved in quality. This striving to unbundle the particular characteristics of goods and services in order to maximize their value to each individual inevitably results in the shift toward value created through the exploitation of ideas and concepts, rather than simply the utilization of physical resources and manual labor.  Indeed, over the past century, by far the smallest part of the growth in America's real gross domestic product reflects increased physical product measured in bulk or weight.  Most of our gains have been the result of new insights into how to rearrange physical reality to achieve ever-higher standards of living.  We have dramatically reduced the physical bulk of our radios, for example, by substituting transistors for vacuum tubes.  New architectural, engineering, and materials technologies have enabled the construction of buildings with the same space, but far less physical material, than was required 50 or 100 years ago.  Most recently, mobile phones have been significantly downsized as they have been improved. The increasing importance of new insights has, of course, raised the value of information creation and transfer in boosting standards of living.  Thus, it should be no surprise that new computer and telecommunications products have been accorded particularly high value by consumers and business and, hence, why companies that successfully innovate in this field exhibit particularly high stock market values. Breakthroughs in all areas of technology are continually adding to the growing list of almost wholly conceptual elements in our economic output.  These developments are affecting how we produce output and are demanding greater specialized knowledge. The use, for example, of computer-assisted design instruments, machine tools, and inventory control systems has given our former, more rigid factory assembly lines greater flexibility.  Businesses now can more quickly customize their production to changes in market conditions; design cycles are shorter, quality control has been improved, and costs are lower.  Offices are now routinely outfitted with high-speed information-processing technology.  The accelerated pace of technological advance has also interacted with the rapid rise in financial innovation, with the result that business services and financial transactions now are transmitted almost instantaneously across global networks.  Financial instruments have become increasingly diverse, the products more customized, and the markets more intensely competitive.  Our nation's financial institutions, in turn, are endeavoring to find more effective and efficient ways to deliver their services. In this environment, America's prospects for economic growth will greatly depend on our capacity to develop and to apply new technology a quest that inevitably will entail some risk-taking.  One lesson we have clearly learned is that we never can predict with any precision which particular technology or synergies of technologies will add significantly to our knowledge and ability to gain from that knowledge.  Moreover, America's ability to remain in the forefront of new ideas and products has become ever more difficult because of the rapid international diffusion of technology.  Nonetheless, to date, we have not fallen behind in converting scientific and technological breakthroughs into viable commercial products.  But, to be fully effective in realizing the gains from technological advance will require a considerable amount of human investment on the part of managers and workers who have to implement new processes and who must be prepared to adapt, over their lifetimes, to the ongoing change that innovations bring. Clearly our educational institutions will continue to play an important role in preparing workers.  While we all are concerned about the performance of American elementary and secondary schools compared with those in other developed countries, there is little question about the quality of our university system, which for decades has attracted growing numbers of students from abroad.  However, the notion that formal degree programs at any level can be crafted to fully support the requirements of one's lifework is being challenged. A great deal of innovation and development has been occurring in the business sector where firms are striving to stay on the cutting edge, in an environment where products and knowledge rapidly become obsolete.  Education, as a result, is increasingly becoming a lifelong activity; businesses are now looking for employees who are prepared to continue learning, and workers and managers in many kinds of pursuits had better look forward to persistent hard work acquiring and maintaining the skills needed to cope with a dynamically evolving economy. The recognition that more productive workers and learning go hand-in-hand is becoming ever more visible in both schools and in the workplace.  Linkages between business and education should be encouraged at all levels of our education system.  Your business school is an excellent example of how our educational institutions are building bridges to the private sector that will have payoffs in how well graduates are prepared to meet the challenges of an increasingly knowledge-based global economy.  The growth of high-tech industry here in the Research Triangle, as well as in Silicon Valley and Boston all areas rich in educational and research institutions is no accident. In the private sector, a number of major corporations have invested in their own internal training centers so-called corporate universities.  Some labor unions have done the same.  More broadly, recent surveys by the Bureau of Labor Statistics indicate that the provision of formal education on the job has risen markedly in recent years.  By 1995, 70 percent of workers in establishments with 50 or more employees had received some formal training during the twelve months preceding the survey.  The incidence of training was relatively high across age groups and educational attainment.  Most often this training was conducted in-house by company personnel, but larger firms also relied importantly on educational institutions. At the same time, we must be alert to the need to improve the skills and earning power of those who appear to be falling behind.  In the long run, better child-rearing and better basic education at the elementary and secondary school level are essential to providing the foundation for a lifetime of learning.  But in the shorter run, we must also develop strategies to overcome the education deficiencies of all too many of our young people, and to renew the skills of workers who have not kept up with the changing demands of the workplace.",
                  "1997-09-12 00:00:00"
                ],
                [
                  "38",
                  "Chairman Alan Greenspan",
                  " It is a pleasure to be at this conference marking the fifteenth anniversary of the Center for Economic Policy Research.  The Center, by encouraging academic research into public policy and bringing that research to the attention of policymakers, is performing a most valuable role in our society.  I am particularly pleased that Milton Friedman has taken time to join us.  His views have had as much, if not more, impact on the way we think about monetary policy and many other important economic issues as those of any person in the last half of the twentieth century.  Federal Reserve policy, over the years, has been subject to criticism, often with justification, from Professor Friedman and others.  It has been argued, for example, that policy failed to anticipate the emerging inflation of the 1970s, and by fostering excessive monetary creation, contributed to the inflationary upsurge.  Surely, it was maintained, some monetary policy rule, however imperfect, would have delivered far superior performance.  Even if true in this case, though, policy rules might not always be preferable.  Policy rules, at least in a general way, presume some understanding of how economic forces work.  Moreover, in effect, they anticipate that key causal connections observed in the past will remain fixed over time, or evolve only very slowly.  Use of a rule presupposes that action x will, with a reasonably high probability, be followed over time by event y.  Another premise behind many rule-based policy prescriptions, however, is that our knowledge of the full workings of the system is quite limited, so that attempts to improve on the results of policy rules will, on average, only make matters worse.  In this view, ad hoc or discretionary policy can cause uncertainty for private decision makers and be wrong for extended periods if there is no anchor to bring it back into line.  In addition, discretionary policy is obviously vulnerable to political pressures; if ad hoc judgments are to be made, why shouldn't those of elected representatives supersede those of unelected officials?  The monetary policy of the Federal Reserve has involved varying degrees of rule- and discretionary-based modes of operation over time.  Recognizing the potential drawbacks of purely discretionary policy, the Federal Reserve frequently has sought to exploit past patterns and regularities to operate in a systematic way.  But we have found that very often historical regularities have been disrupted by unanticipated change, especially in technologies.  The evolving patterns mean that the performance of the economy under any rule, were it to be rigorously followed, would deviate from expectations.  Accordingly we are constantly evaluating how much we can infer from the past and how relationships might have changed.  In an ever changing world, some element of discretion appears to be an unavoidable aspect of policymaking.  Such changes mean that we can never construct a completely general model of the economy, invariant through time, on which to base our policy.  Still, sensible policy does presuppose a conceptual framework, or implicit model, however incompletely specified, of how the economic system operates.  Of necessity, we make judgments based importantly on historical regularities in behavior inferred from data relationships.  These perceived regularities can be embodied in formal empirical models, often covering only a portion of the economic system.  Generally, the regularities inform our interpretation of \"experience\" and tell us what to look for to determine whether history is in the process of repeating itself, and if not, why not.  From such an examination, along with an assessment of past policy actions, we attempt to judge to what extent our current policies should deviate from our past patterns of behavior.   When this Center was founded 15 years ago, the rules versus discretion debate focussed on the appropriate policy role of the monetary aggregates, and this discussion was echoed in the Federal Reserve's policy process.   In the late 1970s, the Federal Reserve's actions to deal with developing inflationary instabilities were shaped in part by the reality portrayed by Milton Friedman's analysis that ever-rising inflation rate peaks, as well as ever-rising inflation rate troughs, followed on the heels of similar patterns of average money growth.  The Federal Reserve, in response to such evaluations, acted aggressively under newly installed Chairman Paul Volcker.  A considerable tightening of the average stance of policy based on intermediate M1 targets tied to reserve operating objectives eventually reversed the surge in inflation.  The last fifteen years have been a period of consolidating the gains of the early 1980s and extending them to their logical end the achievement of price stability.  We are not quite there yet, but we trust it is on the horizon.  Although the ultimate goals of policy have remained the same over these past fifteen years, the techniques used in formulating and implementing policy have changed considerably as a consequence of vast changes in technology and regulation.  Focussing on M1, and following operating procedures that imparted a considerable degree of automaticity to short-term interest rate movements, was extraordinarily useful in the early Volcker years.  But after nationwide NOW accounts were introduced, the demand for M1 in the judgment of the Federal Open Market Committee became too interest sensitive for that aggregate to be useful in implementing policy.  Because the velocity of such an aggregate varies substantially in response to small changes in interest rates, target ranges for M1 growth in its judgment no longer were reliable guides for outcomes in nominal spending and inflation.   In response to an unanticipated movement in spending and hence the quantity of money demanded, a small variation in interest rates would be sufficient to bring money back to path but not to correct the deviation in spending.  As a consequence, by late 1982, M1 was de-emphasized and policy decisions per force became more discretionary.  However, in recognition of the longer-run relationship of prices and M2, especially its stable long-term velocity, this broader aggregate was accorded more weight, along with a variety of other indicators, in setting our policy stance.   As an indicator, M2 served us well for a number of years.  But by the early 1990s, its usefulness was undercut by the increased attractiveness and availability of alternative outlets for saving, such as bond and stock mutual funds, and by mounting financial difficulties for depositories and depositors that led to a restructuring of business and household balance sheets.  The apparent result was a significant rise in the velocity of M2, which was especially unusual given continuing declines in short-term market interest rates.  By 1993, this extraordinary velocity behavior had become so pronounced that the Federal Reserve was forced to begin disregarding the signals M2 was sending, at least for the time being.  Data since mid-1994 do seem to show the reemergence of a relationship of M2 with nominal income and short-term interest rates similar to that experienced during the three decades of the 1960s through the 1980s.  As I indicated to the Congress recently, however, the period of predictable velocity is too brief to justify restoring M2 to its role of earlier years, though clearly persistent outsized changes would get our attention.  Increasingly since 1982 we have been setting the funds rate directly in response to a wide variety of factors and forecasts.  We recognize that, in fixing the short-term rate, we lose much of the information on the balance of money supply and demand that changing market rates afford, but for the moment we see no alternative.  In the current state of our knowledge, money demand has become too difficult to predict.  Although our operating target is a nominal short-term rate, we view its linkages to spending and prices as indirect and complex.  For one, arguably, it is real, not nominal, rates that are more relevant to spending.  For another, spending, prices and other economic variables respond to a whole host of financial variables.  Hence, in judging the stance of policy we routinely look at the financial impulses coming from foreign exchange, bond, and equity markets, along with  supply conditions in credit markets generally, including at financial intermediaries.  Nonetheless, we recognize that inflation is fundamentally a monetary phenomenon, and ultimately determined by the growth of the stock of money, not by nominal or real interest rates.  In current circumstances, however, determining which financial data should be aggregated to provide an appropriate empirical proxy for the money stock that tracks income and spending represents a severe challenge for monetary analysts.  The absence of a monetary aggregate anchor, however, has not left policy completely adrift.  From a longer-term perspective we have been guided by a firm commitment to contain any forces that would undermine economic expansion and efficiency by raising inflation, and we have kept our focus firmly on the ultimate goal of achieving price stability.  Within that framework we have attempted not only to lean against the potential for an overheating economy, but also to cushion shortfalls in economic growth.  And, recognizing the lags in the effects of policy, we have tried to move in anticipation of such disequilibria developing.  But this is a very general framework and does not present clear guidance for day-to-day policy decisions. Thus, as the historic relationship between measured money supply and spending deteriorated, policymaking, seeing no alternative, turned more eclectic and discretionary.  Nonetheless, we try to develop as best we can a stable conceptual framework, so policy actions are as regular and predictable as possible that is, governed by systematic behavior but open to evidence of structural macroeconomic changes that require policy to adapt.     The application of such an approach is illustrated by a number of disparate events we have confronted since 1982 that were in some important respects outside our previous experience.  In the early and mid-1980s, the FOMC faced most notably the sharp swings in fiscal policy, the unprecedented rise and fall of the dollar, and the associated shifts in international trade and capital flows.  But I will concentrate on several events of the last decade where I personally participated in forming the judgments used in policy implementation.    One such event was the stock market crash of October 1987 shortly after I arrived.  Unlike many uncertain situations that have confronted monetary policy, there was little question that the appropriate central bank action was to ease policy significantly.  We knew we would soon have to sop up the excess liquidity that we added to the system, but the timing and, I believe, the magnitude of our actions were among our easier decisions.  Our concerns at that time reflected questions about how the financial markets and the economy would respond to the shock of a decline of more than one-fifth in stock prices in one day, and whether monetary policy alone could stabilize the system.  By the early spring of 1988 it was evident that the economy had stabilized and we needed to begin reversing the easy stance of policy.  Another development that confronted policy was the commercial property price bust of the late 1980s and early 1990s.  Since a large volume of bank and thrift loans was tied to the real estate market and backed by real estate collateral, the fall in property prices impaired the capital of a large number of depositories.  These institutions reacted by curtailing new lending the unprecedented \"credit crunch\" of 1990 and 1991.  Not unexpectedly, our policy response was to move toward significant ease.  Our primary concern was the state of the credit markets and the economy, but we could also see that these broader issues were linked inextricably to the state of depository institutions' balance sheets and profitability.  A satisfactory recovery from the recession of that period, in our judgment, required the active participation of a viable banking system.  The extraordinary circumstances dictated a highly unusual path for monetary policy.  The stance of policy eased substantially even after the economy began to recover from the 1990-91 recession, and a stimulative policy was deliberately maintained well into the early expansion period.  By mid-1993, however, property prices stabilized and the credit crunch gradually began to dissipate.  It was clear as the year moved toward a close that monetary policy, characterized by a real federal funds rate of virtually zero, was now far too easy in light of the strengthening economy on the horizon.  Financial and economic conditions were returning to more traditional relationships, and policy had to shift from a situation-specific formulation to one based more closely on previous historical patterns.  Although it was difficult at that time to discern any overt inflationary signals, the balance of risks, in our judgment, clearly dictated preemptive action.  The 1994 to 1995 period was most instructive.  It appears we were successful in moving preemptively to throttle down an impending unstable boom, which almost surely would have resulted in the current expansion coming to an earlier halt.  Because this was the first change in the stance of policy after a prolonged period of unusual ease, we took special care to spell out our analysis and expectations for policy in an unusually explicit way to inform the markets well before we began to tighten.  In addition, we began for the first time to issue explanatory statements as changes in the stance of policy were implemented.  Even so, the idea of tightening to head off inflation before it was visible in the data was not universally applauded or perhaps understood.  Financial markets reacted unusually strongly to our 1994 policy actions, often ratcheting up their expectations for further rate increases when we actually tightened, resulting in very large increases in longer-term interest rates.  At the time, these reactions seemed to reflect the extent to which investment strategies had been counting on a persistence of low interest rates.  This was a classic case in which we had to be careful not to allow market expectations of Federal Reserve actions to be major elements of policy determination.  We are always concerned about assuming that short-term movements in market prices are reflections of changes in underlying supply and demand conditions when we may be observing nothing more than fluctuating expectations about our own policy actions.  Most recently, the economy has demonstrated a remarkable confluence of robust growth, high resource utilization, and damped inflation.  Once again we have been faced with analyzing and reacting to a situation in which incoming data have not readily conformed to historical experience.    Specifically, the persistence of rising profit margins in the face of stable or falling inflation raises the question of what is happening to productivity.  If data on profits and prices are even approximately accurate, total consolidated corporate unit costs have, of necessity, been materially contained.  With labor costs constituting three-fourths of costs, unless growth in compensation per hour is falling, which seems most unlikely from other information, it is difficult to avoid the conclusion that output per hour has to be rising at a pace significantly in excess of the officially published annual growth rate of nonfarm productivity of one percent over recent quarters.  The degree to which these data may be understated is underlined by backing out from the total what appears to be a reasonably accurate, or at least consistent, measure of productivity of corporate businesses.  The level of nonfarm noncorporate productivity implied by this exercise has been falling continuously since 1973 despite reasonable earnings margins for proprietorships and partnerships.  Presumably this reflects the significant upward bias in our measurement of service prices, which dominate our noncorporate sector.    Nonetheless, the still open question is whether productivity growth is in the process of picking up.  For it is the answer to this question that is material to the current debate between those who argue that the economy is entering a \"new era\" of greatly enhanced sustainable growth and unusually high levels of resource utilization, and those who do not.  A central bank, while needing to be open to evidence of structural economic change, also needs to be cautious.  Supplying excess liquidity to support growth that turns out to have been ephemeral would undermine the very good economic performance we have enjoyed.  We raised the federal funds rate in March to help protect against this latter possibility, and with labor resources currently stretched tight, we need to remain on alert.  Whatever its successes, the current monetary policy regime is far from ideal.  Each episode has had to be treated as unique or nearly so.  It may have been the best we could do at the moment.  But we continuously examine alternatives that might better anchor policy, so that it becomes less subject to the abilities of the Federal Open Market Committee to analyze developments and make predictions.  Gold was such an anchor or rule, prior to World War I, but it was first compromised and eventually abandoned because it restrained the type of discretionary monetary and fiscal policies that modern democracies appear to value.  A fixed, or even adaptive, rule on the expansion of the monetary base would anchor the system, but it is hard to envision acceptance for that approach because it also limits economic policy discretion.  Moreover, flows of U.S. currency abroad, which are variable and difficult to estimate, and bank reserves avoidance are subverting any relationship that might have existed between growth in the monetary base and U.S. economic performance.    Another type of rule using readings on output and prices to help guide monetary policy, such as John Taylor's, has attracted widening interest in recent years in the financial markets, the academic community, and at central banks.  Taylor-type rules or reaction functions have a number of attractive features.  They assume that central banks can appropriately pay attention simultaneously to developments in both output and inflation, provided their reactions occur in the context of a longer-run goal of price stability and that they recognize that activity is limited by the economy's sustainable potential.  As Taylor himself has pointed out, these types of formulations are at best \"guideposts\" to help central banks, not inflexible rules that eliminate discretion.  One reason is that their formulation depends on the values of certain key variables most crucially the equilibrium real federal funds rate and the production potential of the economy.  In practice these have been obtained by observation of past macroeconomic behavior either through informal inspection of the data, or more formally as embedded in models.  In that sense, like all rules, as I noted earlier, they embody a forecast that the future will be like the past.  Unfortunately, however, history is not an infallible guide to the future, and the levels of these two variables are currently under active debate.  The mechanics of monetary policy that I have been addressing are merely means to an end.  What are we endeavoring to achieve, and why?  The goal of macroeconomic policy should be maximum sustainable growth over the long term, and evidence has continued to accumulate around the world that price stability is a necessary condition for the achievement of that goal.  Beyond this very general statement, however, lie difficult issues of concept and measurement for policymakers and academicians to keep us occupied for the next fifteen years and more.   Inflation impairs economic efficiency in part because people have difficulty separating movements in relative prices from movements in the general price level.  But what prices matter?  Certainly prices of goods and services now being produced our basic measure of inflation matter.  But what about prices of claims on future goods and services, like equities, real estate or other earning assets?  Is stability in the average level of these prices essential to the stability of the economy?  Recent Japanese economic history only underlines the difficulty and importance of this question.  The prices of final goods and services were stable in Japan in the mid-to-late 1980s, but soaring asset prices distorted resource allocation and ultimately undermined the performance of the macroeconomy.  In the United States, evaluating the effects on the economy of shifts in balance sheets and variations in asset prices have been an integral part of the development of monetary policy.  In recent years, for example, we have expended considerable effort to understand the implications of changes in household balance sheets in the form of high and rising consumer debt burdens and increases in market wealth from the run-up in the stock market.  And the equity market itself has been the subject of analysis as we attempt to assess the implications for financial and economic stability of the extraordinary rise in equity prices a rise based apparently on continuing upward revisions in estimates of our corporations' already robust long-term earning prospects.  But, unless they are moving together, prices of assets and of goods and services cannot both be an objective of a particular monetary policy, which, after all, has one effective instrument the short-term interest rate.  We have chosen product prices as our primary focus on the grounds that stability in the average level of these prices is likely to be consistent with financial stability as well as maximum sustainable growth.  History, however, is somewhat ambiguous on the issue of whether central banks can safely ignore asset markets, except as they affect product prices.  Over the coming decades, moreover, what constitutes product price and, hence, price stability will itself become harder to measure.  When industrial product was the centerpiece of the economy during the first two-thirds of this century, our overall price indexes served us well.  Pricing a pound of electrolytic copper presented few definitional problems.  The price of a ton of cold rolled steel sheet, or a linear yard of cotton broad woven fabrics, could be reasonably compared over a period of years.  I have already noted the problems in defining price and output and, hence, in measuring productivity over the past twenty years.  The simple notion of price has turned decidedly complex.  What is the price of a unit of software or of a medical procedure?  How does one evaluate the price change of a cataract operation over a ten-year period when the nature of the procedure and its impact on the patient has been altered so radically?  The pace of change and the shifting to harder-to-measure types of output are more likely to quicken than to slow down.  Indeed, how will we measure inflation in the future when our data using current techniques could become increasingly less adequate to trace price trends over time?  However, so long as individuals make contractual arrangements for future payments valued in dollars and other currencies, there must be a presumption on the part of those involved in the transaction about the future purchasing power of money.  No matter how complex individual products become, there will always be some general sense of the purchasing power of money both across time and across goods and services.  Hence, we must assume that embodied in all products is some unit of output, and hence of price, that is recognizable to producers and consumers and upon which they will base their decisions.  The emergence of inflation-indexed bonds does not solve the problem of pinning down an economically meaningful measure of the general price level.  While there is, of course, an inflation expectation premium embodied in all nominal interest rates, it is fundamentally unobservable.  Returns on indexed bonds are tied to forecasts of specific published price indexes, which may or may not reflect the market's judgment of the future purchasing power of money.  To the extent they do not, of course, the implicit real interest rate is biased in the opposite direction. ",
                  "1997-09-05 00:00:00"
                ],
                [
                  "39",
                  "Governor Laurence H. Meyer",
                  " I am very pleased to be here in Boston to discuss affordable housing with the members of the National Association of Affordable Housing Lenders.  Since coming to the Board and particularly since becoming Chairman of the Boards Committee on Consumer and Community Affairs and a member of the board of the Neighborhood Reinvestment Corporation, I have had an opportunity to tour housing initiatives in a number of communities, to see community development nonprofits working side by side with bankers, and to get a first-hand look at the problems and successes in making affordable housing available to families of low and moderate incomes.  This afternoon, I want to share with you some thoughts on the roles that the Federal Reserve and financial institutions are playing in supporting the affordable housing market and then touch on some challenges we face in sustaining the growth of affordable housing finance. Monetary Policy and Affordable Housing  Let me begin with a few words about the role that monetary policy can and cannot play in promoting affordable housing.  Interest rates certainly are an important element in the housing affordability calculus.  It might therefore appear that the Federal Reserve could make a significant contribution to housing affordability by working to keep interest rates low.   What monetary policy can do Monetary policy can, at least indirectly, make an important contribution to affordable housing, by pursuing price stability and maximum sustainable employment, the dual mandate that Congress has established for the Federal Reserve.   First, by promoting price stability, monetary policy can keep nominal interest rates low.  Whereas most forms of spending depend primarily on real interest rates, the housing market is significantly affected by nominal interest rates which greatly influence the ability of borrowers to qualify for and service mortgages.  Because nominal interest rates rise and fall with changes in inflation expectations, the pursuit of price stability directly contributes to low nominal interest rates.  Second, to the extent that the Federal Reserve is successful in helping maintain maximum sustainable employment, it will contribute to a healthy economic environment of stable and high levels of income and employment.  Clearly recessions and periods of high unemployment increase economic stress and exacerbate affordable housing problems.  What monetary policy cannot do I am often asked whether monetary policy is capable of doing still more, of making a conscious and direct effort to remedy social problems, including affordable housing, above and beyond what it can accomplish indirectly by pursuing its traditional macroeconomic objectives.  This question is often posed by community groups in advance of Federal Open Market Committee meetings and by members of Congress in those instances when FOMC decisions raise the federal funds rate.  Specifically,  shouldnt the Fed lower interest rates or avoid raising rates to support social policy objectives, such as affordable housing?  The simple answer is: No.  The reason why the Federal Reserve should not take on this commitment is that it exceeds the limits of what monetary policy can deliver.  We have one policy instrument, a short-term interest rate, and two macroeconomic objectives, full employment and price stability.  Pursuing these broad macroeconomic objectives is truly a full-time job for monetary policy.  We cannot do more.  In particular, monetary policy cannot target particular quintiles of the income distribution, particular regions or communities, or particular sectors of the economy.  Fortunately, by pursuing its broad macroeconomics objectives, monetary policy can make an important indirect contribution to affordable housing. Other Federal Reserve Efforts in Support of Affordable Housing  The Federal Reserve can and does play a more direct supporting role in promoting affordable housing, above and beyond the indirect contribution from monetary policy, in a variety of ways.  For example, the Federal Reserve assesses CRA performance and monitors compliance with fair lending laws to ensure equitable treatment of all applicants.  I believe that the encouragement and incentives provided by CRA have contributed to the expanded participation of depository institutions in affordable housing.  In addition, principally through its Community Affairs program at each of the twelve Federal Reserve Banks, the Federal Reserve has supplemented its bank supervision role with an expansive program of educational and informational activities designed to help banks and their communities understand community needs and the potential of community development partnerships, including those for affordable housing.   This past year alone, the Federal Reserve System sponsored more than 200 conferences and workshops on community development and reinvestment topics  attended by more than 11,000 bankers and others.  Over 74,000 bankers and others regularly receive Community Affairs newsletters.  The Reserve Banks often play active roles in forming and supporting multi-bank community development lending organizations.  For example, the San Francisco, Atlanta and Boston Reserve Banks have all assisted in the creation of community reinvestment consortia in their districts and provide advisory and administrative support to these organizations.  Collectively, these organizations represent over 400 commercial banks, thrifts, and savings and loans, with loan commitments and fundings totaling over $800 million.    Another excellent example of the activities of the Community Affairs programs is the major initiative six Federal Reserve Banks are currently undertaking to help identify and address barriers to equal access to credit in the home buying process.  The Federal Reserve Banks of Boston, New York, Cleveland, St. Louis, Chicago and San Francisco each initiated community-targeted programs designed to bring together key participants in the home buying process, such as Realtors, appraisers, property insurers, and lenders, along with community representatives, to discuss problems affecting minority and lower-income home buyers and to forge solutions.  Cross-industry task groups have now issued findings and recommendations and, more importantly, have developed action plans to ensure effective implementation.  I know that the Residential Mortgage Project is well along here in Boston, and that Reserve Bank President Minehan has been deeply involved.  The Affordable Housing Marketplace  But when monetary policy has done all it can do,  there will still be an affordable housing problem.  And while I have discussed some additional roles the Federal Reserve can and does play to promote affordable housing, it is the people in this room who do the heavy lifting.  You and your organizations represent the backbone of what has become a full-function affordable housing delivery system.    The two key elements that really distinguish the affordable housing market from virtually every other line of business in which financial institutions engage are: one, its broad structure of working partnerships with a remarkably diverse set of players; and, two, its unique set of financial tools that often use third-party resources to help leverage private financing.  Perhaps one of the best illustrations of the use of partnerships and leveraging is the NeighborWorks Campaign for Home Ownership, a coordinated effort by over 100 NeighborWorks organizations to form working partnerships with financial institutions, public agencies and others and create special loan products and in-depth mortgage counseling programs.  The Campaign recently completed its fourth year.  The results: thus far, the Campaign helped over 10,000 low- and moderate-income families become new homeowners and helped leverage over $700 million in investment in economically distressed communities.  What's amazing, however, is that 20 years ago, many of these types of partnerships and the financial tools commonly used now did not exist, and some were just beginning to take shape.  The sheer number and diversity of players and their efforts have helped create healthy competition for loans and resources.  And that competition appears, at least on the home mortgage side, to be producing significant benefits for low- and moderate-income borrowers.  Sustaining the Affordable Housing Delivery System  Although the efforts of the organizations represented here today have been impressive, we have learned that loan programs that specifically target low- and moderate-income persons or areas can raise a multitude of problems and issues.  We need therefore to work together on a number of fronts to ensure continued success and further progress.  There are still a number of challenges to meeting the demand for affordable housing, and more may be on the horizon.  Let me touch on a few that I believe may have broad impact.  Need for Continuing Education, Technical Assistance and Research One quite important challenge is to maintain and expand the education, technical assistance and, especially, the research components of the affordable housing finance system.  The Federal Reserve certainly considers itself a partner in that process.   As an economist, I subscribe to the principle that free markets work best when information about the economic performance of participants is readily available.  The better the information about market opportunities or unmet needs, the more likely it is that someone will find a way to fill them.  That principle certainly applies to financial institutions and their relationships with low- and moderate-income and minority communities.  The more banks and thrifts have learned, the more they have served the financial needs of those markets. Portfolio Research One area in which more information will be critical is in lending standards and risk factors.  I believe that there is a continuing need for additional research on lending standards and how they relate to delinquency, default and loss rates.  Efforts such as the borrower education programs as part of the NeighborWorks Campaign for home ownership and a number of special bank and thrift loan products using flexible standards have demonstrated success in serving low- and moderate-income borrowers, while keeping delinquency and default rates at acceptable levels.  Other products have been less successful.  Lenders, private mortgage insurers, the secondary market agencies, and the Federal Reserve have begun to do important research on factors affecting the performance of their affordable mortgage portfolios, and this is beginning to shed considerable light on many issues faced by all participants in this market.  That type of research has only become possible recently, as institutions and nonprofit organizations have developed affordable housing loan portfolios that were large enough to analyze effectively.  But we need more and better research to help sustain the affordable housing finance delivery system.  I hope all of you will continue to develop research and share the kind of information that will help all participants to better understand affordable housing lending. Consolidation of Banking Another key challenge is the ongoing consolidation of the banking industry.  The commitment of the banking organizations and thrifts to the affordable housing market has been as welcomed as it has been impressive.  In part, institutions have been successful because they committed the personnel and resources that were necessary to learn the business and compete in local markets with specialized products, marketing programs and organizational units, right down to the neighborhood level.   With the increasing pace of consolidation of financial institutions, however, there are emerging concerns that the resources and personnel devoted to affordable housing and other community development activities may be decreasing relative to the increasing size of institutions.  Some institutions are placing more emphasis on standardized loan products, and are adopting credit scoring systems for many types of loans, including affordable mortgage loans.  Although this may reflect lenders efforts to reduce the substantial upfront costs of making a loan and generate loan volumes consistent with economies of scale, there are growing concerns that this approach may not be sufficiently responsive to the special circumstances and needs of lower income households. Whether increasingly larger institutions can maintain the level of commitment to affordable housing and community development in proportion to their increased size  remains to be seen, but it is a growing concern to community groups and others.   Secondary Market Issues Another key issue is the continued lack of a well-developed secondary market for affordable housing loans, especially for multi-family housing loans.  This remains a major impediment to financial institution participation.  Community development projects usually require longer term, fixed-rate financing to achieve affordability for renters or buyers and financial institutions have difficulty funding such loans without incurring unacceptable interest rate risk.  Lack of a reliable secondary market outlet for such loans continues to limit the number and amounts of community development loans that any one institution can make.  There is some secondary market activity fueled by private placements of loans, purchases by socially minded investors, and some new initiatives by Fannie Mae, Freddie Mac, Local Initiatives Managed Assets Corporation (LIMAC), and Neighborhood Housing Services of America (NHSA).  These have provided some spot relief, but much larger, institutionalized efforts are needed.  This may be another area in which additional research can help.  There are a number of existing multi-family portfolios, including those produced by a growing number of multi-bank consortia, that are of sufficient size and maturity as to warrant a closer look at how underwriting criteria are related to risk factors. Minority Lending Finally, the specter of discrimination in mortgage lending will continue to drive public scrutiny of the mortgage business generally, and affordable housing lending, in particular.   As you may know, HMDA data for 1996 was recently released by the FFIEC and compared to recent experience was disappointing in certain respects.  Overall, lending to low- and moderate-income households did increase by nearly 18% over 1995 levels, more than the 12% increase in lending to higher income households, and the number of home purchase loans of all types extended to all minorities was somewhat higher in 1996 than in 1995.  But the number of loans to black households increased by only 3% over 1995 levels, the smallest growth experienced by this group in recent years.  Moreover, if the focus is only on conventional mortgages, the number of loans to black households actually fell 1.5% from 1995.  As a result, there is concern in some quarters that lenders might be retreating from their commitment to minority lending.  The longer-term trend in the number of home purchase loans extended to black households does not appear to justify an overly pessimistic reading of the 1996 data.  Since 1993, even with only the modest growth in 1996, loans to black households are up 53% while loans made to whites are up 14%.  There was a sharp jump in such lending beginning in 1992 and 1993, reflecting the start of a number of affordable lending programs, increased enforcement of fair lending standards, and the beginning of the current economic recovery.  It is not surprising that there would be a slower pace of increase after this initial jump.  While denial rates for conventional home loans remained higher in 1996 for black applicants than for other groups, all racial and ethnic groups experienced higher denials in 1996 than in 1995.  This might suggest that a greater number of relatively marginally qualified applicants sought home loans in 1996, perhaps as a result of the heavy marketing of affordable home loan products.  The increase in denial rates might also reflect a tightening of underwriting standards in response to somewhat higher delinquency rates on loans underwritten using multiple flexibilities.  We are continuing to look at the data to determine the possible reasons for the slower growth in loans to black borrowers in 1996 and the increase in application denial rates for all racial and ethnic groups.  The Federal Reserve, as well as all of the banking agencies, remains concerned about maintaining an equitable mortgage application and lending system.  If there are additional barriers to minorities in the mortgage process not faced by others, they must be addressed.   Conclusion",
                  "1997-09-04 00:00:00"
                ],
                [
                  "40",
                  "Governor Laurence H. Meyer",
                  " Before coming to the Federal Reserve Board, I frankly didn't fully appreciate the scope of the Fed's involvement in encouraging bank involvement in community development and reinvestment.  But I am learning quickly.  As a Federal Reserve Board member, and a member of the Board of the Neighborhood Reinvestment Corporation, I have taken the opportunity to visit with NHS organizations on several of my trips to Reserve Bank cities, and I can't help but be impressed with the incredible work NeighborWorks groups do with their banking and other partners.    Recently, in fact, I toured several NHS neighborhoods right here in New York, with a mixed group of NHS leaders, bankers and others.  I remember that as we traveled together on the bus, I was struck by how well the bankers and neighborhood residents worked together to solve problems and understood each others' perspectives and needs.  What impressed me most was the spirit of teamwork among the bankers and the neighborhood representatives and their genuine enthusiasm for the process and the projects we saw.  The partnership approach to community development is certainly alive and well, and its living and thriving in NeighborWorks organizations. The NeighborWorks Model In fact, I admit that I sometimes refer to this partnership approach to community development as the NeighborWorks \"formula,\" though that may be somewhat of a misnomer given the flexibility of the approach to adapt to different conditions in NeighborWorks neighborhoods throughout the country.  From the outside looking in, and viewing it in action, it appears on the surface to be a simple formula: involve neighborhood residents, nonprofit development groups and the public and private sectors in a multi-faceted program that attacks neighborhood problems on a comprehensive basis.  In short, the  NeighborWorks model focuses on the overall economic health and well being of neighborhoods, not just on housing, and uses a sound, public/private partnership approach to attack neighborhood problems.  Yes, I guess that might look simple to the uninitiated.  But as everyone in this room knows and I've come to learn, it's an extraordinary process in which much can go wrong if NHS leadership and vision are missing, or if bankers are unwilling to take a closer look at lending opportunities in neighborhoods.  Campaign for Home Ownership  There may be no better example of the NHS partnership model than the recently completed four-year National Campaign for Home Ownership in which NHS of New York, along with over 100 other NeighborWorks groups from around the country, participated.  The Campaign helped over 10,000 low- and moderate-income families become new homeowners through major partnerships with banks, thrifts, insurance companies, foundations and other private companies.  In doing so, the Campaign helped attract over $700 million in investment in economically distressed communities.  The NHS of New York should be extremely proud that it was the number two producer during the campaign, helping over 900 families to become homeowners. Full-Cycle Lending These are really quite extraordinary accomplishments for the NetWork participants, and especially for NHS of New York.  At the person-to-person level, the campaign provided services that literally helped change the lives of families and the futures of neighborhoods.  At another level, the campaign was a clear demonstration of the wisdom and strength of the NHS partnership approach.  In this case, the formula is the NetWork's \"Full-Cycle Lending\" system.  Using the system, NHS organized the partnerships among bankers, public officials, residents and others at the local level.  It provided pre-purchase home buyer education that is so important in helping new home buyers to wade through the complexities of financing a real estate purchase.  The NHS also worked with lenders, insurers, secondary market participants and others to help create flexible loan products, and provided property inspection services.  And finally, the NHS continues to provide post-purchase counseling for the new home owners to help retain neighborhood stability and avoid delinquency and default.     Did I say that this was a simple model? about as simple as, well... maybe macroeconomics.  Banking and the Future of Community Development My visits with NHS here and in other cities have given me an opportunity to see how the NHS model works under a variety of conditions.  And that has been invaluable in itself.  But it also gave me a chance to reflect on why the model works and how to keep it working in the future in the face of dramatic changes in government policy, the banking industry, and larger economic forces developing in the wider economy.  So as we think about your accomplishments, I want to share some thoughts with you concerning several challenges that I believe confront NeighborWorks and other community-based development organizations in keeping the model viable.  I think some of these issues confront the NeighborWorks Network as a whole, while others will be more of a challenge for bankers.  Why the NHS Model Works First...briefly... why I think the NHS model works.  I believe that the NHS model works because it's a true partnership based on respect for the considerable knowledge and experience of the partners.  Each of the partners involved in process is willing to work with the others and forgo some benefits that might be demanded in other situations.  The NHS partnership model works because it usually is able to take the long-term view of neighborhood revitalization, with a special interest in making the neighborhood viable for low- and moderate-income residents.  Although the model often utilizes public and private sector subsidies, it helps maximize the benefits of the subsidies.  Finally, and perhaps most importantly, the partnership works because it is adaptable to different local conditions. Adapting to Change Will the model continue to work in the future?  We all hope so. Certainly the NHS model appears to be a good fit with current and emerging public policy.  Large federal programs as a response to community and neighborhood problems are probably a thing of the past. Public policy now emphasizes decentralization; community development, as well as other programs now must reflect local solutions to local problems and private sector participation at the local level is imperative.  As the NHS model demonstrates, that policy makes a lot of sense.  But I think that we're all realists and recognize that the model must be capable of responding to a rapidly changing community development environment.  The adaptability of the model and NeighborWorks organizations will continue to be tested by the changes in the economy and public policy environment.  What are some of those changes?  There are many, but let me focus on a few that I believe significantly affect community development finance and the role banks and other financial institutions will continue to play in the process. Changing Structure of Banking The first is the changing shape of banking and how that will affect bank participation in the kinds of programs supported by NeighborWorks organizations at the neighborhood level.  Clearly, there is a major restructuring of banking occurring in the United States.  Financial institutions are being allowed to offer a wider variety of financial products and services and the geographic restraints on depository institutions are finally falling away.  As a result, mergers and acquisitions are increasing and larger banking companies are moving interstate at a rapid pace.  Moreover, interstate branching will accelerate the movement toward standardization of loan products and use of standardized risk-based pricing models on a regional and national basis for many types of loans, including mortgage and small business credit.  So while public policy and community development continues to move in a decentralized direction, banking is becoming increasingly centralized.  In that kind of environment, what happens to bank participation in the community development process?  I believe that the challenge for bankers will be to remain committed to work with NeighborWorks groups to develop products and services responsive to the special needs of low- and moderate-income families.  Increasingly, that is being done with some new, fairly standardized products.  But in many cases, loan products will still have to be tailored to fit the unique conditions of individual neighborhoods.  I think bankers will be up to the task, especially if community-based organizations remain sensitive to bank needs in the new banking environment.  Need for Long-Term Approaches  All of us recognize that successful community development requires the long-term view and long-term commitment.  But the changing structure of banking is also reinforcing a second  challenge: how to maintain banking's long-term commitment to local community development in the face of changing bank ownership and the need to demonstrate short-term market gains.  Here in New York, in fact, many of the mutual savings institutions that were responsive to depositors were able to take the longer view and, along with larger money center banks, could support community development activity that was based on  multi-year goals and programs.  With many of the mutuals gone, however, and competition heating up, bank management is under increasing pressure to show short-term success and profits.  As a result, many bank functions, including community development, are being given profitability goals and measures that reflect short-term needs to satisfy stockholders.  Community development departments are restructuring.  One concern is that the new profitability goals will force some institutions to focus more on the higher end of the low- and moderate-income market, while placing less emphasis on neighborhoods and solutions that include a wide mix of incomes.  Financial institutions must be able to take longer view and make longer term commitments if neighborhood revitalization is to be successful.  I believe that this will be a major challenge for banks and for NeighborWorks groups. Post-lending Intervention Finally, let me mention another challenge that I believe is shared by bankers and NeighborWorks groups: the need to ensure that the performance of low/mod loan portfolios, whether those of a financial institution or an NHS's revolving loan fund, will be dependable.  While bankers and regulators recognize that many of these portfolios may not be as profitable as some conventional loan portfolios, it has been demonstrated across the country that they can be reasonably profitable, under certain conditions.  The major challenge in maintaining the performance of these portfolios is keeping delinquency and default at a fairly low and predictable level.  Most banks and community organizations try to reduce delinquency and default by working hard to create a good loan package on the front end, one that's affordable to the borrower and carries sufficient protection for the lender.  And I think that NeighborWorks groups have been at the forefront of the best practices in efforts to make good loans.    But many groups now recognize that what happens after the loan closing may be as important as good underwriting up front.  The new frontier in successful lending in low- and moderate-income communities just may be in post-purchase services, such as family budgeting, financial counseling, maintenance training and, perhaps, reduced-price maintenance services for low- and moderate-income borrowers.  These techniques have shown promise in helping reduce delinquencies and defaults to levels that help sustain the economic viability of loan portfolios.  How these services are provided and paid for, however, will continue to be a major challenge that I hope bankers and NeighborWorks groups will tackle together. Conclusion No doubt these and other challenges lie ahead.  But based on what I've seen so far, I would have to conclude that these challenges do not appear insurmountable.  There is, after all, much success and momentum to build upon.  There is a formula that has worked and a flexibility that has allowed that formula to be tailored to local needs and situations.  There is also a sense of teamwork and an innovative set of partnerships that provide the strength to meet future challenges.  And most of all, there is the idealism, passion, and unrelenting efforts of those who run and support community development organizations like NHS of New York. ",
                  "1997-06-18 00:00:00"
                ],
                [
                  "41",
                  "Governor Susan M. Phillips",
                  " The Changing Financial Landscape and Umbrella Supervision   It is a pleasure to be here today at the Exchequer Club.  I thank you for the opportunity to discuss the changing financial landscape and offer my own perspectives on what the future might bring.  During the next few months, there will be significant debates on various aspects of financial modernization, both within and without the halls of Congress.  These debates may well set the stage for how financial service companies will operate as we enter the twenty-first century.   As we can all plainly see, the world is changing across many dimensions, posing new and ever increasing challenges for both financial services firms and their supervisors.  To succeed in this new world, I believe it is important for the industry and supervisors to find common ground for coping with these challenges.  By working together to find solutions, we can accomplish our goals, while retaining the core principles and values that have contributed to the industrys success.   So today I would like to discuss briefly the changes underway affecting the financial services industry, as well as the individual and collective responses by the industry and supervisors to those changes.  Then lastly, I will offer some thoughts on what the role of an umbrella supervisor might look like in this changing environment for financial services.  All of these changes must be considered in the context of possible legislative reform.  The Changing World   As widely noted, dramatic advances in information and telecommunication technologies have allowed banks to develop new and more customized products and services and deliver them over a broader geographic area with greater efficiency.  Such innovations by the banking industry, and by financial markets in general, have increased the sophistication and complexity of bank lending, investing, trading, and funding.  They have propelled growth in less traditional or newer banking activities such as investment banking, mutual fund management, insurance and securitization.  In the process, the risk profiles of many banking organizations have been altered in fundamental ways,  placing greater pressure on management to monitor and manage underlying risks.   To meet this challenge, a growing number of institutions are employing modern financial theory for measuring and analyzing the trade-off between risk and returns.  The availability of dramatically more powerful computers at ever more affordable prices has allowed institutions to process vast data bases of rates, prices, defaults, and recoveries.  As a result, techniques for portfolio management and risk measurement that not long ago were possible only in theory are now becoming integral parts of daily operating practice.  By applying these theories and techniques, institutions today are more effectively pricing and hedging risk, allocating capital, evaluating risk-adjusted returns and identifying the optimum mix of financial products or services.  I believe these enhanced management practices have contributed importantly to the economic growth and market gains seen in recent years.   As competition has intensified, we have seen a growing overlap in the activities and product lines provided by both banks and other financial service providers that has diminished the past distinction between banks and many nonbank firms.  That trend has raised public policy questions regarding bank powers and the appropriate organizational structure through which banking organizations should gain new powers.  Proposals recently introduced in Congress to address those issues would fundamentally redefine the relationship of banks to other financial services companies and in some instances their relationship to commercial firms as well.   Banks have not only expanded their products and activities, but have also expanded their geographic reach, both domestically and globally.  Within the United States, banks have expanded nationwide as barriers to interstate banking have been removed.  This expansion should continue as banks exercise their new power to branch across state lines.  A related domestic trend is the rapid consolidation within and between banking organizations.  Although some consolidation is undoubtedly related to the removal of barriers to interstate branching, it is also spurred by improved technology, strong competition in banking markets, and the drive by banks to reduce costs.   Internationally, the globalization of banking has accelerated, driven by  improved technology and the opening of economies in eastern Europe, Asia, Latin America, and other regions.  In particular, U.S. and other international financial institutions are forging a growing presence in lending, trading, and underwriting in these emerging markets.   These efforts have created closer links among the worlds financial markets and have improved the efficiency and availability of capital.  However, market integration has also increased the potential for systemic problems to transcend national borders, as the volume of international financial transactions has grown.  Last year, for example, an estimated $1.5 trillion of foreign exchange contracts were settled daily in New York City alone.  A default by a major U.S. or foreign participant in that market could disrupt financial markets worldwide.   Competitive pressures are intense to reduce the cost of financial services to the public.  This is occurring against the need to improve the financial strength and competitiveness of the banking industry from the levels at the beginning of this decade.  These factors have, in turn, also placed pressure on the banking agencies to remove unnecessary burdens on the industry without threatening safety and soundness.  Regulatory and Supervisory Responses to Change  What have been the regulatory and supervisory responses to these changes?  Let me first discuss how we addressed the issue of regulatory burden.  Although the poor bank profitability of the 1980s and early 1990s was mostly related to industry asset quality problems, regulators and Congress alike recognized that improvements could be made in bank regulations and in supervisory processes to improve credit availability and bank competitiveness without sacrificing safety and soundness.     Both legislative and regulatory efforts undertaken in the decade of the 1990s have simplified regulatory reporting requirements, expedited the application process, eliminated duplicate regulatory filings, and have led to more streamlined and uniform banking agency guidelines and regulations.  Taken individually, these and other refinements may not appear material, but taken as a whole they have put a meaningful dent in regulatory costs.  In fact, the industry on several occasions has reminded us that it is not necessarily any particular individual regulatory requirement that is problematic, but rather, their cumulative effect, much like the straw that broke the camels back.  We have taken that point to heart when considering new guidelines and regulations.   Efforts to reduce regulatory burden apply not only to banks, but to holding companies as well.  Earlier this year, for example, the Board streamlined Regulation Y and reduced application requirements.  These changes recognize that regulatory burden arises not only from the direct operational costs of compliance, but also from the indirect costs of delayed or lost opportunities to enter new activities.   To reduce impediments, the Board has decided that the application process should focus on the analysis of the effects of a specific proposal, and should not generally become a vehicle for comprehensively evaluating and addressing supervisory and compliance issues.  Rather, the latter can more effectively be addressed in the supervisory process.  The Board also recently completed a lengthy review of its policies and procedures for assessing the competitive implications of bank mergers and acquisitions.  Modifications have been made to that process to make it more efficient and address the potential benefits of scale economies for small bank mergers.    Another improvement in our regulations is the ability of well-capitalized, well-run companies to apply to acquire banks and nonbanks in a faster and more streamlined fashion and to commence nonbanking activities approved by regulation without obtaining prior approval.  To allow bank holding companies greater opportunities to innovate, the Board has also indicated that it will be pro-active in approving new activities.    Further efforts to provide flexibility and help modernize bank holding company regulation have been directed toward securities firms known as section 20 affiliates.  Last year the Board raised the Section 20 ineligible revenue limit on underwriting and dealing in securities from 10 to 25 percent.  This appears to be allowing greater flexibility for these operations.   The Board has also eliminated certain firewalls between banks and their securities affiliates and for other firewalls has proposed to eliminate or scale back even more, recognizing that other laws, regulations, and improved disclosures provide adequate protections against conflicts of interest.  These and other refinements should allow holding companies to move closer toward their goal of operating as a one-stop financial service firm for customers, while operating safely and soundly.   The Comptroller of the Currency has also taken steps to widen the breadth of activities undertaken by banking organizations. For example, the expansion of insurance sales activities has opened new opportunities for national banks.   Beyond efforts to reduce burden and  modernize banking powers, regulators are also redesigning their supervisory practices to address more effectively the changing nature of the industry.  These efforts are leading to  a more risk-focused approach to supervision.  That approach is more responsive to the industrys rapidly evolving activities and risk profiles and places emphasis on the institutions own ongoing system for managing risk, rather than point-in-time transaction testing.  By focusing resources on the areas of highest risk, and eliminating unnecessary procedures, this approach is not only more effective, but also less intrusive and costly to all parties.  I should note, however, that successfully implementing this approach requires that supervisors attract, train, and retain qualified staff while also upgrading training, automation, and other resources.  This is a continuing challenge indeed!   Regulators are also trying to build on private sector initiatives that promote safety, soundness and systemic stability.  For example, at the height of Congressional concern about financial derivatives, the Group of Thirty sponsored a study to identify principles of sound practice for managing risks in derivatives for both dealers and end-users.   By providing guidance on this issue, that study served as a catalyst for industry participants to analyze and evaluate their own practices.  Subsequent guidance from the Federal Reserve and the Comptroller benefited from the insights provided by the study, while adding a supervisors perspective.      The studys emphasis on education and sound practices spurred greater understanding and acceptance by the industry of supervisory recommendations for sound risk management systems.  I think it is safe to say that this cooperative approach between the private sector and regulators resulted in stronger industry practices and better supervisory oversight, not only for derivatives, but also for bank risk management more generally.  Together, the industry and agency response helped stave off potentially restrictive legislation.   Another example of how supervisors are trying to build on bank management practices is their use of internal value at risk models in the calculation of capital requirements for market risk.  By relying on internal models already used by the institutions for their trading and risk management activities, regulators can reduce burden while vastly improving the accuracy of the capital calculation.  In addition, by embracing internal models for regulatory purposes, supervisors are encouraging organizations to incorporate sophisticated risk models more fully and formally into their risk management systems and to continue to upgrade and improve the models.   As these two examples illustrate, supervisors recognize that they do not have all the answers and that rigid regulatory solutions may often do more harm than good.  A supervisory approach that promotes continued improvements in private sector practices provides the right incentives to industry and, in the case of banking, also reduces risks to the federal safety net.     In these ways, supervisors are placing greater reliance on a banks own risk management system as the first line of defense for ensuring safety and soundness.  We also want to rely more on market discipline as another line of defense.  This requires increased, improved disclosure of a banks activities, risk exposures, and philosophy for managing and controlling risk.  We have made significant gains for derivatives and market risks.  Hopefully we will see further gains in other areas in the years ahead.   While it is important for supervisors to identify risk at individual banks, as the central bank the Federal Reserve must also be watchful for conditions and trends external to the banking system that could place the financial system and the economy at risk.  This broader perspective has become especially important with the globalization of banking and integration of markets.  That is why the Federal Reserve has worked closely with financial regulators around the world to reduce systemic risk and promote sound banking practices and improved disclosures among both developed and emerging countries.  These efforts have led to the advancement by the BIS of core principles of bank supervision for authorities world-wide and, significantly, promotion of consolidated supervision of banking organizations by home country authorities.  The issue of consolidated supervision is particularly relevant in revisiting the question of the modernization of the banking system.  I will come to that in a moment.  Financial Modernization and Umbrella Supervision   First I would like to point out that whether legislative agreement is reached or not, market forces will continue the modernization of the financial services industry and will further blur the lines between banks and nonbanks.  For example, we can expect mutual funds to refine their offerings to compete with bank checking and savings accounts, albeit without deposit insurance.  Banks will undoubtedly make further inroads in mutual fund management and investment banking through internal growth and through acquisitions of securities firms.  Investment banks may also  supplement their services by making commercial loans and participating in loan syndications.   With such things happening, why do we need a legislative solution?  The answer is that a well thought out proposal addressing the appropriate structure for the industry would allow for a more rapid and efficient integration of financial services.  Moreover, by clearly defining the boundaries and structure of financial conglomerates, a well considered supervisory program could adequately protect banks without undue intrusion to other parts of the conglomerate.   Because financial conglomerates generally operate as integrated entities and manage risks on a global basis across business lines, their true operating structure superimposes a risk management and internal control process that extends across legal-entity-based corporate structures.  In this light, supervision by legal entity can create important supervisory gaps that may expose the insured depository institution to unnecessary risk.   That is to say, someone should look at the risk management of the organization as an organic whole, rather than as separate pieces that are simply added together.  In fact,  comprehensive, consolidated supervision by the home country supervisor is a legal requirement for foreign banks operating in the U.S.  Some foreign supervisors are now beginning to question the consolidated supervision of U.S. firms operating in their countries.   Now, I suspect some nonbank firms may feel apprehension at having an umbrella supervisor evaluate their operations.  But let me emphasize that such oversight need not be overly onerous or intrusive.  In fact, regulators are probably better prepared than ever before to implement an umbrella supervisory approach as a result of the supervisory techniques and approaches I just discussed.  By applying risk-focused supervision, and promoting sound practices, and improved market disclosures, an umbrella supervisor should be able to implement an effective, unintrusive oversight process for conglomerates.  Moreover, an umbrella supervisor may be able to provide assurances and information to other regulators and individual supervisors which may minimize their need to extend their reviews beyond the legal supervised entity and into the conglomerates other operations, creating duplication and burden.   I believe that the umbrella supervisor, whether it is the central bank or another agency, should not attempt to duplicate efforts of other regulators.  Rather, the umbrella supervisor should evaluate the financial conglomerate from a more comprehensive perspective, bridging the gap between an organizations legal structure and its structure for taking and managing risk.  Similarly, the umbrella supervisor need not attempt to extend bank-like safety and soundness regulations to nonbank entities.  Those standards were never intended to apply to the nonbank entities of a conglomerate and would insert unnecessary competitive barriers without achieving the desired benefits.   How exactly should an umbrella supervisor meet its responsibilities?  First by focusing its supervisory efforts on the adequacy of the risk management and internal control process of the parent company and of the group as a whole, and determining how well those systems protect the safety and soundness of affiliated banks.   That evaluation could be performed in a manner similar to that of a securities analyst, albeit from a different viewpoint.  This assessment might involve analysis of public financial statements, rating agencies and Wall Street analyst reports, internal management reports, internal and external audit reports, meetings with management, and only limited, if any, on-site inspections of nonbank affiliates.  Any visits that are made could be limited to testing the adequacy of management and operating systems, to protect the insured depository institution.    While various approaches could be taken to address capital adequacy and to avoid the unnecessary or inappropriate use of double leverage, I believe such approaches should be measured against the goal of assuring the safety and soundness of the affiliated banks.  And finally, the umbrella supervisor should have appropriate enforcement authority, including the authority to require the sale of the bank in extreme situations.  Conclusion  It is clear that the financial services industry is changing and that banking powers must also change if banks are to remain competitive.   The Board has long supported reforms and strongly urges them today.  However, changes such as these carry risks.  It is important, therefore, that change be introduced properly through legislative debate and by adopting proper safeguards to ensure that nonbank activities do not unduly expose banks and taxpayers. ",
                  "1997-06-18 00:00:00"
                ],
                [
                  "42",
                  "Chairman Alan Greenspan",
                  "The Embrace of Free Markets  On November 9, 1989, the Berlin Wall came down, symbolizing the end of an experiment in economic and social policy that began more than four decades earlier with the division of the states of Western and Central Europe into market economies and those governed by state central planning.  At the end of World War II, as Winston Churchill put it, \"From Stettin in the Baltic to Trieste in the Adriatic an iron curtain ... descended across the Continent.\"  Aside from the Soviet Union itself, the economies on the Soviet side of the \"curtain\" had been, in the prewar period, similar to the market-based economies on the western side.  Over four decades both types of economies developed with limited interaction across the dividing line.  It was as close to a controlled experiment in the viability of economic systems as could ever be implemented.  The results, unequivocal in favor of market economies, have had far-reaching consequences.  The long-standing debate between the virtues of economies organized around free markets and those governed by centrally planned socialism is essentially at an end.  To be sure, there are still a few who still support the old fashioned socialism but for the vast majority of professed socialists it is now a highly diluted socialism, an amalgam of social equity and the efficiency of the market, often called market socialism.  The verdict on rigid central planning has been rendered, and it is generally appreciated to have been unequivocally negative.  Over the last seven years, with the Soviet bloc books now open, we of course have learned much about how communist economics worked, or, more to the point, did not.  But the biggest surprise is what the aftermath of the four-decade experiment has been teaching us about how and why our own Western economies and societies function, or, perhaps more exactly, refreshing our own long-dormant memories of the process.  Economists have had considerable experience this century in observing how market economies converted to centrally planned ones but until recently have had virtually no exposure in the opposite direction.  Ironically, in aiding in the process of implementing the latter, we are being forced to more fully understand the roots of our own system.  Much of what we took for granted in our free market system and assumed to be human nature was not nature at all, but culture.  The dismantling of the central planning function in an economy does not, as some had supposed, automatically establish a free market entrepreneurial system.  There is a vast amount of capitalist culture and infrastructure underpinning market economies that has evolved over generations: laws, conventions, behaviors, and a wide variety of business professions and practices that have no important functions in a centrally planned economy.  Centrally planned economic systems, such as that which existed in the Soviet Union, had great difficulty in creating wealth and rising standards of living.  In theory, and to a large extent in practice, production and distribution were determined by specific instructions often in the form of state orders coming from the central planning agencies to the various different producing establishments, indicating from whom, and in what quantities, they should receive their raw materials and services, and to whom they should distribute their final outputs.  The work force was assumed to be fully employed and wages were somewhat arbitrarily predetermined.  Without an effective market clearing mechanism, the consequences of such a paradigm, as one might readily anticipate, were both huge surpluses of goods which, while produced, were not wanted by the populace, and huge shortages of products that consumers desired but were not produced in adequate quantities.  The imbalance of demand over supply inevitably required rationing or its equivalent, standing in queues for limited quantities of goods and services.   One might think that the planning authorities should have been able to adjust to these distortions.  They tried.  But they faced insurmountable handicaps in that they did not have access to the immediate signals of price changes that so efficiently clear markets in capitalist economies.  Just as important, they did not have the signals of finance to adjust the allocation of physical resources to accommodate the shifting tastes of consumers.  In a centrally planned system, banking and finance play a decidedly minor role.  Since the production and distribution of goods and services are essentially driven by state orders and rationing, finance is little more than record keeping.  While there are pro-forma payment transfers among state-owned enterprises, few if any actions are driven by them.  Payment arrears, or even defaults, are largely irrelevant in the sense that they are essentially transactions among enterprises owned by the same entity, that is, the state.  Under central planning there are no credit standards, no interest rate risks, no market value changes, that is, none of the key financial signals that determine who gets credit, and who does not, and hence who produces what, and sells to whom, in a market economy.  In short, none of the financial infrastructure which converts the changing valuations of consumers into market signals that direct production for profit are available.  But it didn't matter in the Soviet-bloc economies.  Few decisions in those centrally planned systems were affected by the lack of a developed financial system.    That centrally planned economies, as a consequence, were highly inefficient is best illustrated by the fact that energy consumed per unit of output was as much as five to seven times higher in Eastern Europe and the former Soviet Union than in the West.  Moreover, the exceptionally large amount of resources devoted to capital investment, without contributing to the productive capacity of these economies, suggests that these resources were largely wasted.  Regrettably, until the Berlin Wall was breached and the need to develop market economies out of the rubble of Eastern Europe's central planning regime became apparent, little contemporary thought had been given to the institutional infrastructure required of markets.  Nonetheless, in the years immediately following the fall of the Berlin Wall many of the states of the former Soviet bloc did get something akin to a market system in the form of a rapid growth of black markets that replicated some of what seemingly goes on in a market economy.    But only in part.  Black markets, by definition, are not supported by the rule of law.  There are no rights to own and dispose of property protected by the enforcement power of the state.  There are no laws of contract or bankruptcy, or judicial review and determination again enforced by the state.  The essential infrastructure of a market economy is missing.  Black markets offer few of the benefits of legally sanctioned trade.  To know that the state will protect one's rights to property will encourage the taking of risks that create wealth and foster growth.  Few will risk their capital, however, if there is little assurance that the rewards of risk are secure from the arbitrary actions of government or street mobs.  Indeed, today's Russia is striving to rid itself of a substantial black market intertwined with its evolving market economy.  Law enforcement in support of private property is uneven in its application.  Private security forces, to a large extent, have taken over protection, with results sometimes less than satisfactory.  The shift of vast real resources from the defunct Soviet state to private parties, whose claims in many instances are perceived as dubious, has not enhanced public support for the protection of such claims by official authorities.  Some, but not all, would argue with the Russian academic who last month told the Washington Post that \"The state thinks ... private capital should be defended by those who have it. ...It's a completely conscious policy of the law enforcement authorities to remove themselves from defending private capital.\"  Certainly, if generations of Russians have been brought up on the Marxist notion that private property is \"theft,\" a breakdown of the Soviet central planning infrastructure is not going to automatically alter the perceived moral base of its social system.  The right to property in market economies, on the other hand, is morally rooted in its culture.  Indeed, the presumption of property ownership and the legality of its transfer must be deeply embedded in the culture of a society for free market economies to function effectively.  In the West and especially under British common law and its derivatives, the moral validity of property rights is accepted, or at least acquiesced in, by virtually the whole of the population.  Accordingly, a very small proportion of contracts have to be enforced through actions in the courts.  Moreover, reflecting a strong commitment to property rights, a surprisingly large number of contracts, especially in financial markets, are initially oral, confirmed only at a later date, and at times after much price movement, by a written document.  The differing attitudes and views toward property ownership are passed from generation to generation through family values and education systems.  Hence, the process of full transition from the so-called collective rights of socialist economies to the individual property rights of market economies and legal certainties can be expected to be slow.  One prominent young Russian reformer of my acquaintance thinks the transition is moving quickly among those under forty years of age, much less so among their elders.  Altering what a nation teaches its children is a profoundly difficult task and clearly cannot be accomplished overnight.  Changing attitudes toward property and profit is not simple.  These attitudes derive from the deepest values of personal worth people hold.  Aside from property rights enforced by an impartial judiciary, for a market economy to function effectively, there must also be widespread dissemination of timely financial and other relevant information.  This enables market participants to make the type of informed judgments that foster the most efficient allocation of capital efficient in the sense that our physical resources are directed at producing those goods and services most valued by consumers.  This requires a free press and government data information systems that are perceived to be free of hidden political manipulation.  Government censorship in any form renders information suspect.  Such information will be disregarded by market participants as virtually useless, requiring individuals to rely on rumor and other dubious sources of information.  This leads to misjudgments about the changing patterns of consumer demand and hence significantly eviscerates the market's effectiveness and its role in directing real resources to their optimum uses.  Most other rights that we Americans cherish protection against extra-legal violence or intimidation by the state, arbitrary confiscation of property without due process, as well as freedom of speech and of the press, and an absence of discrimination are all essential to an effective, functioning market system.  Indeed a list or bill of rights enforced by an impartial judiciary is, and I hesitate to use the analogy, what substitutes for the central planning function as the guiding mechanism of a free market economy.  It is these \"rights\" that enable the value judgements of millions of consumers to be converted through a legally protected free market into prices of products and financial instruments; and it is, of course, these market prices that substitute for the state orders of the centrally planned economies.  We depend on government in a free society to ensure those market \"rights.\"  Perhaps of greater importance, those rights can also be viewed as a list of prohibitions delimiting the actions of government.  Thus, the more effective the list is in constraining the arbitrary actions of government officials, the less it matters what they do.  The tighter the proscription on government officials' discretion, the less arbitrary government power is available to the highest bidder.  The democratic process, of course, is needed to ensure that the \"list of market rights\" has the continued sanction of the people.  Since any bill of rights specifies the limits to which government officials can infringe on the rights of individuals, the rational self-interest of the populace is always to protect and broaden individual rights.  The self-interest of those officials who have the power to exert discretionary power in areas not specifically delimited by a bill of rights, is, too often, to broaden that scope.  Hence, authoritarian societies, even benevolent ones, are biased to restraining the rights of individuals generally and property in particular.  Clearly, not all democracies protect the private right of property with the same fervor.  Indeed, they vary widely.  Nor is it the case that all societies with firmly protected property rights bend invariably to the majority will of the populace on all public issues.  Certainly in its earlier years Hong Kong did not have a democratic process but a \"list of rights\" protected by British common law and Britain's democracy.  Singapore, from a similar heritage, does protect property and contract rights, the crucial pillars of market efficiency, but does not have some of the other characteristics of western democracies with which we are familiar.  There are those who argue, however, that as this remarkable city-state evolves, increasing wealth will push it toward broader freedoms.  To summarize then, the ideal state of affairs for a centrally planned economy is one in which there is continuous production of the same type of goods, of the same quality, of the same design, obediently purchased in repetitive quantities, with cash wages backed as necessary by rationing coupons.  Centrally planned economies are frozen in time. They cannot readily accommodate innovation, new ideas, new products, and altered specifications.  In sharp contrast, capitalist market economies are driven by what Professor Joseph Schumpeter, a number of decades ago, called \"creative destruction.\"  By this he meant newer ways of doing things, newer products, and novel engineering and architectural insights that induce the continuous obsolescence and retirement of factories and equipment and a reshuffling of workers to new and different activities.  Market economies in that sense are continuously renewing themselves.  Innovation, risk taking, and competition are the driving forces that propel standards of living progressively higher. ",
                  "1997-06-10 00:00:00"
                ],
                [
                  "43",
                  "Governor Laurence H. Meyer",
                  "The Role of Banks in Small Business Finance Good afternoon.  It is a pleasure to be here to meet with you at New York University for this Conference on Small Business Finance.  It is clear from the conference program that there is an excellent mix of academics, government representatives, and practitioners here to study how small business is financed.  Indeed, I am glad to see so much attention being paid to this important topic.  Small business is a vital and energetic part of our economy that plays a key role in the generation of jobs, new ideas, and the encouragement of entrepreneurial activity.  Without doubt, a thriving small business sector contributes to the well-being of our nation.  Today, I would like to share with you some thoughts about the role of banks in supplying credit to small business.  The part played by banks in small business finance is not a new topic for the Federal Reserve.  In fact, for many years we have been devoting substantial resources to collecting and analyzing data on small business finance generally, and the credit supplied by banks in particular.  We collect data from small businesses on how they obtain financing   or in some cases fail to obtain financing   using the National Survey of Small Business Finance and the Survey of Consumer Finances.   We also gather information directly on the small business credit extended by individual commercial banks.  We have collected information on the contract terms of bank loans to both small and large businesses since 1977 through the Survey of Terms of Bank Lending to Business.  Since 1993, the banking agencies have required all commercial banks to report their quantities of loans to businesses by size of loan on the June Call Reports.  Lastly, as part of revised Community Reinvestment Act procedures, the banking agencies have just this year begun to collect data on small business loans by local geographic area.  When these data become available, they should prove to be a rich source of new information.  A number of economists have used the existing data in research that has helped us to better understand the potential effects on the supply of small business credit of public  policies regarding bank mergers and acquisitions, financial modernization, and prudential supervision and regulation.  For example, some have argued that the consolidation of the banking industry may be reducing the supply of credit to small business, since larger banking institutions tend to devote smaller proportions of their assets to small business lending.   Solid economic research applying modern econometric techniques to accurate data is needed to evaluate such claims and to determine the likely effects of policy actions in order to improve future policy decisions.    The Importance of the Bank-Small Business Relationship According to our survey information, commercial banks are the single most important source of external credit to small firms.  Small businesses rely on banks not just for a reliable supply of credit, but for transactions and deposit services as well.  Because of their needs for banking services on both the asset and liability sides of their balance sheets, small businesses typically enter into relationships with nearby banks.  The data show, for example, that 85 percent of small businesses use the services of a commercial bank within 30 miles of their firm, and that small businesses typically obtain multiple different services from their local bank.  The 30 miles actually overstates the distance that small businesses are willing to travel for most of their basic financial services.  For example, the median distances from a small business' offices to the institutions where it obtains deposit, credit, or financial management services are all 5 miles or less.  One of the reasons why the banking relationship is so important to small business finance is that banks can efficiently gain valuable information on a small business over the course of their relationship, and then use this information to help make pricing and credit decisions.  The financial conditions of small firms are usually rather opaque to investors, and the costs of issuing securities directly to the public are prohibitive for most small firms.  Thus, without financial intermediaries like banks it would simply be too costly for most investors to learn the information needed to provide the credit, and too costly for the small firm to issue the credit itself.  Banks, performing the classic functions of financial intermediaries, solve these problems by producing information about borrowers and monitoring them over time, by setting loan contract terms to improve borrower incentives, by renegotiating the terms if and when the borrower is in financial difficulty, and by diversifying the risks across many small business credits.   Some recent empirical research suggests that this characterization of the bank-small business borrower relationship is accurate.  For example, as the relationship matures, banks typically reduce the interest rates charged and often drop the collateral requirements on small business loans.  In short, the bank-borrower relationship appears to be an efficient means for overcoming information and cost problems in small firm finance, and for allowing fundamentally creditworthy small firms to finance sound projects that might otherwise go unfunded.  One implication of the importance of the bank-small business relationship is that it may impose limits on the migration of small business finance out of the banking sector.  Over the last two decades, many large business loans left the banking sector as improvements in information technology, increased use of statistical techniques in applied finance, and the  globalization of financial markets have allowed nonbank and foreign bank competitors to gain market share over U.S. banks.  For example, over the 1980s and first half of the 1990s, the share of total U.S. nonfarm, nonfinancial corporate debt held by U.S. banks fell by about one-quarter from 19.6 percent to 14.5 percent.   Banks compensated somewhat for these on-balance sheet reductions in a variety of ways.  Many banks expanded their participation in off-balance sheet back-up lines of credit, standby letters of credit, and the securitization and sale of some large loans.  Other adaptations included a shift in focus  toward fee-based services and derivatives activities.  The types of developments that might similarly reduce bank market share in small business lending are proceeding rather slowly at present, but may accelerate in the future.  Improvements in analytical and information technologies such as credit scoring may decrease the cost of lending to small businesses and make it easier for nonbank lenders to enter this market.  These developments are already contributing to more competition for small business loans within the banking industry and between bank and nonbank lenders.  Similarly, a significant secondary market for securitization of loans to some small businesses may develop in the future.  Those small businesses among current bank borrowers whose information problems are the least severe   that is, those that are the least informationally opaque   would presumably be the most likely to be funded outside of the banking system.  Nevertheless, no matter how many advances there are in information processing and no matter how sophisticated financial markets may become, there will likely remain a significant role for bank-borrower relationship lending to solve the information and other financing problems of small businesses.  That is, in the foreseeable future it seems very likely that there will remain many small business borrowers with sufficient problems that only bank information gathering, monitoring, and financing can overcome, although this group of borrowers will almost surely differ somewhat from current relationship borrowers.  As technology and markets improve to the point that some relatively transparent small business borrowers can be financed outside the bank, other, more opaque potential borrowers that previously had information and other problems too serious for even a bank loan will enter the bank intermediation process.  Put another way, the relationship lending process will  fund small business borrowers with increasingly difficult information problems as the technology for resolving these problems improves.  In my view, this should only increase the efficiency and the competitiveness of small business finance.  For example, the improved ability of banks to lend to more opaque borrowers should provide some increased competition for the venture capitalists and angel financiers that were discussed at the conference yesterday.  The value of gathering information through the relationship between banks and small businesses also bodes well for the survival of small community-based banks that tend to specialize in these relationships.  Most forecasts of the future of the U.S. banking industry predict that thousands of small banks will survive.  I hasten to point out that these are not my personal forecasts.  I stick to predicting interest rates, GDP growth, and inflation    items over which I have more control and inside information   and I leave the banking forecasts to others!  But the forecast of thousands of small banks continuing to operate and do well makes sense to me.  They have information advantages, knowhow, and local community orientations that are hard to duplicate in large organizations.  The importance of relationship lending to small business also raises prudential concerns about bank risk taking.  When a bank fails, the losses to society exceed the book values involved because of the loss of the value of the bank's customer  relationships.  Even if small business borrowers are able to find financing after their bank fails, it may be at a higher interest rate and with additional collateral requirements until the new bank has had a chance to learn about the borrower's condition and prospects.  When many banks fail during a crisis, this can create a credit crunch or significant reduction in the supply of credit to bank-dependent small business borrowers.  For example, research on the Great Depression suggests that the loss of bank-borrower relationships in the 1930s may have deepened and prolonged the economic downturn.  More recently, it appears that the weak capital positions of many banks in the late 1980s and early 1990s, not to mention the outright failure of over 1,100 banks during this period, contributed importantly to the sharp slowdown in bank commercial lending during the early 1990s.  While the ability of small businesses to find alternative sources of funds is considerably greater today than in the 1930s, and will likely be even greater in the future than it was in the early 1990s, such arguments do reinforce the importance of the connection between macroeconomic and bank supervisory policy.   Financial Modernization and Bank Small Business Lending In the remainder of my remarks, I will touch on three additional  concerns about the potential effects of financial modernization on the supply of bank credit to small business.  I will first discuss the effects of increases in market concentration created by bank mergers and acquisitions within a local market; second, the effects of consolidation of the banking industry as a whole; and third, the possible impacts of the increased complexity of financial service firms in which banking and other organizations may provide a multitude of traditional banking and nonbanking services.  At the outset, I would emphasize that the overriding public policy concern regarding these issues is not the quantity of small business lending, but rather economic efficiency.  If some banks are issuing loans to finance negative net present value projects, then such loans should be discouraged.  If consolidation of the banking industry or the increased complexity of financial services firms reduces such lending, then economic efficiency is promoted by freeing up those resources to be invested elsewhere, even though the supply of small business credit to these borrowers is reduced.  Similarly, a lack of competition or poor corporate control may currently be keeping some positive net present value loans from being made.  If modernization increases the supply of loans to creditworthy small business borrowers to pursue financially sound projects, then economic efficiency is also raised as the supply of credit to these small businesses rises.  Antitrust analysis in banking has typically been based on the concentration of bank deposits in local markets like Metropolitan Statistical Areas (MSAs) or non-MSA rural counties.  Under the traditional \"cluster approach,\" small business loans and other products are assumed to be competitive on approximately the same basis as bank  deposits in local markets.  While on-going technological and institutional changes seem likely to erode the usefulness of this assumption over time, evidence continues to generally support this assumption.  As I noted earlier, small businesses typically get their loans and other financial services from a local bank.  Additional research finds that the concentration of the local banking market is a key determinant of the rates that are charged on small business loans.  For example, it is estimated that small business borrowers in the most concentrated markets pay rates about 50 to 150 basis points higher than those in the least concentrated markets.  This exceeds estimates of the effects of local market concentration on retail deposit rates of about 50 basis points.   Research has also suggested that high local-market deposit concentration may lead to reduced managerial efficiency, as the price cushion provided by market power allows a \"quiet life\" for managers in which relatively little effort is required to be profitable.  Managers in these concentrated markets may choose to work less hard or pursue their own personal interests because the lower rates on deposits and higher rates on small business loans raise profits enough to cover for inefficient or self-serving practices.  These findings support the need to maintain competition in local banking markets to deter the exercise of market power in pricing consumer deposits and small business loans, and to ensure that the local banks are under sufficient competitive pressure that they are operated in a reasonably efficient way.   When bank mergers and acquisitions involve banks operating in different local markets, the issues raised are typically quite different from those I have just discussed.  Since the late 1970s, states have been liberalizing laws that previously restricted mergers and acquisitions between banks in different local markets, including allowing holding company acquisitions across state lines.  The U.S. banking industry has responded strongly and has been consolidating at a rapid rate over the last 15 years.  Consolidation has picked up even more in the first half of the 1990s   each year bank mergers have involved about 20 percent of industry assets.  This trend is likely to continue or accelerate under the Riegle-Neal Act, which has already allowed increased interstate banking, and which will allow interstate branching into almost all states this summer.  Importantly, an increase in local market concentration is not a major issue in most of these mergers and acquisitions, as they are primarily of the market-extension type.  As such,  these consolidations, and sometimes merely the threat of such actions,  may be pro-competitive and reduce the market power of local banks over depositors and small business borrowers in the markets that are invaded.  They may also improve the diversification and efficiency of the consolidating institutions.  Research generally suggests that most mergers and acquisitions, by improving diversification, allow the consolidating institutions to make more loans and improve their profit efficiency.  Mostly as a result of these mergers and acquisitions, the mean size of banking organizations has approximately doubled in real terms in the last 15 years.  As I mentioned earlier, a frequently voiced concern about this consolidation is whether the supply of credit to small business may be decreased, since larger banking institutions tend to devote smaller proportions of their assets to small business lending. To illustrate, banks with under $100 million in assets devote about 9 percent of their assets to small business lending on average, whereas banks with over $10 billion in assets invest only about 2 percent  of assets in these loans.  While such a simplistic analysis may sound appealing on the surface, it is clearly  incomplete.  It neglects the fundamental nature of mergers and acquisitions as dynamic events that may involve significant changes in the business focus of the consolidating institutions.  That is, banks get involved in mergers and acquisitions because they want to do something different, not simply behave like a larger bank. The simplistic comparison of the lending patterns of large and small banks also ignores the reactions of other lenders in the same local markets.  Other existing or even new local banks or nonbank lenders might pick up any profitable loans that are no longer supplied by the consolidated banking institutions.  These other institutions may also react to M&As with their own dynamic changes in focus that could either increase or decrease their supplies of small business loans.  Thus, even if merging institutions reduce their own supplies of small business loans substantially, the total supply of these loans in the local market need not decline.  There have been a number of recent studies of these dynamic effects of bank mergers and acquisitions, some of which we heard about this morning.  The results suggest that the dynamic effects of mergers and acquisitions are much more complex and heterogenous than would be suggested by the increased sizes of the consolidating institutions alone.  For example, mergers of small and medium-sized banks appear to be associated with  increases in small business lending by the merging banks, whereas mergers of large banks may be  associated with decreases in small business lending by the participants.  On average, mergers appear to reduce small business lending by the participants, but this decline appears to be offset in part or in whole by an increase in lending by other banks in the same local market.  These other banks may pick up profitable loans that are dropped by merging institutions, or otherwise have dynamic reactions that increase their supplies of small business lending.  Moreover, these results do not include the potential for increased lending by nonbank firms.  The bottom line is that small business loan markets seem to work quite well.  Creditworthy borrowers with financially sound projects seem to receive financing, although they sometimes have to bear the short-term switching costs, such as temporarily higher loan rates and collateral requirements, of changing banks after their institutions merge.  On-going technological change in small business lending should only help to improve the efficiency of this process.   Again, I would emphasize that it is not the quantity of small business loans supplied that is most important, but rather the economic efficiency with which the market chooses which small businesses receive credit.  To the extent that mergers and acquisitions are pro-competitive and improve corporate control and efficiency, the supply of credit to some borrowers with negative net present value projects may be reduced, as it should be.  That is, the protection from competition provided by interstate and intrastate barriers may have allowed some firms with market power to be inefficient or make uneconomic loans.  Similarly, any improvement in competition and efficiency may increase the supply of credit to borrowers with positive net present value projects that inefficient lenders previously did not fund.  In either of these cases, economic efficiency is improved.  As promised, the final issue I will discuss is that aspect of the modernization of financial markets in which financial service firms are likely to become more complex, providing more types of financial services within the same organization.  At the present time, we do not know if and when the Glass-Steagall Act will be repealed, whether nontraditional activities will be provided by bank subsidiaries or bank holding company affiliates, and in which activities banking organizations will be allowed to engage or choose to engage.  However, similar to the arguments regarding consolidation of the banking industry, concern is sometimes expressed that small business borrowers may receive less credit from these larger, more complex financial institutions.  There is much less research evidence available regarding the potential effects on small business lending of this type of  financial modernization than there is about the consolidation of the banking industry,  so my remarks here are substantially more speculative.   However, I believe there are several reasons for optimism regarding adequate supplies of services to creditworthy small businesses.  First, a limited amount of research suggests that there is little if any effect of the current organizational complexity of U.S. banks on their treatment of  small businesses, other things equal.  In particular, banking organizations with multiple layers of management, those that operate in multiple states, those with Section 20 securities affiliates, and those with other organizational complexities tend to charge about as much for small business credit as other banks of their same size.  Second, the research  results for the consolidation of banks alone suggest that if profitable loans are dropped by the newer universal-like banks, other small banks or nonbank firms will be standing by to pick up these loans.  Finally, the additional insurance, securities underwriting, or other financial services provided by the new institutions should provide greater opportunities for small businesses to have access to these nontraditional services.",
                  "1997-05-23 00:00:00"
                ],
                [
                  "44",
                  "Chairman Alan Greenspan",
                  " I am pleased to accept this years Charles Waldo Haskins Award and have the opportunity to address this distinguished audience on current monetary policy. A central banks raising interest rates is rarely popular.  But the Federal Reserves action on March 25, to tighten the stance of monetary policy, seems to have attracted more than the usual share of attention and criticism.  I believe the critics of our action deserve a response.  So tonight, I would like to take a few minutes to put this action in the broad context of the Feds mandate to promote the stable financial environment that will encourage economic growth. The Federal Open Market Committee raised rates as a form of insurance.  It was a small prudent step in the face of the increasing possibility that excessive credit creation, spurred by an overly accommodative monetary policy, might undermine the sustained economic expansion.  That expansion has been fostered by the maintenance of low inflation.  But the persisting indeed increasing strength of nominal demand for goods and services suggested to us that monetary policy might not be positioned appropriately to avoid a buildup of inflationary pressures and imbalances that would be incompatible with extending the current expansion into 1998, and hopefully beyond.  Even if it should appear in retrospect that we could have skirted the dangers of credit excesses without a modest tightening, the effect on the expansion would be small, temporary, and like most insurance, its purchase to protect against possible adverse outcomes would still be eminently sensible. For the Federal Reserve to remain inactive against a possible buildup of insidious inflationary pressures would be to sanction a threat to the job security and standards of living of too many Americans.  As I pointed out in testimony before the Congress in March, the type of economy that we are now experiencing, with strong growth and tight labor markets, has the special advantage of drawing hundreds of thousands of people onto employment payrolls, where they can acquire permanent work skills.  Under less favorable conditions they would have remained out of the labor force, or among the long-term unemployed.  Moreover, the current more-than-six-year expansion has enabled us to accelerate the modernization of our productive facilities. It has long been the goal of monetary policy to foster the maximum sustainable growth in the American economy.  I emphasize sustainable because it is clear from our history that surges in growth financed by excessive credit creation are, by their nature, unsustainable, and, unless contained, threaten the underlying stability of our economy.  Such stability, in turn, is necessary to nurture the sources of permanent growth.  The Federal Reserve, of late, has been criticized as being too focused on subduing nonexistent inflation and, in the process, being willing to suppress economic growth, retard job expansion, and inhibit real wage gains.  On the contrary, our actions to tighten money market conditions in 1994, and again in March of this year, were directed at sustaining and fostering growth in economic activity, jobs, and real wages.  Our goal has never been to contain inflation as an end in itself.  Prices are only signals of how the economy is functioning.  If inflation had no effect on economic growth, we would be much less concerned about inflationary pressures. But the evidence is compelling that low inflation is necessary to the most favorable performance of the economy.  Inflation, as is generally recognized throughout the world, destroys jobs and undermines productivity gains, the foundation for increases in real wages.  Low inflation is being increasingly viewed as a necessary condition for sustained growth. It may be an old cliché, but you cannot have a vibrant growing economy without sound money.  History is unequivocal on this. The Federal Reserve has not always been successful at maintaining sound money and sustained growth, and the lessons have been costly.  The Federal Reserves policy actions, the evidence demonstrates, affect the financial markets immediately, but work with a significant lag of several quarters or more on output and employment, and even longer on prices.  Too often in the past, policymakers responded late to unfolding economic developments and found they were far behind the curve, so to speak; as a result, their policy actions were creating or accentuating business cycles, rather than sustaining expansion.  Those who wish for us, in the current environment, to await clearly visible signs of emerging inflation before acting are recommending we return to a failed regime of monetary policy that cost jobs and living standards. I wish it were otherwise, but there is no alternative to basing policy on what are, unavoidably, uncertain forecasts.  As I have indicated to the Congress, we do not base policy on a single best-estimate forecast, but rather on a series of potential outcomes and the possible effects of alternative policies, including judgments of the consequences of taking a policy action that might, in the end, have turned out to be less than optimal. I viewed our small increase in the federal funds rate on March 25 as taken not so much as a consequence of a change in the most probable forecast of moderate growth and low inflation for later this year and next, but rather to address the probability that being wrong had materially increased. In the same sense that it would be folly not to endure the small immediate discomfort of a vaccination against the possibility of getting a serious disease, it would have been folly not to take this small prudent step last March to reduce  the probabilities that destabilizing inflation would re-emerge.  The risk to the economy from inaction came to outweigh the risk from action. To be sure, 1997 is not 1994 when the Fed was forced to tighten monetary conditions very substantially to avoid accommodating rising inflation.  Current financial conditions are much less accommodative than they were in 1994.  Yet we must be wary.  While there is scant evidence of any imminent resurgence of inflation at the moment, there also appears to be little  slack in our capacity to produce.  Should the expected slowing in the growth of demand fail to materialize, we would need to address any emerging pressures in product and credit markets. To understand the problems of capacity restraint, I should like to spend a few moments on what we have learned over the years about economic growth and the conditions necessary to foster it. First it is useful to distinguish between two quite different types of economic growth.  One is true, sustainable growth, the other is not.  True growth reflects the capacity of the economic system to produce goods and services and is based on the growth in productivity and in the labor force. That growth contrasts with the second type, what I would call transitory growth.  An economy producing near capacity can expand faster for a short time through excess credit creation.  But this is not growth in any meaningful sense of promoting lasting increases in standards of living for our nation.  Indeed, it will detract from achieving our long-term goals.  Temporary fluctuations in output owing to say, inventory adjustments, but not financed through excess credit, will quickly adjust on their own and need not concern us as much, provided policy is appropriately positioned to foster sustainable growth.   When excessive credit fostered by the central bank finances excess demand, history tells us destabilizing inflationary pressures eventually emerge.  For a considerable portion of the nineteenth and early twentieth centuries, inflationary credit excesses and prices were contained by a gold standard and balanced budgets.  Both, however, were deemed too constraining to the achievement of wider social goals as well as for other reasons, and instead the Federal Reserve was given the mandate of maintaining the appropriate degree of liquidity in the system. Over the long haul, the economy's growth is effectively limited to the expansion of capacity based on productivity and labor force growth.  To be sure, it is often difficult to judge whether observed growth is soundly based on productivity or arises from transitory surges in output financed in many cases by excess credit, but this is in part what making monetary policy is all about. In that regard and in the current context, how can we be confident we at the Federal Reserve are not inhibiting the nation reaching its full growth potential? One way is to examine closely the recent economic record.  Only two and a half years ago, rising commodity prices, lengthening delivery times, and heavy overtime indicated that our productive facilities were under some strain to meet demand.  To be sure, since early 1995, those pressures have eased off.  However, given the good pace of economic expansion since then, it would stretch credulity to believe that capacity growth has accelerated at a sufficient pace to produce a large degree of slack at this moment.  Capacity utilization in industry is a little below its level through much of 1994, and pressures in product markets have remained tame.  However, falling unemployment rates and rising overtime hours as well as anecdotal reports unambiguously point to growing tightness in labor markets.   With tight labor markets and little slack in product markets, we are led to conclude that significant persistent strength in the growth of nominal demand for goods and services, outstripping the likely rate of increase in capacity, will presumably be resisted by higher market interest rates.  If, instead, that demand is accommodated for a time by a step up in credit expansion facilitated by monetary policy, increasing pressures on productive resources would sow, as they have in the past, the seeds of even higher interest rates and a consequent subsequent economic retrenchment. This, then, was the context for our recent action.  We saw a significant risk that monetary policy was not positioned to promote sustainable economic expansion, and we took a small step to increase the odds that the good performance of the economy can continue. There is another point of view of the current context that merits consideration.  It is the notion that, owing largely to technological advance and to freer international trade, the conventional notions of capacity are becoming increasingly outmoded, and that domestic resources can be used much more intensively than in the past without added price pressures.  There is, no doubt, a substantial element of truth in these observations, as I have often noted in the past.  Computer and telecommunication based technologies are truly revolutionizing the way we produce goods and services.  This has imparted a substantially increased degree of flexibility into the workplace, which in conjunction with just-in-time inventory strategies and increased availability of products from around the world, has kept costs in check through increased productivity. Our production system and the notion of capacity are far more flexible than they were ten or twenty years ago.  Nonetheless, any inference that our productive capacity is essentially unlimited is clearly unwarranted.  As I pointed out earlier, judging from a number of tangible signs of strains on facilities, we were producing near capacity in early 1995, and it is just not credible that an economy as vast and complex as that of the United States could have changed its underlying structure in the short time since then. If we consider the current rate of true, sustainable growth unsatisfactory, are there policies which could augment it? In my view, improving productivity and standards of living necessitates increasing incentives to risk taking.  To encourage people to take prudent risks, the potential rewards must be perceived to exceed the possible losses.  Maintaining low inflation rates reduces the levels of future uncertainties and, hence, increases the scope of investment opportunities.  It is here that the Federal Reserve can most contribute to long-term growth. Other government policies also can affect these perceptions.  For example, lower marginal tax rates and capital gains taxes would increase the return to successful investments and, thus, the incentive to initiate them.  In addition, coming to grips now with the outsized projected growth in entitlement spending in the early years of the next century could have a profound effect on current expectations of stability.  Early actions could bring real long-term interest rates down, also increasing the scope of investment opportunities.  And, clearly, removing the federal deficits drain on private savings would help to finance such private investment. Deregulation, by increasing the flexibility in the deployment of our capital and management resources, can also make a decided contribution to growth.  The deregulation of telecommunications, motor and rail transport, utilities, and financial services, to name a few, may have done more to foster Americas competitive market efficiencies than we can readily document. Finally, though not a function of government policies, is the continued good pace of productivity growth this late in the business expansion.  This cyclical pattern is contrary to our experience and it suggests there may be an undetected delayed bonus from technical and managerial efficiencies coming from the massive advances in computer and telecommunications technology applications over the last two decades.  If so, it is important that we nurture it with adequate incentives at a minimum, eschew regulations and taxation that reduce most incentives for this may well be one source of our low inflation environment. While productivity improvement through capital investment and technological advance is clearly central to the process of economic growth, the pace and quality of labor force expansion is additive to productivity growth in achieving overall gains in GDP.  Hence, appropriate upgrading of skills through education and training should go with any menu to expand economic growth.   Looking ahead, there are many reasons to be optimistic about the economy's prospects.",
                  "1997-05-08 00:00:00"
                ],
                [
                  "45",
                  "Chairman Alan Greenspan",
                  "Financial Reform and the Importance of the State Charter I am pleased once again to address this annual meeting of the Conference of State Bank Supervisors.  Before I begin, I would like to join his colleagues in wishing Bob Richard well.  Over the years, it has been a pleasure to work with him.  He will be sorely missed.   Today, I shall concentrate my remarks on the current debate in Congress and elsewhere on how best to accomplish financial reform.  This subject has been a recurring theme in Federal Reserve comments, speeches, and testimonies during the first part of 1997 and, I suspect, the subject will continue to engage us for some months ahead.  My remarks today will reemphasize some of the points made at other venues this year, although I will attempt to place these arguments in the context of the impact of financial reform on the state-chartered bank and on the roles such banks, and their regulators, play in maintaining the overall well-being of our banking system and our economy. To begin, there does appear to be general agreement on the need for financial reform.  Permitting various financial businesses to be conducted jointly should provide the benefits of increased services and/or lower prices to financial customers, improved risk reduction, and cost savings for financial firms.  More broadly, it should improve the efficiency and stability of the financial system that underlies our economy.  These benefits are expected to flow primarily from opportunities for diversification, non-interest cost reduction, and cross-marketing for those banks, investment banks, and insurance companies that find ways to profitably merge their businesses in the wake of legislation permitting expanded powers for banking organizations.   But the longer financial reform is delayed, the less important and useful it will be.  Put in economists jargon, the longer the delay the lower the marginal economic benefits produced by reform legislation, and the more we should be concerned instead with possible unintended negative effects that might outweigh those marginal benefits.  Let me explain.   Financial markets, as we all should know by now, have a way of effectively circumventing uneconomic barriers or bottlenecks created by inefficient legislation or regulation.  Today, it has become possible, through the judicious use of derivative instruments, for a financial firm engaged primarily in one kind of financial activity to mimic the risks and returns of any other financial activity.  Banking, investment banking, and insurance can no longer be viewed, from a risk-return perspective, as separate and distinct lines of business.  To cite just one example, banks are prohibited from underwriting insurance, yet the writing of a put option a form of derivative activity engaged in widely by large banks is, in economic substance, a form of insurance underwriting.  Other derivative markets, including the emerging credit derivative instruments, now permit banks to diversify their credit and market risks as if they had been permitted to merge with investment banks or insurance companies.  Thus, some of the long-sought-after economic benefits resulting from the repeal of legislative barriers between and among different types of financial firm already have been achieved through the creativity of the marketplace.  Nevertheless, by not being able to engage directly in the impermissible activity, a banking company cannot achieve the production or marketing synergies, and therefore the cost reductions, that may flow from joint operations and that may benefit a banks shareholders as well as its customers.  In addition to the actions of the marketplace, banking regulators have acted, within the constraints of statute, to facilitate economic combinations of banking and nonbanking financial activities.  Specifically, the Federal Reserve has adopted both liberalization of Section 20 activities and expedited procedures for processing applications under Regulation Y.  The OCC, meanwhile, has generated some controversy by liberalizing banks insurance agency powers as well as procedures generally for establishing operating subsidiaries of national banks that may engage in activities not permitted to the bank.  This is not to say that financial reform legislation will have no marginal benefit.  Clearly, in addition to the benefit of lowered costs, much remains to be accomplished in the form of improved management efficiency.  These benefits, which will accrue both to the banks and the general public, probably can be maximized only within the context of clear legislative authority for combining financial firms of various types.  We must be careful, however, in our efforts to achieve the benefits of financial reform, not to violate the tenets of good public policy.  In this regard, the Federal Reserve believes that any financial reform should be consistent with four basic objectives: (1) continuing the safety and soundness of the banking system; (2) limiting systemic risk; (3) contributing to macroeconomic stability; and (4) limiting the spread of both the moral hazard and the subsidy implicit in the federal safety net.  I have spent a good deal of time of late on the fourth objective.  Therefore, today I will concentrate on the first three and how, in particular, financial reform must be careful to preserve the role of the state-chartered bank in meeting our economys macroeconomic objectives and our concerns regarding systemic risk. The importance of the state-chartered bank  Some erroneously dismiss state-chartered banks as representing only the down-scale end of the banking market and, therefore, being not particularly worthy of careful policy consideration.  State-chartered banks indeed are smaller on average than national banks, and are disproportionately represented within the very smallest size class.  Nevertheless, state-chartered banks account for about a third of our superregionals, not to mention a few state banks that are among the very largest money center institutions.  Even the preponderance of small, state-chartered banks, however, play a critical role within our financial system, for several reasons.  First, having large numbers of community-sized banks, be they state-chartered or national banks, is a major contribution to the stability of the banking system and the well-being of the macroeconomy.  Just as a more highly diversified loan portfolio reduces risk to the individual bank, a more highly diversified banking structure reduces risk to the banking system as a whole.  Indeed, our decentralized and diverse banking structure was arguably the key to weathering the financial crisis of the late 1980s.  During those dark days, our system was able to absorb more than a thousand U.S. bank failures.  And yet here we are, less than a decade later, with loan loss reserves and bank capital at their highest levels in almost a half century, and the insurance fund restored to its maximum coverage ratio all without cost to the taxpayer.  Of course, the bank failures of the past decade, combined with the current wave of mergers and acquisitions, have served to reduce significantly the total number of banking organizations in the U.S.  But the more than 7,000 separate banking companies that remain are more than sufficient to maintain our highly decentralized and flexible banking structure.  Large numbers of small banks go hand in hand with a macroeconomy characterized by large numbers of small, entrepreneurial nonfinancial businesses.  Smaller banks traditionally have been a major source of capital for small businesses that may not have access to securities markets.  In turn, small businesses account for the major portion of new employment and new ideas, thereby playing a major role in fueling economic growth. This connection running between small banks, small business, and the macroeconomy indeed the role of banks generally in funding business expansion is so important that we must be sensitive to the tradeoff between risk-taking and bank solvency.  Risk-taking prudent risk-taking to be sure is the primary economic function of banking.  All wealth is measured by its perceived ability to produce goods and services of value in the future.  Since the future is fundamentally unknown, endeavoring to create wealth implies an uncertain expectation of how the future will unfold.  That is, creating wealth is risky.   Hence banking, to further its primary economic purpose of financing the economy, cannot and should not avoid prudent risk-taking.  Bank supervisors, in turn, need to recognize that the optimal bank failure rate is not zero.  A zero failure rate over time implies either extraordinary insight by bankers, a notion I readily dismiss, or an undue and unhelpful degree of conservatism in banking practice.  In taking on risk, of course, some mistakes will be made, and some banks will fail.  Even if a bank is well-managed, it can simply become unlucky.  Failure should occur, indeed does occur, as part of the natural process within our competitive economy.  It should not be viewed as a flaw in our financial system, and certainly we should not attempt to eliminate it.  Only when the failure rate threatens to breach a prudent threshold should we become concerned.   Just as large numbers of smaller banks are a key to the robustness of our economy, the state charter is a key to the robustness of our banking structure.  The dual banking system has fostered a steady stream of banking innovations that have benefited consumers and bank shareholders alike.  For example, the NOW account, as I like to point out, was invented at a state-chartered bank; and the NOW account was the opening shot in the campaign to remove national deposit interest rate controls and allow banks to compete on common ground with nonbank institutions such as money funds.  The 1994 interstate branching statute likewise has its origin in the state laws that permitted cross-border banking, beginning with the rewriting of the Maine banking laws.  Adjustable rate mortgages are another innovation that began at the state level, and of course, the National Banking Act itself has its origin in the states free banking laws of the nineteenth century. The dual banking system not only fosters and preserves innovation but also constitutes our main protection against overly zealous and rigid federal regulation and supervision.  A bank must have a choice of more than one federal regulator, must be permitted to change charters, to protect itself against arbitrary and capricious regulatory behavior.  Naturally, some observers are concerned that two or more federal agencies will engage in a competition in laxity, and we must guard against that; but the greater danger, I believe, is that a single federal regulator would become rigid and insensitive to the needs of the marketplace.  Thus, so long as we have a federal guarantee of deposits, Federal Reserve guarantee of intraday payments over Fedwire, and other elements of the safety net and, therefore, so long as there is a need for federal regulation of banks such regulation should entail a choice of that regulator at the federal level. As you are well aware, the Federal Reserve has long been a strong supporter of the dual banking system in the context of efficient supervision.  That is why we, along with the FDIC, have sought examination partnerships with the state banking regulators.  Currently, the Fed has cooperative agreements with about three dozen states, calling for either joint examinations or alternate year exams.  Overall, our experience with these programs has been quite positive, in part because of the quality of state supervision in the states with the cooperative agreements.  Indeed, the evidence suggests that safety and soundness of state banks compare quite favorably with national banks, possibly reflecting the benefits of having both state and federal supervision.  For example, during the banking crisis of the late 1980s, when the failure rate by any measure breached the prudent threshold I mentioned earlier, the national bank failure rate was considerably greater than for state banks.  While bank failure is determined by more than just the supervision process, these data nevertheless speak well of the quality of the state supervisory process and the ability of the state and federal regulators to function together efficiently. The dual banking system, however, despite its advantages and achievements, is under attack.  This attack is neither particularly intentional nor particularly coordinated, but rather consists of the unintended consequences of statutory and regulatory changes aimed at achieving broader policy objectives.  I am referring primarily to the consequences of the 1994 interstate branching legislation, coupled with the OCCs recent liberalization of regulatory procedures for operating subsidiaries of national banks.  These events may have served to tip the balance in favor of national banks, so to speak, in a manner that weakens banks ability to switch federal regulators without incurring prohibitive real economic costs.  In particular, while most state-chartered banks will continue to operate on an intrastate basis in local markets, regional and nationwide banks may find that state charters are burdensome to the extent that the banks are forced to operate under varying regulatory rules and procedures across multiple states.  If that burden were to become excessive, banks with interstate operations especially interstate retail operations would likely turn to the national charter on grounds of simple expediency.  For example, I am struck by the fact that the very largest state-chartered banks among the money center institutions are without significant retail operations or without announced intentions to expand retail banking beyond their home states.  The rest of the large state-chartered banks, those with assets over $10 billion, consist mainly of lead banks in multi-bank, multi-state holding companies.  It seems likely that some of these institutions will seek to consolidate their interstate retail operations under a national bank charter after interstate branching becomes fully operational, unless countervailing forces emerge. The evident superiority of the national charter is not a foregone conclusion, however.  For example, the Federal Reserve this past month approved an application by a superregional banking company to consolidate its retail branches in four states under a single state-chartered bank headquartered in Alabama.  The consolidation would become effective on or after June 1, 1997, when the Riegle-Neal Interstate Banking Act becomes operational.  Another positive indication of the resiliency of the state charter has been the establishment of the State-Federal Working Group.  This cooperative effort involving the states, the CSBS, the Federal Reserve, and the FDIC is contributing importantly to the strengthening of the supervision of state-chartered institutions through a number of initiatives, including the adoption of the State/Federal Protocol.  The Protocol and the Nationwide Supervisory Agreement of 1996 spell out the principles and specific actions that would lead to a seamless supervision and examination of interstate, state-chartered banks.  Other initiatives of the State-Federal Working Group include greater examination emphasis on bank risk management processes, a more formalized, risk-focused approach to examination, and expanded and more effective use of information technology.  It would also be extremely helpful, especially if enacted prior to interstate branching becoming fully operational, if the Congress were to pass the so-called home state rule, which would place state-chartered banks on an equal footing with national banks with regard to permissible activities of branches in a host state. Systemic Risk and the Role of the Federal Reserve  By now, we are all acutely aware that the process of financial reform is a complex one, with intended and unintended consequences flowing from almost every act of the legislator or regulator.  I have focused today on only two aspects of the debate over financial reform, albeit two very important aspects the need to maintain our uniquely decentralized banking system, with its reliance on large numbers of relatively small institutions, and the desirability of retaining the dual banking system, with its implicit choice of regulator.  Let me conclude by turning to another important facet of the debate over financial reform the role of the Federal Reserve in containing systemic risk.  It is critical that we guard against diminution of this role as yet another unintended consequence of financial reform. The risk of systemwide disruptions, for better or for worse, is importantly determined by the actions or inactions of our largest, most complex banking organizations.  The architects of financial reform, therefore, must necessarily consider how best to supervise risk-taking at these large organizations and, in particular, whether there should be significant umbrella or consolidated supervision of the banking company. In the past, holding company supervision was concentrated at the bank level, not only because the bank tended to constitute the bulk of risk-taking activities but also because the holding company tended to manage the bank separately from the various nonbank activities of the organization.  More recently, however, the focus of supervision of holding companies by the Federal Reserve has been modified to reflect changes in management procedures holding companies now tend to manage risk on a consolidated basis across all their bank and nonbank subsidiaries.  Risk and profitability measurements, including, for example, risk-adjusted return on capital calculations, most often are made by business line rather than on a subsidiary basis.  As banks engage in new or expanded nonbanking activity in the wake of financial reform, it is likely that these activities too would be managed on a consolidated basis.  For this reason, and because supervisors recognize that scarce examination resources are often most effectively employed by focusing on risk management processes, our determination of an institutions safety and soundness increasingly will be based on an analysis of the decisionmaking and internal control processes for the total organization.   Such umbrella supervision need not be in any significant way intrusive, nor should financial firms be burdened by the extension of bank-like regulation and supervision to their nonbank activities.  For some time, the focus of the Feds inspections of nonbanking activities of bank holding companies has been to assess the strengths of the individual units and their interrelations with one another and with the bank.  Emphasis is placed on the adequacy of risk measurement and managements systems, as well as internal control systems, and only if there is a major deficiency in these areas should the inspection of the nonbank activities become at all intrusive.  We intend that this philosophy of holding company supervision will not change as banks are granted extended powers. Finally, I should note that some have questioned not only the need for umbrella supervision but also the need for the Feds involvement in such supervision.  It is primarily the responsibility of the Federal Reserve to maintain the stability of our overall financial system, including the interconnections between the domestic financial system and world financial markets.  This obligation to protect against systemic disruptions cannot be met solely via open market operations and use of the discount window, as powerful as these tools may be.   If the past is any guide, financial crises of the future will be unpredictable and unique in nature.  The globalization of financial and real markets means that a foreign crisis can impact on the domestic financial system, and vice versa.  Our ability to respond quickly and decisively to any systemic threat depends critically on the experience and expertise of the central bank with regard to the institutional detail of the U.S. and foreign financial systems, including our familiarity with payments and settlement systems.  Thus, in order to carry out our systemic obligation, the Federal Reserve must be directly involved in the supervision of banks of all sizes and must, in particular, be able to address the problems of large banking companies if one or more of their activities constitute a threat to the stability of the financial system.",
                  "1997-05-03 00:00:00"
                ],
                [
                  "46",
                  "Chairman Alan Greenspan",
                  "Technological Change and the Design of Bank Supervisory Policies  For more than three decades, this conference has focused our attention on key issues facing banks, their customers, and regulators.  Its proceedings have chronicled a remarkable and ongoing transformation of the U.S. financial services industry.  At the time of the first gathering in 1963, our financial system was highly segmented, with commercial banks, savings and loans, investment banks, insurance companies, and finance companies providing distinctly separate products.  Statutes and regulations greatly restricted competition between banks and nonbanks, and among banks themselves.  Today, the marketplace for financial services is intensely competitive, innovative, and global.  Banks and nonbanks, domestic and foreign, now compete aggressively across a broad range of on- and off-balance-sheet financial activities.  It is noteworthy that, for the most part, this transformation has not been propelled by sweeping legislative reforms.  Rather, the primary driving forces have been advances in computing, telecommunications, and theoretical finance that, taken together, have eroded economic and regulatory barriers to competition, de facto.  Technology has fundamentally reshaped how financial products are created and how these products are delivered, received, and employed by end-users.  In my remarks this morning, I plan to discuss two aspects of this process of technological change.  First is the recurring theme of financial products being unbundled into their component parts, including the unbundling of credit, market, and other risks.  These developments have worked to enhance the competitiveness and efficiency of the financial system and, at the same time, to provide financial institutions and their customers with better tools for managing risks.  A byproduct is that our largest and most complex financial organizations increasingly are measuring and managing risk on a centralized basis.  This trend seems irreversible, and in my view provides a compelling reason for maintaining some type of umbrella supervision over banking organizations, especially as we contemplate repeal of Glass-Steagall and other restrictions on the activities of banking organizations. The second theme I want to explore is the large element of uncertainty underlying technological progress.  Reflecting this uncertainty, it is inherently very difficult to predict the extent to which government policies may distort the private sector's incentives to innovate.  This argues for supervisory and regulatory policies that are more \"incentive-compatible,\" in the sense that they are reinforced by market discipline and the profit-maximizing incentives of bank owners and managers.  To the extent this can be achieved, and I believe we have taken some innovative steps in this direction, supervisory and regulatory policies will be both less burdensome and more effective. Unbundling of Financial Services  The unbundling of financial products is now extensive throughout our financial system.  Perhaps the most obvious example is the ever-expanding array of financial derivatives available to help firms manage interest rate risk, other market risks, and, increasingly, credit risks.  Derivatives are now used routinely to separate the total risk of more generic products into component parts associated with various risk factors.  These components frequently are repackaged into synthetic products having risk profiles that mimic financial instruments in other markets.  The synthetic products can then be resold to those investors most willing and able to bear the associated risks. Another far-reaching innovation is the technology of securitization a form of derivative which has encouraged unbundling of the production processes for many credit services.  Securitization permits separate financial institutions to originate, service, fund, and assume the credit or market risks of a portfolio of loans or other assets.  Thus, a financial institution may specialize in those activities where it has particular expertise or other comparative advantages.  For example, to reduce the costs of originating and securitizing certain types of household loans, the underwriting processes used by some financial institutions rely on highly automated credit-scoring models developed by third-party vendors.  These models, in turn, typically are linked to huge databases on borrower characteristics maintained independently by national credit bureaus. Numerous types of assets are now routinely securitized, including residential mortgages, commercial mortgages, auto loans, and credit card loans.   In addition, medium- and large-size businesses, including some that are below investment-grade, regularly access the commercial paper market by securitizing their trade accounts or other assets.  Recently, securitization and credit-scoring are beginning to be applied to small business lending. These and other developments facilitating the unbundling of financial products have surely improved the efficiency of our financial markets.  One benefit is greater economic specialization, as banks and other financial institutions are able to create market niches, for example, in cash management, investment management, or the origination or servicing of certain loans. Moreover, by lowering the costs of hedging and financial arbitrage, derivatives and securitization work to enhance market liquidity and reduce both absolute risk premiums and disparities in risk premiums across financial instruments and geographic regions. Unbundling also has lowered economic barriers to competition, affording households and businesses a greater choice of potential providers for financial products.  The ability to unbundle permits potential competitors to target highly specific product- or market-attributes, for which existing providers are earning excessive \"rents.\"  Through credit-scoring and direct-mail marketing, for instance, a financial institution can identify and recruit potentially profitable credit card customers over a wide geographic area, without incurring the costs associated with a large branch network.  According to our Survey of Consumer Finances, for example, 84 percent of general purpose credit cards held by U.S. households in 1995 were issued by financial institutions from which the card holder received no other financial service. In addition, unbundling has helped erode legal barriers to competition, by enabling one or more attributes of a product to be modified in order to exploit statutory or regulatory \"loopholes.\"  A classic example, of course, is the introduction of money market mutual funds, which ultimately forced the removal of Regulation Q interest rate ceilings on deposit accounts. It is important to recognize that these developments would not have been possible without complementary advances in technology across several disciplines.  First, innovations in finance theory, such as the principle of financial arbitrage and models for pricing contingent claims, provided a conceptual framework for understanding and modeling financial risks.  Second, advances in computer and communications technologies have made these conceptual innovations economically feasible, by lowering the costs associated with information processing and with the transmission of large volumes of data over long distances. Besides promoting competition and improved products and production efficiencies, these same technological advances have spawned a sea-change in the risk management practices of financial institutions.  The largest and most sophisticated banking organizations increasingly have centralized their risk management at the parent level cutting across legal entities and financial instruments. This new management paradigm is grounded in the same conceptual techniques employed by financial engineers to unbundle the total risk of an individual asset.  Such techniques rely on the financial engineer's ability to model the relationship between an individual asset's economic value and a number of separate risk factors.  Carrying this process further, the relationship between these risk factors and the value of an overall portfolio can be obtained by summing the relationships for the individual underlying assets.  With the processing power of modern computers, it is now possible to estimate the joint probability distribution of many risk factors and, given this distribution, to simulate the probability distributions of losses for large, complex portfolios. Over the past decade or so, the largest banking organizations have invested substantial sums to hire the staff and to create the software, databases, and related management information systems to carry out such computations.  Most of you are aware of the application of this technology in VAR, or \"value-at-risk,\" models, which are used to estimate loss distributions for trading portfolios.  More recently, many large banking organizations have begun using similar technologies to measure the credit risk in their loan portfolios.  In both applications, the measurements of overall portfolio risk are used to determine the prices for loans and other products needed to achieve hurdle rates-of-return on shareholder equity, to assess the adequacy of an organization's overall equity capital, as well as for other management purposes. These efforts to develop more centralized risk management systems are being driven by normal competitive pressures to maximize synergies within financial organizations, such as joint-production and cross-selling opportunities involving multiple subsidiaries.  This, in turn, is the logical outcome of the organization's desire to produce and market its products most efficiently and to achieve the highest risk-adjusted returns for shareholders.  Such synergies cannot occur if the parent is merely a passive portfolio investor in its subsidiaries.  Reflecting this economic reality, virtually all large bank holding companies are now operated and managed as integrated units. The trend toward centralized risk management raises some fundamental policy issues for how we should regulate and supervise large, complex banking organizations.  Chief among these, this trend raises serious doubts regarding suggestions that we rely solely on decentralized \"functional regulation\" as we move to expand further the permissible activities of banking organizations.  The traditional view of the functional approach to regulating a banking organization would involve a bank regulator supervising the insured bank, the SEC supervising any broker/dealer subsidiary, a state insurance department supervising any insurance subsidiary, and so on.  Each functional regulator would look only at the risk management practices of the regulated entity under its supervision; unregulated subsidiaries, including the parent, would be unsupervised.  Before technology advanced to a point where substantial oversight and control of large banking organizations could be consolidated at the parent level, functional regulation conformed with practical limitations on the abilities of managers to coordinate resources, and evaluate risks, for the organizations as a whole.  In essence, a decentralized approach to regulation followed from the decentralized financial decisionmaking process of its day.  To borrow a concept from architecture: form followed function. In today's world, however, the \"form,\" decentralized regulation, no longer follows the \"function,\" centralized risk management.  Almost by definition, the synergies upon which centralized management is predicated imply that neither a subsidiary's economic condition on a going-concern basis nor its exposure to potential risks can be evaluated independently of the condition and management policies of the consolidated organization.  Regulation must fit the architecture of what is being regulated. To give one example, it is common for complex banking organizations to manage the relationships with large customers centrally, even though the underlying cash management, credit, or capital markets services provided to the customer may transcend several subsidiaries.  Under this framework, the way the organization's internal transfer pricing system allocates costs, revenues, and risks to a specific regulated entity may be somewhat arbitrary, or even misleading.  Yet, a functional regulator looking only at the entity under its supervision generally would have insufficient information to validate the reasonableness of these allocations. A purely decentralized regulatory approach would also greatly diminish our ability to evaluate and contain potential systemic disruptions in the financial system, since no regulator would be responsible for monitoring the consolidated banking organization.  We should remember that one of the primary motivations of a society having a central bank and a safety net is precisely to limit systemic risk.  Partly in recognition of the fact that financial organizations are managed on a consolidated basis, financial markets generally view them as single economic entities.  Thus, troubles in the nongovernment-regulated portion of a bank holding company cannot be expected to leave the government-regulated subsidiaries unscathed.  In a worst case scenario, problems in one part of an organization could precipitate a run at a healthy affiliate bank and could even generate spillover effects onto nonaffiliated banks. It is worth noting that recent deposit insurance and depositor preference legislation may increase these concerns, by exposing uninsured creditors of banks to a greater risk of loss than in the past.  While these new initiatives have the significant benefit of strengthening market discipline, they may also induce some additional systemic risks, even for healthy banks, in periods characterized by heightened levels of economic uncertainty.  We don't have much experience, yet, in operating under these new ground rules. For all of  these reasons, I believe we must continue to have some type of umbrella supervision for banking organizations, especially for the largest and most complex organizations that pose the greatest systemic risk concerns.  In my judgment, therefore, the critical challenge is to develop approaches to implementing umbrella supervision that are effective in limiting systemic risk without distorting economic incentives or being unduly burdensome to banking organizations. Innovation, Uncertainty, and Bank Supervision If history is our guide, market innovations with or without supporting legislation will continue to stimulate financial modernization.  As this process unfolds, we can expect banking organizations to undertake an increasing number of financial activities.  Under these circumstances, policymakers face a very difficult tradeoff: namely, balancing the need for financial stability and umbrella supervision, on the one hand, against our desire to avoid extending bank-like regulation and the safety net over these new activities. In addressing this tradeoff, policymakers also have an obligation to consider the potential effects of their policies, unintended as well as intended, on the process of financial innovation.  Technological progress has been a critical element in rising living standards.  This is not surprising, because the creation and diffusion of innovations have represented voluntary decisions by individuals and firms acting in their own self-interests.  Government policies always pose some risk of misdirecting or distorting this process by interfering with normal competitive market mechanisms.  This concern is particularly relevant to the financial sector, whose innovations seem to be especially attuned to the risk-return incentives created by the safety net and regulatory policies. Designing government policies that minimize the potentially disruptive effects on private incentives to innovate is complicated by how little we really understand the process of innovation and technological change.  Forecasting the direction or pace of technological change has proved to be especially precarious over the generations, even for relatively mature industries. While uncertainty is inherent in any creative process, Nathan Rosenberg of Stanford suggests that even after an innovation's technical feasibility has been clearly established, its ultimate effect on society is often highly unpredictable.  He notes at least two sources of this uncertainty.  First, the range of applications for a new technology may not be immediately apparent.  For instance, Alexander Graham Bell initially viewed the telephone as solely a business instrument merely an enhancement of the telegraph for use in transmitting very specific messages, such as the terms of a contract.  Indeed, he offered to sell his telephone patent to Western Union for only $100,000, but was turned down.  Similarly, Guglielmo Marconi initially overlooked the radio's value as a public broadcast medium, instead believing its principal application would be in the transmission of point-to-point messages, such as ship-to-ship, where communication by wire was infeasible. A second source of technological uncertainty reflects the possibility that an innovation's full potential may be realizable only after extensive improvements, or after complementary innovations in other fields of science.  According to Charles Townes, a Nobel Prize winner for his work on the laser, the attorneys for Bell Labs initially refused, in the 1960s, to patent the laser because they believed it had no applications in the field of telecommunications.  Only in the 1980s, after extensive improvements in fiber optics technology, did the laser's importance for telecommunications become apparent. It's not hard to find examples of such uncertainties within the financial services industry.  The evolution of the OTC derivatives market over the past decade has been nothing less than spectacular.  But as the theoretical underpinnings of financial arbitrage were being published by Modigliani and Miller in the late 1950s, few observers could have predicted how their insights would eventually revolutionize global financial markets.  This is because, in addition to their insights, at least two complementary innovations had to fall into place.  The first was further conceptual advances in contingent claims theory, such as the Black-Scholes option pricing model.  The second was several generations of advances in computer and communications technologies that were necessary to make these concepts computationally practicable. Given the high degree of uncertainty inherent in the development of new products and processes, policymakers should be cautious when attempting to anticipate the future path of innovation, or the effects new regulations may have on innovation.  There are several aspects to this interaction between government policies and market innovation.  First, banking organizations may develop new products or innovations to exploit regulatory \"loopholes,\" or they may decline to develop new products whose likely regulatory treatments are viewed as burdensome or unclear.  Another unintended consequence is that a policy action may establish an inappropriate unofficial government standard for how certain activities should be conducted.  In contrast to government standards, which can be extremely difficult to change, when the private sector adopts a standard that subsequently becomes outmoded, market forces generally can be expected to remedy the situation. The history of retail electronic payments provides a useful illustration.  In the 1970s, when many were heralding the advent of a \"cashless society,\" the Federal Reserve and the Treasury played an important role in developing and promoting what was seen as a key component of this vision the automated clearinghouse system.  Now, twenty years later, we know that while the ACH has been successful in some areas, it has failed to replace a substantial portion of the daily flow of paper checks in the economy.  This experience leads me to conclude that the experimentation with innovative electronic payment methods that we are seeing today in the private sector is likely to have a much better chance of meeting the needs of consumers and businesses than did the government-led initiatives two decades ago. Within the context of banking regulation, concerns about setting a potentially inappropriate regulatory standard were an important factor in the decision by the banking agencies several years ago not to incorporate interest rate risk and asset concentration risk into the formal risk-based capital standards.  In the end, we became convinced that the technologies for measuring and managing interest rate risk and concentration risk were evolving so rapidly that any regulatory standard would quickly become outmoded or, worse, inhibit private market innovations.  Largely for these reasons, ultimately we chose to address the relationship between these risks and capital adequacy through the supervisory process. I believe that in many cases, policymakers can reduce potential distortions by structuring policies to be more \"incentive-compatible\"  that is, by working with, rather than around, the profit-maximizing goals of investors and firm managers.  In light of the underlying uncertainties illustrated in my earlier examples, I readily acknowledge this is often easier said than done.  Nevertheless, I believe some useful guiding principles can be formulated. The first guiding principle is that, where possible, we should attempt to strengthen market discipline, without compromising financial stability.  As financial transactions become increasingly rapid and complex, I believe we have no choice but to harness market forces, as best we can, to reinforce our supervisory objectives.  The appeal of market-led discipline lies not only in its cost-effectiveness and flexibility, but also in its limited intrusiveness and its greater adaptability to changing financial environments. Measures to enhance market discipline involve providing private investors    the incentives and the means to reward good bank performance and penalize poor performance.  Expanded risk management disclosures by financial institutions is a significant step in this direction.  In addition, Congress has undertaken important initiatives, including a national depositor preference statute and the least-cost resolution and prompt corrective action provisions of the FDIC Improvement Act.  Of course, the value of these initiatives will depend on the credibility of regulators in implementing the legislative mandates consistently over time. A second guiding principle is that, to the extent possible, our regulatory policies should attempt to simulate what would be the private market's response in the absence of the safety net.  Such a principle suggests that supervisory and regulatory policies, like market responses, should be capable of evolving over time, along with changes in institutional practices and financial technologies.  Almost certainly, such a principle implies that we avoid locking ourselves into formulaic, one-size-fits-all approaches to measuring and affecting bank safety and soundness.  For example, as a bank's internal systems for measuring and managing market, credit, and operating risks improve with advances in technology and finance, our supervisory policies should become more tailored to that bank's specific needs and internal management processes. Recently, we have taken several steps that attempt to operationalize this concept, including the introduction of an internal models approach to assessing capital for market risks in large banks' trading accounts.  Also, as I am sure most of you are aware, the Board is currently pilot-testing with the New York Clearing House Association an alternative capital allocation procedure for market risk, called the \"pre-commitment\" approach.  The pre-commitment approach would permit capital requirements for market risk to reflect not only the estimates of risk derived from a bank's internal market-risk model, but also other features of the bank's trading risk management system that help limit its overall risk exposure such as the effectiveness of its internal controls and other  risk-management tools. Conclusions Over the last three decades, the folly of attempting to legislate or regulate against the primal forces of the market is one of the most fundamental lessons learned by banking regulators.  If those market forces are driving financial firms toward centralized decisionmaking regarding risk, pricing, and other operational issues, it will be difficult, at best, to implement a decentralized approach to prudential regulation, however attractive its apparent simplicity.  Similarly, in the face of continual market-driven innovations in banks' risk measurement and management systems, regulatory approaches based on rigid, one-size-fits-all rules are likely to become quickly outdated, ineffectual, and, worse, potentially counterproductive.",
                  "1997-05-01 00:00:00"
                ],
                [
                  "47",
                  "Chairman Alan Greenspan",
                  " It is a pleasure to be here today. I will take this occasion to offer some thoughts related to the upcoming G-7 economic summit meeting, which will be held in Denver in less than two months.  One theme in recent summit meetings starting in Halifax in 1995 and continuing in Lyon last year has been the promotion of stability in international financial markets.  My purpose today is not to describe all the efforts that have been made in that regard, which relate primarily to supervision and regulation.  Rather, I would like to step back a bit and offer a framework for thinking about those efforts. To begin with, we should not lose sight of the fact that government regulation, if not carefully designed, can undermine the effectiveness of private market regulation and can itself be ineffective in protecting the public interest.  No market is ever truly unregulated in that the self-interest of participants generates private market regulation.  Counterparties thoroughly scrutinize each other, often requiring collateral and special legal protections; self-regulated clearing houses and exchanges set margins and capital requirements to protect the interests of the members.  Thus, the real question is not whether a market should be regulated.  Rather, it is whether government intervention strengthens or weakens private regulation, and at what cost.  At worst, the introduction of government rules may actually weaken the effectiveness of regulation if government regulation is itself ineffective or, more importantly, undermines incentives for private market regulation.  Regulation by government unavoidably involves some element of perverse incentives, that is, moral hazard.  If private market participants believe that government is protecting their interests, their own efforts to do so will diminish. At the same time, societies have judged that it is not sufficient to rely exclusively on the private sector to ensure the adequacy of the management of risk in our financial systems.  There is a perceived need for supervision and regulation by the public sector, as well.  As I will point out shortly, this need arises largely to counter the potential moral hazard that arises as a consequence of the development of large safety nets for our financial systems. Many of the benefits banks provide modern societies derive from their willingness to take risks and from their use of a relatively high degree of financial leverage.  Through leverage, in the form principally of taking deposits, banks perform a critical role in the financial intermediation process; they provide savers with additional investment choices and borrowers with a greater range of sources of credit, thereby facilitating a more efficient allocation of resources and contributing importantly to greater economic growth.  Indeed, it has been the evident value of intermediation and leverage that has shaped the development of our financial systems from the earliest times certainly since Renaissance goldsmiths discovered that lending out deposited gold was feasible and profitable. Central bank provision of mechanisms for converting highly illiquid portfolios into liquid ones in extraordinary circumstances a key element of our safety nets has led to a greater degree of leverage in banking than market forces alone would support.  Traditionally these mechanisms involve making discount or Lombard facilities available, so that individual depositories could turn illiquid assets into liquid resources and not exacerbate unsettled market conditions by the forced selling of such assets or the calling of loans.  More broadly, open market operations, in situations like that which followed the crash of stock markets around the world in 1987, satisfy increased needs for liquidity for the system as a whole that otherwise could feed cumulative, self-reinforcing contractions across many financial markets. Of course, this same leverage and risk-taking also greatly increase the possibility of bank failures.  Without leverage, losses from risk-taking would be absorbed by a bank's owners, virtually eliminating the chance that the bank would be unable to meet its obligations in the case of a \"failure.\"  Some failures can be of a bank's own making, resulting, for example, from poor credit judgments.  For the most part, these failures are a normal and important part of the market process and provide discipline and information to other participants regarding the level of business risks.  However, because of the important roles that banks and other financial intermediaries play in our financial systems, such failures could have large ripple effects that spread throughout business and financial markets at great cost. The presence of the safety net, which inevitably imparts a subsidy to banks, has created a disconnect between risk-taking by banks and banks' cost of capital.  It is this disconnect that has made necessary a degree of supervision and regulation that would not be necessary without the existence of the safety net.  That is, regulators are compelled to act as a surrogate for market discipline since the market signals that usually accompany excessive risk-taking are substantially muted, and because the prices to banks of government deposit guarantees, or of access to the safety net more generally, do not, and probably cannot, vary sufficiently with risk to mimic market prices.  The problems that arise from the retarding of the pressures of market discipline have led us increasingly to accept supervision and regulation that endeavors to simulate the market responses that would occur if there were no safety net, but without giving up its protections. To be sure, we should recognize that if we choose to have the advantages of a safety net and a leveraged system of financial intermediaries, the burden of managing risk in the financial system will not lie with the private sector alone.  With leveraging there will always exist a remote possibility of a chain reaction, a cascading sequence of defaults that will culminate in financial implosion if it proceeds unchecked.  Only a modern central bank, with its unlimited power to create money, can with a high probability thwart such a process before it becomes destructive.  Hence, central banks will of necessity be drawn into becoming lenders of last resort.  But implicit in the existence of such a role is that there will be some form of allocation between the public and private sectors of the burden of risk of extreme outcomes.  Thus, central banks are led to provide what essentially amounts to catastrophic financial insurance coverage.  Such a public subsidy should be reserved for only the rarest of disasters.  If the owners or managers of private financial institutions were to anticipate being propped up frequently by government support, it would only encourage reckless and irresponsible practices. In theory, the allocation of responsibility for risk-bearing between the private sector and the central bank depends upon an evaluation of the private cost of capital.  In order to attract, or at least retain, capital, a private financial institution must earn at minimum the overall economy's rate of return, adjusted for risk.  In competitive financial markets, the greater the leverage, the higher the rate of return, before adjustment for risk.  If private financial institutions have to absorb all financial risk, then the degree to which they can leverage will be limited, the financial sector smaller, and its contribution to the economy more limited.  On the other hand, if central banks effectively insulate private institutions from the largest potential losses, however incurred, increased laxity could threaten a major drain on taxpayers or produce inflationary instability as a consequence of excess money creation. Thus, governments, including central banks, have been given certain responsibilities related to their banking and financial systems that must be balanced.  We have the responsibility to prevent major financial market disruptions through development and enforcement of prudent regulatory standards and, if necessary in rare circumstances, through direct intervention in market events.  But we also have the responsibility to ensure that private sector institutions have the capacity to take prudent and appropriate risks.  Our goal as supervisors should not be to prevent all bank failures, but to maintain sufficient prudential standards so that banking problems that do occur do not become widespread.  We try to achieve the proper balance through official regulations, as well as through formal and informal supervisory policies and procedures. The revolution in information and data processing technology has transformed our financial markets and the way our financial institutions conduct their operations.  In most respects, these technological advances have enhanced the potential for reducing transactions costs, to the benefit of consumers of financial services, and for managing risks.  But in some respects they have increased the potential for more rapid and widespread disruption. The efficiency of global financial markets, engendered by the rapid proliferation of financial products, has the capability of transmitting mistakes at a far faster pace throughout the financial system in ways that were unknown a generation ago, and not even remotely imagined in the 19th century.  Financial crises in the early 19th century, for example, particularly those associated with the Napoleonic Wars, were often related to military and other events in faraway places.  Communication was still comparatively primitive.  An investor's speculative position could be wiped out by a military setback, and he might not even know about it for days or even weeks, which, from the perspective of central banking today, might be considered bliss. Similarly, the collapse of Barings Brothers in 1995 showed how much more rapidly losses can be generated in the current environment relative to a century earlier when Barings Brothers confronted a similar episode.  Current technology enables single individuals to initiate massive transactions with very rapid execution.  Clearly, not only has the productivity of global finance increased markedly, but so, obviously, has the ability to generate losses at a previously inconceivable rate.  These technological forces also have been central to the process of globalization, that is, the growing integration of national economies including national financial markets.  They are, of course, not the only forces.  The gradual removal of barriers to trade, deregulation and reform of financial systems, and simply the enormous creation of wealth have all generated the demand and opportunities for the expansion of investment and business horizons beyond national boundaries.  Technological changes have facilitated such an expansion.  The growing importance of emerging market economies in international financial markets is one manifestation not just of the impressive growth of those economies but also of increasing global integration.  Thus, it is not surprising that the need to promote financial stability, and in particular to enhance prudential supervision, in emerging market economies was identified at the Lyon summit as an important objective.  It is important for those economies individually and for all of us collectively. One element of the follow-up to the Lyon summit that is especially fitting in the context of my earlier remarks has been efforts to enhance market transparency, including more and more meaningful public disclosure.  Meaningful public disclosures by firms about the nature of their risk exposures and their procedures for managing those risks contribute significantly to the constructive role of market discipline.  Not surprisingly, the market itself is probably the most powerful source of pressure for improved disclosures. I might mention one specific accomplishment related to market transparency.  Central banks have agreed to establish a system of regular reporting of derivatives activities by the world's major dealers, beginning as of June 1998.  The system has been designed to yield aggregate data on global trading activities in a manner that avoids double counting and is sensitive to reporting burden.  The aggregate data will be publicly released to enable firms to assess their own activities in relation to the market as a whole. The globalization of international financial markets and of the operations of individual firms clearly calls for international cooperation among supervisors.  Correspondingly, supervisory cooperation is an important element of the G-7 summit agenda on financial stability.  Much of the recent work has related to the desirability of a more systematic exchange of information among national supervisors, including consideration of what kinds of information need to be exchanged and under what circumstances.  The possible need for and possible roles of an \"information coordinator\" have been central issues in the Joint Forum discussions. The objective of a more systematic exchange of information is easy to support in principle.  However, when it comes to implementation, there are questions that need to be addressed.  Even more questions arise when one thinks of going beyond the exchange of information to other forms of supervisory coordination, involving a \"lead regulator\" of some kind that is intended to fill so-called supervisory gaps. What are the supervisory gaps that need to be filled?  Each of us could probably point to episodes where problems could have been avoided, or the degree of disruption could have been reduced, if better information had been available sooner to supervisory authorities.  Perhaps Barings is one example.  It is more difficult to point to episodes when the absence of formal arrangements for coordination of supervisory actions inhibited a response to a problem.  Conversely, might arrangements that are too formal, too rigid, or too cumbersome themselves inhibit appropriate responses in emergency situations, each of which is likely to be unique?",
                  "1997-04-29 00:00:00"
                ],
                [
                  "48",
                  "Governor Laurence H. Meyer",
                  "The Economic Outlook and Challenges Facing Monetary Policy It is a pleasure to be here and discuss the economic outlook and monetary policy with fellow forecasters.  I am going to offer some interpretations of the outlook as a context for the recent policy action by the Federal Reserve and explain how I view this action as part of a prudent and systematic strategy for monetary policy.  The Forecasters Club of New York is an ideal forum for me to offer this commentary because, in my view, the recent policy action must be understood not in terms of where the economy has been recently, but rather in terms of the change in the forecast,  a change in expectations about where the economy likely would be in six or twelve months in the absence of a policy change.  Before proceeding, let me emphasize that the views on the economic outlook and monetary policy strategy I present this afternoon are my own.  I am not speaking for either the FOMC or the Board of Governors or for any other individual members.  If you want to know the views of the FOMC, you will have to do your homework-for example, read the announcement issued at the end of the last FOMC meeting, the Humphrey Hawkins testimony of the Chairman, the speeches and other comments by the full complement of participants in the FOMC, and the minutes of the last meeting when they become available.     First, I shall discuss some aspects of the analytical framework or model that underlies my forecast, which in turn underpins my reasoning for the recent policy action.  Second, I'll discuss the outlook context of the policy decision.  Third, I'll describe the evolution of policy from a period of steady policy and asymmetric directives to the recent preemptive action.  Fourth, I'll offer several interpretations of the policy action in relation to what I believe are important aspects of the strategy of monetary policy.  Finally, I'll discuss some of the factors that will influence my views of the appropriate course of policy in the months ahead.  The Analytical Framework Let me remind you at the outset of the framework I have been using to explain the challenge facing monetary policy in the current environment of healthy growth and high levels of resource utilization.  The risk of higher inflation in this environment has two dimensions.  First, there is the risk that current utilization rates are already so high that inflation will gradually increase over time.  Second, there is the risk that the growth in output will be above trend going forward, implying that utilization rates will rise from their already high level, compounding the risk of higher inflation.  Some apparently believe there are no speed limits, and no utilization rate can be so elevated that it threatens higher inflation.  The reality is that above-trend growth raises utilization rates and, after some point, excessively high utilization rates result in higher inflation.  But it is also true that threshold utilization rates and trend growth can change, that the current threshold levels for both utilization and growth rates are uncertain, that inflation can be affected by factors other than excess demand, and that policy is not infallible.   Such uncertainty is a fact of life for both forecasters and policymakers.  Just as forecasters do not stop forecasting because the job is difficult, policymakers have to adjust to uncertainty and not be paralyzed by it.  The recent Federal Reserve policy action was clearly a preemptive one.  This means that it was undertaken not in response to where the economy and inflation were at the time of the policy change, but in response to where the economy and inflation were projected to be in the future, absent a policy change.  Such policy action necessarily involves a forecast and such a forecast typically is grounded in some model that relates growth, unemployment, wage change and inflation, among other variables.  So let me be specific about the causal structure of the model that underpins my judgment with respect to appropriate monetary policy action.    I am a strong and unapologetic proponent of the Phillips Curve and the NAIRU concept.  Fundamentally, the NAIRU framework involves two principles.  First, the proximate source of an increase in inflation is excess demand in labor and/or product markets.  In the labor market, this excess demand gap is often expressed in this model as the difference between the prevailing unemployment rate and NAIRU, the non-accelerating inflation rate of unemployment. Second, once an excess demand gap opens up, inflation increases indefinitely and progressively until the excess demand gap is closed, and then stabilizes at the higher level until cumulative excess supply gaps reverse the process. There is a third principle that I subscribe to, which, though not as fundamental as the first two, also plays a role in my forecast and in my judgment about the appropriate posture of monetary policy today.  Utilization rates in the labor market play a special role in the inflation process.  That is, inflation is often initially transmitted from labor market excess demand to wage change and then to price change.  This third principle may be especially important today because, in my view, there is an important disparity between the balance between supply and demand in the labor and product markets, with at least a hint of excess demand in labor markets, but very little to suggest such imbalance in product markets.  It is important to understand that the Phillips Curve is a model of inflation dynamics, not a model that determines the equilibrium inflation rate.  For this reason, the Phillips Curve paradigm is not at all inconsistent with the view that inflation is, in the long run, exclusively a monetary phenomenon.  Perhaps the easiest way to appreciate this is to recall that the long-run Phillips Curve is widely understood to be vertical.  In other words, NAIRU is consistent with any constant rate of inflation, including zero.  The Phillips Curve therefore cannot determine inflation in the long run because it is consistent with any constant rate of inflation.  What does determine the rate of inflation in the long run?  The rate of money growth, of course, though one needs to assume a stable money demand function to get a stable relationship between money growth and inflation.  What does the Phillips Curve explain, if not the long-run level of inflation?  The answer is that it explains the dynamics of the inflation process, how the economy evolves from one inflation rate to another, for example, in response to an increase in the rate of money growth.  The dynamics of changes in inflation operate through excess demand in labor and/or product markets.  Thus the Phillips Curve indicates that, if the unemployment rate is maintained at a level below NAIRU, inflation increases over time, progressively and indefinitely.   The initial source of an increase in inflation can be anything which produces excess demand in labor and output markets.  It could also be a supply shock, but I am ignoring this possibility so I can focus exclusively on the implications of the current strength in aggregate demand.  Under an interest rate operating procedure, an increase in aggregate demand which increases output, utilization rates, and, ultimately, inflation will itself generate an increase in the money supply to support the higher nominal income.  Money is not pinned down in such a regime, but passively adjusts to changes in nominal income.     Despite the sharpness and force of the Phillips Curve/NAIRU model, it can be difficult to implement in practice.  Still, this relationship was about the most stable tool in the macroeconomists' tool kit for most of the past 20 years; those who were willing to depend on it were likely to be very successful forecasters of inflation, and the record speaks for itself on this score.  Nevertheless, the combination of the 7-year low in the unemployment rate and 30-year low in inflation was a surprise to those using this framework.  The challenge is to understand why we have been so fortunate.  But, it should also be noted that monetary policy has responded appropriately to this surprise.  That is, monetary policy has been careful not to be tied rigidly to a constant estimate of NAIRU.  Instead, in my view, monetary policymakers have, in effect, implicitly adjusted their estimate of NAIRU to reflect the incoming data; this might be viewed as following a procedure like the time-varying parameter estimation technique applied by Robert Gordon and others.  In the short run, there are many factors, in addition to aggregate demand, that influence inflation  including changes in the minimum wage, shocks to food and oil prices unrelated to the balance between aggregate demand and supply in the U.S., changes in the exchange rate, and exogenous effects on health care costs, etc.   Some of these can be and have been effectively incorporated into the Phillips Curve model, but some of these factors have generally been outside the model.  One explanation for the better than expected performance of core inflation in relation to the unemployment rate focuses, for example, on a series of favorable supply shocks  including the slowdown in benefit costs and the decline in import prices  that traditionally are not incorporated in estimated Phillips Curves.  In addition, even adjusting for the above factors, NAIRU is not a constant, but can and has changed over time.  For example, the evidence suggests that changes in the demographic composition of the labor force affect NAIRU and it is also likely that government programs, including unemployment compensation and welfare, also affect NAIRU.  Further, the evidence suggests that, even accounting for demographics, government programs, and supply shocks, NAIRU may have edged lower over the last couple of years. The consensus in the profession is that NAIRU may have declined from around 6 percent in the decade ending in the early 1990s to perhaps 5½ percent today, though some believe that the decline is even larger, while others believe that any appearance of decline is due to temporary factors so that NAIRU will ultimately settle back to close to the earlier estimate.  Clearly, one of the challenges of monetary policy is to set policy in the context of uncertainty about the precise value of NAIRU.   The second element in the analytical framework is the link from output growth to the level of excess demand.  The economy has a capacity to grow over time that is limited by the sum of the trend rate of growth in the labor force and the trend rate of growth in labor productivity.  While both components can change over time and labor force and productivity growth are subject to both cyclical variation as well as secular shift, the historical record suggests that the trend rate of output growth changes very slowly over time.  Currently, the trend rate of labor force growth is near 1 percent per year (based on population growth and leaving, for later, the interpretation of the recent rise in the participation rate) and the trend rate of productivity growth is slightly above 1 percent per year (though there is more than the usual uncertainty about this estimate, in part due to conflicting indications in measures of productivity derived from the product and income sides of the national accounts), resulting in trend output growth in the 2-2½ percent range.  A key relationship is that when actual growth in output equals trend growth, utilization rates are constant; and when actual growth exceeds trend growth, utilization rates increase.   Now we can put the causal structure of the inflation process together, connecting up growth, unemployment rates, and inflation.  Growth above trend raises utilization rates.  Rising labor force utilization rates raise wage change relative to productivity growth.  An increase in wage change relative to productivity growth raises labor costs and an increase in labor costs results in higher price inflation.   Quiz time!  Does growth cause inflation?  Not exactly.  Certainly, higher trend growth does not raise inflation.  Indeed, an unexpected increase in trend productivity and hence trend growth in output would likely result in lower inflation for a while; if the rate of money growth were held constant, a permanent increase in productivity growth would result in a permanent decline in inflation.   Although above-trend growth in output does not directly cause inflation, to the extent it results in increases in utilization rates, after some point, sustained above-trend growth will result in higher  inflation.    There are, to be sure, a number of uncertainties in this causal structure that are highly relevant to the current circumstances.  First, we have to worry about whether there may have been a change in trend growth, for example, due to a rise in trend productivity growth or a change in the trend in labor force participation.  If trend growth has increased, whether because of higher labor force growth or higher productivity growth, then we would observe that rapid growth does not raise utilization rates.   Second, we have to worry about whether NAIRU may be declining or, at least, may be lower than currently estimated.  If NAIRU is lower than we expect, then the current unemployment rate is less likely to be associated with excess demand in the labor market and therefore poses less risk of higher inflation.  Checks and balances are essential here.  For example, it is important to confirm that utilization rates are rising before continuing very long to tighten policy to damp presumed above-trend growth.  This will prevent a persistent mistake in the face of an unexpected shift in the economy's trend rate of growth.  Monetary policy usually avoids this mistake by focusing on utilization rates and not growth.  The second check is to confirm that, following a decline in the unemployment rate, wage change is moving higher, consistent with increased excess demand in the labor market.  In addition, we have to take into account temporary forces related to, for example, minimum wage, health care costs, and exchange rates.  Finally, we have to make allowances for the dynamics of the process, including the tendency for inertia to result in only a very small initial increase in inflation once excess demand has developed and the tendency of the initial rise in wages in excess of productivity to be tempered by a decline in profit margins before leading to higher prices.   The Outlook Context  Now let me summarize the key features of recent macroeconomic performance.  The economy advanced at a 3.1 percent rate over 1996, including a 3.8 percent rate in the fourth quarter.  Growth in the first quarter appears to have been at least as strong as the pace in the fourth quarter, and the economy seems to have solid momentum in the current quarter.  In short, the economy appears to be growing at an unsustainable above-trend rate.  By the way, is the prevailing trend rate of growth both historically low and disappointing?  Yes.  Would it be desirable, therefore, to raise the trend rate of growth?  Yes.  Can monetary policy accomplish this worthy task?  No.  Can the Congress and the Administration, through judicious combination of deficit reduction and saving and investment incentives, raise trend growth (at least for a while)?  Yes.  Are there opportunities for monetary policy to contribute to steady growth?  Yes.  First, to the extent that policy can avoid a cyclical rise in inflation, it can avoid the subsequent monetary policy response to limit and then reverse the rise in inflation; the result of avoiding the boom is avoiding the bust.  Disciplined monetary policy therefore encourages steady growth, with the emphasis on the steady.  Second, to the extent that price stability encourages saving and investment and a more efficient allocation of resources, as is widely believed, a monetary policy that promotes price stability is the one that best encourages steady growth, now with the emphasis on growth.  Now back to the economic outlook.    The unemployment rate which has fluctuated in a rather narrow band over the last year and a half has recently been inching lower and is now equal to its cyclical and 7-year low.  I suspect that the unemployment rate is now below NAIRU, though the steady rise in wage change over the last year suggests that the unemployment rate may have been somewhat below NAIRU for a while.  Another aside.  Don't I like wage growth?  Yes, but only to the extent it is real; that is, only to the extent that it does not yield increases in inflation that in turn prevent the purchasing power of wages from advancing.  Shouldn't workers share in the bounty of a healthy economy?  Of course.  But workers will best share in the bounty when there is sustainable growth and will pay a high price for unsustainable growth in the cyclical instability that would surely follow such excess.  Let me add one more complication.  It is possible for wages to increase faster than productivity for a while to allow a rebound in real wages, for example, if real wages had earlier in the expansion advanced at a rate less than allowed by trend productivity.   In this case,  a rebound in real wages could be unwinding a temporary increase in profit margins and could therefore be accommodated without an increase in inflation.     Wage change, as I just noted, has been rising.  The 12-month increase in average hourly earnings is now 4.1 percent, a percentage point higher than a year ago.  Compensation per hour, as measured by the ECI, has to date accelerated more modestly, with the slowing rise in benefit costs tempering the effect of a sharper rise in wage costs.  The first quarter ECI bears watching for signs of a further rise in wage change and possibly a bottoming out of the recent slowing in the pace of increase in benefit costs.  Core inflation remains at a cyclical and 30-year low, with the 12-month increase in the core CPI at 2.5 percent.  Note, however, to correctly measure the change in inflation, a comparison of core inflation over the last couple of years has to be adjusted to account for the methodological revisions to the CPI.  To date, BLS revisions have lowered inflation cumulatively by around a quarter point over the past two years.  The point of the policy action, of course, is to try to prevent any significant increase in core inflation.  Clearly the recent performance has been extraordinary.  I have noted previously that it is not only better than virtually anyone had forecast, it is better than historical regularities would have suggested was possible.  The explanations for the continuing decline in core inflation, despite an unemployment rate that in earlier periods would have been associated with rising inflation, include some combination of temporary coincidences and longer-lasting structural changes.  First, the labor force has been growing about twice as rapidly as a trend rate based on population growth.   It is as if demand is calling forth its own supply.  Part of the explanation is a rebound from a sharp decline in participation rates over 1995.  Part reflects a normal cyclical rise in participation rates, delayed in this expansion.  A small part could be the early effects of changes in welfare laws and previous state efforts to trim welfare roles.  As a result, the recent strength of output growth has not resulted in much of an increase in resource utilization rates.  I do not expect labor force growth to continue at its recent rapid rate, though the underlying trend over the next several years may well be augmented by an upward trend in participation rates.  The net result is that output growth must slow from recent levels to prevent further increases in utilization rates.  Second, increased job insecurity appears to have moderated the pace of wage change, relative to what we would have expected at current levels of labor force utilization.  It is important to note here that the effects on inflation of an increase in worker insecurity may be only temporary.  Even with the higher worker insecurity, wages are clearly on a rising trend.  Third, a slowing in the rise in benefit costs (primarily via slower increase in health care costs) has moderated the rise in labor compensation associated with wage pressures.  As a result, the rise in compensation and hence labor costs has been muted, compared to the faster pace of wage gains.  Fourth, declining import prices  directly and indirectly-have restrained price inflation.  Some judgment has to be made in any forecast about the persistence of the special forces that have contributed to restrained wage and price change over recent quarters.  The least likely to continue to act as a restraining influence, in my judgment, is health care and therefore benefit costs, based on surveys of prospective health care insurance premiums. Given the recent further appreciation of the dollar, import prices may decline further, though the restraining effect on inflation may be less important going forward than it has been over the past year.     From an Asymmetric Directive to Preemptive Policy: Why Now?  During the period from July of 1996 through February of 1997, monetary policy remained unchanged but operated with an asymmetric directive.  Utilization rates were high high enough to suggest some risk of rising inflation, but wage gains while trending higher, remained modest and core inflation remained on a downward trend, perhaps due to declining import prices and the slowing of the rise in health care costs.  The anxiety associated with high utilization rates was clearly tempered by the excellent performance of core inflation, resulting in a posture of \"watchful waiting.\"  The Federal Reserve remained alert during this period, but on the sidelines.  While growth was at times well above my estimate of trend, various factors made it reasonable to expect a slowdown in growth toward trend immediately ahead, suggesting that utilization rates would likely remain within their recent ranges.  The asymmetric directive reflected a view that the risks in this environment were asymmetric, that there was a greater risk that inflation would rise in response to the prevailing high utilization rate (and to still higher utilization rates if growth continued above-trend growth) than that the economy would slow to below trend growth.  The asymmetric policy posture was, therefore, a reflection of concern that our forecast might be wrong and that if it were wrong it was more likely to underestimate inflation going forward.  What was different in March, compared to this earlier period?  Not utilization rates.  They were still within the narrow range that had prevailed during this period, though admittedly close to the bottom of that range.  Not core inflation.  If anything, core inflation was lower.  No, the difference, from my perspective, was not in the data for utilization rates, wage change, and inflation, but in my forecast of the future path of these variables.  The change in the forecast, to be sure, was prompted by incoming data suggesting persistent strength in aggregate demand.  Instead of projecting a slowing to trend immediately ahead, it now appeared to me that we were in a period of sustained above-trend growth that would push utilization rates higher and, in particular, would push the unemployment rate below its recent range. A tightening of monetary policy was motivated, from my perspective, not by the prevailing data on unemployment rates, wage change, and inflation, but rather by a forecast of where I expected utilization rates and inflation to be six months and a year from now, if monetary policy remained unchanged.  Whereas I supported the earlier asymmetric directive based on concern that my forecast might be wrong, the preemptive policy action was motivated for me by concern that my (new) forecast might be correct!  The case for a preemptive approach is that it alone holds the promise of sustaining a durable expansion with continued healthy, balanced  growth.  The greatest threat to expansions does not come from a spontaneous weakening of demand, from lethargy, but rather from over-exuberance and overheating.  Once overheating unleashes an increase in inflation, the attempt to first control and then reverse the higher inflation often results in recession.  This gives substance to the well-known worth of \"an ounce of prevention.\"    Interpreting the Policy Action as Part of a Strategy for Monetary Policy  Let me now interpret the tightening in relation to several descriptions of monetary policy strategy.  The first three really are alternative perspectives on a single essential principle of prudent monetary policy, the importance of leaning against the wind by enforcing pro-cyclical movements in short-term interest rates.  The fourth reflects one way in which monetary policy might take into account the uncertainty in the outlook.   A Taylor Rule perspective  I have noted in a number of previous speeches that I view the Taylor Rule as highlighting a couple of important requirements for prudent monetary policy.  First, the Taylor Rule links Federal Reserve policy to a long-run inflation target and thus ensures that, in the long run, policy will force the actual inflation rate to converge to the long-run target.  The Taylor Rule thus imposes a powerful nominal anchor on monetary policy.  Second, the Taylor Rule generally imposes a pro-cyclical pattern on real short-term interest rates, so that monetary policy leans against the cyclical winds and thereby stabilizes the economy, in much the same way that automatic stabilizers in our fiscal institutions, via cyclical swings in government budget deficits, damp business cycles.  Nevertheless, the traditional specification of the Taylor Rule does not provide a justification for tightening in March, relative to the earlier decisions to hold policy unchanged.  According to the Taylor Rule, the federal funds rate should adjust over time to changes in utilization rates (the gap between actual and potential output or between the unemployment rate and NAIRU) and to changes in inflation.  Because utilization rates had not increased (at least had not increased outside the range of the last year) and core inflation was actually lower in March compared with earlier, the Taylor Rule did not dictate a tightening.  The Rule did suggest, however, that monetary policy would have had to tighten over time if the forecast of rising utilization rates and higher inflation proved correct.  But it did not dictate immediate action.  There is however an alternative specification of the Taylor Rule that does motivate an immediate tightening.  I call this a forward looking version of the Taylor Rule.  The traditional specification is forward looking to a degree in relation to inflation, in that it sets the funds rate in relation to both the utilization rate (an advance warning of future increases in inflation) and to inflation.  But the forward-looking specification I have in mind replaces actual inflation and utilization rates in the rule with forecasts of future inflation and utilization rates.  This approach to policy reaction functions was pioneered by Steve McNees of the Federal Reserve Bank of Boston in the mid 1980s and there has been a renewed interest in such an approach, in the context of the Taylor Rule, during the last couple of years.  Such a forward-looking specification would rationalize and justify an increase in the funds rate in response to the forecast of rising utilization rates in the future.    This leaves an interesting question.  Does following a Taylor Rule based on an uncertain forecast outperform a Taylor Rule based on actual data?  That, of course, depends on the quality of the forecasts.  This is an interesting question, one that deserves scrutiny.  But it is really the same as the question: Should policy be preemptive or reactive?  As a forecaster, I am inclined to believe in the forward-looking approach and therefore in preemptive policy.  But I recognize that further work should be done on this subject.  An IS-LM perspective on leaning against the wind  I would interpret the recent strength in demand, from the perspective of an IS-LM model, as a shift in the IS curve.  Such an interpretation of cyclical swings is, of course, in the Keynesian tradition: output is demand determined in the short run (reflecting price stickiness) and swings in output are dominated by autonomous changes in aggregate demand.  How should monetary policy respond to cyclical swings in demand?  Should monetary policy hold short-term interest rates constant, in effect imposing a horizontal LM curve?  In order to do so, it would, in general, have to respond to rightward shifts in the IS curve by adding reserves and facilitating faster money growth, so as to prevent interest rates from rising.  This might be appropriate very early in an expansion, when the unemployment rate is high and inflation is declining, but it is not, in my judgment, prudent in the mature stage of an expansion, and it is most surely imprudent once utilization rates have increased toward or beyond their capacity levels.  The alternative is to maintain an upward sloping LM curve.  In the static model, this is the case when the money supply is fixed; allowing for trend growth and inflation, it would be equivalent to holding money growth constant, assuming a stable money demand function.  In this case, a shift in the IS curve would raise interest rates as the IS curve moved along the upward sloping LM curve.  This is an example of monetary policy \"leaning against the wind.\"  The resulting pro-cyclical movement in interest rates increases the stability of the economy in much the same way as cyclical swings in the federal budget deficit.    Some might argue, however, that even if short-term interest rates do not rise, long-term interest rates, equity prices, and the dollar may change in ways that damp the cyclical swing in demand and thereby lessen the necessity of a direct response of monetary policy.  This is sometimes referred to as the \"gyroscope\" theory (the bond market is the economy's gyroscope) and the active part of management of the cycle is in the hands of so-called \"bond market vigilantes,\" some of whom are undoubtedly in the audience this afternoon.  When long-term rates rise in response to a cyclical strengthening, it reflects, in large part, the expectation of higher short-term interest rates.  Specifically, it reflects expectations about monetary policy.  While monetary policy cannot be a slave to the bond market, when the cyclical state of the economy suggests the desirability of a pro-cyclical response in interest rates, the Federal Reserve should pat the bond market on the back and appreciate its help, but not expect the bond market to carry the entire burden.  Monetary policy in this case needs to validate the movement in the bond market, rather than resist it.  If it does not, surely real long-term interest rates and the dollar will decrease, eroding the market restraint, and in the future markets will be less likely to perform this stabilizing function.  Of course, there will be times when the bond market is, in our view, misreading the strength of the economy and hence also misjudging the future course of our policy.  In this case, we should ignore the bond market and provide an anchor for long-term interest rates to adjust back toward.  Implications of a money growth rule  As I have just noted, a pro-cyclical path for short-term interest rates would result from following a money growth rule.  For an extended period, money demand has been insufficiently stable to allow the monetary aggregates to play a constructive role in the monetary policy process.  More recently, the relationship between M2 and its determinants has stabilized, but the period of a more stable relationship has been relatively brief and has coincided with a relatively stable economy.  As a result, there is not yet much inclination to place increased weight on M2 in the policy process.  What I am offering here is therefore only a thought experiment. Assume that the money demand function for M2 has stabilized and that we could conduct policy by enforcing a constant rate of M2 growth.  Assuming policy maintained a fixed rate of money growth (perhaps the better way to define an unchanged policy), what would be the effect of a cyclical strengthening of the economy (an increase in nominal income growth)?  The answer, of course, is that short-term interest rates would rise.  This is of course just another way of telling the IS-LM story.   What would it take to prevent interest rates from rising?  The answer is that an increase in the rate of money growth would be required to accommodate the faster pace of nominal income growth.  But would this be prudent?  I think not.  Policy in an interest rate regime: the importance of flexibility  Note that under a money growth strategy, it is possible to operate without a change in policy (no change in money growth) while nevertheless imposing an important degree of stability to the economy through the resulting pro-cyclical movement in interest rates.  A constant rate of money supply will not always be optimal, but it will keep you out of a lot of serious trouble you could otherwise get into.  The Federal Reserve and virtually all other central banks operate in a policy regime in which we set some short-term interest rate in our case, the federal funds rate.  For a variety of reasons, this is generally viewed as the best choice of operating strategy.  In this type of regime, however, it is more dangerous to be passive and fail to respond to changing economic conditions.  The prudent pro-cyclical pattern in interest rates, in particular, must be actively put in place, rather than passively served up as would be the case with a policy of constant money growth.  It is important to recognize the importance of moving interest rates in response to changing conditions and the potential for destabilizing policy when policy resists the natural tendency for interest rates to rise during cyclical upswings, especially when the economy is near its potential.  Indeed, the major monetary policy mistakes in the past have not originated in overly aggressive movements in interest rates, but in the failure of policy to adjust interest rates in a timely fashion to changes in cyclical developments.   Tightening as a maximin solution  I noted at the outset the uncertainties in the outlook.  As a result, it is possible to make policy mistakes.  Another way of interpreting the policy action is as an attempt to avoid the worst possible errors in an uncertain environment.  I call this a maximin solution to the policy problem.  It involves comparing the relative costs of two potential policy mistakes in the current uncertain environment: tightening when such a move turned out to be inappropriate and failing to tighten when a tightening would have been appropriate.  The maximin solution (patterned after the solution to the \"prisoners' dilemma\") is to select the option that would yield the smaller cost if the policy turned out to be a mistake.  This analysis does not, in this case, help one to understand why the policy action was taken in March, rather than earlier.  But it does provide a perspective on the role of uncertainty in the setting of monetary policy.  If the Fed tightens and it turns out to have been unnecessary, the result would be that utilization rates turn out lower than desired and inflation lower than would otherwise have been the case.  In the context of the prevailing 7-year low of the unemployment rate, that translates into a higher but still modest unemployment rate and further progress toward price stability, a central legislative mandate.  This may not be the best solution.  I would prefer, in the near term, trend growth at full employment with a continuation of the prevailing modest inflation rate.  But the alternative outcome just described is not a bad result indeed, it would be a preferred result for those who favor a more rapid convergence to price stability.  If the Fed fails to tighten when it would have been appropriate, the result would be higher utilization rates and higher inflation than desirable.  To the extent that the result is a persistent excess demand gap, inflation will steadily rise over time.  This outcome will yield what I call the Taylor Rule's \"triple whammy.\"  Once inflation takes off, interest rates will have to be raised first to prevent a decline in real rates, second to erase the increase in output beyond the economy's productive capacity, and third to lower inflation relative to the inflation target.  This is an affair that almost always turns out be ugly, and poses a much greater threat to a sustained expansion, in my view, than a premature tightening.  What Lies Ahead?  I always taught my students that there was an answer that worked remarkably well most of the time to interesting questions in economics: \"It depends.\"  And this is the only answer I can offer to this second question of the day.  But let me discuss some of the considerations likely to condition my judgment about policy in coming months. I would make a sharp distinction between the action of March 25 and the initial move in February 1994.  Before the tightening in February 1994, monetary policy had been in an unprecedentedly stimulative posture into the third year of an expansion with the real federal funds rate at zero!  This was justified by the unusually slow and erratic nature of the recovery up to this point.  However, once the economy moved into a self-sustaining mode, as was the case during 1994, it was clear that the funds rate would quickly move toward its longer-run equilibrium level, meaning at least a 200 basis point increase, and the market was jolted into this realization by the Fed's initial move.  In the current environment, entering the seventh year of the expansion, the real federal funds rate is already above its longer-term average.  Looking ahead, monetary policy decisions will, as one would expect, depend on how the economy evolves in coming months.  I will be focusing, in particular, on whether growth is continuing above trend with utilization rates rising further and whether inflation pressures are mounting at current utilization rates.        Conclusion  If I have made the setting of monetary policy in an environment characterized by numerous uncertainties appear to be a challenging task, I have accomplished one of my goals.  While such uncertainty can affect the timing and aggressiveness of policy action, it is important that uncertainty does not paralyze monetary policy, especially under an interest rate policy regime.  It is essential that monetary policy \"leans against the wind,\" and the best way to do so is by enforcing a pro-cyclical pattern in short-term interest rates.  This requires that real interest rates rise as long as growth is above-trend and utilization rates are rising.  An exception to this regularity is in the early stages of an expansion, when utilization rates are at a cyclical low and inflation may be falling.  In addition, as production approaches capacity, it is appropriate that policy become still more preemptive.  One way for policy to be more preemptive is to respond to forecasts of rising utilization rates and higher inflation, especially when supported by a recent pattern of strong growth and evidence of continued momentum.  One can take an optimistic or pessimistic view of the recent Fed tightening.  A pessimistic reading would be that the move was unnecessary and that the economy is going to quickly move from rapid growth into a slump, or at least that the Federal Reserve is constraining the economy from achieving its maximum sustainable rate of growth.  An alternative pessimistic assessment is that the policy move was too little, too late, so that the failure to act more swiftly and more aggressively has set the stage for a resurgence in inflation that will threaten the expansion.  An optimistic assessment is that the March 25 move was a small, prudent, and preemptive step to lean against the strengthening cyclical forces and will increase the prospects of a continuation of an expansion with healthy but sustainable growth and continued modest inflation.  Count me among the optimists.",
                  "1997-04-24 00:00:00"
                ],
                [
                  "49",
                  "Chairman Alan Greenspan",
                  "The Evolution of Banking in a Market Economy  I am quite pleased and gratified to receive the Adam Smith Award this evening.  Having been a bank regulator for ten years, I need something to remind me that the world operates just fine with a minimum of us.  Fortunately, I have never lost sight of the fact that government regulation can undermine the effectiveness of private market regulation and can itself be ineffective in protecting the public interest. It is most important to recognize that no market is ever truly unregulated in that the self-interest of participants generates private market regulation.  Counterparties thoroughly scrutinize each other, often requiring collateral and special legal protections; self-regulated clearing houses and exchanges set margins and capital requirements to protect the interests of the members.  Thus, the real question is not whether a market should be regulated.  Rather, it is whether government intervention strengthens or weakens private regulation, and at what cost.  At worst, the introduction of government rules may actually weaken the effectiveness of regulation if government regulation is itself ineffective or, more importantly, undermines incentives for private market regulation.  Regulation by government unavoidably involves some element of perverse incentives.  If private market participants believe that government is protecting their interests, their own efforts to do so will diminish. No doubt the potential effectiveness of private market regulation and the potential ineffectiveness of government intervention is well understood by those attending this conference on zero-based government.  However, I am sure that you will not be taken aback to hear that many here in Washington are skeptical of market self-regulation and seem inclined to believe that more government regulation, especially in the case of banking, necessarily means better regulation. To a significant degree, attitudes toward banking regulation have been shaped by a perception of the history of American banking as plagued by repeated market failures that ended only with the enactment of comprehensive federal regulation.  The historical record, however, is currently undergoing a healthy reevaluation.  In my remarks this evening I shall touch on the evolution of the American banking system, focusing especially on the pre-Civil War period, when government regulation was less comprehensive and less intrusive and interfered less with the operation of market forces.  A recent growing body of research supports the view that during that period market forces were fairly effective in assuring that individual banks constrained risktaking to prudent endeavors.  Nonetheless, the then nascent system as a whole proved quite vulnerable to various macroeconomic shocks essentially unrelated to the degree of banking regulation.  I shall conclude by drawing some implications for how banking regulation needs to evolve in the future, with greater reliance on private market regulation. The Roots of Banking Many of the benefits banks provide modern societies derive from their willingness to take risks and from their use of a relatively high degree of financial leverage.  Through leverage, in the form principally of taking deposits, banks perform a critical role in the financial intermediation process; they provide savers with additional investment choices and borrowers with a greater range of sources of credit, thereby facilitating a more efficient allocation of resources and contributing importantly to greater economic growth.  Indeed, it has been the evident value of intermediation and leverage that has shaped the development of our financial systems from the earliest times certainly since Renaissance goldsmiths discovered that lending out deposited gold was feasible and profitable. When Adam Smith formulated his views on banking, in the Wealth of Nations, he had in view the Scottish banking system of the 1760s and 1770s.  That system was a highly competitive one in which entry into the banking business was entirely free.  Competitors included a large number of private, that is, unincorporated, bankers who discounted commercial paper and issued bank notes.  Those private bankers sought no government assistance. Chartered Banking (1781-1838) From the very beginning the American banking system has had an entirely different character.  Although some private individuals undoubtedly circulated limited volumes of bank notes, those seeking to circulate a significant volume of notes invariably applied for a corporate charter from state or federal authorities.  Entry into the banking business was far from free.  Indeed, by the early 1800s chartering decisions by state authorities became heavily influenced by political considerations.  Aside from restrictions on entry, for much of the antebellum period state regulation largely took the form of restrictions inserted into bank charters, which were individually negotiated and typically had a life of ten or even twenty years.  The regulations were modest and appear to have been intended primarily to ensure that banks had adequate specie reserves to meet their debt obligations, especially obligations on their circulating notes. Nonetheless, the very early history of American banking was an impressive success story.  Not a single bank failed until massive fraud brought down the Farmers Exchange Bank in Rhode Island in 1809.  Thereafter, a series of severe macroeconomic shocks the War of 1812, the depression of 1819-20, and the panic of 1837 produced waves of failures.  What should be emphasized, however, is the stability of banking in the absence of severe macroeconomic shocks, a stability that reflected the discipline of the marketplace.  A bank's ability to circulate its notes was dependent on the public's confidence in its ability to redeem its notes on demand.  Then, far more than now, there was competition for reputation.  The market put a high value on integrity and punished fly-by-night operators. When confidence was lacking in a bank, its notes tended to exchange at a discount to specie and to the rates of other, more creditworthy banks.  This phenomenon was evident as early as the late 1790s in Boston, where large amounts of notes issued by New England country banks circulated.  In 1799 the Boston banks agreed to accept notes of certain country banks only at discounts of one-half percent.  Several years later they began systematically sending back country notes for redemption, and they eventually refused for a time to accept such notes, even at a discount.  Early in the 1800s private money brokers seem to have made their first appearance.  These brokers, our early arbitrageurs, purchased bank notes at a discount and transported them to the issuing bank, where they demanded par redemption. Difficulties in redeeming the notes of New England country banks eventually produced the first notable example of cooperative self-regulation in American banking, known as the Suffolk Bank System.  The Suffolk Bank was chartered in 1818 and entered the business of collecting country bank notes in 1819.  In effect, the Suffolk Bank created the first regional clearing system.  By doing so, it effectively constrained the supply of notes by individual banks to prudential levels and thereby allowed the notes of all of its associated banks to circulate consistently at face value.  In the 1830s, there was a large expansion of state-chartered banks, many of which were severely tested and found wanting during the panic of 1837.  However, very few banks failed in New England, where the Suffolk Bank continued to provide an effective, and entirely private, creditor discipline. Free Banking (1837-1863) The intense political controversy over the charter renewal of the Second Bank of the United States and the wave of bank failures following the panic led many states to fundamentally reconsider their approach to banking regulation.  In particular, in 1838 New York introduced a new approach, known as free banking, which in the following two decades was emulated by many other states.  The nature of free banking and the states' experience with this approach to regulation have been the subject of profound misconceptions.  Specifically, many seem to believe that free banking was banking free from government regulation and that the result was a series of debacles.  They conclude that the experience with free banking demonstrates that market forces cannot effectively constrain bank risktaking.  In fact, the \"free\" in free banking meant free entry under the terms of a general law of incorporation rather than through a specific legislative act.  The public, especially in New York, had become painfully aware that the restrictions on entry in the chartered system were producing a number of adverse effects.  For one thing, in the absence of competition, access to bank credit was perceived to have become politicized banks' boards of directors seemed to regard those who shared their political convictions as the most creditworthy borrowers.  In addition, because a bank charter promised monopoly profits, bank promoters were willing to pay handsomely for the privilege and legislators apparently eagerly accepted payment, often in the form of allocations of bank stock at below-market prices. If free banking was not actually as free as commonly perceived, it also was not nearly as unstable.  The perception of the free banking era as an era of \"wildcat\" banking marked by financial instability and, in particular, by widespread significant losses to noteholders also turns out to be wide of the mark.  Recent scholarship has demonstrated that free bank failures were not as common and resulting losses to noteholders were not as severe as earlier historians had claimed.  In addition, failure rates and loss rates differed significantly across states, suggesting that whatever instability was experienced was not inherent in free banking per se.  In particular, widely cited losses to holders of notes issued by free banks in Indiana, Illinois, and Wisconsin appear to have resulted from banks in these states being forced to hold portfolios of risky state bonds that were not well-diversified, were not especially liquid, and too often defaulted.  It was, in short, state regulation that caused the high failure rates. During the free banking era private market regulation also matured in several respects.  Particularly after the panic of 1837, the public was acutely aware of the possibility that banks would prove unable to redeem their notes.  Discounting of bank notes was widespread.  Indeed, between 1838 and the Civil War quite a few note brokers began to publish monthly or biweekly periodicals called bank note reporters that listed prevailing discounts on thousands of individual banks.  Research based on data from these publications has shown that the notes of new entrants into banking tended to trade at significant discounts.  If a bank demonstrated its ability to redeem its notes, over time the discount diminished.  The declining discount on a bank's notes implies a lower cost of funds, the present value of which can be considered an intangible asset, the bank's reputation.  Banks had a strong incentive to avoid overissuing notes so as not to impair the value of this intangible asset.  Throughout the free banking era the effectiveness of this competition for reputation imparted an increased type of market discipline, perhaps because technological change the telegraph and the railroad made monitoring of banks more effective and reduced the time required to send a note home for redemption.  Between 1838 and 1860 the discounts on notes of new entrants diminished and discounts came to correspond more closely to objective measures of the riskiness of individual banks. Another element of the maturation of private market regulation in banking was the emergence of full-fledged bank clearing houses, beginning with the establishment of the New York Clearing House in 1853.  The primary impetus for the development of clearing houses was the increasing importance of checkable deposits as a means of payment.  Large merchants were making payments by checks drawn on their deposit accounts as early as the 1780s.  But in the 1840s and 1850s the use of checks spread rapidly to shopkeepers, mechanics and professional men.  The clearing house reduced the costs of clearing and settling the interbank obligations arising from the collection of checks and banknotes, and thereby made feasible the daily settlement in specie of each bank's multilateral net claim on, or obligation to, the other banks in the clearing house.  By itself, such an efficient clearing mechanism constrained the ability of individual banks to expand their lending imprudently.  From the very beginning, however, clearing  houses introduced other important elements of private, self-regulation.  For example, the New York Clearing House's 1854 constitution established capital requirements for admission to the clearing house and required members to submit to periodic exams of the clearing house.  If an exam revealed that the bank's capital had become impaired, it could be expelled from the clearing house.  National Banking (1863-1913) One compelling piece of evidence that contemporary observers did not regard free banking as a failure is that the National Banking System, established by an act of Congress in 1863, incorporated key elements of free banking.  These included free entry and collateralized bank notes.  However, unlike the state laws, the federal law interfered with private market forces by imposing an aggregate limit on note issues, along with a set of geographic allocations of the limit that produced a serious maldistribution of notes. Although the aggregate limit on note issues was repealed in 1875, the collateral requirement for note issues continued to unduly restrict the longer-term growth of the money supply, eventually producing a significant price deflation and, in the 1890s, very poor economic growth.  In addition, the restrictions on note issues precluded the accommodation of temporary increases in demands for currency.  The inelasticity of the note issue produced strains in financial markets each spring and fall as crops were planted and then brought to market.  More seriously, when depositors periodically became nervous about the health of the banks, the demands to convert deposits into well-secured bank notes simply could not be met in the aggregate, and attempts to do so resulted in withdrawals of reserves from the money centers that severely and repeatedly disrupted the money markets. Private markets innovated in ways that tempered the adverse consequences resulting from these flaws in the government regulatory framework.  Most notably, the New York Clearing House effectively pooled its members' reserves by issuing clearing house loan certificates and paying them out as substitutes for reserves in interbank settlements, first in the panic of 1857 and in every subsequent panic.  By 1873, clearing houses in many other cities were following the same policy.  In addition, the clearing houses accepted as settlement media other currency substitutes issued by their members including certified checks and cashier's checks.  In effect, the clearing houses were assuming some of the functions of central banks.   But a true central bank was perceived through most of the 19th century as an infringement of states' rights.  A central bank, in any event, was deemed by many as superfluous given the fully functioning gold standard of the day.  It was only with the emergence of periodic credit crises late in the century and especially in 1907, that a central bank gained support.  These crises were seen in part as a consequence of the inelastic currency engendered by the National Bank Act.  Even with the advent of the Federal Reserve in 1913, monetary policy through the 1920s was largely governed by gold standard rules. Fiscal policy was also restrained.  For most of the period prior to the early 1930s, obligations of the U.S. Treasury were payable in gold or silver.  This meant the whole outstanding debt of our government was subject to redemption in a medium, the quantity of which could not be altered at the will of the government as it can with todays fiat currency.  Hence, debt issuance and budget deficits were constrained by the potential market response to an economy inflated with excess credit, which would have drained the Treasurys gold stock.  Indeed, the United States skirted on the edges of bankruptcy in 1895 when our government gold stock shrank ominously and was bailed out by a last minute gold loan, underwritten by a Wall Street syndicate.  In the broadest sense, the existence of a gold standard delimited the capability of the banking system to expand imprudently. Creation of the Federal Safety Net When the efforts of the Federal Reserve failed to prevent the bank collapses of the 1930s, the Banking Act of 1933 created federal deposit insurance.  The subsequent evidence appears persuasive that the combination of a lender of last resort (the Federal Reserve) and federal deposit insurance has contributed significantly to financial stability and has accordingly achieved wide support within the Congress.  Inevitably, however, such significant government intervention has not been an unmixed blessing.  The federal safety net for banks clearly has diminished the effectiveness of private market regulation and created perverse incentives in the banking system. To cite the most obvious and painful example, without federal deposit insurance, private markets presumably would never have permitted thrift institutions to purchase the portfolios that brought down the industry insurance fund and left future generations of taxpayers responsible for huge losses.  To be sure, government regulators and politicians have learned from this experience and taken significant steps to diminish the likelihood of a recurrence.  Nonetheless, the safety net undoubtedly still affects decisions by creditors of depository institutions in ways that weaken the effectiveness of private market regulation and leave us all vulnerable to any future failures of government regulation.  As the history of American banking demonstrates, private market regulation can be quite effective, provided that government does not get in its way. Indeed, rapidly changing technology is rendering obsolescent much of the old bank examination regime.  Bank regulators are perforce being pressed to depend increasingly on ever more complex and sophisticated private market regulation.  This is certainly the case for the rapidly expanding bank derivatives markets, and increasingly so for the more traditional loan products.  The lessons of early American banking should encourage us in this endeavor. In closing, I should like to emphasize that the rapidly changing technology that is rendering much government bank regulation irrelevant also bids fair to undercut regulatory efforts in a much wider segment of our economy. The reason is that such regulation is inherently conservative.  It endeavors to maintain the status quo and the special interests who benefit therefrom.  New ideas, new products, new ways of doing things, all, of necessity, raise the riskiness of any organization, riskiness for which regulators have a profound aversion.  Yet since the value of all wealth reflects its future productive capabilities, all wealth creation rests on uncertain forecasts, which means every investment is risky.  Or put another way, you cannot have wealth creation without risktaking.  With technological change clearly accelerating, existing regulatory structures are being bypassed, freeing market forces to enhance wealth creation and economic growth. In finance, regulatory restraints against interstate banking and combinations of investment and commercial banking are being swept away under the pressures of technological change.  Much the same is true in transportation and communications. As we move into a new century, the market-stabilizing private regulatory forces should gradually displace many cumbersome, increasingly ineffective government structures.  This is a likely outcome since governments, by their nature, cannot adjust sufficiently quickly to a changing environment, which too often veers in unforeseen directions.",
                  "1997-04-12 00:00:00"
                ]
              ],
              "shape": {
                "columns": 3,
                "rows": 1456
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>speaker</th>\n",
              "      <th>text</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Vice Chair Alice M. Rivlin</td>\n",
              "      <td>I discovered when I joined the Board of Govern...</td>\n",
              "      <td>1996-12-19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Chairman Alan Greenspan</td>\n",
              "      <td>I am privileged to accept the Union League of...</td>\n",
              "      <td>1996-12-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Chairman Alan Greenspan</td>\n",
              "      <td>The Challenge of Central Banking in a Democrat...</td>\n",
              "      <td>1996-12-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Governor Edward W. Kelley, Jr.</td>\n",
              "      <td>It is a pleasure to be with you this morning ...</td>\n",
              "      <td>1996-12-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Governor Susan M. Phillips</td>\n",
              "      <td>Supervisory and Regulatory Responses to Financ...</td>\n",
              "      <td>1996-11-25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1451</th>\n",
              "      <td>Governor Lael Brainard</td>\n",
              "      <td>I want to thank Darrell Duffie for inviting m...</td>\n",
              "      <td>2020-02-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1452</th>\n",
              "      <td>Vice Chair for Supervision Randal K. Quarles</td>\n",
              "      <td>It's a great pleasure to be with you today at...</td>\n",
              "      <td>2020-01-17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1453</th>\n",
              "      <td>Governor Michelle W. Bowman</td>\n",
              "      <td>Few sectors are as central to the success of ...</td>\n",
              "      <td>2020-01-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1454</th>\n",
              "      <td>Vice Chairman Richard H. Clarida</td>\n",
              "      <td>Thank you for the opportunity to join you bri...</td>\n",
              "      <td>2020-01-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1455</th>\n",
              "      <td>Governor Lael Brainard</td>\n",
              "      <td>Good morning. I am pleased to be here at the ...</td>\n",
              "      <td>2020-01-08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1456 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           speaker  \\\n",
              "0                       Vice Chair Alice M. Rivlin   \n",
              "1                          Chairman Alan Greenspan   \n",
              "2                          Chairman Alan Greenspan   \n",
              "3                   Governor Edward W. Kelley, Jr.   \n",
              "4                       Governor Susan M. Phillips   \n",
              "...                                            ...   \n",
              "1451                        Governor Lael Brainard   \n",
              "1452  Vice Chair for Supervision Randal K. Quarles   \n",
              "1453                   Governor Michelle W. Bowman   \n",
              "1454              Vice Chairman Richard H. Clarida   \n",
              "1455                        Governor Lael Brainard   \n",
              "\n",
              "                                                   text       date  \n",
              "0     I discovered when I joined the Board of Govern... 1996-12-19  \n",
              "1      I am privileged to accept the Union League of... 1996-12-06  \n",
              "2     The Challenge of Central Banking in a Democrat... 1996-12-05  \n",
              "3      It is a pleasure to be with you this morning ... 1996-12-03  \n",
              "4     Supervisory and Regulatory Responses to Financ... 1996-11-25  \n",
              "...                                                 ...        ...  \n",
              "1451   I want to thank Darrell Duffie for inviting m... 2020-02-05  \n",
              "1452   It's a great pleasure to be with you today at... 2020-01-17  \n",
              "1453   Few sectors are as central to the success of ... 2020-01-16  \n",
              "1454   Thank you for the opportunity to join you bri... 2020-01-09  \n",
              "1455   Good morning. I am pleased to be here at the ... 2020-01-08  \n",
              "\n",
              "[1456 rows x 3 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# drop irrelevant columns\n",
        "# 'link', 'title', 'year', 'event', 'text_len', 'location'\n",
        "\n",
        "df = df[['speaker', 'text', 'date']]\n",
        "\n",
        "# change date to use datetime instead\n",
        "\n",
        "df['date'] = (\n",
        "    df['date']\n",
        "      .dropna()\n",
        "      .astype(int)\n",
        "      .astype(str)\n",
        "      .reindex(df.index)\n",
        ")\n",
        "\n",
        "df['date'] = pd.to_datetime(df['date'], format='%Y%m%d', errors='coerce')\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pE77mtrJep1O"
      },
      "source": [
        "## FinBERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVoxW-aIwZOf",
        "outputId": "3250d0a7-7ef2-4b3a-b961-25ad423b441c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ FinBERT model loaded (CPU mode)\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
        "\n",
        "model_name = \"ProsusAI/finbert\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "# Force CPU usage to avoid CUDA compatibility issues\n",
        "finbert_pipeline = pipeline(\n",
        "    \"sentiment-analysis\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device=-1  # Always use CPU\n",
        ")\n",
        "print(\"✅ FinBERT model loaded (CPU mode)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLDxf6fVzpq4"
      },
      "outputs": [],
      "source": [
        "def chunk_text(text, max_tokens=400):\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    for i in range(0, len(tokens), max_tokens):\n",
        "        chunk_tokens = tokens[i:i+max_tokens]\n",
        "        yield tokenizer.convert_tokens_to_string(chunk_tokens)\n",
        "\n",
        "def finbert_on_long_text(text, max_tokens=400):\n",
        "    if not isinstance(text, str) or text.strip() == \"\":\n",
        "        return None\n",
        "\n",
        "    chunks = list(chunk_text(text, max_tokens=max_tokens))\n",
        "    if not chunks:\n",
        "        return None\n",
        "\n",
        "    results = finbert_pipeline(\n",
        "        chunks,\n",
        "        truncation=True,\n",
        "        max_length=512\n",
        "    )\n",
        "\n",
        "    # convert to simple numeric scores: +1 (positive), -1 (negative), 0 (neutral)\n",
        "    label_to_score = {\"positive\": 1, \"negative\": -1, \"neutral\": 0}\n",
        "    numeric_scores = [label_to_score[r[\"label\"].lower()] for r in results]\n",
        "\n",
        "    # can change the scoring methodology if necessary\n",
        "    avg_score = np.mean(numeric_scores)\n",
        "    if avg_score > 0.1:\n",
        "        label = \"positive\"\n",
        "    elif avg_score < -0.1:\n",
        "        label = \"negative\"\n",
        "    else:\n",
        "        label = \"neutral\"\n",
        "\n",
        "    return {\"label\": label, \"score\": float(avg_score)}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2WTl0olDzqIu"
      },
      "outputs": [],
      "source": [
        "# 1) Get all texts as a list\n",
        "texts = df[\"text\"].fillna(\"\").tolist()\n",
        "\n",
        "# 2) Run pipeline once on the whole list (batched internally)\n",
        "results = finbert_pipeline(\n",
        "    texts,\n",
        "    truncation=True,\n",
        "    max_length=512,\n",
        "    batch_size=32   # tweak for your GPU / CPU\n",
        ")\n",
        "\n",
        "# 3) Put results back into the DataFrame\n",
        "df[\"finbert_label\"] = [r[\"label\"] for r in results]\n",
        "df[\"finbert_score\"] = [r[\"score\"] for r in results]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "YJVHVBVZzwMn",
        "outputId": "0fb3ded3-348f-4fb8-8bd9-aa546e9dfec0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>speaker</th>\n",
              "      <td>335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>text</th>\n",
              "      <td>336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <td>336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>finbert_label</th>\n",
              "      <td>336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>finbert_score</th>\n",
              "      <td>336</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "speaker          335\n",
              "text             336\n",
              "date             336\n",
              "finbert_label    336\n",
              "finbert_score    336\n",
              "dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[df['finbert_label'] != 'neutral'].count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "-brBJlYa1xYj",
        "outputId": "f5b4c0f6-6662-4236-a94b-440495b10342"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>speaker</th>\n",
              "      <td>1454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>text</th>\n",
              "      <td>1456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <td>1455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>finbert_label</th>\n",
              "      <td>1456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>finbert_score</th>\n",
              "      <td>1456</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "speaker          1454\n",
              "text             1456\n",
              "date             1455\n",
              "finbert_label    1456\n",
              "finbert_score    1456\n",
              "dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGPnxZjYemBL"
      },
      "source": [
        "## Loughran–McDonald"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rrc6KYNe3Qn",
        "outputId": "a09e2c4e-3e4b-42bc-9e6c-f98be9f94dc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pysentiment2 in /usr/local/lib/python3.12/dist-packages (0.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from pysentiment2) (2.2.2)\n",
            "Requirement already satisfied: nltk>=2.0 in /usr/local/lib/python3.12/dist-packages (from pysentiment2) (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>=2.0->pysentiment2) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>=2.0->pysentiment2) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>=2.0->pysentiment2) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk>=2.0->pysentiment2) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas->pysentiment2) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->pysentiment2) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->pysentiment2) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->pysentiment2) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->pysentiment2) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pysentiment2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3MPuaOLUelnK"
      },
      "outputs": [],
      "source": [
        "import pysentiment2 as ps\n",
        "import re\n",
        "\n",
        "lm = ps.lm.LM()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFQGtFvNhByj"
      },
      "outputs": [],
      "source": [
        "def clean_text(t):\n",
        "    if pd.isna(t):\n",
        "        return \"\"\n",
        "    t = t.replace(\"\\n\", \" \")\n",
        "    t = re.sub(r\"\\s+\", \" \", t)\n",
        "    return t.strip()\n",
        "\n",
        "df[\"text_clean\"] = df[\"text\"].apply(clean_text)\n",
        "\n",
        "def lm_scores(text):\n",
        "    tokens = lm.tokenize(text)\n",
        "    return lm.get_score(tokens)   # returns a dict of sentiment metrics\n",
        "\n",
        "scores = df[\"text_clean\"].apply(lm_scores)\n",
        "\n",
        "# Turn list of dicts into columns and join back to df\n",
        "scores_df = pd.DataFrame(list(scores))\n",
        "df = pd.concat([df, scores_df], axis=1)\n",
        "\n",
        "def token_count(text):\n",
        "    return len(lm.tokenize(text))\n",
        "\n",
        "df[\"n_tokens\"] = df[\"text_clean\"].apply(token_count)\n",
        "\n",
        "df[\"LM_pos_rate\"] = df[\"Positive\"] / df[\"n_tokens\"]\n",
        "df[\"LM_neg_rate\"] = df[\"Negative\"] / df[\"n_tokens\"]\n",
        "df[\"LM_net_polarity_per_token\"] = (df[\"Positive\"] - df[\"Negative\"]) / df[\"n_tokens\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zYU0FdurbUd"
      },
      "source": [
        "## Removing Stop Words\n",
        "This is only needed for BERTopic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpEROHugrhH4",
        "outputId": "03df7546-8010-4acc-f9bf-864063e0b540"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "    tokens = text.split()\n",
        "    tokens = [t for t in tokens if t not in stop_words]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "df[\"text_clean_nostop\"] = df[\"text_clean\"].apply(preprocess)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEPsTnFVpR1A"
      },
      "source": [
        "## BERTopic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVUFsK6BpXaD",
        "outputId": "995d382a-9df0-4de7-d3f7-b4d73b177464"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting bertopic\n",
            "  Downloading bertopic-0.17.4-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.2)\n",
            "Requirement already satisfied: hdbscan>=0.8.29 in /usr/local/lib/python3.12/dist-packages (from bertopic) (0.8.40)\n",
            "Requirement already satisfied: umap-learn>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from bertopic) (0.5.9.post2)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.12/dist-packages (from bertopic) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.12/dist-packages (from bertopic) (2.2.2)\n",
            "Requirement already satisfied: plotly>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from bertopic) (5.24.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.12/dist-packages (from bertopic) (1.6.1)\n",
            "Requirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.12/dist-packages (from bertopic) (4.67.1)\n",
            "Requirement already satisfied: llvmlite>0.36.0 in /usr/local/lib/python3.12/dist-packages (from bertopic) (0.43.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cu126)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from hdbscan>=0.8.29->bertopic) (1.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.5->bertopic) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.5->bertopic) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.5->bertopic) (2025.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly>=4.7.0->bertopic) (9.1.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.0->bertopic) (3.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.12/dist-packages (from umap-learn>=0.5.0->bertopic) (0.60.0)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.12/dist-packages (from umap-learn>=0.5.0->bertopic) (0.5.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->bertopic) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.11.12)\n",
            "Downloading bertopic-0.17.4-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.7/154.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bertopic\n",
            "Successfully installed bertopic-0.17.4\n"
          ]
        }
      ],
      "source": [
        "!pip install bertopic sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anAk1Pxzpc52",
        "outputId": "4d0bfd18-b93c-4a07-bb20-d3cae0906dea"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/hdbscan/robust_single_linkage_.py:175: SyntaxWarning: invalid escape sequence '\\{'\n",
            "  $max \\{ core_k(a), core_k(b), 1/\\alpha d(a,b) \\}$.\n"
          ]
        }
      ],
      "source": [
        "from bertopic import BERTopic\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5v-Zy1BNpegn"
      },
      "outputs": [],
      "source": [
        "docs = df[\"text_clean_nostop\"].tolist()  # or df[\"text\"]\n",
        "\n",
        "topic_model = BERTopic(\n",
        "    language=\"english\",\n",
        "    embedding_model=\"all-MiniLM-L6-v2\",\n",
        "    calculate_probabilities=True\n",
        ")\n",
        "\n",
        "topics, probs = topic_model.fit_transform(docs)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "df[\"topic\"] = topics\n",
        "df[\"topic_confidence\"] = probs.max(axis=1)          # max probability across topics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lk-6Rf5fpsRe"
      },
      "outputs": [],
      "source": [
        "probs_df = pd.DataFrame(\n",
        "    probs,\n",
        "    columns=[f\"topic_prob_{i}\" for i in range(probs.shape[1])]\n",
        ")\n",
        "\n",
        "df = pd.concat([df.reset_index(drop=True), probs_df], axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exYl9a6Fps7s",
        "outputId": "6da0b1c9-77a9-447c-f9ba-2b56ab246239"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Topic  Count                                Name  \\\n",
            "0     -1    493  -1_financial_policy_market_federal   \n",
            "1      0    135      0_labor_rate_inflation_percent   \n",
            "2      1    119   1_community_banks_cra_development   \n",
            "3      2     70      2_policy_rate_federal_monetary   \n",
            "4      3     63   3_education_women_economic_school   \n",
            "\n",
            "                                      Representation  \\\n",
            "0  [financial, policy, market, federal, bank, ban...   \n",
            "1  [labor, rate, inflation, percent, growth, econ...   \n",
            "2  [community, banks, cra, development, communiti...   \n",
            "3  [policy, rate, federal, monetary, inflation, t...   \n",
            "4  [education, women, economic, school, students,...   \n",
            "\n",
            "                                 Representative_Docs  \n",
            "0  [titled talk \"policy challenges federal reserv...  \n",
            "1  [thank economic club washington inviting speak...  \n",
            "2  [pleasure speak federal deposit insurance corp...  \n",
            "3  [century, economic club new york served one na...  \n",
            "4  [pleased opportunity meet today address remark...  \n"
          ]
        }
      ],
      "source": [
        "topic_info = topic_model.get_topic_info()\n",
        "print(topic_info.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0luFBqKtwMT"
      },
      "source": [
        "## Hawkish-Dovish Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZL5YuFzIxRZo",
        "outputId": "9dcca5f0-f3eb-469a-b3d0-7fee8bc3ce51"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
        "import pandas as pd\n",
        "\n",
        "model_name = \"gtfintechlab/FOMC-RoBERTa\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "fomc_cls = pipeline(\n",
        "    \"text-classification\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    return_all_scores=True,\n",
        "    truncation=True,\n",
        "    max_length=512,\n",
        "    device=0 if torch.cuda.is_available() else -1  # Use GPU if available\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ouTBYw094Ef_"
      },
      "outputs": [],
      "source": [
        "def fomc_scores(texts, batch_size=8):\n",
        "    hawk_list = []\n",
        "    dove_list = []\n",
        "    neutral_list = []\n",
        "\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch = texts[i:i+batch_size]\n",
        "        outputs = fomc_cls(batch)   # list of lists\n",
        "\n",
        "        for out in outputs:\n",
        "            # initialize\n",
        "            hawk = dove = neutral = 0.0\n",
        "            for d in out:\n",
        "                label = d[\"label\"]  # e.g. \"LABEL_0\"\n",
        "                score = d[\"score\"]\n",
        "                if label == \"LABEL_1\":      # Hawkish\n",
        "                    hawk = score\n",
        "                elif label == \"LABEL_0\":    # Dovish\n",
        "                    dove = score\n",
        "                elif label == \"LABEL_2\":    # Neutral\n",
        "                    neutral = score\n",
        "\n",
        "            hawk_list.append(hawk)\n",
        "            dove_list.append(dove)\n",
        "            neutral_list.append(neutral)\n",
        "\n",
        "    return pd.DataFrame({\n",
        "        \"fomc_hawk\": hawk_list,\n",
        "        \"fomc_dove\": dove_list,\n",
        "        \"fomc_neutral\": neutral_list,\n",
        "    })\n",
        "\n",
        "\n",
        "df_fomc = fomc_scores(df[\"text_clean\"].tolist(), batch_size=8)\n",
        "\n",
        "# Overwrite/assign safely instead of concat (prevents duplicate columns)\n",
        "df[[\"fomc_hawk\", \"fomc_dove\", \"fomc_neutral\"]] = df_fomc.values\n",
        "\n",
        "df[\"HDI_fomc\"] = df[\"fomc_hawk\"] - df[\"fomc_dove\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        },
        "id": "D-5Xe84mxX3L",
        "outputId": "0638b2e5-3f73-45d6-a09a-67986a44eae1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-3f60a826-761e-4e71-8478-11a3ebb10ead\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>speaker</th>\n",
              "      <th>text</th>\n",
              "      <th>date</th>\n",
              "      <th>finbert_label</th>\n",
              "      <th>finbert_score</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>Positive</th>\n",
              "      <th>Negative</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Subjectivity</th>\n",
              "      <th>...</th>\n",
              "      <th>topic_prob_29</th>\n",
              "      <th>topic_prob_30</th>\n",
              "      <th>topic_prob_31</th>\n",
              "      <th>hawk_count</th>\n",
              "      <th>dove_count</th>\n",
              "      <th>HDI_dict</th>\n",
              "      <th>fomc_hawk</th>\n",
              "      <th>fomc_dove</th>\n",
              "      <th>fomc_other</th>\n",
              "      <th>HDI_fomc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Vice Chair Alice M. Rivlin</td>\n",
              "      <td>I discovered when I joined the Board of Govern...</td>\n",
              "      <td>1996-12-19</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.896602</td>\n",
              "      <td>I discovered when I joined the Board of Govern...</td>\n",
              "      <td>50</td>\n",
              "      <td>88</td>\n",
              "      <td>-0.275362</td>\n",
              "      <td>0.081802</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003773</td>\n",
              "      <td>1.317410e-02</td>\n",
              "      <td>5.232198e-03</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Chairman Alan Greenspan</td>\n",
              "      <td>I am privileged to accept the Union League of...</td>\n",
              "      <td>1996-12-06</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.646885</td>\n",
              "      <td>I am privileged to accept the Union League of ...</td>\n",
              "      <td>59</td>\n",
              "      <td>70</td>\n",
              "      <td>-0.085271</td>\n",
              "      <td>0.102707</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.330262e-308</td>\n",
              "      <td>7.818059e-308</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Chairman Alan Greenspan</td>\n",
              "      <td>The Challenge of Central Banking in a Democrat...</td>\n",
              "      <td>1996-12-05</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.887193</td>\n",
              "      <td>The Challenge of Central Banking in a Democrat...</td>\n",
              "      <td>62</td>\n",
              "      <td>137</td>\n",
              "      <td>-0.376884</td>\n",
              "      <td>0.107684</td>\n",
              "      <td>...</td>\n",
              "      <td>0.005472</td>\n",
              "      <td>8.693169e-03</td>\n",
              "      <td>6.906108e-03</td>\n",
              "      <td>18</td>\n",
              "      <td>3</td>\n",
              "      <td>0.681818</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Governor Edward W. Kelley, Jr.</td>\n",
              "      <td>It is a pleasure to be with you this morning ...</td>\n",
              "      <td>1996-12-03</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.765716</td>\n",
              "      <td>It is a pleasure to be with you this morning t...</td>\n",
              "      <td>36</td>\n",
              "      <td>59</td>\n",
              "      <td>-0.242105</td>\n",
              "      <td>0.076305</td>\n",
              "      <td>...</td>\n",
              "      <td>0.005974</td>\n",
              "      <td>9.061292e-03</td>\n",
              "      <td>7.424955e-03</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Governor Susan M. Phillips</td>\n",
              "      <td>Supervisory and Regulatory Responses to Financ...</td>\n",
              "      <td>1996-11-25</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.808607</td>\n",
              "      <td>Supervisory and Regulatory Responses to Financ...</td>\n",
              "      <td>52</td>\n",
              "      <td>32</td>\n",
              "      <td>0.238095</td>\n",
              "      <td>0.076853</td>\n",
              "      <td>...</td>\n",
              "      <td>0.007788</td>\n",
              "      <td>1.155057e-02</td>\n",
              "      <td>1.003424e-02</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 56 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3f60a826-761e-4e71-8478-11a3ebb10ead')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3f60a826-761e-4e71-8478-11a3ebb10ead button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3f60a826-761e-4e71-8478-11a3ebb10ead');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f873c965-602a-4522-9778-66ff1d61190a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f873c965-602a-4522-9778-66ff1d61190a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f873c965-602a-4522-9778-66ff1d61190a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                          speaker  \\\n",
              "0      Vice Chair Alice M. Rivlin   \n",
              "1         Chairman Alan Greenspan   \n",
              "2         Chairman Alan Greenspan   \n",
              "3  Governor Edward W. Kelley, Jr.   \n",
              "4      Governor Susan M. Phillips   \n",
              "\n",
              "                                                text       date finbert_label  \\\n",
              "0  I discovered when I joined the Board of Govern... 1996-12-19       neutral   \n",
              "1   I am privileged to accept the Union League of... 1996-12-06       neutral   \n",
              "2  The Challenge of Central Banking in a Democrat... 1996-12-05       neutral   \n",
              "3   It is a pleasure to be with you this morning ... 1996-12-03       neutral   \n",
              "4  Supervisory and Regulatory Responses to Financ... 1996-11-25       neutral   \n",
              "\n",
              "   finbert_score                                         text_clean  Positive  \\\n",
              "0       0.896602  I discovered when I joined the Board of Govern...        50   \n",
              "1       0.646885  I am privileged to accept the Union League of ...        59   \n",
              "2       0.887193  The Challenge of Central Banking in a Democrat...        62   \n",
              "3       0.765716  It is a pleasure to be with you this morning t...        36   \n",
              "4       0.808607  Supervisory and Regulatory Responses to Financ...        52   \n",
              "\n",
              "   Negative  Polarity  Subjectivity  ...  topic_prob_29  topic_prob_30  \\\n",
              "0        88 -0.275362      0.081802  ...       0.003773   1.317410e-02   \n",
              "1        70 -0.085271      0.102707  ...       1.000000  6.330262e-308   \n",
              "2       137 -0.376884      0.107684  ...       0.005472   8.693169e-03   \n",
              "3        59 -0.242105      0.076305  ...       0.005974   9.061292e-03   \n",
              "4        32  0.238095      0.076853  ...       0.007788   1.155057e-02   \n",
              "\n",
              "   topic_prob_31  hawk_count  dove_count  HDI_dict  fomc_hawk  fomc_dove  \\\n",
              "0   5.232198e-03           0           0  0.000000        0.0        0.0   \n",
              "1  7.818059e-308           7           1  0.666667        0.0        0.0   \n",
              "2   6.906108e-03          18           3  0.681818        0.0        0.0   \n",
              "3   7.424955e-03           0           0  0.000000        0.0        0.0   \n",
              "4   1.003424e-02           0           0  0.000000        0.0        0.0   \n",
              "\n",
              "   fomc_other  HDI_fomc  \n",
              "0         1.0       0.0  \n",
              "1         1.0       0.0  \n",
              "2         1.0       0.0  \n",
              "3         1.0       0.0  \n",
              "4         1.0       0.0  \n",
              "\n",
              "[5 rows x 56 columns]"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1GCjfmO-lta"
      },
      "outputs": [],
      "source": [
        "cols_to_drop = [c for c in df.columns if c.startswith(\"fomc_\") or c.startswith(\"HDI_fomc\")]\n",
        "df = df.drop(columns=cols_to_drop, errors=\"ignore\")\n",
        "\n",
        "# also remove any duplicated columns generally, just in case\n",
        "df = df.loc[:, ~df.columns.duplicated()]\n",
        "\n",
        "df[[\"fomc_hawk\", \"fomc_dove\", \"fomc_neutral\"]] = df_fomc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "RzX0V_1e8PXy",
        "outputId": "fb284ea6-cef6-4bf3-ae08-9daea461ffdb"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-7817e694-6819-44b5-beb9-0e28eca504d5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>finbert_score</th>\n",
              "      <th>Positive</th>\n",
              "      <th>Negative</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Subjectivity</th>\n",
              "      <th>n_tokens</th>\n",
              "      <th>LM_pos_rate</th>\n",
              "      <th>LM_neg_rate</th>\n",
              "      <th>LM_net_polarity_per_token</th>\n",
              "      <th>...</th>\n",
              "      <th>topic_prob_28</th>\n",
              "      <th>topic_prob_29</th>\n",
              "      <th>topic_prob_30</th>\n",
              "      <th>topic_prob_31</th>\n",
              "      <th>hawk_count</th>\n",
              "      <th>dove_count</th>\n",
              "      <th>HDI_dict</th>\n",
              "      <th>fomc_hawk</th>\n",
              "      <th>fomc_dove</th>\n",
              "      <th>fomc_neutral</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1455</td>\n",
              "      <td>1456.000000</td>\n",
              "      <td>1456.000000</td>\n",
              "      <td>1456.000000</td>\n",
              "      <td>1456.000000</td>\n",
              "      <td>1456.000000</td>\n",
              "      <td>1456.000000</td>\n",
              "      <td>1456.000000</td>\n",
              "      <td>1456.000000</td>\n",
              "      <td>1456.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.456000e+03</td>\n",
              "      <td>1.456000e+03</td>\n",
              "      <td>1.456000e+03</td>\n",
              "      <td>1.456000e+03</td>\n",
              "      <td>1456.000000</td>\n",
              "      <td>1456.000000</td>\n",
              "      <td>1456.000000</td>\n",
              "      <td>1456.000000</td>\n",
              "      <td>1456.000000</td>\n",
              "      <td>1456.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2007-12-26 03:05:04.329896960</td>\n",
              "      <td>0.765768</td>\n",
              "      <td>60.800137</td>\n",
              "      <td>91.685440</td>\n",
              "      <td>-0.137018</td>\n",
              "      <td>0.098984</td>\n",
              "      <td>1534.934066</td>\n",
              "      <td>0.041532</td>\n",
              "      <td>0.057452</td>\n",
              "      <td>-0.015921</td>\n",
              "      <td>...</td>\n",
              "      <td>1.913822e-02</td>\n",
              "      <td>1.745676e-02</td>\n",
              "      <td>2.077427e-02</td>\n",
              "      <td>1.887339e-02</td>\n",
              "      <td>10.797390</td>\n",
              "      <td>4.849588</td>\n",
              "      <td>0.037467</td>\n",
              "      <td>0.054572</td>\n",
              "      <td>0.087195</td>\n",
              "      <td>0.858234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1996-06-13 00:00:00</td>\n",
              "      <td>0.340610</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.200000</td>\n",
              "      <td>...</td>\n",
              "      <td>7.771240e-309</td>\n",
              "      <td>6.673994e-309</td>\n",
              "      <td>7.406991e-309</td>\n",
              "      <td>6.852995e-309</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.991803</td>\n",
              "      <td>0.000080</td>\n",
              "      <td>0.000043</td>\n",
              "      <td>0.000282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2002-10-22 12:00:00</td>\n",
              "      <td>0.678517</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>49.000000</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>0.082768</td>\n",
              "      <td>1048.750000</td>\n",
              "      <td>0.031584</td>\n",
              "      <td>0.040484</td>\n",
              "      <td>-0.034676</td>\n",
              "      <td>...</td>\n",
              "      <td>1.695715e-307</td>\n",
              "      <td>1.131053e-307</td>\n",
              "      <td>1.585389e-307</td>\n",
              "      <td>1.451137e-307</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.289286</td>\n",
              "      <td>0.000202</td>\n",
              "      <td>0.000111</td>\n",
              "      <td>0.977739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2007-03-06 00:00:00</td>\n",
              "      <td>0.808972</td>\n",
              "      <td>58.000000</td>\n",
              "      <td>82.000000</td>\n",
              "      <td>-0.172739</td>\n",
              "      <td>0.097234</td>\n",
              "      <td>1512.000000</td>\n",
              "      <td>0.039609</td>\n",
              "      <td>0.055686</td>\n",
              "      <td>-0.016400</td>\n",
              "      <td>...</td>\n",
              "      <td>8.897444e-03</td>\n",
              "      <td>6.336690e-03</td>\n",
              "      <td>9.172671e-03</td>\n",
              "      <td>8.443941e-03</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000376</td>\n",
              "      <td>0.000243</td>\n",
              "      <td>0.999282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2013-05-25 12:00:00</td>\n",
              "      <td>0.874925</td>\n",
              "      <td>78.000000</td>\n",
              "      <td>124.000000</td>\n",
              "      <td>0.028854</td>\n",
              "      <td>0.114967</td>\n",
              "      <td>1931.000000</td>\n",
              "      <td>0.048912</td>\n",
              "      <td>0.072111</td>\n",
              "      <td>0.002340</td>\n",
              "      <td>...</td>\n",
              "      <td>1.504631e-02</td>\n",
              "      <td>1.388152e-02</td>\n",
              "      <td>2.205817e-02</td>\n",
              "      <td>1.698010e-02</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.461538</td>\n",
              "      <td>0.001711</td>\n",
              "      <td>0.002796</td>\n",
              "      <td>0.999652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2020-06-19 00:00:00</td>\n",
              "      <td>0.969811</td>\n",
              "      <td>263.000000</td>\n",
              "      <td>391.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>5183.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>301.000000</td>\n",
              "      <td>121.000000</td>\n",
              "      <td>0.990826</td>\n",
              "      <td>0.998993</td>\n",
              "      <td>0.999100</td>\n",
              "      <td>0.999841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0.135948</td>\n",
              "      <td>30.555530</td>\n",
              "      <td>60.443583</td>\n",
              "      <td>0.282381</td>\n",
              "      <td>0.025972</td>\n",
              "      <td>739.995375</td>\n",
              "      <td>0.015731</td>\n",
              "      <td>0.023914</td>\n",
              "      <td>0.031051</td>\n",
              "      <td>...</td>\n",
              "      <td>8.567981e-02</td>\n",
              "      <td>8.480150e-02</td>\n",
              "      <td>8.338028e-02</td>\n",
              "      <td>8.406124e-02</td>\n",
              "      <td>26.031058</td>\n",
              "      <td>9.083880</td>\n",
              "      <td>0.471660</td>\n",
              "      <td>0.194271</td>\n",
              "      <td>0.253830</td>\n",
              "      <td>0.309795</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 50 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7817e694-6819-44b5-beb9-0e28eca504d5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7817e694-6819-44b5-beb9-0e28eca504d5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7817e694-6819-44b5-beb9-0e28eca504d5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a3385e93-5b9f-4d81-9b36-7ae5a0fa59a0\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a3385e93-5b9f-4d81-9b36-7ae5a0fa59a0')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a3385e93-5b9f-4d81-9b36-7ae5a0fa59a0 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                date  finbert_score     Positive     Negative  \\\n",
              "count                           1455    1456.000000  1456.000000  1456.000000   \n",
              "mean   2007-12-26 03:05:04.329896960       0.765768    60.800137    91.685440   \n",
              "min              1996-06-13 00:00:00       0.340610     0.000000     0.000000   \n",
              "25%              2002-10-22 12:00:00       0.678517    41.000000    49.000000   \n",
              "50%              2007-03-06 00:00:00       0.808972    58.000000    82.000000   \n",
              "75%              2013-05-25 12:00:00       0.874925    78.000000   124.000000   \n",
              "max              2020-06-19 00:00:00       0.969811   263.000000   391.000000   \n",
              "std                              NaN       0.135948    30.555530    60.443583   \n",
              "\n",
              "          Polarity  Subjectivity     n_tokens  LM_pos_rate  LM_neg_rate  \\\n",
              "count  1456.000000   1456.000000  1456.000000  1456.000000  1456.000000   \n",
              "mean     -0.137018      0.098984  1534.934066     0.041532     0.057452   \n",
              "min      -1.000000      0.000000     3.000000     0.000000     0.000000   \n",
              "25%      -0.333333      0.082768  1048.750000     0.031584     0.040484   \n",
              "50%      -0.172739      0.097234  1512.000000     0.039609     0.055686   \n",
              "75%       0.028854      0.114967  1931.000000     0.048912     0.072111   \n",
              "max       1.000000      0.250000  5183.000000     0.250000     0.200000   \n",
              "std       0.282381      0.025972   739.995375     0.015731     0.023914   \n",
              "\n",
              "       LM_net_polarity_per_token  ...  topic_prob_28  topic_prob_29  \\\n",
              "count                1456.000000  ...   1.456000e+03   1.456000e+03   \n",
              "mean                   -0.015921  ...   1.913822e-02   1.745676e-02   \n",
              "min                    -0.200000  ...  7.771240e-309  6.673994e-309   \n",
              "25%                    -0.034676  ...  1.695715e-307  1.131053e-307   \n",
              "50%                    -0.016400  ...   8.897444e-03   6.336690e-03   \n",
              "75%                     0.002340  ...   1.504631e-02   1.388152e-02   \n",
              "max                     0.250000  ...   1.000000e+00   1.000000e+00   \n",
              "std                     0.031051  ...   8.567981e-02   8.480150e-02   \n",
              "\n",
              "       topic_prob_30  topic_prob_31   hawk_count   dove_count     HDI_dict  \\\n",
              "count   1.456000e+03   1.456000e+03  1456.000000  1456.000000  1456.000000   \n",
              "mean    2.077427e-02   1.887339e-02    10.797390     4.849588     0.037467   \n",
              "min    7.406991e-309  6.852995e-309     0.000000     0.000000    -0.991803   \n",
              "25%    1.585389e-307  1.451137e-307     0.000000     0.000000    -0.289286   \n",
              "50%     9.172671e-03   8.443941e-03     1.000000     1.000000     0.000000   \n",
              "75%     2.205817e-02   1.698010e-02     9.000000     6.000000     0.461538   \n",
              "max     1.000000e+00   1.000000e+00   301.000000   121.000000     0.990826   \n",
              "std     8.338028e-02   8.406124e-02    26.031058     9.083880     0.471660   \n",
              "\n",
              "         fomc_hawk    fomc_dove  fomc_neutral  \n",
              "count  1456.000000  1456.000000   1456.000000  \n",
              "mean      0.054572     0.087195      0.858234  \n",
              "min       0.000080     0.000043      0.000282  \n",
              "25%       0.000202     0.000111      0.977739  \n",
              "50%       0.000376     0.000243      0.999282  \n",
              "75%       0.001711     0.002796      0.999652  \n",
              "max       0.998993     0.999100      0.999841  \n",
              "std       0.194271     0.253830      0.309795  \n",
              "\n",
              "[8 rows x 50 columns]"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZtPysjUetON"
      },
      "source": [
        "## Financial Data and Formatting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "lHJFDsj1ETT9",
        "outputId": "2a5a4f13-22a5-4d9d-fd5f-870a7e065201"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_fin\",\n  \"rows\": 6167,\n  \"fields\": [\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"1996-06-13 00:00:00\",\n        \"max\": \"2020-06-19 00:00:00\",\n        \"num_unique_values\": 1236,\n        \"samples\": [\n          \"2002-07-26 00:00:00\",\n          \"2007-04-26 00:00:00\",\n          \"2019-04-09 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SP500\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5541.3256498171495,\n        \"min\": 5032.93994140625,\n        \"max\": 29551.419921875,\n        \"num_unique_values\": 6123,\n        \"samples\": [\n          10716.1298828125,\n          10282.41015625,\n          11414.8603515625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RSL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 620.2254317402875,\n        \"min\": 598.47998046875,\n        \"max\": 3386.14990234375,\n        \"num_unique_values\": 6018,\n        \"samples\": [\n          1151.43994140625,\n          2966.60009765625,\n          929.010009765625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DJIA\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2056.7856158719533,\n        \"min\": 534.4199829101562,\n        \"max\": 10209.8203125,\n        \"num_unique_values\": 6102,\n        \"samples\": [\n          2962.89990234375,\n          4234.259765625,\n          1155.969970703125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NDQ\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 384.02199276745006,\n        \"min\": 301.75,\n        \"max\": 1740.75,\n        \"num_unique_values\": 5973,\n        \"samples\": [\n          1507.1500244140625,\n          1112.1800537109375,\n          721.5599975585938\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_fin"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-9fc001f3-89cc-4402-9e7e-154261362eea\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>SP500</th>\n",
              "      <th>RSL</th>\n",
              "      <th>DJIA</th>\n",
              "      <th>NDQ</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1996-12-19</td>\n",
              "      <td>5177.450195</td>\n",
              "      <td>620.729980</td>\n",
              "      <td>585.940002</td>\n",
              "      <td>316.809998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1996-12-06</td>\n",
              "      <td>5194.069824</td>\n",
              "      <td>621.320007</td>\n",
              "      <td>572.289978</td>\n",
              "      <td>315.209991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1996-12-05</td>\n",
              "      <td>5173.839844</td>\n",
              "      <td>617.700012</td>\n",
              "      <td>563.479980</td>\n",
              "      <td>310.769989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1996-12-03</td>\n",
              "      <td>5181.430176</td>\n",
              "      <td>616.710022</td>\n",
              "      <td>565.140015</td>\n",
              "      <td>312.190002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1996-11-25</td>\n",
              "      <td>5197.700195</td>\n",
              "      <td>618.460022</td>\n",
              "      <td>563.150024</td>\n",
              "      <td>312.390015</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9fc001f3-89cc-4402-9e7e-154261362eea')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9fc001f3-89cc-4402-9e7e-154261362eea button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9fc001f3-89cc-4402-9e7e-154261362eea');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5b2a38ae-6cf7-48e1-ae54-d75ed7b7c17f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5b2a38ae-6cf7-48e1-ae54-d75ed7b7c17f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5b2a38ae-6cf7-48e1-ae54-d75ed7b7c17f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "        date        SP500         RSL        DJIA         NDQ\n",
              "0 1996-12-19  5177.450195  620.729980  585.940002  316.809998\n",
              "1 1996-12-06  5194.069824  621.320007  572.289978  315.209991\n",
              "2 1996-12-05  5173.839844  617.700012  563.479980  310.769989\n",
              "3 1996-12-03  5181.430176  616.710022  565.140015  312.190002\n",
              "4 1996-11-25  5197.700195  618.460022  563.150024  312.390015"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_fin = pd.read_csv('index_prices_1996_2020.csv')\n",
        "\n",
        "df_fin = df_fin.rename(columns={'Date': 'date'})\n",
        "\n",
        "df_fin['date'] = pd.to_datetime(df_fin['date'], format='%Y%m%d', errors='coerce')\n",
        "\n",
        "print(f\"✅ Loaded {len(df_fin)} financial data rows\")\n",
        "df_fin.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXxLj2EzCItN"
      },
      "outputs": [],
      "source": [
        "combined_df = df.set_index('date').join(df_fin.set_index('date'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        },
        "id": "zZb0v24HYIyv",
        "outputId": "70348537-5de2-49fe-f182-775e1c16e1ea"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "combined_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-43b1c150-e1cb-4475-8842-be63f0944613\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>speaker</th>\n",
              "      <th>text</th>\n",
              "      <th>finbert_label</th>\n",
              "      <th>finbert_score</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>Positive</th>\n",
              "      <th>Negative</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Subjectivity</th>\n",
              "      <th>n_tokens</th>\n",
              "      <th>...</th>\n",
              "      <th>hawk_count</th>\n",
              "      <th>dove_count</th>\n",
              "      <th>HDI_dict</th>\n",
              "      <th>fomc_hawk</th>\n",
              "      <th>fomc_dove</th>\n",
              "      <th>fomc_neutral</th>\n",
              "      <th>SP500</th>\n",
              "      <th>RSL</th>\n",
              "      <th>DJIA</th>\n",
              "      <th>NDQ</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1996-12-19</th>\n",
              "      <td>Vice Chair Alice M. Rivlin</td>\n",
              "      <td>I discovered when I joined the Board of Govern...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.896602</td>\n",
              "      <td>I discovered when I joined the Board of Govern...</td>\n",
              "      <td>50</td>\n",
              "      <td>88</td>\n",
              "      <td>-0.275362</td>\n",
              "      <td>0.081802</td>\n",
              "      <td>1687</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000294</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.999606</td>\n",
              "      <td>5177.450195</td>\n",
              "      <td>620.729980</td>\n",
              "      <td>585.940002</td>\n",
              "      <td>316.809998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996-12-06</th>\n",
              "      <td>Chairman Alan Greenspan</td>\n",
              "      <td>I am privileged to accept the Union League of...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.646885</td>\n",
              "      <td>I am privileged to accept the Union League of ...</td>\n",
              "      <td>59</td>\n",
              "      <td>70</td>\n",
              "      <td>-0.085271</td>\n",
              "      <td>0.102707</td>\n",
              "      <td>1256</td>\n",
              "      <td>...</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.099280</td>\n",
              "      <td>0.041803</td>\n",
              "      <td>0.858917</td>\n",
              "      <td>5194.069824</td>\n",
              "      <td>621.320007</td>\n",
              "      <td>572.289978</td>\n",
              "      <td>315.209991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996-12-05</th>\n",
              "      <td>Chairman Alan Greenspan</td>\n",
              "      <td>The Challenge of Central Banking in a Democrat...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.887193</td>\n",
              "      <td>The Challenge of Central Banking in a Democrat...</td>\n",
              "      <td>62</td>\n",
              "      <td>137</td>\n",
              "      <td>-0.376884</td>\n",
              "      <td>0.107684</td>\n",
              "      <td>1848</td>\n",
              "      <td>...</td>\n",
              "      <td>18</td>\n",
              "      <td>3</td>\n",
              "      <td>0.681818</td>\n",
              "      <td>0.002163</td>\n",
              "      <td>0.000350</td>\n",
              "      <td>0.997486</td>\n",
              "      <td>5173.839844</td>\n",
              "      <td>617.700012</td>\n",
              "      <td>563.479980</td>\n",
              "      <td>310.769989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996-12-03</th>\n",
              "      <td>Governor Edward W. Kelley, Jr.</td>\n",
              "      <td>It is a pleasure to be with you this morning ...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.765716</td>\n",
              "      <td>It is a pleasure to be with you this morning t...</td>\n",
              "      <td>36</td>\n",
              "      <td>59</td>\n",
              "      <td>-0.242105</td>\n",
              "      <td>0.076305</td>\n",
              "      <td>1245</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000181</td>\n",
              "      <td>0.000077</td>\n",
              "      <td>0.999741</td>\n",
              "      <td>5181.430176</td>\n",
              "      <td>616.710022</td>\n",
              "      <td>565.140015</td>\n",
              "      <td>312.190002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996-11-25</th>\n",
              "      <td>Governor Susan M. Phillips</td>\n",
              "      <td>Supervisory and Regulatory Responses to Financ...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.808607</td>\n",
              "      <td>Supervisory and Regulatory Responses to Financ...</td>\n",
              "      <td>52</td>\n",
              "      <td>32</td>\n",
              "      <td>0.238095</td>\n",
              "      <td>0.076853</td>\n",
              "      <td>1093</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000161</td>\n",
              "      <td>0.000130</td>\n",
              "      <td>0.999709</td>\n",
              "      <td>5197.700195</td>\n",
              "      <td>618.460022</td>\n",
              "      <td>563.150024</td>\n",
              "      <td>312.390015</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 58 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-43b1c150-e1cb-4475-8842-be63f0944613')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-43b1c150-e1cb-4475-8842-be63f0944613 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-43b1c150-e1cb-4475-8842-be63f0944613');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f15d8614-646b-4215-b300-7d2dad4f251b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f15d8614-646b-4215-b300-7d2dad4f251b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f15d8614-646b-4215-b300-7d2dad4f251b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                   speaker  \\\n",
              "date                                         \n",
              "1996-12-19      Vice Chair Alice M. Rivlin   \n",
              "1996-12-06         Chairman Alan Greenspan   \n",
              "1996-12-05         Chairman Alan Greenspan   \n",
              "1996-12-03  Governor Edward W. Kelley, Jr.   \n",
              "1996-11-25      Governor Susan M. Phillips   \n",
              "\n",
              "                                                         text finbert_label  \\\n",
              "date                                                                          \n",
              "1996-12-19  I discovered when I joined the Board of Govern...       neutral   \n",
              "1996-12-06   I am privileged to accept the Union League of...       neutral   \n",
              "1996-12-05  The Challenge of Central Banking in a Democrat...       neutral   \n",
              "1996-12-03   It is a pleasure to be with you this morning ...       neutral   \n",
              "1996-11-25  Supervisory and Regulatory Responses to Financ...       neutral   \n",
              "\n",
              "            finbert_score                                         text_clean  \\\n",
              "date                                                                           \n",
              "1996-12-19       0.896602  I discovered when I joined the Board of Govern...   \n",
              "1996-12-06       0.646885  I am privileged to accept the Union League of ...   \n",
              "1996-12-05       0.887193  The Challenge of Central Banking in a Democrat...   \n",
              "1996-12-03       0.765716  It is a pleasure to be with you this morning t...   \n",
              "1996-11-25       0.808607  Supervisory and Regulatory Responses to Financ...   \n",
              "\n",
              "            Positive  Negative  Polarity  Subjectivity  n_tokens  ...  \\\n",
              "date                                                              ...   \n",
              "1996-12-19        50        88 -0.275362      0.081802      1687  ...   \n",
              "1996-12-06        59        70 -0.085271      0.102707      1256  ...   \n",
              "1996-12-05        62       137 -0.376884      0.107684      1848  ...   \n",
              "1996-12-03        36        59 -0.242105      0.076305      1245  ...   \n",
              "1996-11-25        52        32  0.238095      0.076853      1093  ...   \n",
              "\n",
              "            hawk_count  dove_count  HDI_dict  fomc_hawk  fomc_dove  \\\n",
              "date                                                                 \n",
              "1996-12-19           0           0  0.000000   0.000294   0.000100   \n",
              "1996-12-06           7           1  0.666667   0.099280   0.041803   \n",
              "1996-12-05          18           3  0.681818   0.002163   0.000350   \n",
              "1996-12-03           0           0  0.000000   0.000181   0.000077   \n",
              "1996-11-25           0           0  0.000000   0.000161   0.000130   \n",
              "\n",
              "            fomc_neutral        SP500         RSL        DJIA         NDQ  \n",
              "date                                                                       \n",
              "1996-12-19      0.999606  5177.450195  620.729980  585.940002  316.809998  \n",
              "1996-12-06      0.858917  5194.069824  621.320007  572.289978  315.209991  \n",
              "1996-12-05      0.997486  5173.839844  617.700012  563.479980  310.769989  \n",
              "1996-12-03      0.999741  5181.430176  616.710022  565.140015  312.190002  \n",
              "1996-11-25      0.999709  5197.700195  618.460022  563.150024  312.390015  \n",
              "\n",
              "[5 rows x 58 columns]"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "combined_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DbQ1KjG9YnbP"
      },
      "outputs": [],
      "source": [
        "combined_df['log_DJAI'] = np.log2(combined_df['DJIA'])\n",
        "combined_df['log_SP500'] = np.log2(combined_df['SP500'])\n",
        "combined_df['log_RSL'] = np.log2(combined_df['RSL'])\n",
        "combined_df['log_NDQ'] = np.log2(combined_df['NDQ'])\n",
        "\n",
        "combined_df['pct_DJAI'] = combined_df['log_DJAI'].pct_change()\n",
        "combined_df['pct_SP500'] = combined_df['log_SP500'].pct_change()\n",
        "combined_df['pct_RSL'] = combined_df['log_RSL'].pct_change()\n",
        "combined_df['pct_NDQ'] = combined_df['log_NDQ'].pct_change()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        },
        "id": "SdacsM2vaGTq",
        "outputId": "415fa8c1-2e3b-4a2f-b51c-db5b945f94d1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "combined_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-29bbdbca-7240-4519-9e63-7dffb0ed6845\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>speaker</th>\n",
              "      <th>text</th>\n",
              "      <th>finbert_label</th>\n",
              "      <th>finbert_score</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>Positive</th>\n",
              "      <th>Negative</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Subjectivity</th>\n",
              "      <th>n_tokens</th>\n",
              "      <th>...</th>\n",
              "      <th>DJIA</th>\n",
              "      <th>NDQ</th>\n",
              "      <th>log_DJAI</th>\n",
              "      <th>log_SP500</th>\n",
              "      <th>log_RSL</th>\n",
              "      <th>log_NDQ</th>\n",
              "      <th>pct_DJAI</th>\n",
              "      <th>pct_SP500</th>\n",
              "      <th>pct_RSL</th>\n",
              "      <th>pct_NDQ</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1996-12-19</th>\n",
              "      <td>Vice Chair Alice M. Rivlin</td>\n",
              "      <td>I discovered when I joined the Board of Govern...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.896602</td>\n",
              "      <td>I discovered when I joined the Board of Govern...</td>\n",
              "      <td>50</td>\n",
              "      <td>88</td>\n",
              "      <td>-0.275362</td>\n",
              "      <td>0.081802</td>\n",
              "      <td>1687</td>\n",
              "      <td>...</td>\n",
              "      <td>585.940002</td>\n",
              "      <td>316.809998</td>\n",
              "      <td>9.194609</td>\n",
              "      <td>12.338026</td>\n",
              "      <td>9.277822</td>\n",
              "      <td>8.307474</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996-12-06</th>\n",
              "      <td>Chairman Alan Greenspan</td>\n",
              "      <td>I am privileged to accept the Union League of...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.646885</td>\n",
              "      <td>I am privileged to accept the Union League of ...</td>\n",
              "      <td>59</td>\n",
              "      <td>70</td>\n",
              "      <td>-0.085271</td>\n",
              "      <td>0.102707</td>\n",
              "      <td>1256</td>\n",
              "      <td>...</td>\n",
              "      <td>572.289978</td>\n",
              "      <td>315.209991</td>\n",
              "      <td>9.160603</td>\n",
              "      <td>12.342650</td>\n",
              "      <td>9.279193</td>\n",
              "      <td>8.300169</td>\n",
              "      <td>-0.003699</td>\n",
              "      <td>0.000375</td>\n",
              "      <td>0.000148</td>\n",
              "      <td>-0.000879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996-12-05</th>\n",
              "      <td>Chairman Alan Greenspan</td>\n",
              "      <td>The Challenge of Central Banking in a Democrat...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.887193</td>\n",
              "      <td>The Challenge of Central Banking in a Democrat...</td>\n",
              "      <td>62</td>\n",
              "      <td>137</td>\n",
              "      <td>-0.376884</td>\n",
              "      <td>0.107684</td>\n",
              "      <td>1848</td>\n",
              "      <td>...</td>\n",
              "      <td>563.479980</td>\n",
              "      <td>310.769989</td>\n",
              "      <td>9.138221</td>\n",
              "      <td>12.337020</td>\n",
              "      <td>9.270763</td>\n",
              "      <td>8.279703</td>\n",
              "      <td>-0.002443</td>\n",
              "      <td>-0.000456</td>\n",
              "      <td>-0.000909</td>\n",
              "      <td>-0.002466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996-12-03</th>\n",
              "      <td>Governor Edward W. Kelley, Jr.</td>\n",
              "      <td>It is a pleasure to be with you this morning ...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.765716</td>\n",
              "      <td>It is a pleasure to be with you this morning t...</td>\n",
              "      <td>36</td>\n",
              "      <td>59</td>\n",
              "      <td>-0.242105</td>\n",
              "      <td>0.076305</td>\n",
              "      <td>1245</td>\n",
              "      <td>...</td>\n",
              "      <td>565.140015</td>\n",
              "      <td>312.190002</td>\n",
              "      <td>9.142465</td>\n",
              "      <td>12.339135</td>\n",
              "      <td>9.268448</td>\n",
              "      <td>8.286281</td>\n",
              "      <td>0.000464</td>\n",
              "      <td>0.000171</td>\n",
              "      <td>-0.000250</td>\n",
              "      <td>0.000794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996-11-25</th>\n",
              "      <td>Governor Susan M. Phillips</td>\n",
              "      <td>Supervisory and Regulatory Responses to Financ...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.808607</td>\n",
              "      <td>Supervisory and Regulatory Responses to Financ...</td>\n",
              "      <td>52</td>\n",
              "      <td>32</td>\n",
              "      <td>0.238095</td>\n",
              "      <td>0.076853</td>\n",
              "      <td>1093</td>\n",
              "      <td>...</td>\n",
              "      <td>563.150024</td>\n",
              "      <td>312.390015</td>\n",
              "      <td>9.137376</td>\n",
              "      <td>12.343658</td>\n",
              "      <td>9.272537</td>\n",
              "      <td>8.287205</td>\n",
              "      <td>-0.000557</td>\n",
              "      <td>0.000367</td>\n",
              "      <td>0.000441</td>\n",
              "      <td>0.000112</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 25 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-29bbdbca-7240-4519-9e63-7dffb0ed6845')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-29bbdbca-7240-4519-9e63-7dffb0ed6845 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-29bbdbca-7240-4519-9e63-7dffb0ed6845');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-814fe80a-afe5-420a-b6c7-d38028a88690\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-814fe80a-afe5-420a-b6c7-d38028a88690')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-814fe80a-afe5-420a-b6c7-d38028a88690 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                   speaker  \\\n",
              "date                                         \n",
              "1996-12-19      Vice Chair Alice M. Rivlin   \n",
              "1996-12-06         Chairman Alan Greenspan   \n",
              "1996-12-05         Chairman Alan Greenspan   \n",
              "1996-12-03  Governor Edward W. Kelley, Jr.   \n",
              "1996-11-25      Governor Susan M. Phillips   \n",
              "\n",
              "                                                         text finbert_label  \\\n",
              "date                                                                          \n",
              "1996-12-19  I discovered when I joined the Board of Govern...       neutral   \n",
              "1996-12-06   I am privileged to accept the Union League of...       neutral   \n",
              "1996-12-05  The Challenge of Central Banking in a Democrat...       neutral   \n",
              "1996-12-03   It is a pleasure to be with you this morning ...       neutral   \n",
              "1996-11-25  Supervisory and Regulatory Responses to Financ...       neutral   \n",
              "\n",
              "            finbert_score                                         text_clean  \\\n",
              "date                                                                           \n",
              "1996-12-19       0.896602  I discovered when I joined the Board of Govern...   \n",
              "1996-12-06       0.646885  I am privileged to accept the Union League of ...   \n",
              "1996-12-05       0.887193  The Challenge of Central Banking in a Democrat...   \n",
              "1996-12-03       0.765716  It is a pleasure to be with you this morning t...   \n",
              "1996-11-25       0.808607  Supervisory and Regulatory Responses to Financ...   \n",
              "\n",
              "            Positive  Negative  Polarity  Subjectivity  n_tokens  ...  \\\n",
              "date                                                              ...   \n",
              "1996-12-19        50        88 -0.275362      0.081802      1687  ...   \n",
              "1996-12-06        59        70 -0.085271      0.102707      1256  ...   \n",
              "1996-12-05        62       137 -0.376884      0.107684      1848  ...   \n",
              "1996-12-03        36        59 -0.242105      0.076305      1245  ...   \n",
              "1996-11-25        52        32  0.238095      0.076853      1093  ...   \n",
              "\n",
              "                  DJIA         NDQ  log_DJAI  log_SP500   log_RSL   log_NDQ  \\\n",
              "date                                                                          \n",
              "1996-12-19  585.940002  316.809998  9.194609  12.338026  9.277822  8.307474   \n",
              "1996-12-06  572.289978  315.209991  9.160603  12.342650  9.279193  8.300169   \n",
              "1996-12-05  563.479980  310.769989  9.138221  12.337020  9.270763  8.279703   \n",
              "1996-12-03  565.140015  312.190002  9.142465  12.339135  9.268448  8.286281   \n",
              "1996-11-25  563.150024  312.390015  9.137376  12.343658  9.272537  8.287205   \n",
              "\n",
              "            pct_DJAI  pct_SP500   pct_RSL   pct_NDQ  \n",
              "date                                                 \n",
              "1996-12-19       NaN        NaN       NaN       NaN  \n",
              "1996-12-06 -0.003699   0.000375  0.000148 -0.000879  \n",
              "1996-12-05 -0.002443  -0.000456 -0.000909 -0.002466  \n",
              "1996-12-03  0.000464   0.000171 -0.000250  0.000794  \n",
              "1996-11-25 -0.000557   0.000367  0.000441  0.000112  \n",
              "\n",
              "[5 rows x 25 columns]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "combined_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kpvQq6aVECoB"
      },
      "outputs": [],
      "source": [
        "combined_df.to_csv(\"preprocessed.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "56f7buH5b_lt"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'combined_df' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m combined_no_text = \u001b[43mcombined_df\u001b[49m.drop([\u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mtext_clean\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mtext_clean_nostop\u001b[39m\u001b[33m'\u001b[39m], axis=\u001b[32m1\u001b[39m)\n",
            "\u001b[31mNameError\u001b[39m: name 'combined_df' is not defined"
          ]
        }
      ],
      "source": [
        "combined_no_text = combined_df.drop(['text', 'text_clean', 'text_clean_nostop'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "kknI_y2ccMJo",
        "outputId": "89481ee6-42d7-42e3-d7cb-da7082d6d2de"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "combined_no_text"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-57010d03-354d-441d-aa4f-4e7e13aec1b6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>speaker</th>\n",
              "      <th>finbert_label</th>\n",
              "      <th>finbert_score</th>\n",
              "      <th>Positive</th>\n",
              "      <th>Negative</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Subjectivity</th>\n",
              "      <th>n_tokens</th>\n",
              "      <th>LM_pos_rate</th>\n",
              "      <th>LM_neg_rate</th>\n",
              "      <th>...</th>\n",
              "      <th>DJIA</th>\n",
              "      <th>NDQ</th>\n",
              "      <th>log_DJAI</th>\n",
              "      <th>log_SP500</th>\n",
              "      <th>log_RSL</th>\n",
              "      <th>log_NDQ</th>\n",
              "      <th>pct_DJAI</th>\n",
              "      <th>pct_SP500</th>\n",
              "      <th>pct_RSL</th>\n",
              "      <th>pct_NDQ</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1996-12-19</th>\n",
              "      <td>Vice Chair Alice M. Rivlin</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.896602</td>\n",
              "      <td>50</td>\n",
              "      <td>88</td>\n",
              "      <td>-0.275362</td>\n",
              "      <td>0.081802</td>\n",
              "      <td>1687</td>\n",
              "      <td>0.029638</td>\n",
              "      <td>0.052164</td>\n",
              "      <td>...</td>\n",
              "      <td>585.940002</td>\n",
              "      <td>316.809998</td>\n",
              "      <td>9.194609</td>\n",
              "      <td>12.338026</td>\n",
              "      <td>9.277822</td>\n",
              "      <td>8.307474</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996-12-06</th>\n",
              "      <td>Chairman Alan Greenspan</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.646885</td>\n",
              "      <td>59</td>\n",
              "      <td>70</td>\n",
              "      <td>-0.085271</td>\n",
              "      <td>0.102707</td>\n",
              "      <td>1256</td>\n",
              "      <td>0.046975</td>\n",
              "      <td>0.055732</td>\n",
              "      <td>...</td>\n",
              "      <td>572.289978</td>\n",
              "      <td>315.209991</td>\n",
              "      <td>9.160603</td>\n",
              "      <td>12.342650</td>\n",
              "      <td>9.279193</td>\n",
              "      <td>8.300169</td>\n",
              "      <td>-0.003699</td>\n",
              "      <td>0.000375</td>\n",
              "      <td>0.000148</td>\n",
              "      <td>-0.000879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996-12-05</th>\n",
              "      <td>Chairman Alan Greenspan</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.887193</td>\n",
              "      <td>62</td>\n",
              "      <td>137</td>\n",
              "      <td>-0.376884</td>\n",
              "      <td>0.107684</td>\n",
              "      <td>1848</td>\n",
              "      <td>0.033550</td>\n",
              "      <td>0.074134</td>\n",
              "      <td>...</td>\n",
              "      <td>563.479980</td>\n",
              "      <td>310.769989</td>\n",
              "      <td>9.138221</td>\n",
              "      <td>12.337020</td>\n",
              "      <td>9.270763</td>\n",
              "      <td>8.279703</td>\n",
              "      <td>-0.002443</td>\n",
              "      <td>-0.000456</td>\n",
              "      <td>-0.000909</td>\n",
              "      <td>-0.002466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996-12-03</th>\n",
              "      <td>Governor Edward W. Kelley, Jr.</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.765716</td>\n",
              "      <td>36</td>\n",
              "      <td>59</td>\n",
              "      <td>-0.242105</td>\n",
              "      <td>0.076305</td>\n",
              "      <td>1245</td>\n",
              "      <td>0.028916</td>\n",
              "      <td>0.047390</td>\n",
              "      <td>...</td>\n",
              "      <td>565.140015</td>\n",
              "      <td>312.190002</td>\n",
              "      <td>9.142465</td>\n",
              "      <td>12.339135</td>\n",
              "      <td>9.268448</td>\n",
              "      <td>8.286281</td>\n",
              "      <td>0.000464</td>\n",
              "      <td>0.000171</td>\n",
              "      <td>-0.000250</td>\n",
              "      <td>0.000794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996-11-25</th>\n",
              "      <td>Governor Susan M. Phillips</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.808607</td>\n",
              "      <td>52</td>\n",
              "      <td>32</td>\n",
              "      <td>0.238095</td>\n",
              "      <td>0.076853</td>\n",
              "      <td>1093</td>\n",
              "      <td>0.047575</td>\n",
              "      <td>0.029277</td>\n",
              "      <td>...</td>\n",
              "      <td>563.150024</td>\n",
              "      <td>312.390015</td>\n",
              "      <td>9.137376</td>\n",
              "      <td>12.343658</td>\n",
              "      <td>9.272537</td>\n",
              "      <td>8.287205</td>\n",
              "      <td>-0.000557</td>\n",
              "      <td>0.000367</td>\n",
              "      <td>0.000441</td>\n",
              "      <td>0.000112</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 63 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-57010d03-354d-441d-aa4f-4e7e13aec1b6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-57010d03-354d-441d-aa4f-4e7e13aec1b6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-57010d03-354d-441d-aa4f-4e7e13aec1b6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4670e0be-d4b7-4fdc-8649-bbc3dcca3cea\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4670e0be-d4b7-4fdc-8649-bbc3dcca3cea')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4670e0be-d4b7-4fdc-8649-bbc3dcca3cea button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                   speaker finbert_label  finbert_score  \\\n",
              "date                                                                      \n",
              "1996-12-19      Vice Chair Alice M. Rivlin       neutral       0.896602   \n",
              "1996-12-06         Chairman Alan Greenspan       neutral       0.646885   \n",
              "1996-12-05         Chairman Alan Greenspan       neutral       0.887193   \n",
              "1996-12-03  Governor Edward W. Kelley, Jr.       neutral       0.765716   \n",
              "1996-11-25      Governor Susan M. Phillips       neutral       0.808607   \n",
              "\n",
              "            Positive  Negative  Polarity  Subjectivity  n_tokens  LM_pos_rate  \\\n",
              "date                                                                            \n",
              "1996-12-19        50        88 -0.275362      0.081802      1687     0.029638   \n",
              "1996-12-06        59        70 -0.085271      0.102707      1256     0.046975   \n",
              "1996-12-05        62       137 -0.376884      0.107684      1848     0.033550   \n",
              "1996-12-03        36        59 -0.242105      0.076305      1245     0.028916   \n",
              "1996-11-25        52        32  0.238095      0.076853      1093     0.047575   \n",
              "\n",
              "            LM_neg_rate  ...        DJIA         NDQ  log_DJAI  log_SP500  \\\n",
              "date                     ...                                                \n",
              "1996-12-19     0.052164  ...  585.940002  316.809998  9.194609  12.338026   \n",
              "1996-12-06     0.055732  ...  572.289978  315.209991  9.160603  12.342650   \n",
              "1996-12-05     0.074134  ...  563.479980  310.769989  9.138221  12.337020   \n",
              "1996-12-03     0.047390  ...  565.140015  312.190002  9.142465  12.339135   \n",
              "1996-11-25     0.029277  ...  563.150024  312.390015  9.137376  12.343658   \n",
              "\n",
              "             log_RSL   log_NDQ  pct_DJAI  pct_SP500   pct_RSL   pct_NDQ  \n",
              "date                                                                     \n",
              "1996-12-19  9.277822  8.307474       NaN        NaN       NaN       NaN  \n",
              "1996-12-06  9.279193  8.300169 -0.003699   0.000375  0.000148 -0.000879  \n",
              "1996-12-05  9.270763  8.279703 -0.002443  -0.000456 -0.000909 -0.002466  \n",
              "1996-12-03  9.268448  8.286281  0.000464   0.000171 -0.000250  0.000794  \n",
              "1996-11-25  9.272537  8.287205 -0.000557   0.000367  0.000441  0.000112  \n",
              "\n",
              "[5 rows x 63 columns]"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "combined_no_text.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yW1RvLmbcQvC"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'combined_no_text' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mcombined_no_text\u001b[49m.to_csv(\u001b[33m\"\u001b[39m\u001b[33mpreprocessed_small.csv\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mNameError\u001b[39m: name 'combined_no_text' is not defined"
          ]
        }
      ],
      "source": [
        "combined_no_text.to_csv(\"preprocessed_small.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save final preprocessed dataset (this is what models will use)\n",
        "combined_no_text.to_csv(\"preprocessed_final.csv\", index=True)\n",
        "print(f\"\\n✅ Saved: preprocessed_final.csv\")\n",
        "print(f\"   Shape: {combined_no_text.shape}\")\n",
        "print(f\"   Columns: {list(combined_no_text.columns)}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "26b436cd08284521a3c31eafb215d158": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d5967ac7a00406494d57ca62ffb67df",
            "placeholder": "​",
            "style": "IPY_MODEL_9e9020cb14974fd5b63e594f856a2999",
            "value": "Connecting..."
          }
        },
        "29e3482c14ab4e19b56bd5b9cfb259af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_6f34015c4607433bb9a0a21f894ebf97",
            "style": "IPY_MODEL_ef8618d2826843e59d8f0686908e50fe",
            "value": true
          }
        },
        "3106e0496640435eb913736709e7012b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33fdeca261c248b88d1970ddc745d11a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "PasswordModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_fdea2fd1fde646f1a4e1a6457aaff3ce",
            "placeholder": "​",
            "style": "IPY_MODEL_3106e0496640435eb913736709e7012b",
            "value": ""
          }
        },
        "35fbc6909c4347c383891729adc7f2ae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38772dbc561d461cb61e08a48a9b2c24": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b16847b0e7745f99f9ed0138382ed91": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "5d5967ac7a00406494d57ca62ffb67df": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f34015c4607433bb9a0a21f894ebf97": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a93ceaf45f0496e9ce8b3dd95cbf30c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d2aaef95e2a4cf18b193a507bcf4fea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_38772dbc561d461cb61e08a48a9b2c24",
            "style": "IPY_MODEL_a2f7cbe5e1e94ca6a10b86b640eb48d4",
            "tooltip": ""
          }
        },
        "9e9020cb14974fd5b63e594f856a2999": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2f7cbe5e1e94ca6a10b86b640eb48d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "b3213eb28cf04eeca9420e2f7c545ba0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_4b16847b0e7745f99f9ed0138382ed91"
          }
        },
        "c0f744b629fb4f309d3672bf8aca12ff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7fb4df754f34590b7a6bed9af174a03": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0f744b629fb4f309d3672bf8aca12ff",
            "placeholder": "​",
            "style": "IPY_MODEL_e66e5fd3658b4b2abbe0262d35bc4d30",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "e66e5fd3658b4b2abbe0262d35bc4d30": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed582dea1de04746a8c9532899145f50": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35fbc6909c4347c383891729adc7f2ae",
            "placeholder": "​",
            "style": "IPY_MODEL_9a93ceaf45f0496e9ce8b3dd95cbf30c",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "ef8618d2826843e59d8f0686908e50fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fdea2fd1fde646f1a4e1a6457aaff3ce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
